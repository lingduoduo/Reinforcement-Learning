{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://artifactory.spotify.net/artifactory/api/pypi/pypi/simple/\n",
      "Requirement already up-to-date: tensorflow-probability in /Users/lingh/.pyenv/versions/3.7.0/envs/my-virtual-env-3.7.0/lib/python3.7/site-packages (0.9.0)\n",
      "Requirement already satisfied, skipping upgrade: decorator in /Users/lingh/.pyenv/versions/3.7.0/envs/my-virtual-env-3.7.0/lib/python3.7/site-packages (from tensorflow-probability) (4.4.1)\n",
      "Requirement already satisfied, skipping upgrade: cloudpickle>=1.2.2 in /Users/lingh/.pyenv/versions/3.7.0/envs/my-virtual-env-3.7.0/lib/python3.7/site-packages (from tensorflow-probability) (1.2.2)\n",
      "Requirement already satisfied, skipping upgrade: gast>=0.2 in /Users/lingh/.pyenv/versions/3.7.0/envs/my-virtual-env-3.7.0/lib/python3.7/site-packages (from tensorflow-probability) (0.3.3)\n",
      "Requirement already satisfied, skipping upgrade: numpy>=1.13.3 in /Users/lingh/.pyenv/versions/3.7.0/envs/my-virtual-env-3.7.0/lib/python3.7/site-packages (from tensorflow-probability) (1.18.1)\n",
      "Requirement already satisfied, skipping upgrade: six>=1.10.0 in /Users/lingh/.pyenv/versions/3.7.0/envs/my-virtual-env-3.7.0/lib/python3.7/site-packages (from tensorflow-probability) (1.14.0)\n",
      "Looking in indexes: https://pypi.org/simple, https://artifactory.spotify.net/artifactory/api/pypi/pypi/simple/\n",
      "Requirement already satisfied: tf-agents in /Users/lingh/.pyenv/versions/3.7.0/envs/my-virtual-env-3.7.0/lib/python3.7/site-packages (0.3.0)\n",
      "Requirement already satisfied: numpy>=1.13.3 in /Users/lingh/.pyenv/versions/3.7.0/envs/my-virtual-env-3.7.0/lib/python3.7/site-packages (from tf-agents) (1.18.1)\n",
      "Requirement already satisfied: six>=1.10.0 in /Users/lingh/.pyenv/versions/3.7.0/envs/my-virtual-env-3.7.0/lib/python3.7/site-packages (from tf-agents) (1.14.0)\n",
      "Requirement already satisfied: absl-py>=0.6.1 in /Users/lingh/.pyenv/versions/3.7.0/envs/my-virtual-env-3.7.0/lib/python3.7/site-packages (from tf-agents) (0.9.0)\n",
      "Requirement already satisfied: gin-config==0.1.3 in /Users/lingh/.pyenv/versions/3.7.0/envs/my-virtual-env-3.7.0/lib/python3.7/site-packages (from tf-agents) (0.1.3)\n",
      "Requirement already satisfied: tensorflow-probability>=0.6.0 in /Users/lingh/.pyenv/versions/3.7.0/envs/my-virtual-env-3.7.0/lib/python3.7/site-packages (from tf-agents) (0.9.0)\n",
      "Requirement already satisfied: gast>=0.2 in /Users/lingh/.pyenv/versions/3.7.0/envs/my-virtual-env-3.7.0/lib/python3.7/site-packages (from tensorflow-probability>=0.6.0->tf-agents) (0.3.3)\n",
      "Requirement already satisfied: cloudpickle>=1.2.2 in /Users/lingh/.pyenv/versions/3.7.0/envs/my-virtual-env-3.7.0/lib/python3.7/site-packages (from tensorflow-probability>=0.6.0->tf-agents) (1.2.2)\n",
      "Requirement already satisfied: decorator in /Users/lingh/.pyenv/versions/3.7.0/envs/my-virtual-env-3.7.0/lib/python3.7/site-packages (from tensorflow-probability>=0.6.0->tf-agents) (4.4.1)\n",
      "Looking in indexes: https://pypi.org/simple, https://artifactory.spotify.net/artifactory/api/pypi/pypi/simple/\n",
      "Requirement already satisfied: gym in /Users/lingh/.pyenv/versions/3.7.0/envs/my-virtual-env-3.7.0/lib/python3.7/site-packages (0.10.11)\n",
      "Requirement already satisfied: numpy>=1.10.4 in /Users/lingh/.pyenv/versions/3.7.0/envs/my-virtual-env-3.7.0/lib/python3.7/site-packages (from gym) (1.18.1)\n",
      "Requirement already satisfied: scipy in /Users/lingh/.pyenv/versions/3.7.0/envs/my-virtual-env-3.7.0/lib/python3.7/site-packages (from gym) (1.4.1)\n",
      "Requirement already satisfied: six in /Users/lingh/.pyenv/versions/3.7.0/envs/my-virtual-env-3.7.0/lib/python3.7/site-packages (from gym) (1.14.0)\n",
      "Requirement already satisfied: requests>=2.0 in /Users/lingh/.pyenv/versions/3.7.0/envs/my-virtual-env-3.7.0/lib/python3.7/site-packages (from gym) (2.22.0)\n",
      "Requirement already satisfied: pyglet>=1.2.0 in /Users/lingh/.pyenv/versions/3.7.0/envs/my-virtual-env-3.7.0/lib/python3.7/site-packages (from gym) (1.3.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/lingh/.pyenv/versions/3.7.0/envs/my-virtual-env-3.7.0/lib/python3.7/site-packages (from requests>=2.0->gym) (2019.11.28)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /Users/lingh/.pyenv/versions/3.7.0/envs/my-virtual-env-3.7.0/lib/python3.7/site-packages (from requests>=2.0->gym) (2.8)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /Users/lingh/.pyenv/versions/3.7.0/envs/my-virtual-env-3.7.0/lib/python3.7/site-packages (from requests>=2.0->gym) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /Users/lingh/.pyenv/versions/3.7.0/envs/my-virtual-env-3.7.0/lib/python3.7/site-packages (from requests>=2.0->gym) (1.25.8)\n",
      "Requirement already satisfied: future in /Users/lingh/.pyenv/versions/3.7.0/envs/my-virtual-env-3.7.0/lib/python3.7/site-packages (from pyglet>=1.2.0->gym) (0.17.1)\n"
     ]
    }
   ],
   "source": [
    "# If you haven't installed tf-agents or gym yet, run:\n",
    "try:\n",
    "    %tensorflow_version 2.x\n",
    "except:\n",
    "    pass\n",
    "!pip install --upgrade tensorflow-probability\n",
    "!pip install tf-agents\n",
    "!pip install gym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "from tf_agents import specs\n",
    "from tf_agents.agents.dqn import dqn_agent\n",
    "from tf_agents.drivers import dynamic_step_driver\n",
    "from tf_agents.environments import suite_gym\n",
    "from tf_agents.environments import tf_py_environment\n",
    "from tf_agents.networks import q_network\n",
    "from tf_agents.replay_buffers import py_uniform_replay_buffer\n",
    "from tf_agents.replay_buffers import tf_uniform_replay_buffer\n",
    "from tf_agents.specs import tensor_spec\n",
    "from tf_agents.trajectories import time_step\n",
    "\n",
    "tf.compat.v1.enable_v2_behavior()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Replay Buffer API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReplayBuffer(tf.Module):\n",
    "  \"\"\"Abstract base class for TF-Agents replay buffer.\"\"\"\n",
    "\n",
    "  def __init__(self, data_spec, capacity):\n",
    "    \"\"\"Initializes the replay buffer.\n",
    "\n",
    "    Args:\n",
    "      data_spec: A spec or a list/tuple/nest of specs describing\n",
    "        a single item that can be stored in this buffer\n",
    "      capacity: number of elements that the replay buffer can hold.\n",
    "    \"\"\"\n",
    "\n",
    "    @property\n",
    "    def data_spec(self):\n",
    "        pass\n",
    "\n",
    "    @property\n",
    "    def capacity(self):\n",
    "        pass\n",
    "\n",
    "    def add_batch(self, items):\n",
    "        pass\n",
    "\n",
    "    def get_next(self,\n",
    "               sample_batch_size=None,\n",
    "               num_steps=None,\n",
    "               time_stacked=True):\n",
    "        pass\n",
    "\n",
    "    def as_dataset(self,\n",
    "                 sample_batch_size=None,\n",
    "                 num_steps=None,\n",
    "                 num_parallel_calls=None):\n",
    "        pass\n",
    "\n",
    "    def gather_all(self):\n",
    "        return self._gather_all()\n",
    "\n",
    "    def clear(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TFUniformReplayBuffer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating the buffer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To create a TFUniformReplayBuffer we pass in:\n",
    "\n",
    "- the spec of the data elements that the buffer will store\n",
    "- the batch size corresponding to the batch size of the buffer\n",
    "- the max_length number of elements per batch segment\n",
    "\n",
    "Here is an example of creating a TFUniformReplayBuffer with sample data specs, batch_size 32 and max_length 1000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_spec =  (\n",
    "        tf.TensorSpec([3], tf.float32, 'action'),\n",
    "        (\n",
    "            tf.TensorSpec([5], tf.float32, 'lidar'),\n",
    "            tf.TensorSpec([3, 2], tf.float32, 'camera')\n",
    "        )\n",
    ")\n",
    "\n",
    "batch_size = 32\n",
    "max_length = 1000\n",
    "\n",
    "replay_buffer = tf_uniform_replay_buffer.TFUniformReplayBuffer(\n",
    "    data_spec,\n",
    "    batch_size=batch_size,\n",
    "    max_length=max_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Writing to the buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "action = tf.constant(1 * np.ones(data_spec[0].shape.as_list(), dtype=np.float32))\n",
    "lidar = tf.constant(2 * np.ones(data_spec[1][0].shape.as_list(), dtype=np.float32))\n",
    "camera = tf.constant(3 * np.ones(data_spec[1][1].shape.as_list(), dtype=np.float32))\n",
    "  \n",
    "values = (action, (lidar, camera))\n",
    "values_batched = tf.nest.map_structure(lambda t: tf.stack([t] * batch_size),values)\n",
    "  \n",
    "replay_buffer.add_batch(values_batched)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reading from the buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterator trajectories:\n",
      "[(TensorShape([4, 2, 3]), (TensorShape([4, 2, 5]), TensorShape([4, 2, 3, 2]))), (TensorShape([4, 2, 3]), (TensorShape([4, 2, 5]), TensorShape([4, 2, 3, 2]))), (TensorShape([4, 2, 3]), (TensorShape([4, 2, 5]), TensorShape([4, 2, 3, 2])))]\n",
      "Trajectories from gather all:\n",
      "(TensorShape([32, 8, 3]), (TensorShape([32, 8, 5]), TensorShape([32, 8, 3, 2])))\n"
     ]
    }
   ],
   "source": [
    "# add more items to the buffer before reading\n",
    "for _ in range(5):\n",
    "    replay_buffer.add_batch(values_batched)\n",
    "\n",
    "# Get one sample from the replay buffer with batch size 10 and 1 timestep:\n",
    "\n",
    "sample = replay_buffer.get_next(sample_batch_size=10, num_steps=1)\n",
    "\n",
    "# Convert the replay buffer to a tf.data.Dataset and iterate through it\n",
    "dataset = replay_buffer.as_dataset(\n",
    "    sample_batch_size=4,\n",
    "    num_steps=2)\n",
    "\n",
    "iterator = iter(dataset)\n",
    "print(\"Iterator trajectories:\")\n",
    "trajectories = []\n",
    "for _ in range(3):\n",
    "    t, _ = next(iterator)\n",
    "    trajectories.append(t)\n",
    "\n",
    "print(tf.nest.map_structure(lambda t: t.shape, trajectories))\n",
    "\n",
    "# Read all elements in the replay buffer:\n",
    "trajectories = replay_buffer.gather_all()\n",
    "\n",
    "print(\"Trajectories from gather all:\")\n",
    "print(tf.nest.map_structure(lambda t: t.shape, trajectories))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PyUniformReplayBuffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "replay_buffer_capacity = 1000*32 # same capacity as the TFUniformReplayBuffer\n",
    "\n",
    "py_replay_buffer = py_uniform_replay_buffer.PyUniformReplayBuffer(\n",
    "    capacity=replay_buffer_capacity,\n",
    "    data_spec=tensor_spec.to_nest_array_spec(data_spec))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using replay buffers during training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/lingh/.pyenv/versions/3.7.0/envs/my-virtual-env-3.7.0/lib/python3.7/site-packages/tf_agents/drivers/dynamic_step_driver.py:201: calling while_loop_v2 (from tensorflow.python.ops.control_flow_ops) with back_prop=False is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "back_prop=False is deprecated. Consider using tf.stop_gradient instead.\n",
      "Instead of:\n",
      "results = tf.while_loop(c, b, vars, back_prop=False)\n",
      "Use:\n",
      "results = tf.nest.map_structure(tf.stop_gradient, tf.while_loop(c, b, vars))\n"
     ]
    }
   ],
   "source": [
    "env = suite_gym.load('CartPole-v0')\n",
    "tf_env = tf_py_environment.TFPyEnvironment(env)\n",
    "\n",
    "q_net = q_network.QNetwork(tf_env.time_step_spec().observation,tf_env.action_spec(),fc_layer_params=(100,))\n",
    "\n",
    "agent = dqn_agent.DqnAgent(tf_env.time_step_spec(),tf_env.action_spec(),q_network=q_net,optimizer=tf.compat.v1.train.AdamOptimizer(0.001))\n",
    "\n",
    "replay_buffer_capacity = 1000\n",
    "\n",
    "replay_buffer = tf_uniform_replay_buffer.TFUniformReplayBuffer(agent.collect_data_spec,batch_size=tf_env.batch_size,max_length=replay_buffer_capacity)\n",
    "\n",
    "# Add an observer that adds to the replay buffer:\n",
    "replay_observer = [replay_buffer.add_batch]\n",
    "\n",
    "collect_steps_per_iteration = 10\n",
    "collect_op = dynamic_step_driver.DynamicStepDriver(tf_env,agent.collect_policy,observers=replay_observer,num_steps=collect_steps_per_iteration).run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reading data for a train step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the replay buffer as a Dataset,\n",
    "# read batches of 4 elements, each with 2 timesteps:\n",
    "dataset = replay_buffer.as_dataset(\n",
    "    sample_batch_size=4,\n",
    "    num_steps=2)\n",
    "\n",
    "iterator = iter(dataset)\n",
    "\n",
    "num_train_steps = 10\n",
    "\n",
    "for _ in range(num_train_steps):\n",
    "    trajectories, _ = next(iterator)\n",
    "    loss = agent.train(experience=trajectories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
