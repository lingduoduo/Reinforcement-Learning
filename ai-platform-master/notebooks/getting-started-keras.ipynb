{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "cellView": "both",
    "colab": {},
    "colab_type": "code",
    "id": "qnMpW5Y9nv2l"
   },
   "outputs": [],
   "source": [
    "# Copyright 2019 Google LLC\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mHF9VCProKJN"
   },
   "source": [
    "# Getting started: Training and prediction with Keras in AI Platform\n",
    "\n",
    "<img src=\"https://storage.googleapis.com/cloud-samples-data/ml-engine/census/keras-tensorflow-cmle.png\" alt=\"Keras, TensorFlow, and AI Platform logos\" width=\"300px\">\n",
    "\n",
    "<table align=\"left\">\n",
    "  <td>\n",
    "    <a href=\"https://cloud.google.com/ml-engine/docs/tensorflow/getting-started-keras\">\n",
    "      <img src=\"https://cloud.google.com/_static/images/cloud/icons/favicons/onecloud/super_cloud.png\"\n",
    "           alt=\"Google Cloud logo\" width=\"32px\"> Read on cloud.google.com\n",
    "    </a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a href=\"https://colab.research.google.com/github/GoogleCloudPlatform/cloudml-samples/blob/master/notebooks/tensorflow/getting-started-keras.ipynb\">\n",
    "      <img src=\"https://cloud.google.com/ml-engine/images/colab-logo-32px.png\" alt=\"Colab logo\"> Run in Colab\n",
    "    </a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a href=\"https://github.com/GoogleCloudPlatform/cloudml-samples/blob/master/notebooks/tensorflow/getting-started-keras.ipynb\">\n",
    "      <img src=\"https://cloud.google.com/ml-engine/images/github-logo-32px.png\" alt=\"GitHub logo\">\n",
    "      View on GitHub\n",
    "    </a>\n",
    "  </td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hZzRVxNtH-zG"
   },
   "source": [
    "## Overview\n",
    "\n",
    "This tutorial shows how to train a neural network on AI Platform\n",
    "using the Keras sequential API and how to serve predictions from that\n",
    "model.\n",
    "\n",
    "Keras is a high-level API for building and training deep learning models.\n",
    "[tf.keras](https://www.tensorflow.org/guide/keras) is TensorFlowâ€™s\n",
    "implementation of this API.\n",
    "\n",
    "The first two parts of the tutorial walk through training a model on Cloud\n",
    "AI Platform using prewritten Keras code, deploying the trained model to\n",
    "AI Platform, and serving online predictions from the deployed model.\n",
    "\n",
    "The last part of the tutorial digs into the training code used for this model and ensuring it's compatible with AI Platform. To learn more about building\n",
    "machine learning models in Keras more generally, read [TensorFlow's Keras\n",
    "tutorials](https://www.tensorflow.org/tutorials/keras)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iN69d4D9Flrh"
   },
   "source": [
    "### Dataset\n",
    "\n",
    "This tutorial uses the [United States Census Income\n",
    "Dataset](https://archive.ics.uci.edu/ml/datasets/census+income) provided by the\n",
    "[UC Irvine Machine Learning\n",
    "Repository](https://archive.ics.uci.edu/ml/index.php). This dataset contains\n",
    "information about people from a 1994 Census database, including age, education,\n",
    "marital status, occupation, and whether they make more than $50,000 a year."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Su2qu-4CW-YH"
   },
   "source": [
    "### Objective\n",
    "\n",
    "The goal is to train a deep neural network (DNN) using Keras that predicts\n",
    "whether a person makes more than $50,000 a year (target label) based on other\n",
    "Census information about the person (features).\n",
    "\n",
    "This tutorial focuses more on using this model with AI Platform than on\n",
    "the design of the model itself. However, it's always important to think about\n",
    "potential problems and unintended consequences when building machine learning\n",
    "systems. See the [Machine Learning Crash Course exercise about\n",
    "fairness](https://developers.google.com/machine-learning/crash-course/fairness/programming-exercise)\n",
    "to learn about sources of bias in the Census dataset, as well as machine\n",
    "learning fairness more generally."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "912RD_3fxGeH"
   },
   "source": [
    "### Costs\n",
    "\n",
    "This tutorial uses billable components of Google Cloud Platform (GCP):\n",
    "\n",
    "* AI Platform\n",
    "* Cloud Storage\n",
    "\n",
    "Learn about [AI Platform\n",
    "pricing](https://cloud.google.com/ml-engine/docs/pricing) and [Cloud Storage\n",
    "pricing](https://cloud.google.com/storage/pricing), and use the [Pricing\n",
    "Calculator](https://cloud.google.com/products/calculator/)\n",
    "to generate a cost estimate based on your projected usage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rgLXkyHEvTVD"
   },
   "source": [
    "## Before you begin\n",
    "\n",
    "You must do several things before you can train and deploy a model in\n",
    "AI Platform:\n",
    "\n",
    "* Set up your local development environment.\n",
    "* Set up a GCP project with billing and the necessary\n",
    "  APIs enabled.\n",
    "* Authenticate your GCP account in this notebook.\n",
    "* Create a Cloud Storage bucket to store your training package and your\n",
    "  trained model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "avDUUQEGTnUo"
   },
   "source": [
    "### Set up your local development environment\n",
    "\n",
    "**If you are using Colab or AI Platform Notebooks**, your environment already meets\n",
    "all the requirements to run this notebook. You can skip this step."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1y4JdKCcTjgJ"
   },
   "source": [
    "**Otherwise**, make sure your environment meets this notebook's requirements.\n",
    "You need the following:\n",
    "\n",
    "* The Google Cloud SDK\n",
    "* Git\n",
    "* Python 3\n",
    "* virtualenv\n",
    "* Jupyter notebook running in a virtual environment with Python 3\n",
    "\n",
    "The Google Cloud guide to [Setting up a Python development\n",
    "environment](https://cloud.google.com/python/setup) and the [Jupyter\n",
    "installation guide](https://jupyter.org/install) provide detailed instructions\n",
    "for meeting these requirements. The following steps provide a condensed set of\n",
    "instructions:\n",
    "\n",
    "1. [Install and initialize the Cloud SDK.](https://cloud.google.com/sdk/docs/)\n",
    "\n",
    "2. [Install Python 3.](https://cloud.google.com/python/setup#installing_python)\n",
    "\n",
    "3. [Install\n",
    "   virtualenv](https://cloud.google.com/python/setup#installing_and_using_virtualenv)\n",
    "   and create a virtual environment that uses Python 3.\n",
    "\n",
    "4. Activate that environment and run `pip install jupyter` in a shell to install\n",
    "   Jupyter.\n",
    "\n",
    "5. Run `jupyter notebook` in a shell to launch Jupyter.\n",
    "\n",
    "6. Open this notebook in the Jupyter Notebook Dashboard."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "i2qsxysTVc-l"
   },
   "source": [
    "### Set up your GCP project\n",
    "\n",
    "**The following steps are required, regardless of your notebook environment.**\n",
    "\n",
    "1. [Select or create a GCP project.](https://console.cloud.google.com/cloud-resource-manager)\n",
    "\n",
    "2. [Make sure that billing is enabled for your project.](https://cloud.google.com/billing/docs/how-to/modify-project)\n",
    "\n",
    "3. [Enable the AI Platform (\"Cloud Machine Learning Engine\") and Compute Engine APIs.](https://console.cloud.google.com/flows/enableapi?apiid=ml.googleapis.com,compute_component)\n",
    "\n",
    "4. Enter your project ID in the cell below. Then run the  cell to make sure the\n",
    "Cloud SDK uses the right project for all the commands in this notebook.\n",
    "\n",
    "**Note**: Jupyter runs lines prefixed with `!` as shell commands, and it interpolates Python variables prefixed with `$` into these commands."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "cellView": "both",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "4qxwBA4RM9Lu",
    "outputId": "c4895bd5-2878-4883-b059-443022489bc7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated property [core/project].\r\n"
     ]
    }
   ],
   "source": [
    "PROJECT_ID = 'paradox-mo'   #@param {type:\"string\"}\n",
    "! gcloud config set project $PROJECT_ID"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TSy-f05IO4LB"
   },
   "source": [
    "### Authenticate your GCP account\n",
    "\n",
    "**If you are using AI Platform Notebooks**, your environment is already\n",
    "authenticated. Skip this step."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fZQUrHdXNJnk"
   },
   "source": [
    "**If you are using Colab**, run the cell below and follow the instructions\n",
    "when prompted to authenticate your account via oAuth.\n",
    "\n",
    "**Otherwise**, follow these steps:\n",
    "\n",
    "1. In the GCP Console, go to the [**Create service account key**\n",
    "   page](https://console.cloud.google.com/apis/credentials/serviceaccountkey).\n",
    "\n",
    "2. From the **Service account** drop-down list, select **New service account**.\n",
    "\n",
    "3. In the **Service account name** field, enter a name.\n",
    "\n",
    "4. From the **Role** drop-down list, select\n",
    "   **Machine Learning Engine > AI Platform Admin** and\n",
    "   **Storage > Storage Object Admin**.\n",
    "\n",
    "5. Click *Create*. A JSON file that contains your key downloads to your\n",
    "local environment.\n",
    "\n",
    "6. Enter the path to your service account key as the\n",
    "`GOOGLE_APPLICATION_CREDENTIALS` variable in the cell below and run the cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "W9i6oektpgld"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "# If you are running this notebook in Colab, run this cell and follow the\n",
    "# instructions to authenticate your GCP account. This provides access to your\n",
    "# Cloud Storage bucket and lets you submit training jobs and prediction\n",
    "# requests.\n",
    "\n",
    "if 'google.colab' in sys.modules:\n",
    "  from google.colab import auth as google_auth\n",
    "  google_auth.authenticate_user()\n",
    "\n",
    "# If you are running this notebook locally, replace the string below with the\n",
    "# path to your service account key and run this cell to authenticate your GCP\n",
    "# account.\n",
    "else:\n",
    "  %env GOOGLE_APPLICATION_CREDENTIALS ''\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tT061irlJwkg"
   },
   "source": [
    "### Create a Cloud Storage bucket\n",
    "\n",
    "**The following steps are required, regardless of your notebook environment.**\n",
    "\n",
    "When you submit a training job using the Cloud SDK, you upload a Python package\n",
    "containing your training code to a Cloud Storage bucket. AI Platform runs\n",
    "the code from this package. In this tutorial, AI Platform also saves the\n",
    "trained model that results from your job in the same bucket. You can then\n",
    "create an AI Platform model version based on this output in order to serve\n",
    "online predictions.\n",
    "\n",
    "Set the name of your Cloud Storage bucket below. It must be unique across all\n",
    "Cloud Storage buckets. \n",
    "\n",
    "You may also change the `REGION` variable, which is used for operations\n",
    "throughout the rest of this notebook. Make sure to [choose a region where Cloud\n",
    "AI Platform services are\n",
    "available](https://cloud.google.com/ml-engine/docs/tensorflow/regions). You may\n",
    "not use a Multi-Regional Storage bucket for training with AI Platform."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bTxmbDg1I0x1"
   },
   "outputs": [],
   "source": [
    "BUCKET_NAME = \"lingh\" #@param {type:\"string\"}\n",
    "REGION = 'us-east1'  #@param {type:\"string\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fsmCk2dwJnLZ"
   },
   "source": [
    "**Only if your bucket doesn't already exist**: Run the following cell to create your Cloud Storage bucket."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "160PRO3aJqLD",
    "outputId": "f59db874-8abd-45c2-d562-a4824989fdc6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating gs://lingh/...\n",
      "ServiceException: 409 Bucket lingh already exists.\n"
     ]
    }
   ],
   "source": [
    "! gsutil mb -l $REGION gs://$BUCKET_NAME"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iTc8RvKlSjIG"
   },
   "source": [
    "Finally, validate access to your Cloud Storage bucket by examining its contents:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OsB4T3sbSb2d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                 gs://lingh/dataflow/\r\n",
      "                                 gs://lingh/ml-testing/\r\n",
      "                                 gs://lingh/push/\r\n"
     ]
    }
   ],
   "source": [
    "! gsutil ls -al gs://$BUCKET_NAME"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aRVMEU2Qshm4"
   },
   "source": [
    "## Part 1. Quickstart for training in AI Platform\n",
    "\n",
    "This section of the tutorial walks you through submitting a training job to Cloud\n",
    "AI Platform. This job runs sample code that uses Keras to train a deep neural\n",
    "network on the United States Census data. It outputs the trained model as a\n",
    "[TensorFlow SavedModel\n",
    "directory](https://www.tensorflow.org/guide/saved_model#save_and_restore_models)\n",
    "in your Cloud Storage bucket.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8zr6lj66UlMn"
   },
   "source": [
    "### Get training code and dependencies\n",
    "\n",
    "First, download the training code and change the notebook's working directory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/lingh/Git/ML/cloudml-samples/notebooks/tensorflow\r\n"
     ]
    }
   ],
   "source": [
    "! pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 153
    },
    "colab_type": "code",
    "id": "Icz22E69smnD",
    "outputId": "a5113351-142c-4c0f-e640-5cccea37a481"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/lingh/Git/ML/cloudml-samples/census/tf-keras\n"
     ]
    }
   ],
   "source": [
    "# Clone the repository of AI Platform samples\n",
    "# ! git clone --depth 1 https://github.com/GoogleCloudPlatform/cloudml-samples\n",
    "\n",
    "# Set the working directory to the sample code directory\n",
    "%cd /Users/lingh/Git/ML/cloudml-samples/census/tf-keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MhubJDDXSVv3"
   },
   "source": [
    "Notice that the training code is structured as a Python package in the\n",
    "`trainer/` subdirectory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "id": "uZ_nfuPJlNpi",
    "outputId": "766d898d-92cf-4560-be1e-3d1cc35b2a0d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "README.md              \u001b[1m\u001b[36mlocal-training-output\u001b[m\u001b[m/ \u001b[1m\u001b[36mtrainer\u001b[m\u001b[m/\r\n",
      "hptuning_config.yaml   requirements.txt\r\n",
      "\r\n",
      "./local-training-output:\r\n",
      "\u001b[1m\u001b[36mkeras_export\u001b[m\u001b[m/      \u001b[1m\u001b[36mkeras_tensorboard\u001b[m\u001b[m/\r\n",
      "\r\n",
      "./local-training-output/keras_export:\r\n",
      "\u001b[1m\u001b[36massets\u001b[m\u001b[m/         saved_model.pb  \u001b[1m\u001b[36mvariables\u001b[m\u001b[m/\r\n",
      "\r\n",
      "./local-training-output/keras_export/assets:\r\n",
      "saved_model.json\r\n",
      "\r\n",
      "./local-training-output/keras_export/variables:\r\n",
      "checkpoint                     variables.data-00001-of-00002\r\n",
      "variables.data-00000-of-00002  variables.index\r\n",
      "\r\n",
      "./local-training-output/keras_tensorboard:\r\n",
      "events.out.tfevents.1568054016.Lings-MacBook-Pro.local\r\n",
      "events.out.tfevents.1568054017.Lings-MacBook-Pro.local.profile-empty\r\n",
      "\u001b[1m\u001b[36mplugins\u001b[m\u001b[m/\r\n",
      "\r\n",
      "./local-training-output/keras_tensorboard/plugins:\r\n",
      "\u001b[1m\u001b[36mprofile\u001b[m\u001b[m/\r\n",
      "\r\n",
      "./local-training-output/keras_tensorboard/plugins/profile:\r\n",
      "\u001b[1m\u001b[36m2019-09-09_14-33-37\u001b[m\u001b[m/\r\n",
      "\r\n",
      "./local-training-output/keras_tensorboard/plugins/profile/2019-09-09_14-33-37:\r\n",
      "local.trace\r\n",
      "\r\n",
      "./trainer:\r\n",
      "__init__.py  \u001b[1m\u001b[36m__pycache__\u001b[m\u001b[m/ model.py     task.py      util.py\r\n",
      "\r\n",
      "./trainer/__pycache__:\r\n",
      "__init__.cpython-37.pyc  task.cpython-37.pyc\r\n",
      "model.cpython-37.pyc     util.cpython-37.pyc\r\n"
     ]
    }
   ],
   "source": [
    "# `ls` shows the working directory's contents. The `p` flag adds trailing \n",
    "# slashes to subdirectory names. The `R` flag lists subdirectories recursively.\n",
    "! ls -pR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7KA87o4HUhby"
   },
   "source": [
    "Run the following cell to install Python dependencies needed to train the model locally. When you run the training job in AI Platform,\n",
    "dependencies are preinstalled based on the [runtime\n",
    "version](https://cloud.google.com/ml-engine/docs/tensorflow/runtime-version-list)\n",
    "you choose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 408
    },
    "colab_type": "code",
    "id": "Wm5w1UrmVU7O",
    "outputId": "ed03f67c-a605-4dcd-e17e-5dfd70426641"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://artifactory.spotify.net/artifactory/api/pypi/pypi/simple/\n",
      "Requirement already satisfied: numpy>=1.14 in /Users/lingh/Git/ML/cloudml-samples/env/lib/python3.7/site-packages (from -r requirements.txt (line 1)) (1.17.2)\n",
      "Requirement already satisfied: pandas>=0.22 in /Users/lingh/Git/ML/cloudml-samples/env/lib/python3.7/site-packages (from -r requirements.txt (line 2)) (0.25.1)\n",
      "Requirement already satisfied: six>=1.11 in /Users/lingh/Git/ML/cloudml-samples/env/lib/python3.7/site-packages (from -r requirements.txt (line 3)) (1.12.0)\n",
      "Requirement already satisfied: tensorflow<2,>=1.13 in /Users/lingh/Git/ML/cloudml-samples/env/lib/python3.7/site-packages (from -r requirements.txt (line 4)) (1.14.0)\n",
      "Requirement already satisfied: pytz>=2017.2 in /Users/lingh/Git/ML/cloudml-samples/env/lib/python3.7/site-packages (from pandas>=0.22->-r requirements.txt (line 2)) (2019.2)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in /Users/lingh/Git/ML/cloudml-samples/env/lib/python3.7/site-packages (from pandas>=0.22->-r requirements.txt (line 2)) (2.8.0)\n",
      "Requirement already satisfied: gast>=0.2.0 in /Users/lingh/Git/ML/cloudml-samples/env/lib/python3.7/site-packages (from tensorflow<2,>=1.13->-r requirements.txt (line 4)) (0.3.1)\n",
      "Requirement already satisfied: google-pasta>=0.1.6 in /Users/lingh/Git/ML/cloudml-samples/env/lib/python3.7/site-packages (from tensorflow<2,>=1.13->-r requirements.txt (line 4)) (0.1.7)\n",
      "Requirement already satisfied: keras-applications>=1.0.6 in /Users/lingh/Git/ML/cloudml-samples/env/lib/python3.7/site-packages (from tensorflow<2,>=1.13->-r requirements.txt (line 4)) (1.0.8)\n",
      "Requirement already satisfied: wrapt>=1.11.1 in /Users/lingh/Git/ML/cloudml-samples/env/lib/python3.7/site-packages (from tensorflow<2,>=1.13->-r requirements.txt (line 4)) (1.11.2)\n",
      "Requirement already satisfied: tensorboard<1.15.0,>=1.14.0 in /Users/lingh/Git/ML/cloudml-samples/env/lib/python3.7/site-packages (from tensorflow<2,>=1.13->-r requirements.txt (line 4)) (1.14.0)\n",
      "Requirement already satisfied: tensorflow-estimator<1.15.0rc0,>=1.14.0rc0 in /Users/lingh/Git/ML/cloudml-samples/env/lib/python3.7/site-packages (from tensorflow<2,>=1.13->-r requirements.txt (line 4)) (1.14.0)\n",
      "Requirement already satisfied: absl-py>=0.7.0 in /Users/lingh/Git/ML/cloudml-samples/env/lib/python3.7/site-packages (from tensorflow<2,>=1.13->-r requirements.txt (line 4)) (0.8.0)\n",
      "Requirement already satisfied: astor>=0.6.0 in /Users/lingh/Git/ML/cloudml-samples/env/lib/python3.7/site-packages (from tensorflow<2,>=1.13->-r requirements.txt (line 4)) (0.8.0)\n",
      "Requirement already satisfied: grpcio>=1.8.6 in /Users/lingh/Git/ML/cloudml-samples/env/lib/python3.7/site-packages (from tensorflow<2,>=1.13->-r requirements.txt (line 4)) (1.23.0)\n",
      "Requirement already satisfied: protobuf>=3.6.1 in /Users/lingh/Git/ML/cloudml-samples/env/lib/python3.7/site-packages (from tensorflow<2,>=1.13->-r requirements.txt (line 4)) (3.9.1)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /Users/lingh/Git/ML/cloudml-samples/env/lib/python3.7/site-packages (from tensorflow<2,>=1.13->-r requirements.txt (line 4)) (1.1.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in /Users/lingh/Git/ML/cloudml-samples/env/lib/python3.7/site-packages (from tensorflow<2,>=1.13->-r requirements.txt (line 4)) (1.1.0)\n",
      "Requirement already satisfied: wheel>=0.26 in /Users/lingh/Git/ML/cloudml-samples/env/lib/python3.7/site-packages (from tensorflow<2,>=1.13->-r requirements.txt (line 4)) (0.33.6)\n",
      "Requirement already satisfied: h5py in /Users/lingh/Git/ML/cloudml-samples/env/lib/python3.7/site-packages (from keras-applications>=1.0.6->tensorflow<2,>=1.13->-r requirements.txt (line 4)) (2.10.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /Users/lingh/Git/ML/cloudml-samples/env/lib/python3.7/site-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow<2,>=1.13->-r requirements.txt (line 4)) (3.1.1)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /Users/lingh/Git/ML/cloudml-samples/env/lib/python3.7/site-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow<2,>=1.13->-r requirements.txt (line 4)) (41.2.0)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /Users/lingh/Git/ML/cloudml-samples/env/lib/python3.7/site-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow<2,>=1.13->-r requirements.txt (line 4)) (0.15.6)\n"
     ]
    }
   ],
   "source": [
    "! pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iSrzwuchvcgv"
   },
   "source": [
    "### Train your model locally\n",
    "\n",
    "Before training on AI Platform, train the job locally to verify the file\n",
    "structure and packaging is correct.\n",
    "\n",
    "For a complex or resource-intensive job, you\n",
    "may want to train locally on a small sample of your dataset to verify your code.\n",
    "Then you can run the job on AI Platform to train on the whole dataset.\n",
    "\n",
    "This sample runs a relatively quick job on a small dataset, so the local\n",
    "training and the AI Platform job run the same code on the same data.\n",
    "\n",
    "Run the following cell to train a model locally:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1890
    },
    "colab_type": "code",
    "id": "D5PIljnYveDN",
    "outputId": "04cd1942-6e37-403d-c298-2d1d65a9b30f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated property [ml_engine/local_python].\n",
      "/Users/lingh/Git/ML/cloudml-samples/env/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Users/lingh/Git/ML/cloudml-samples/env/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Users/lingh/Git/ML/cloudml-samples/env/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Users/lingh/Git/ML/cloudml-samples/env/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Users/lingh/Git/ML/cloudml-samples/env/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Users/lingh/Git/ML/cloudml-samples/env/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/Users/lingh/Git/ML/cloudml-samples/env/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Users/lingh/Git/ML/cloudml-samples/env/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Users/lingh/Git/ML/cloudml-samples/env/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Users/lingh/Git/ML/cloudml-samples/env/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Users/lingh/Git/ML/cloudml-samples/env/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Users/lingh/Git/ML/cloudml-samples/env/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "WARNING:tensorflow:From /Users/lingh/Git/ML/cloudml-samples/census/tf-keras/trainer/task.py:128: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/lingh/Git/ML/cloudml-samples/census/tf-keras/trainer/util.py:128: The name tf.gfile.MakeDirs is deprecated. Please use tf.io.gfile.makedirs instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/lingh/Git/ML/cloudml-samples/census/tf-keras/trainer/util.py:131: The name tf.gfile.Exists is deprecated. Please use tf.io.gfile.exists instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/lingh/Git/ML/cloudml-samples/census/tf-keras/trainer/util.py:108: The name tf.gfile.Open is deprecated. Please use tf.io.gfile.GFile instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/lingh/Git/ML/cloudml-samples/census/tf-keras/trainer/util.py:119: The name tf.gfile.Remove is deprecated. Please use tf.io.gfile.remove instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/lingh/Git/ML/cloudml-samples/env/lib/python3.7/site-packages/tensorflow/python/keras/initializers.py:119: calling RandomUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /Users/lingh/Git/ML/cloudml-samples/env/lib/python3.7/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /Users/lingh/Git/ML/cloudml-samples/env/lib/python3.7/site-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "2019-09-09 14:33:36.344289: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
      "\n",
      "Epoch 00001: LearningRateScheduler reducing learning rate to 0.02.\n",
      "Epoch 1/20\n",
      "2019-09-09 14:33:37.054748: I tensorflow/core/profiler/lib/profiler_session.cc:174] Profiler session started.\n",
      "254/254 [==============================] - 1s 2ms/step - loss: 0.5373 - acc: 0.7857 - val_loss: 0.3803 - val_acc: 0.8306\n",
      "\n",
      "Epoch 00002: LearningRateScheduler reducing learning rate to 0.015.\n",
      "Epoch 2/20\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.3589 - acc: 0.8334 - val_loss: 0.3363 - val_acc: 0.8419\n",
      "\n",
      "Epoch 00003: LearningRateScheduler reducing learning rate to 0.0125.\n",
      "Epoch 3/20\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.3421 - acc: 0.8404 - val_loss: 0.3285 - val_acc: 0.8456\n",
      "\n",
      "Epoch 00004: LearningRateScheduler reducing learning rate to 0.01125.\n",
      "Epoch 4/20\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.3377 - acc: 0.8422 - val_loss: 0.3353 - val_acc: 0.8433\n",
      "\n",
      "Epoch 00005: LearningRateScheduler reducing learning rate to 0.010625.\n",
      "Epoch 5/20\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.3349 - acc: 0.8449 - val_loss: 0.3224 - val_acc: 0.8489\n",
      "\n",
      "Epoch 00006: LearningRateScheduler reducing learning rate to 0.0103125.\n",
      "Epoch 6/20\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.3321 - acc: 0.8451 - val_loss: 0.3336 - val_acc: 0.8468\n",
      "\n",
      "Epoch 00007: LearningRateScheduler reducing learning rate to 0.01015625.\n",
      "Epoch 7/20\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.3328 - acc: 0.8452 - val_loss: 0.3266 - val_acc: 0.8500\n",
      "\n",
      "Epoch 00008: LearningRateScheduler reducing learning rate to 0.010078125.\n",
      "Epoch 8/20\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.3300 - acc: 0.8477 - val_loss: 0.3222 - val_acc: 0.8505\n",
      "\n",
      "Epoch 00009: LearningRateScheduler reducing learning rate to 0.0100390625.\n",
      "Epoch 9/20\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.3309 - acc: 0.8471 - val_loss: 0.3335 - val_acc: 0.8413\n",
      "\n",
      "Epoch 00010: LearningRateScheduler reducing learning rate to 0.01001953125.\n",
      "Epoch 10/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "254/254 [==============================] - 0s 2ms/step - loss: 0.3282 - acc: 0.8476 - val_loss: 0.3219 - val_acc: 0.8501\n",
      "\n",
      "Epoch 00011: LearningRateScheduler reducing learning rate to 0.010009765625.\n",
      "Epoch 11/20\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.3301 - acc: 0.8477 - val_loss: 0.3433 - val_acc: 0.8437\n",
      "\n",
      "Epoch 00012: LearningRateScheduler reducing learning rate to 0.010004882812500001.\n",
      "Epoch 12/20\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.3278 - acc: 0.8475 - val_loss: 0.3257 - val_acc: 0.8477\n",
      "\n",
      "Epoch 00013: LearningRateScheduler reducing learning rate to 0.01000244140625.\n",
      "Epoch 13/20\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.3276 - acc: 0.8473 - val_loss: 0.3246 - val_acc: 0.8492\n",
      "\n",
      "Epoch 00014: LearningRateScheduler reducing learning rate to 0.010001220703125.\n",
      "Epoch 14/20\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.3267 - acc: 0.8494 - val_loss: 0.3264 - val_acc: 0.8475\n",
      "\n",
      "Epoch 00015: LearningRateScheduler reducing learning rate to 0.0100006103515625.\n",
      "Epoch 15/20\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.3260 - acc: 0.8487 - val_loss: 0.3308 - val_acc: 0.8494\n",
      "\n",
      "Epoch 00016: LearningRateScheduler reducing learning rate to 0.01000030517578125.\n",
      "Epoch 16/20\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.3257 - acc: 0.8486 - val_loss: 0.3475 - val_acc: 0.8441\n",
      "\n",
      "Epoch 00017: LearningRateScheduler reducing learning rate to 0.010000152587890625.\n",
      "Epoch 17/20\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.3248 - acc: 0.8494 - val_loss: 0.3317 - val_acc: 0.8472\n",
      "\n",
      "Epoch 00018: LearningRateScheduler reducing learning rate to 0.010000076293945313.\n",
      "Epoch 18/20\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.3242 - acc: 0.8498 - val_loss: 0.3292 - val_acc: 0.8493\n",
      "\n",
      "Epoch 00019: LearningRateScheduler reducing learning rate to 0.010000038146972657.\n",
      "Epoch 19/20\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.3225 - acc: 0.8510 - val_loss: 0.3235 - val_acc: 0.8501\n",
      "\n",
      "Epoch 00020: LearningRateScheduler reducing learning rate to 0.010000019073486329.\n",
      "Epoch 20/20\n",
      "254/254 [==============================] - 0s 2ms/step - loss: 0.3236 - acc: 0.8503 - val_loss: 0.3235 - val_acc: 0.8511\n",
      "WARNING:tensorflow:\n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "WARNING:tensorflow:From /Users/lingh/Git/ML/cloudml-samples/env/lib/python3.7/site-packages/tensorflow/python/ops/init_ops.py:97: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /Users/lingh/Git/ML/cloudml-samples/env/lib/python3.7/site-packages/tensorflow/python/ops/init_ops.py:97: calling GlorotUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /Users/lingh/Git/ML/cloudml-samples/env/lib/python3.7/site-packages/tensorflow/python/saved_model/signature_def_utils_impl.py:253: build_tensor_info (from tensorflow.python.saved_model.utils_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.utils.build_tensor_info or tf.compat.v1.saved_model.build_tensor_info.\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Classify: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Regress: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Predict: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Train: ['train']\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Eval: None\n",
      "WARNING:tensorflow:Export includes no default signature!\n",
      "INFO:tensorflow:No assets to save.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Classify: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Regress: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Predict: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Train: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Eval: ['eval']\n",
      "WARNING:tensorflow:Export includes no default signature!\n",
      "INFO:tensorflow:No assets to save.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Classify: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Regress: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Predict: ['serving_default']\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Train: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Eval: None\n",
      "INFO:tensorflow:No assets to save.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: local-training-output/keras_export/saved_model.pb\n",
      "Model exported to: local-training-output/keras_export\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.momentum\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.rho\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'rms' for (root).layer_with_weights-0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'rms' for (root).layer_with_weights-0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'rms' for (root).layer_with_weights-1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'rms' for (root).layer_with_weights-1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'rms' for (root).layer_with_weights-2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'rms' for (root).layer_with_weights-2.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'rms' for (root).layer_with_weights-3.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'rms' for (root).layer_with_weights-3.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'rms' for (root).layer_with_weights-4.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'rms' for (root).layer_with_weights-4.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/alpha/guide/checkpoints#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.momentum\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.rho\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'rms' for (root).layer_with_weights-0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'rms' for (root).layer_with_weights-0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'rms' for (root).layer_with_weights-1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'rms' for (root).layer_with_weights-1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'rms' for (root).layer_with_weights-2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'rms' for (root).layer_with_weights-2.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'rms' for (root).layer_with_weights-3.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'rms' for (root).layer_with_weights-3.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'rms' for (root).layer_with_weights-4.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'rms' for (root).layer_with_weights-4.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/alpha/guide/checkpoints#loading_mechanics for details.\n"
     ]
    }
   ],
   "source": [
    "# Explicitly tell `gcloud ai-platform local train` to use Python 3 \n",
    "! gcloud config set ml_engine/local_python $(which python3)\n",
    "\n",
    "# This is similar to `python -m trainer.task --job-dir local-training-output`\n",
    "# but it better replicates the AI Platform environment, especially for\n",
    "# distributed training (not applicable here).\n",
    "! gcloud ai-platform local train \\\n",
    "  --package-path trainer \\\n",
    "  --module-name trainer.task \\\n",
    "  --job-dir local-training-output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rAX4hZip53SR"
   },
   "source": [
    "### Train your model using AI Platform\n",
    "\n",
    "Next, submit a training job to AI Platform. This runs the training module\n",
    "in the cloud and exports the trained model to Cloud Storage.\n",
    "\n",
    "First, give your training job a name and choose a directory within your Cloud\n",
    "Storage bucket for saving intermediate and output files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "05lDch9-0-2v"
   },
   "outputs": [],
   "source": [
    "JOB_NAME = 'my_first_keras_job'\n",
    "JOB_DIR = 'gs://' + BUCKET_NAME + '/keras-job-dir'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yp9nyrZ01a2q"
   },
   "source": [
    "Run the following command to package the `trainer/` directory, upload it to the\n",
    "specified `--job-dir`, and instruct AI Platform to run the\n",
    "`trainer.task` module from that package.\n",
    "\n",
    "The `--stream-logs` flag lets you view training logs in the cell below. You can\n",
    "also see logs and other job details in the GCP Console."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 7500
    },
    "colab_type": "code",
    "id": "1haRe54v53CN",
    "outputId": "dfa15c82-604e-4451-fa19-0dc13ced3ced"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job [my_first_keras_job] submitted successfully.\n",
      "INFO\t2019-03-27 17:54:27 +0000\tservice\t\tValidating job requirements...\n",
      "INFO\t2019-03-27 17:54:27 +0000\tservice\t\tJob creation request has been successfully validated.\n",
      "INFO\t2019-03-27 17:54:27 +0000\tservice\t\tJob my_first_keras_job is queued.\n",
      "INFO\t2019-03-27 17:54:27 +0000\tservice\t\tWaiting for job to be provisioned.\n",
      "INFO\t2019-03-27 17:54:30 +0000\tservice\t\tWaiting for training program to start.\n",
      "INFO\t2019-03-27 17:56:09 +0000\tmaster-replica-0\t\tRunning task with arguments: --cluster={\"master\": [\"127.0.0.1:2222\"]} --task={\"type\": \"master\", \"index\": 0} --job={  \"package_uris\": [\"gs://<your-bucket-name>/keras-job-dir/packages/dcc159f40836cff74a27866227b327b0a8ccb5266194e76cff5368266b6d1cdd/trainer-0.0.0.tar.gz\"],  \"python_module\": \"trainer.task\",  \"region\": \"us-central1\",  \"runtime_version\": \"1.13\",  \"job_dir\": \"gs://<your-bucket-name>/keras-job-dir\",  \"run_on_raw_vm\": true,  \"python_version\": \"3.5\"}\n",
      "WARNING\t2019-03-27 17:56:09 +0000\tmaster-replica-0\t\tFrom /usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "WARNING\t2019-03-27 17:56:09 +0000\tmaster-replica-0\t\tInstructions for updating:\n",
      "WARNING\t2019-03-27 17:56:09 +0000\tmaster-replica-0\t\tColocations handled automatically by placer.\n",
      "INFO\t2019-03-27 17:56:18 +0000\tmaster-replica-0\t\tRunning module trainer.task.\n",
      "INFO\t2019-03-27 17:56:18 +0000\tmaster-replica-0\t\tDownloading the package: gs://<your-bucket-name>/keras-job-dir/packages/dcc159f40836cff74a27866227b327b0a8ccb5266194e76cff5368266b6d1cdd/trainer-0.0.0.tar.gz\n",
      "INFO\t2019-03-27 17:56:18 +0000\tmaster-replica-0\t\tRunning command: gsutil -q cp gs://<your-bucket-name>/keras-job-dir/packages/dcc159f40836cff74a27866227b327b0a8ccb5266194e76cff5368266b6d1cdd/trainer-0.0.0.tar.gz trainer-0.0.0.tar.gz\n",
      "INFO\t2019-03-27 17:56:20 +0000\tmaster-replica-0\t\tInstalling the package: gs://<your-bucket-name>/keras-job-dir/packages/dcc159f40836cff74a27866227b327b0a8ccb5266194e76cff5368266b6d1cdd/trainer-0.0.0.tar.gz\n",
      "INFO\t2019-03-27 17:56:20 +0000\tmaster-replica-0\t\tRunning command: pip3 install --user --upgrade --force-reinstall --no-deps trainer-0.0.0.tar.gz\n",
      "INFO\t2019-03-27 17:56:22 +0000\tmaster-replica-0\t\tProcessing ./trainer-0.0.0.tar.gz\n",
      "INFO\t2019-03-27 17:56:22 +0000\tmaster-replica-0\t\tGenerating grammar tables from /usr/lib/python3.5/lib2to3/Grammar.txt\n",
      "INFO\t2019-03-27 17:56:22 +0000\tmaster-replica-0\t\tGenerating grammar tables from /usr/lib/python3.5/lib2to3/PatternGrammar.txt\n",
      "INFO\t2019-03-27 17:56:23 +0000\tmaster-replica-0\t\tBuilding wheels for collected packages: trainer\n",
      "INFO\t2019-03-27 17:56:23 +0000\tmaster-replica-0\t\t  Building wheel for trainer (setup.py): started\n",
      "INFO\t2019-03-27 17:56:23 +0000\tmaster-replica-0\t\tGenerating grammar tables from /usr/lib/python3.5/lib2to3/Grammar.txt\n",
      "INFO\t2019-03-27 17:56:23 +0000\tmaster-replica-0\t\tGenerating grammar tables from /usr/lib/python3.5/lib2to3/PatternGrammar.txt\n",
      "INFO\t2019-03-27 17:56:23 +0000\tmaster-replica-0\t\t  Building wheel for trainer (setup.py): finished with status 'done'\n",
      "INFO\t2019-03-27 17:56:23 +0000\tmaster-replica-0\t\t  Stored in directory: /root/.cache/pip/wheels/0d/1b/db/f8e86b296734f0b137e17e5d34862f4ae4faf8388755c6272f\n",
      "INFO\t2019-03-27 17:56:23 +0000\tmaster-replica-0\t\tSuccessfully built trainer\n",
      "INFO\t2019-03-27 17:56:23 +0000\tmaster-replica-0\t\tInstalling collected packages: trainer\n",
      "INFO\t2019-03-27 17:56:23 +0000\tmaster-replica-0\t\tSuccessfully installed trainer-0.0.0\n",
      "INFO\t2019-03-27 17:56:23 +0000\tmaster-replica-0\t\tRunning command: pip3 install --user trainer-0.0.0.tar.gz\n",
      "INFO\t2019-03-27 17:56:24 +0000\tmaster-replica-0\t\tProcessing ./trainer-0.0.0.tar.gz\n",
      "INFO\t2019-03-27 17:56:24 +0000\tmaster-replica-0\t\tGenerating grammar tables from /usr/lib/python3.5/lib2to3/Grammar.txt\n",
      "INFO\t2019-03-27 17:56:24 +0000\tmaster-replica-0\t\tGenerating grammar tables from /usr/lib/python3.5/lib2to3/PatternGrammar.txt\n",
      "INFO\t2019-03-27 17:56:24 +0000\tmaster-replica-0\t\tBuilding wheels for collected packages: trainer\n",
      "INFO\t2019-03-27 17:56:24 +0000\tmaster-replica-0\t\t  Building wheel for trainer (setup.py): started\n",
      "INFO\t2019-03-27 17:56:25 +0000\tmaster-replica-0\t\tGenerating grammar tables from /usr/lib/python3.5/lib2to3/Grammar.txt\n",
      "INFO\t2019-03-27 17:56:25 +0000\tmaster-replica-0\t\tGenerating grammar tables from /usr/lib/python3.5/lib2to3/PatternGrammar.txt\n",
      "INFO\t2019-03-27 17:56:25 +0000\tmaster-replica-0\t\t  Building wheel for trainer (setup.py): finished with status 'done'\n",
      "INFO\t2019-03-27 17:56:25 +0000\tmaster-replica-0\t\t  Stored in directory: /root/.cache/pip/wheels/0d/1b/db/f8e86b296734f0b137e17e5d34862f4ae4faf8388755c6272f\n",
      "INFO\t2019-03-27 17:56:25 +0000\tmaster-replica-0\t\tSuccessfully built trainer\n",
      "INFO\t2019-03-27 17:56:29 +0000\tmaster-replica-0\t\tInstalling collected packages: trainer\n",
      "INFO\t2019-03-27 17:56:29 +0000\tmaster-replica-0\t\t  Found existing installation: trainer 0.0.0\n",
      "INFO\t2019-03-27 17:56:29 +0000\tmaster-replica-0\t\t    Uninstalling trainer-0.0.0:\n",
      "INFO\t2019-03-27 17:56:29 +0000\tmaster-replica-0\t\t      Successfully uninstalled trainer-0.0.0\n",
      "INFO\t2019-03-27 17:56:29 +0000\tmaster-replica-0\t\tSuccessfully installed trainer-0.0.0\n",
      "INFO\t2019-03-27 17:56:29 +0000\tmaster-replica-0\t\tRunning command: python3 -m trainer.task --job-dir gs://<your-bucket-name>/keras-job-dir\n",
      "WARNING\t2019-03-27 17:56:43 +0000\tmaster-replica-0\t\tFrom /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "WARNING\t2019-03-27 17:56:43 +0000\tmaster-replica-0\t\tInstructions for updating:\n",
      "WARNING\t2019-03-27 17:56:43 +0000\tmaster-replica-0\t\tColocations handled automatically by placer.\n",
      "INFO\t2019-03-27 17:56:44 +0000\tmaster-replica-0\t\tYour CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
      "INFO\t2019-03-27 17:56:44 +0000\tmaster-replica-0\t\tCPU Frequency: 2300000000 Hz\n",
      "INFO\t2019-03-27 17:56:44 +0000\tmaster-replica-0\t\tXLA service 0x4f15c40 executing computations on platform Host. Devices:\n",
      "INFO\t2019-03-27 17:56:44 +0000\tmaster-replica-0\t\t  StreamExecutor device (0): <undefined>, <undefined>\n",
      "WARNING\t2019-03-27 17:56:44 +0000\tmaster-replica-0\t\tFrom /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "WARNING\t2019-03-27 17:56:44 +0000\tmaster-replica-0\t\tInstructions for updating:\n",
      "WARNING\t2019-03-27 17:56:44 +0000\tmaster-replica-0\t\tUse tf.cast instead.\n",
      "INFO\t2019-03-27 17:56:45 +0000\tmaster-replica-0\t\tEpoch 00001: LearningRateScheduler reducing learning rate to 0.02.\n",
      "INFO\t2019-03-27 17:56:45 +0000\tmaster-replica-0\t\tEpoch 1/20\n",
      "INFO\t2019-03-27 17:56:45 +0000\tmaster-replica-0\t\t  1/254 [..............................] - ETA: 1:06 - loss: 0.5855 - acc: 0.7891\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "INFO\t2019-03-27 17:56:45 +0000\tmaster-replica-0\t\t 16/254 [>.............................] - ETA: 4s - loss: 3.8615 - acc: 0.7495  \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "INFO\t2019-03-27 17:56:45 +0000\tmaster-replica-0\t\t 34/254 [===>..........................] - ETA: 2s - loss: 3.1560 - acc: 0.7415\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "INFO\t2019-03-27 17:56:45 +0000\tmaster-replica-0\t\t 52/254 [=====>........................] - ETA: 1s - loss: 2.2601 - acc: 0.7515\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "INFO\t2019-03-27 17:56:45 +0000\tmaster-replica-0\t\t 69/254 [=======>......................] - ETA: 1s - loss: 1.8414 - acc: 0.7505\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "INFO\t2019-03-27 17:56:45 +0000\tmaster-replica-0\t\t 87/254 [=========>....................] - ETA: 0s - loss: 1.5580 - acc: 0.7543\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "INFO\t2019-03-27 17:56:45 +0000\tmaster-replica-0\t\t105/254 [===========>..................] - ETA: 0s - loss: 1.3674 - acc: 0.7613\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "INFO\t2019-03-27 17:56:45 +0000\tmaster-replica-0\t\t121/254 [=============>................] - ETA: 0s - loss: 1.2418 - acc: 0.7677\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "INFO\t2019-03-27 17:56:45 +0000\tmaster-replica-0\t\t141/254 [===============>..............] - ETA: 0s - loss: 1.1292 - acc: 0.7703\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "INFO\t2019-03-27 17:56:45 +0000\tmaster-replica-0\t\t161/254 [==================>...........] - ETA: 0s - loss: 1.0420 - acc: 0.7741\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "INFO\t2019-03-27 17:56:45 +0000\tmaster-replica-0\t\t179/254 [====================>.........] - ETA: 0s - loss: 0.9786 - acc: 0.7781\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "INFO\t2019-03-27 17:56:45 +0000\tmaster-replica-0\t\t198/254 [======================>.......] - ETA: 0s - loss: 0.9222 - acc: 0.7832\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "INFO\t2019-03-27 17:56:45 +0000\tmaster-replica-0\t\t218/254 [========================>.....] - ETA: 0s - loss: 0.8751 - acc: 0.7866\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "INFO\t2019-03-27 17:56:45 +0000\tmaster-replica-0\t\t238/254 [===========================>..] - ETA: 0s - loss: 0.8347 - acc: 0.7886\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "INFO\t2019-03-27 17:56:45 +0000\tmaster-replica-0\t\t254/254 [==============================] - 1s 4ms/step - loss: 0.8076 - acc: 0.7896 - val_loss: 0.4046 - val_acc: 0.8322\n",
      "INFO\t2019-03-27 17:56:45 +0000\tmaster-replica-0\t\tEpoch 00002: LearningRateScheduler reducing learning rate to 0.015.\n",
      "INFO\t2019-03-27 17:56:45 +0000\tmaster-replica-0\t\tEpoch 2/20\n",
      "INFO\t2019-03-27 17:56:45 +0000\tmaster-replica-0\t\t  1/254 [..............................] - ETA: 0s - loss: 0.3897 - acc: 0.8438\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "INFO\t2019-03-27 17:56:45 +0000\tmaster-replica-0\t\t 21/254 [=>............................] - ETA: 0s - loss: 0.3849 - acc: 0.8307\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "INFO\t2019-03-27 17:56:46 +0000\tmaster-replica-0\t\t 40/254 [===>..........................] - ETA: 0s - loss: 0.3795 - acc: 0.8273\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "INFO\t2019-03-27 17:56:46 +0000\tmaster-replica-0\t\t 61/254 [======>.......................] - ETA: 0s - loss: 0.3706 - acc: 0.8262\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "INFO\t2019-03-27 17:56:46 +0000\tmaster-replica-0\t\t 80/254 [========>.....................] - ETA: 0s - loss: 0.3666 - acc: 0.8264\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "INFO\t2019-03-27 17:56:46 +0000\tmaster-replica-0\t\t 99/254 [==========>...................] - ETA: 0s - loss: 0.3618 - acc: 0.8298\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "INFO\t2019-03-27 17:56:46 +0000\tmaster-replica-0\t\t119/254 [=============>................] - ETA: 0s - loss: 0.3604 - acc: 0.8303\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "INFO\t2019-03-27 17:56:46 +0000\tmaster-replica-0\t\t139/254 [===============>..............] - ETA: 0s - loss: 0.3622 - acc: 0.8294\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "INFO\t2019-03-27 17:56:46 +0000\tmaster-replica-0\t\t158/254 [=================>............] - ETA: 0s - loss: 0.3593 - acc: 0.8310\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "INFO\t2019-03-27 17:56:46 +0000\tmaster-replica-0\t\t177/254 [===================>..........] - ETA: 0s - loss: 0.3601 - acc: 0.8312\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "INFO\t2019-03-27 17:56:46 +0000\tmaster-replica-0\t\t197/254 [======================>.......] - ETA: 0s - loss: 0.3598 - acc: 0.8309\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "INFO\t2019-03-27 17:56:46 +0000\tmaster-replica-0\t\t216/254 [========================>.....] - ETA: 0s - loss: 0.3599 - acc: 0.8311\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "INFO\t2019-03-27 17:56:46 +0000\tmaster-replica-0\t\t237/254 [==========================>...] - ETA: 0s - loss: 0.3597 - acc: 0.8312\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "INFO\t2019-03-27 17:56:46 +0000\tmaster-replica-0\t\t254/254 [==============================] - 1s 3ms/step - loss: 0.3580 - acc: 0.8321 - val_loss: 0.3400 - val_acc: 0.8372\n",
      "INFO\t2019-03-27 17:56:46 +0000\tmaster-replica-0\t\tEpoch 00003: LearningRateScheduler reducing learning rate to 0.0125.\n",
      "INFO\t2019-03-27 17:56:46 +0000\tmaster-replica-0\t\tEpoch 3/20\n",
      "INFO\t2019-03-27 17:56:46 +0000\tmaster-replica-0\t\t  1/254 [..............................] - ETA: 1s - loss: 0.3455 - acc: 0.8203\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "INFO\t2019-03-27 17:56:46 +0000\tmaster-replica-0\t\t 17/254 [=>............................] - ETA: 0s - loss: 0.3449 - acc: 0.8419\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "INFO\t2019-03-27 17:56:46 +0000\tmaster-replica-0\t\t 36/254 [===>..........................] - ETA: 0s - loss: 0.3414 - acc: 0.8414\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "INFO\t2019-03-27 17:56:46 +0000\tmaster-replica-0\t\t 55/254 [=====>........................] - ETA: 0s - loss: 0.3324 - acc: 0.8449\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "INFO\t2019-03-27 17:56:46 +0000\tmaster-replica-0\t\t 74/254 [=======>......................] - ETA: 0s - loss: 0.3378 - acc: 0.8417\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "INFO\t2019-03-27 17:56:46 +0000\tmaster-replica-0\t\t 91/254 [=========>....................] - ETA: 0s - loss: 0.3372 - acc: 0.8423\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "INFO\t2019-03-27 17:56:46 +0000\tmaster-replica-0\t\t107/254 [===========>..................] - ETA: 0s - loss: 0.3394 - acc: 0.8424\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "INFO\t2019-03-27 17:56:47 +0000\tmaster-replica-0\t\t122/254 [=============>................] - ETA: 0s - loss: 0.3433 - acc: 0.8397\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "INFO\t2019-03-27 17:56:47 +0000\tmaster-replica-0\t\t138/254 [===============>..............] - ETA: 0s - loss: 0.3426 - acc: 0.8398\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "INFO\t2019-03-27 17:56:47 +0000\tmaster-replica-0\t\t158/254 [=================>............] - ETA: 0s - loss: 0.3421 - acc: 0.8412\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "INFO\t2019-03-27 17:56:47 +0000\tmaster-replica-0\t\t175/254 [===================>..........] - ETA: 0s - loss: 0.3427 - acc: 0.8413\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "INFO\t2019-03-27 17:56:47 +0000\tmaster-replica-0\t\t192/254 [=====================>........] - ETA: 0s - loss: 0.3417 - acc: 0.8418\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "INFO\t2019-03-27 17:56:47 +0000\tmaster-replica-0\t\t209/254 [=======================>......] - ETA: 0s - loss: 0.3405 - acc: 0.8423\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "INFO\t2019-03-27 17:56:47 +0000\tmaster-replica-0\t\t226/254 [=========================>....] - ETA: 0s - loss: 0.3409 - acc: 0.8424\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "INFO\t2019-03-27 17:56:47 +0000\tmaster-replica-0\t\t247/254 [============================>.] - ETA: 0s - loss: 0.3412 - acc: 0.8428\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "INFO\t2019-03-27 17:56:47 +0000\tmaster-replica-0\t\t254/254 [==============================] - 1s 3ms/step - loss: 0.3409 - acc: 0.8425 - val_loss: 0.3308 - val_acc: 0.8496\n",
      "INFO\t2019-03-27 17:56:47 +0000\tmaster-replica-0\t\tEpoch 00004: LearningRateScheduler reducing learning rate to 0.01125.\n",
      "INFO\t2019-03-27 17:56:47 +0000\tmaster-replica-0\t\tEpoch 4/20\n",
      "INFO\t2019-03-27 17:56:47 +0000\tmaster-replica-0\t\t  1/254 [..............................] - ETA: 0s - loss: 0.4057 - acc: 0.8203\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "INFO\t2019-03-27 17:56:47 +0000\tmaster-replica-0\t\t 17/254 [=>............................] - ETA: 0s - loss: 0.3522 - acc: 0.8323\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "INFO\t2019-03-27 17:56:47 +0000\tmaster-replica-0\t\t 34/254 [===>..........................] - ETA: 0s - loss: 0.3467 - acc: 0.8447\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "INFO\t2019-03-27 17:56:47 +0000\tmaster-replica-0\t\t 54/254 [=====>........................] - ETA: 0s - loss: 0.3441 - acc: 0.8459\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "INFO\t2019-03-27 17:56:47 +0000\tmaster-replica-0\t\t 71/254 [=======>......................] - ETA: 0s - loss: 0.3448 - acc: 0.8445\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "INFO\t2019-03-27 17:56:47 +0000\tmaster-replica-0\t\t 91/254 [=========>....................] - ETA: 0s - loss: 0.3435 - acc: 0.8449\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "INFO\t2019-03-27 17:56:47 +0000\tmaster-replica-0\t\t111/254 [============>.................] - ETA: 0s - loss: 0.3417 - acc: 0.8449\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "INFO\t2019-03-27 17:56:47 +0000\tmaster-replica-0\t\t130/254 [==============>...............] - ETA: 0s - loss: 0.3392 - acc: 0.8462\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "INFO\t2019-03-27 17:56:47 +0000\tmaster-replica-0\t\t149/254 [================>.............] - ETA: 0s - loss: 0.3386 - acc: 0.8461\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "INFO\t2019-03-27 17:56:47 +0000\tmaster-replica-0\t\t167/254 [==================>...........] - ETA: 0s - loss: 0.3370 - acc: 0.8455\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "INFO\t2019-03-27 17:56:47 +0000\tmaster-replica-0\t\t188/254 [=====================>........] - ETA: 0s - loss: 0.3361 - acc: 0.8459\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "INFO\t2019-03-27 17:56:48 +0000\tmaster-replica-0\t\t208/254 [=======================>......] - ETA: 0s - loss: 0.3349 - acc: 0.8458\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "INFO\t2019-03-27 17:56:48 +0000\tmaster-replica-0\t\t228/254 [=========================>....] - ETA: 0s - loss: 0.3364 - acc: 0.8452\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "INFO\t2019-03-27 17:56:48 +0000\tmaster-replica-0\t\t245/254 [===========================>..] - ETA: 0s - loss: 0.3367 - acc: 0.8453\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "INFO\t2019-03-27 17:56:48 +0000\tmaster-replica-0\t\t254/254 [==============================] - 1s 3ms/step - loss: 0.3366 - acc: 0.8451 - val_loss: 0.3431 - val_acc: 0.8319\n",
      "INFO\t2019-03-27 17:56:48 +0000\tmaster-replica-0\t\tEpoch 00005: LearningRateScheduler reducing learning rate to 0.010625.\n",
      "INFO\t2019-03-27 17:56:48 +0000\tmaster-replica-0\t\tEpoch 5/20\n",
      "INFO\t2019-03-27 17:56:48 +0000\tmaster-replica-0\t\t  1/254 [..............................] - ETA: 0s - loss: 0.3805 - acc: 0.8281\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "INFO\t2019-03-27 17:56:48 +0000\tmaster-replica-0\t\t 22/254 [=>............................] - ETA: 0s - loss: 0.3307 - acc: 0.8544\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "INFO\t2019-03-27 17:56:48 +0000\tmaster-replica-0\t\t 41/254 [===>..........................] - ETA: 0s - loss: 0.3297 - acc: 0.8470\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "INFO\t2019-03-27 17:56:48 +0000\tmaster-replica-0\t\t 59/254 [=====>........................] - ETA: 0s - loss: 0.3334 - acc: 0.8455\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "INFO\t2019-03-27 17:56:48 +0000\tmaster-replica-0\t\t 74/254 [=======>......................] - ETA: 0s - loss: 0.3299 - acc: 0.8502\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "INFO\t2019-03-27 17:56:48 +0000\tmaster-replica-0\t\t 87/254 [=========>....................] - ETA: 0s - loss: 0.3323 - acc: 0.8495\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "INFO\t2019-03-27 17:56:48 +0000\tmaster-replica-0\t\t 97/254 [==========>...................] - ETA: 0s - loss: 0.3336 - acc: 0.8490\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "INFO\t2019-03-27 17:56:48 +0000\tmaster-replica-0\t\t107/254 [===========>..................] - ETA: 0s - loss: 0.3344 - acc: 0.8495\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "INFO\t2019-03-27 17:56:48 +0000\tmaster-replica-0\t\t120/254 [=============>................] - ETA: 0s - loss: 0.3367 - acc: 0.8472\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "INFO\t2019-03-27 17:56:48 +0000\tmaster-replica-0\t\t136/254 [===============>..............] - ETA: 0s - loss: 0.3368 - acc: 0.8463\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "INFO\t2019-03-27 17:56:48 +0000\tmaster-replica-0\t\t151/254 [================>.............] - ETA: 0s - loss: 0.3359 - acc: 0.8468\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "INFO\t2019-03-27 17:56:48 +0000\tmaster-replica-0\t\t169/254 [==================>...........] - ETA: 0s - loss: 0.3373 - acc: 0.8449\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "INFO\t2019-03-27 17:56:48 +0000\tmaster-replica-0\t\t187/254 [=====================>........] - ETA: 0s - loss: 0.3364 - acc: 0.8450\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "INFO\t2019-03-27 17:56:48 +0000\tmaster-replica-0\t\t205/254 [=======================>......] - ETA: 0s - loss: 0.3348 - acc: 0.8449\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "INFO\t2019-03-27 17:56:48 +0000\tmaster-replica-0\t\t223/254 [=========================>....] - ETA: 0s - loss: 0.3345 - acc: 0.8451\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "INFO\t2019-03-27 17:56:49 +0000\tmaster-replica-0\t\t242/254 [===========================>..] - ETA: 0s - loss: 0.3353 - acc: 0.8448\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "INFO\t2019-03-27 17:56:49 +0000\tmaster-replica-0\t\t254/254 [==============================] - 1s 3ms/step - loss: 0.3339 - acc: 0.8453 - val_loss: 0.3486 - val_acc: 0.8504\n",
      "INFO\t2019-03-27 17:56:49 +0000\tmaster-replica-0\t\tEpoch 00006: LearningRateScheduler reducing learning rate to 0.0103125.\n",
      "INFO\t2019-03-27 17:56:49 +0000\tmaster-replica-0\t\tEpoch 6/20\n",
      "INFO\t2019-03-27 17:56:49 +0000\tmaster-replica-0\t\t  1/254 [..............................] - ETA: 0s - loss: 0.5068 - acc: 0.7891\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "INFO\t2019-03-27 17:56:49 +0000\tmaster-replica-0\t\t 18/254 [=>............................] - ETA: 0s - loss: 0.3490 - acc: 0.8459\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "INFO\t2019-03-27 17:56:49 +0000\tmaster-replica-0\t\t 38/254 [===>..........................] - ETA: 0s - loss: 0.3355 - acc: 0.8512\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "INFO\t2019-03-27 17:56:49 +0000\tmaster-replica-0\t\t 58/254 [=====>........................] - ETA: 0s - loss: 0.3312 - acc: 0.8528\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "INFO\t2019-03-27 17:56:49 +0000\tmaster-replica-0\t\t 78/254 [========>.....................] - ETA: 0s - loss: 0.3311 - acc: 0.8526\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "INFO\t2019-03-27 17:56:49 +0000\tmaster-replica-0\t\t 99/254 [==========>...................] - ETA: 0s - loss: 0.3317 - acc: 0.8501\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "INFO\t2019-03-27 17:56:49 +0000\tmaster-replica-0\t\t116/254 [============>.................] - ETA: 0s - loss: 0.3312 - acc: 0.8496\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "INFO\t2019-03-27 17:56:49 +0000\tmaster-replica-0\t\t134/254 [==============>...............] - ETA: 0s - loss: 0.3326 - acc: 0.8500\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "INFO\t2019-03-27 17:56:49 +0000\tmaster-replica-0\t\t153/254 [=================>............] - ETA: 0s - loss: 0.3326 - acc: 0.8499\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "INFO\t2019-03-27 17:56:49 +0000\tmaster-replica-0\t\t169/254 [==================>...........] - ETA: 0s - loss: 0.3351 - acc: 0.8485\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "INFO\t2019-03-27 17:56:49 +0000\tmaster-replica-0\t\t187/254 [=====================>........] - ETA: 0s - loss: 0.3351 - acc: 0.8481\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "INFO\t2019-03-27 17:56:49 +0000\tmaster-replica-0\t\t204/254 [=======================>......] - ETA: 0s - loss: 0.3346 - acc: 0.8478\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "INFO\t2019-03-27 17:56:49 +0000\tmaster-replica-0\t\t220/254 [========================>.....] - ETA: 0s - loss: 0.3345 - acc: 0.8482\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "INFO\t2019-03-27 17:56:49 +0000\tmaster-replica-0\t\t237/254 [==========================>...] - ETA: 0s - loss: 0.3330 - acc: 0.8483\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "INFO\t2019-03-27 17:56:49 +0000\tmaster-replica-0\t\t254/254 [==============================] - 1s 3ms/step - loss: 0.3317 - acc: 0.8483 - val_loss: 0.3297 - val_acc: 0.8402\n",
      "INFO\t2019-03-27 17:56:49 +0000\tmaster-replica-0\t\tEpoch 00007: LearningRateScheduler reducing learning rate to 0.01015625.\n",
      "INFO\t2019-03-27 17:56:49 +0000\tmaster-replica-0\t\tEpoch 7/20\n",
      "INFO\t2019-03-27 17:56:49 +0000\tmaster-replica-0\t\t  1/254 [..............................] - ETA: 0s - loss: 0.2934 - acc: 0.8906\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "INFO\t2019-03-27 17:56:49 +0000\tmaster-replica-0\t\t 19/254 [=>............................] - ETA: 0s - loss: 0.3127 - acc: 0.8586\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "INFO\t2019-03-27 17:56:49 +0000\tmaster-replica-0\t\t 37/254 [===>..........................] - ETA: 0s - loss: 0.3242 - acc: 0.8554\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "INFO\t2019-03-27 17:56:50 +0000\tmaster-replica-0\t\t 55/254 [=====>........................] - ETA: 0s - loss: 0.3300 - acc: 0.8482\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "INFO\t2019-03-27 17:56:50 +0000\tmaster-replica-0\t\t 74/254 [=======>......................] - ETA: 0s - loss: 0.3345 - acc: 0.8486\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "INFO\t2019-03-27 17:56:50 +0000\tmaster-replica-0\t\t 93/254 [=========>....................] - ETA: 0s - loss: 0.3329 - acc: 0.8465\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "INFO\t2019-03-27 17:56:50 +0000\tmaster-replica-0\t\t111/254 [============>.................] - ETA: 0s - loss: 0.3327 - acc: 0.8466\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "INFO\t2019-03-27 17:56:50 +0000\tmaster-replica-0\t\t128/254 [==============>...............] - ETA: 0s - loss: 0.3327 - acc: 0.8468\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "INFO\t2019-03-27 17:56:50 +0000\tmaster-replica-0\t\t147/254 [================>.............] - ETA: 0s - loss: 0.3307 - acc: 0.8479\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "INFO\t2019-03-27 17:56:50 +0000\tmaster-replica-0\t\t163/254 [==================>...........] - ETA: 0s - loss: 0.3310 - acc: 0.8484\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "INFO\t2019-03-27 17:56:50 +0000\tmaster-replica-0\t\t183/254 [====================>.........] - ETA: 0s - loss: 0.3316 - acc: 0.8488\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "INFO\t2019-03-27 17:56:50 +0000\tmaster-replica-0\t\t202/254 [======================>.......] - ETA: 0s - loss: 0.3335 - acc: 0.8477\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "INFO\t2019-03-27 17:56:50 +0000\tmaster-replica-0\t\t219/254 [========================>.....] - ETA: 0s - loss: 0.3312 - acc: 0.8491\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "INFO\t2019-03-27 17:56:50 +0000\tmaster-replica-0\t\t238/254 [===========================>..] - ETA: 0s - loss: 0.3312 - acc: 0.8489\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "INFO\t2019-03-27 17:56:50 +0000\tmaster-replica-0\t\t254/254 [==============================] - 1s 3ms/step - loss: 0.3316 - acc: 0.8480 - val_loss: 0.3250 - val_acc: 0.8461\n",
      "INFO\t2019-03-27 17:56:50 +0000\tmaster-replica-0\t\tEpoch 00008: LearningRateScheduler reducing learning rate to 0.010078125.\n",
      "INFO\t2019-03-27 17:56:50 +0000\tmaster-replica-0\t\tEpoch 8/20\n",
      "INFO\t2019-03-27 17:56:50 +0000\tmaster-replica-0\t\t  1/254 [..............................] - ETA: 0s - loss: 0.3214 - acc: 0.8594\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "INFO\t2019-03-27 17:56:50 +0000\tmaster-replica-0\t\t 19/254 [=>............................] - ETA: 0s - loss: 0.3520 - acc: 0.8425\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "INFO\t2019-03-27 17:56:50 +0000\tmaster-replica-0\t\t 34/254 [===>..........................] - ETA: 0s - loss: 0.3456 - acc: 0.8447\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "INFO\t2019-03-27 17:56:50 +0000\tmaster-replica-0\t\t 49/254 [====>.........................] - ETA: 0s - loss: 0.3347 - acc: 0.8492\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "INFO\t2019-03-27 17:56:50 +0000\tmaster-replica-0\t\t 64/254 [======>.......................] - ETA: 0s - loss: 0.3296 - acc: 0.8503\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "INFO\t2019-03-27 17:56:50 +0000\tmaster-replica-0\t\t 79/254 [========>.....................] - ETA: 0s - loss: 0.3293 - acc: 0.8502\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "INFO\t2019-03-27 17:56:50 +0000\tmaster-replica-0\t\t 95/254 [==========>...................] - ETA: 0s - loss: 0.3288 - acc: 0.8502\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "INFO\t2019-03-27 17:56:50 +0000\tmaster-replica-0\t\t112/254 [============>.................] - ETA: 0s - loss: 0.3285 - acc: 0.8489\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "INFO\t2019-03-27 17:56:51 +0000\tmaster-replica-0\t\t128/254 [==============>...............] - ETA: 0s - loss: 0.3307 - acc: 0.8480\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "INFO\t2019-03-27 17:56:51 +0000\tmaster-replica-0\t\t144/254 [================>.............] - ETA: 0s - loss: 0.3294 - acc: 0.8484\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "INFO\t2019-03-27 17:56:51 +0000\tmaster-replica-0\t\t161/254 [==================>...........] - ETA: 0s - loss: 0.3294 - acc: 0.8488\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "INFO\t2019-03-27 17:56:51 +0000\tmaster-replica-0\t\t175/254 [===================>..........] - ETA: 0s - loss: 0.3289 - acc: 0.8494\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "INFO\t2019-03-27 17:56:51 +0000\tmaster-replica-0\t\t190/254 [=====================>........] - ETA: 0s - loss: 0.3308 - acc: 0.8486\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "INFO\t2019-03-27 17:56:51 +0000\tmaster-replica-0\t\t206/254 [=======================>......] - ETA: 0s - loss: 0.3302 - acc: 0.8491\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "INFO\t2019-03-27 17:56:51 +0000\tmaster-replica-0\t\t221/254 [=========================>....] - ETA: 0s - loss: 0.3310 - acc: 0.8492\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "INFO\t2019-03-27 17:56:51 +0000\tmaster-replica-0\t\t237/254 [==========================>...] - ETA: 0s - loss: 0.3327 - acc: 0.8483\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "INFO\t2019-03-27 17:56:51 +0000\tmaster-replica-0\t\t254/254 [==============================] - 1s 3ms/step - loss: 0.3313 - acc: 0.8483 - val_loss: 0.3255 - val_acc: 0.8500\n",
      "INFO\t2019-03-27 17:56:51 +0000\tmaster-replica-0\t\tEpoch 00009: LearningRateScheduler reducing learning rate to 0.0100390625.\n",
      "INFO\t2019-03-27 17:56:51 +0000\tmaster-replica-0\t\tEpoch 9/20\n",
      "INFO\t2019-03-27 17:56:51 +0000\tmaster-replica-0\t\t  1/254 [..............................] - ETA: 0s - loss: 0.4250 - acc: 0.7969\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "INFO\t2019-03-27 17:56:51 +0000\tmaster-replica-0\t\t 20/254 [=>............................] - ETA: 0s - loss: 0.3384 - acc: 0.8500\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "INFO\t2019-03-27 17:56:51 +0000\tmaster-replica-0\t\t 35/254 [===>..........................] - ETA: 0s - loss: 0.3326 - acc: 0.8484\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "INFO\t2019-03-27 17:56:51 +0000\tmaster-replica-0\t\t 51/254 [=====>........................] - ETA: 0s - loss: 0.3307 - acc: 0.8508\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "INFO\t2019-03-27 17:56:51 +0000\tmaster-replica-0\t\t 68/254 [=======>......................] - ETA: 0s - loss: 0.3312 - acc: 0.8516\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "INFO\t2019-03-27 17:56:51 +0000\tmaster-replica-0\t\t 85/254 [=========>....................] - ETA: 0s - loss: 0.3337 - acc: 0.8500\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "INFO\t2019-03-27 17:56:51 +0000\tmaster-replica-0\t\t102/254 [===========>..................] - ETA: 0s - loss: 0.3346 - acc: 0.8494\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "INFO\t2019-03-27 17:56:51 +0000\tmaster-replica-0\t\t118/254 [============>.................] - ETA: 0s - loss: 0.3358 - acc: 0.8485\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "INFO\t2019-03-27 17:56:51 +0000\tmaster-replica-0\t\t134/254 [==============>...............] - ETA: 0s - loss: 0.3320 - acc: 0.8493\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "INFO\t2019-03-27 17:56:51 +0000\tmaster-replica-0\t\t150/254 [================>.............] - ETA: 0s - loss: 0.3319 - acc: 0.8489\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "INFO\t2019-03-27 17:56:52 +0000\tmaster-replica-0\t\t168/254 [==================>...........] - ETA: 0s - loss: 0.3337 - acc: 0.8492\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "INFO\t2019-03-27 17:56:52 +0000\tmaster-replica-0\t\t187/254 [=====================>........] - ETA: 0s - loss: 0.3332 - acc: 0.8481\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "INFO\t2019-03-27 17:56:52 +0000\tmaster-replica-0\t\t206/254 [=======================>......] - ETA: 0s - loss: 0.3315 - acc: 0.8489\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "INFO\t2019-03-27 17:56:52 +0000\tmaster-replica-0\t\t224/254 [=========================>....] - ETA: 0s - loss: 0.3311 - acc: 0.8490\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "INFO\t2019-03-27 17:56:52 +0000\tmaster-replica-0\t\t242/254 [===========================>..] - ETA: 0s - loss: 0.3304 - acc: 0.8489\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "INFO\t2019-03-27 17:56:52 +0000\tmaster-replica-0\t\t254/254 [==============================] - 1s 3ms/step - loss: 0.3314 - acc: 0.8485 - val_loss: 0.3236 - val_acc: 0.8520\n",
      "INFO\t2019-03-27 17:56:52 +0000\tmaster-replica-0\t\tEpoch 00010: LearningRateScheduler reducing learning rate to 0.01001953125.\n",
      "INFO\t2019-03-27 17:56:52 +0000\tmaster-replica-0\t\tEpoch 10/20\n",
      "INFO\t2019-03-27 17:56:52 +0000\tmaster-replica-0\t\t  1/254 [..............................] - ETA: 0s - loss: 0.2766 - acc: 0.8906\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "INFO\t2019-03-27 17:56:52 +0000\tmaster-replica-0\t\t 18/254 [=>............................] - ETA: 0s - loss: 0.3305 - acc: 0.8507\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "INFO\t2019-03-27 17:56:52 +0000\tmaster-replica-0\t\t 33/254 [==>...........................] - ETA: 0s - loss: 0.3337 - acc: 0.8487\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "INFO\t2019-03-27 17:56:52 +0000\tmaster-replica-0\t\t 48/254 [====>.........................] - ETA: 0s - loss: 0.3414 - acc: 0.8439\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "INFO\t2019-03-27 17:56:52 +0000\tmaster-replica-0\t\t 62/254 [======>.......................] - ETA: 0s - loss: 0.3370 - acc: 0.8448\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "INFO\t2019-03-27 17:56:52 +0000\tmaster-replica-0\t\t 73/254 [=======>......................] - ETA: 0s - loss: 0.3332 - acc: 0.8472\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "INFO\t2019-03-27 17:56:52 +0000\tmaster-replica-0\t\t 84/254 [========>.....................] - ETA: 0s - loss: 0.3283 - acc: 0.8501\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "INFO\t2019-03-27 17:56:52 +0000\tmaster-replica-0\t\t 94/254 [==========>...................] - ETA: 0s - loss: 0.3290 - acc: 0.8503\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "INFO\t2019-03-27 17:56:52 +0000\tmaster-replica-0\t\t105/254 [===========>..................] - ETA: 0s - loss: 0.3292 - acc: 0.8510\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "INFO\t2019-03-27 17:56:52 +0000\tmaster-replica-0\t\t119/254 [=============>................] - ETA: 0s - loss: 0.3262 - acc: 0.8522\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "INFO\t2019-03-27 17:56:52 +0000\tmaster-replica-0\t\t133/254 [==============>...............] - ETA: 0s - loss: 0.3295 - acc: 0.8505\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "INFO\t2019-03-27 17:56:52 +0000\tmaster-replica-0\t\t148/254 [================>.............] - ETA: 0s - loss: 0.3296 - acc: 0.8493\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "INFO\t2019-03-27 17:56:52 +0000\tmaster-replica-0\t\t164/254 [==================>...........] - ETA: 0s - loss: 0.3290 - acc: 0.8492\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "INFO\t2019-03-27 17:56:53 +0000\tmaster-replica-0\t\t181/254 [====================>.........] - ETA: 0s - loss: 0.3303 - acc: 0.8485\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "INFO\t2019-03-27 17:56:53 +0000\tmaster-replica-0\t\t199/254 [======================>.......] - ETA: 0s - loss: 0.3291 - acc: 0.8492\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "INFO\t2019-03-27 17:56:53 +0000\tmaster-replica-0\t\t217/254 [========================>.....] - ETA: 0s - loss: 0.3297 - acc: 0.8496\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "INFO\t2019-03-27 17:56:53 +0000\tmaster-replica-0\t\t236/254 [==========================>...] - ETA: 0s - loss: 0.3295 - acc: 0.8496\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "INFO\t2019-03-27 17:56:53 +0000\tmaster-replica-0\t\t254/254 [==============================] - 1s 4ms/step - loss: 0.3291 - acc: 0.8494 - val_loss: 0.3264 - val_acc: 0.8516\n",
      "INFO\t2019-03-27 17:56:53 +0000\tmaster-replica-0\t\tEpoch 00011: LearningRateScheduler reducing learning rate to 0.010009765625.\n",
      "INFO\t2019-03-27 17:56:53 +0000\tmaster-replica-0\t\tEpoch 11/20\n",
      "INFO\t2019-03-27 17:56:53 +0000\tmaster-replica-0\t\t  1/254 [..............................] - ETA: 0s - loss: 0.3474 - acc: 0.8594\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "INFO\t2019-03-27 17:56:53 +0000\tmaster-replica-0\t\t 18/254 [=>............................] - ETA: 0s - loss: 0.3394 - acc: 0.8572\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "INFO\t2019-03-27 17:56:53 +0000\tmaster-replica-0\t\t 37/254 [===>..........................] - ETA: 0s - loss: 0.3287 - acc: 0.8554\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "INFO\t2019-03-27 17:56:53 +0000\tmaster-replica-0\t\t 56/254 [=====>........................] - ETA: 0s - loss: 0.3220 - acc: 0.8559\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "INFO\t2019-03-27 17:56:53 +0000\tmaster-replica-0\t\t 74/254 [=======>......................] - ETA: 0s - loss: 0.3257 - acc: 0.8545\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "INFO\t2019-03-27 17:56:53 +0000\tmaster-replica-0\t\t 92/254 [=========>....................] - ETA: 0s - loss: 0.3259 - acc: 0.8527\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "INFO\t2019-03-27 17:56:53 +0000\tmaster-replica-0\t\t111/254 [============>.................] - ETA: 0s - loss: 0.3267 - acc: 0.8504\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "INFO\t2019-03-27 17:56:53 +0000\tmaster-replica-0\t\t130/254 [==============>...............] - ETA: 0s - loss: 0.3266 - acc: 0.8497\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "INFO\t2019-03-27 17:56:53 +0000\tmaster-replica-0\t\t147/254 [================>.............] - ETA: 0s - loss: 0.3260 - acc: 0.8510\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "INFO\t2019-03-27 17:56:53 +0000\tmaster-replica-0\t\t166/254 [==================>...........] - ETA: 0s - loss: 0.3253 - acc: 0.8500\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "INFO\t2019-03-27 17:56:53 +0000\tmaster-replica-0\t\t185/254 [====================>.........] - ETA: 0s - loss: 0.3249 - acc: 0.8502\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "INFO\t2019-03-27 17:56:53 +0000\tmaster-replica-0\t\t204/254 [=======================>......] - ETA: 0s - loss: 0.3257 - acc: 0.8496\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "INFO\t2019-03-27 17:56:53 +0000\tmaster-replica-0\t\t221/254 [=========================>....] - ETA: 0s - loss: 0.3275 - acc: 0.8496\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "INFO\t2019-03-27 17:56:53 +0000\tmaster-replica-0\t\t241/254 [===========================>..] - ETA: 0s - loss: 0.3264 - acc: 0.8496\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "INFO\t2019-03-27 17:56:53 +0000\tmaster-replica-0\t\t254/254 [==============================] - 1s 3ms/step - loss: 0.3270 - acc: 0.8494 - val_loss: 0.3246 - val_acc: 0.8499\n",
      "INFO\t2019-03-27 17:56:53 +0000\tmaster-replica-0\t\tEpoch 00012: LearningRateScheduler reducing learning rate to 0.010004882812500001.\n",
      "INFO\t2019-03-27 17:56:53 +0000\tmaster-replica-0\t\tEpoch 12/20\n",
      "INFO\t2019-03-27 17:56:54 +0000\tmaster-replica-0\t\t  1/254 [..............................] - ETA: 0s - loss: 0.3179 - acc: 0.8516\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "INFO\t2019-03-27 17:56:54 +0000\tmaster-replica-0\t\t 19/254 [=>............................] - ETA: 0s - loss: 0.3353 - acc: 0.8433\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "INFO\t2019-03-27 17:56:54 +0000\tmaster-replica-0\t\t 39/254 [===>..........................] - ETA: 0s - loss: 0.3319 - acc: 0.8482\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "INFO\t2019-03-27 17:56:54 +0000\tmaster-replica-0\t\t 59/254 [=====>........................] - ETA: 0s - loss: 0.3268 - acc: 0.8546\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "INFO\t2019-03-27 17:56:54 +0000\tmaster-replica-0\t\t 79/254 [========>.....................] - ETA: 0s - loss: 0.3309 - acc: 0.8492\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "INFO\t2019-03-27 17:56:54 +0000\tmaster-replica-0\t\t 99/254 [==========>...................] - ETA: 0s - loss: 0.3315 - acc: 0.8509\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "INFO\t2019-03-27 17:56:54 +0000\tmaster-replica-0\t\t119/254 [=============>................] - ETA: 0s - loss: 0.3311 - acc: 0.8513\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "INFO\t2019-03-27 17:56:54 +0000\tmaster-replica-0\t\t135/254 [==============>...............] - ETA: 0s - loss: 0.3284 - acc: 0.8524\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "INFO\t2019-03-27 17:56:54 +0000\tmaster-replica-0\t\t153/254 [=================>............] - ETA: 0s - loss: 0.3270 - acc: 0.8516\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "INFO\t2019-03-27 17:56:54 +0000\tmaster-replica-0\t\t172/254 [===================>..........] - ETA: 0s - loss: 0.3263 - acc: 0.8517\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "INFO\t2019-03-27 17:56:54 +0000\tmaster-replica-0\t\t190/254 [=====================>........] - ETA: 0s - loss: 0.3263 - acc: 0.8513\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "INFO\t2019-03-27 17:56:54 +0000\tmaster-replica-0\t\t206/254 [=======================>......] - ETA: 0s - loss: 0.3271 - acc: 0.8509\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "INFO\t2019-03-27 17:56:54 +0000\tmaster-replica-0\t\t225/254 [=========================>....] - ETA: 0s - loss: 0.3274 - acc: 0.8505\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "INFO\t2019-03-27 17:56:54 +0000\tmaster-replica-0\t\t242/254 [===========================>..] - ETA: 0s - loss: 0.3271 - acc: 0.8505\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "INFO\t2019-03-27 17:56:54 +0000\tmaster-replica-0\t\t254/254 [==============================] - 1s 3ms/step - loss: 0.3276 - acc: 0.8500 - val_loss: 0.3452 - val_acc: 0.8444\n",
      "INFO\t2019-03-27 17:56:54 +0000\tmaster-replica-0\t\tEpoch 00013: LearningRateScheduler reducing learning rate to 0.01000244140625.\n",
      "INFO\t2019-03-27 17:56:54 +0000\tmaster-replica-0\t\tEpoch 13/20\n",
      "INFO\t2019-03-27 17:56:54 +0000\tmaster-replica-0\t\t  1/254 [..............................] - ETA: 0s - loss: 0.3248 - acc: 0.8516\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "INFO\t2019-03-27 17:56:54 +0000\tmaster-replica-0\t\t 19/254 [=>............................] - ETA: 0s - loss: 0.3278 - acc: 0.8376\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "INFO\t2019-03-27 17:56:54 +0000\tmaster-replica-0\t\t 38/254 [===>..........................] - ETA: 0s - loss: 0.3317 - acc: 0.8425\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "INFO\t2019-03-27 17:56:54 +0000\tmaster-replica-0\t\t 53/254 [=====>........................] - ETA: 0s - loss: 0.3286 - acc: 0.8464\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "INFO\t2019-03-27 17:56:55 +0000\tmaster-replica-0\t\t 71/254 [=======>......................] - ETA: 0s - loss: 0.3204 - acc: 0.8524\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "INFO\t2019-03-27 17:56:55 +0000\tmaster-replica-0\t\t 88/254 [=========>....................] - ETA: 0s - loss: 0.3232 - acc: 0.8511\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "INFO\t2019-03-27 17:56:55 +0000\tmaster-replica-0\t\t105/254 [===========>..................] - ETA: 0s - loss: 0.3271 - acc: 0.8512\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "INFO\t2019-03-27 17:56:55 +0000\tmaster-replica-0\t\t124/254 [=============>................] - ETA: 0s - loss: 0.3308 - acc: 0.8484\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "INFO\t2019-03-27 17:56:55 +0000\tmaster-replica-0\t\t141/254 [===============>..............] - ETA: 0s - loss: 0.3316 - acc: 0.8480\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "INFO\t2019-03-27 17:56:55 +0000\tmaster-replica-0\t\t157/254 [=================>............] - ETA: 0s - loss: 0.3294 - acc: 0.8488\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "INFO\t2019-03-27 17:56:55 +0000\tmaster-replica-0\t\t171/254 [===================>..........] - ETA: 0s - loss: 0.3298 - acc: 0.8480\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "INFO\t2019-03-27 17:56:55 +0000\tmaster-replica-0\t\t189/254 [=====================>........] - ETA: 0s - loss: 0.3304 - acc: 0.8482\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "INFO\t2019-03-27 17:56:55 +0000\tmaster-replica-0\t\t206/254 [=======================>......] - ETA: 0s - loss: 0.3295 - acc: 0.8490\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "INFO\t2019-03-27 17:56:55 +0000\tmaster-replica-0\t\t225/254 [=========================>....] - ETA: 0s - loss: 0.3315 - acc: 0.8477\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "INFO\t2019-03-27 17:56:55 +0000\tmaster-replica-0\t\t242/254 [===========================>..] - ETA: 0s - loss: 0.3305 - acc: 0.8481\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "INFO\t2019-03-27 17:56:55 +0000\tmaster-replica-0\t\t254/254 [==============================] - 1s 3ms/step - loss: 0.3301 - acc: 0.8485 - val_loss: 0.3439 - val_acc: 0.8439\n",
      "INFO\t2019-03-27 17:56:55 +0000\tmaster-replica-0\t\tEpoch 00014: LearningRateScheduler reducing learning rate to 0.010001220703125.\n",
      "INFO\t2019-03-27 17:56:55 +0000\tmaster-replica-0\t\tEpoch 14/20\n",
      "INFO\t2019-03-27 17:56:55 +0000\tmaster-replica-0\t\t  1/254 [..............................] - ETA: 1s - loss: 0.3098 - acc: 0.8906\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "INFO\t2019-03-27 17:56:55 +0000\tmaster-replica-0\t\t 16/254 [>.............................] - ETA: 0s - loss: 0.3104 - acc: 0.8550\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "INFO\t2019-03-27 17:56:55 +0000\tmaster-replica-0\t\t 33/254 [==>...........................] - ETA: 0s - loss: 0.3184 - acc: 0.8520\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "INFO\t2019-03-27 17:56:55 +0000\tmaster-replica-0\t\t 49/254 [====>.........................] - ETA: 0s - loss: 0.3204 - acc: 0.8520\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "INFO\t2019-03-27 17:56:55 +0000\tmaster-replica-0\t\t 64/254 [======>.......................] - ETA: 0s - loss: 0.3218 - acc: 0.8510\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "INFO\t2019-03-27 17:56:55 +0000\tmaster-replica-0\t\t 80/254 [========>.....................] - ETA: 0s - loss: 0.3252 - acc: 0.8482\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "INFO\t2019-03-27 17:56:55 +0000\tmaster-replica-0\t\t 96/254 [==========>...................] - ETA: 0s - loss: 0.3242 - acc: 0.8476\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "INFO\t2019-03-27 17:56:56 +0000\tmaster-replica-0\t\t112/254 [============>.................] - ETA: 0s - loss: 0.3230 - acc: 0.8488\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "INFO\t2019-03-27 17:56:56 +0000\tmaster-replica-0\t\t129/254 [==============>...............] - ETA: 0s - loss: 0.3256 - acc: 0.8485\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "INFO\t2019-03-27 17:56:56 +0000\tmaster-replica-0\t\t144/254 [================>.............] - ETA: 0s - loss: 0.3255 - acc: 0.8480\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "INFO\t2019-03-27 17:56:56 +0000\tmaster-replica-0\t\t162/254 [==================>...........] - ETA: 0s - loss: 0.3251 - acc: 0.8479\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "INFO\t2019-03-27 17:56:56 +0000\tmaster-replica-0\t\t177/254 [===================>..........] - ETA: 0s - loss: 0.3249 - acc: 0.8488\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "INFO\t2019-03-27 17:56:56 +0000\tmaster-replica-0\t\t195/254 [======================>.......] - ETA: 0s - loss: 0.3263 - acc: 0.8482\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "INFO\t2019-03-27 17:56:56 +0000\tmaster-replica-0\t\t211/254 [=======================>......] - ETA: 0s - loss: 0.3261 - acc: 0.8489\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "INFO\t2019-03-27 17:56:56 +0000\tmaster-replica-0\t\t227/254 [=========================>....] - ETA: 0s - loss: 0.3257 - acc: 0.8497\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "INFO\t2019-03-27 17:56:56 +0000\tmaster-replica-0\t\t242/254 [===========================>..] - ETA: 0s - loss: 0.3262 - acc: 0.8502\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "INFO\t2019-03-27 17:56:56 +0000\tmaster-replica-0\t\t254/254 [==============================] - 1s 4ms/step - loss: 0.3265 - acc: 0.8503 - val_loss: 0.3399 - val_acc: 0.8413\n",
      "INFO\t2019-03-27 17:56:56 +0000\tmaster-replica-0\t\tEpoch 00015: LearningRateScheduler reducing learning rate to 0.0100006103515625.\n",
      "INFO\t2019-03-27 17:56:56 +0000\tmaster-replica-0\t\tEpoch 15/20\n",
      "INFO\t2019-03-27 17:56:56 +0000\tmaster-replica-0\t\t  1/254 [..............................] - ETA: 1s - loss: 0.2755 - acc: 0.8594\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "INFO\t2019-03-27 17:56:56 +0000\tmaster-replica-0\t\t 14/254 [>.............................] - ETA: 0s - loss: 0.3182 - acc: 0.8482\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "INFO\t2019-03-27 17:56:56 +0000\tmaster-replica-0\t\t 27/254 [==>...........................] - ETA: 0s - loss: 0.3285 - acc: 0.8466\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "INFO\t2019-03-27 17:56:56 +0000\tmaster-replica-0\t\t 39/254 [===>..........................] - ETA: 0s - loss: 0.3268 - acc: 0.8496\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "INFO\t2019-03-27 17:56:56 +0000\tmaster-replica-0\t\t 47/254 [====>.........................] - ETA: 0s - loss: 0.3321 - acc: 0.8499\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "INFO\t2019-03-27 17:56:56 +0000\tmaster-replica-0\t\t 59/254 [=====>........................] - ETA: 0s - loss: 0.3231 - acc: 0.8538\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "INFO\t2019-03-27 17:56:56 +0000\tmaster-replica-0\t\t 72/254 [=======>......................] - ETA: 0s - loss: 0.3262 - acc: 0.8516\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "INFO\t2019-03-27 17:56:56 +0000\tmaster-replica-0\t\t 86/254 [=========>....................] - ETA: 0s - loss: 0.3273 - acc: 0.8483\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "INFO\t2019-03-27 17:56:56 +0000\tmaster-replica-0\t\t101/254 [==========>...................] - ETA: 0s - loss: 0.3294 - acc: 0.8476\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "INFO\t2019-03-27 17:56:57 +0000\tmaster-replica-0\t\t117/254 [============>.................] - ETA: 0s - loss: 0.3276 - acc: 0.8488\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "INFO\t2019-03-27 17:56:57 +0000\tmaster-replica-0\t\t131/254 [==============>...............] - ETA: 0s - loss: 0.3263 - acc: 0.8504\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "INFO\t2019-03-27 17:56:57 +0000\tmaster-replica-0\t\t148/254 [================>.............] - ETA: 0s - loss: 0.3250 - acc: 0.8513\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "INFO\t2019-03-27 17:56:57 +0000\tmaster-replica-0\t\t165/254 [==================>...........] - ETA: 0s - loss: 0.3260 - acc: 0.8511\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "INFO\t2019-03-27 17:56:57 +0000\tmaster-replica-0\t\t182/254 [====================>.........] - ETA: 0s - loss: 0.3261 - acc: 0.8510\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "INFO\t2019-03-27 17:56:57 +0000\tmaster-replica-0\t\t201/254 [======================>.......] - ETA: 0s - loss: 0.3259 - acc: 0.8504\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "INFO\t2019-03-27 17:56:57 +0000\tmaster-replica-0\t\t218/254 [========================>.....] - ETA: 0s - loss: 0.3261 - acc: 0.8502\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "INFO\t2019-03-27 17:56:57 +0000\tmaster-replica-0\t\t237/254 [==========================>...] - ETA: 0s - loss: 0.3266 - acc: 0.8506\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "INFO\t2019-03-27 17:56:57 +0000\tmaster-replica-0\t\t254/254 [==============================] - 1s 4ms/step - loss: 0.3285 - acc: 0.8496 - val_loss: 0.3191 - val_acc: 0.8499\n",
      "INFO\t2019-03-27 17:56:57 +0000\tmaster-replica-0\t\tEpoch 00016: LearningRateScheduler reducing learning rate to 0.01000030517578125.\n",
      "INFO\t2019-03-27 17:56:57 +0000\tmaster-replica-0\t\tEpoch 16/20\n",
      "INFO\t2019-03-27 17:56:57 +0000\tmaster-replica-0\t\t  1/254 [..............................] - ETA: 0s - loss: 0.3200 - acc: 0.8281\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "INFO\t2019-03-27 17:56:57 +0000\tmaster-replica-0\t\t 20/254 [=>............................] - ETA: 0s - loss: 0.3262 - acc: 0.8441\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "INFO\t2019-03-27 17:56:57 +0000\tmaster-replica-0\t\t 40/254 [===>..........................] - ETA: 0s - loss: 0.3369 - acc: 0.8436\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "INFO\t2019-03-27 17:56:57 +0000\tmaster-replica-0\t\t 59/254 [=====>........................] - ETA: 0s - loss: 0.3348 - acc: 0.8451\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "INFO\t2019-03-27 17:56:57 +0000\tmaster-replica-0\t\t 79/254 [========>.....................] - ETA: 0s - loss: 0.3302 - acc: 0.8462\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "INFO\t2019-03-27 17:56:57 +0000\tmaster-replica-0\t\t 98/254 [==========>...................] - ETA: 0s - loss: 0.3292 - acc: 0.8478\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "INFO\t2019-03-27 17:56:57 +0000\tmaster-replica-0\t\t117/254 [============>.................] - ETA: 0s - loss: 0.3301 - acc: 0.8468\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "INFO\t2019-03-27 17:56:57 +0000\tmaster-replica-0\t\t134/254 [==============>...............] - ETA: 0s - loss: 0.3275 - acc: 0.8482\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "INFO\t2019-03-27 17:56:57 +0000\tmaster-replica-0\t\t151/254 [================>.............] - ETA: 0s - loss: 0.3253 - acc: 0.8492\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "INFO\t2019-03-27 17:56:57 +0000\tmaster-replica-0\t\t167/254 [==================>...........] - ETA: 0s - loss: 0.3259 - acc: 0.8493\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "INFO\t2019-03-27 17:56:57 +0000\tmaster-replica-0\t\t185/254 [====================>.........] - ETA: 0s - loss: 0.3271 - acc: 0.8489\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "INFO\t2019-03-27 17:56:58 +0000\tmaster-replica-0\t\t205/254 [=======================>......] - ETA: 0s - loss: 0.3292 - acc: 0.8473\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "INFO\t2019-03-27 17:56:58 +0000\tmaster-replica-0\t\t224/254 [=========================>....] - ETA: 0s - loss: 0.3284 - acc: 0.8485\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "INFO\t2019-03-27 17:56:58 +0000\tmaster-replica-0\t\t244/254 [===========================>..] - ETA: 0s - loss: 0.3271 - acc: 0.8495\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "INFO\t2019-03-27 17:56:58 +0000\tmaster-replica-0\t\t254/254 [==============================] - 1s 3ms/step - loss: 0.3278 - acc: 0.8495 - val_loss: 0.3245 - val_acc: 0.8537\n",
      "INFO\t2019-03-27 17:56:58 +0000\tmaster-replica-0\t\tEpoch 00017: LearningRateScheduler reducing learning rate to 0.010000152587890625.\n",
      "INFO\t2019-03-27 17:56:58 +0000\tmaster-replica-0\t\tEpoch 17/20\n",
      "INFO\t2019-03-27 17:56:58 +0000\tmaster-replica-0\t\t  1/254 [..............................] - ETA: 0s - loss: 0.2615 - acc: 0.8828\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "INFO\t2019-03-27 17:56:58 +0000\tmaster-replica-0\t\t 19/254 [=>............................] - ETA: 0s - loss: 0.3367 - acc: 0.8442\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "INFO\t2019-03-27 17:56:58 +0000\tmaster-replica-0\t\t 37/254 [===>..........................] - ETA: 0s - loss: 0.3328 - acc: 0.8461\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "INFO\t2019-03-27 17:56:58 +0000\tmaster-replica-0\t\t 55/254 [=====>........................] - ETA: 0s - loss: 0.3300 - acc: 0.8503\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "INFO\t2019-03-27 17:56:58 +0000\tmaster-replica-0\t\t 71/254 [=======>......................] - ETA: 0s - loss: 0.3255 - acc: 0.8537\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "INFO\t2019-03-27 17:56:58 +0000\tmaster-replica-0\t\t 88/254 [=========>....................] - ETA: 0s - loss: 0.3239 - acc: 0.8533\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "INFO\t2019-03-27 17:56:58 +0000\tmaster-replica-0\t\t105/254 [===========>..................] - ETA: 0s - loss: 0.3245 - acc: 0.8519\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "INFO\t2019-03-27 17:56:58 +0000\tmaster-replica-0\t\t122/254 [=============>................] - ETA: 0s - loss: 0.3234 - acc: 0.8515\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "INFO\t2019-03-27 17:56:58 +0000\tmaster-replica-0\t\t139/254 [===============>..............] - ETA: 0s - loss: 0.3218 - acc: 0.8526\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "INFO\t2019-03-27 17:56:58 +0000\tmaster-replica-0\t\t156/254 [=================>............] - ETA: 0s - loss: 0.3244 - acc: 0.8518\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "INFO\t2019-03-27 17:56:58 +0000\tmaster-replica-0\t\t172/254 [===================>..........] - ETA: 0s - loss: 0.3267 - acc: 0.8508\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "INFO\t2019-03-27 17:56:58 +0000\tmaster-replica-0\t\t188/254 [=====================>........] - ETA: 0s - loss: 0.3286 - acc: 0.8497\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "INFO\t2019-03-27 17:56:58 +0000\tmaster-replica-0\t\t203/254 [======================>.......] - ETA: 0s - loss: 0.3278 - acc: 0.8500\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "INFO\t2019-03-27 17:56:58 +0000\tmaster-replica-0\t\t219/254 [========================>.....] - ETA: 0s - loss: 0.3263 - acc: 0.8503\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "INFO\t2019-03-27 17:56:59 +0000\tmaster-replica-0\t\t236/254 [==========================>...] - ETA: 0s - loss: 0.3270 - acc: 0.8502\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "INFO\t2019-03-27 17:56:59 +0000\tmaster-replica-0\t\t254/254 [==============================] - 1s 3ms/step - loss: 0.3270 - acc: 0.8500 - val_loss: 0.3272 - val_acc: 0.8521\n",
      "INFO\t2019-03-27 17:56:59 +0000\tmaster-replica-0\t\tEpoch 00018: LearningRateScheduler reducing learning rate to 0.010000076293945313.\n",
      "INFO\t2019-03-27 17:56:59 +0000\tmaster-replica-0\t\tEpoch 18/20\n",
      "INFO\t2019-03-27 17:56:59 +0000\tmaster-replica-0\t\t  1/254 [..............................] - ETA: 1s - loss: 0.3422 - acc: 0.8281\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "INFO\t2019-03-27 17:56:59 +0000\tmaster-replica-0\t\t 16/254 [>.............................] - ETA: 0s - loss: 0.3106 - acc: 0.8506\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "INFO\t2019-03-27 17:56:59 +0000\tmaster-replica-0\t\t 32/254 [==>...........................] - ETA: 0s - loss: 0.3128 - acc: 0.8508\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "INFO\t2019-03-27 17:56:59 +0000\tmaster-replica-0\t\t 47/254 [====>.........................] - ETA: 0s - loss: 0.3246 - acc: 0.8477\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "INFO\t2019-03-27 17:56:59 +0000\tmaster-replica-0\t\t 63/254 [======>.......................] - ETA: 0s - loss: 0.3241 - acc: 0.8508\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "INFO\t2019-03-27 17:56:59 +0000\tmaster-replica-0\t\t 79/254 [========>.....................] - ETA: 0s - loss: 0.3233 - acc: 0.8495\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "INFO\t2019-03-27 17:56:59 +0000\tmaster-replica-0\t\t 95/254 [==========>...................] - ETA: 0s - loss: 0.3282 - acc: 0.8479\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "INFO\t2019-03-27 17:56:59 +0000\tmaster-replica-0\t\t111/254 [============>.................] - ETA: 0s - loss: 0.3282 - acc: 0.8470\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "INFO\t2019-03-27 17:56:59 +0000\tmaster-replica-0\t\t126/254 [=============>................] - ETA: 0s - loss: 0.3266 - acc: 0.8486\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "INFO\t2019-03-27 17:56:59 +0000\tmaster-replica-0\t\t145/254 [================>.............] - ETA: 0s - loss: 0.3273 - acc: 0.8484\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "INFO\t2019-03-27 17:56:59 +0000\tmaster-replica-0\t\t163/254 [==================>...........] - ETA: 0s - loss: 0.3287 - acc: 0.8471\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "INFO\t2019-03-27 17:56:59 +0000\tmaster-replica-0\t\t178/254 [====================>.........] - ETA: 0s - loss: 0.3267 - acc: 0.8485\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "INFO\t2019-03-27 17:56:59 +0000\tmaster-replica-0\t\t194/254 [=====================>........] - ETA: 0s - loss: 0.3253 - acc: 0.8494\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "INFO\t2019-03-27 17:56:59 +0000\tmaster-replica-0\t\t209/254 [=======================>......] - ETA: 0s - loss: 0.3248 - acc: 0.8497\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "INFO\t2019-03-27 17:56:59 +0000\tmaster-replica-0\t\t224/254 [=========================>....] - ETA: 0s - loss: 0.3249 - acc: 0.8495\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "INFO\t2019-03-27 17:56:59 +0000\tmaster-replica-0\t\t240/254 [===========================>..] - ETA: 0s - loss: 0.3254 - acc: 0.8494\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "INFO\t2019-03-27 17:56:59 +0000\tmaster-replica-0\t\t254/254 [==============================] - 1s 4ms/step - loss: 0.3244 - acc: 0.8493 - val_loss: 0.3271 - val_acc: 0.8508\n",
      "INFO\t2019-03-27 17:56:59 +0000\tmaster-replica-0\t\tEpoch 00019: LearningRateScheduler reducing learning rate to 0.010000038146972657.\n",
      "INFO\t2019-03-27 17:56:59 +0000\tmaster-replica-0\t\tEpoch 19/20\n",
      "INFO\t2019-03-27 17:57:00 +0000\tmaster-replica-0\t\t  1/254 [..............................] - ETA: 1s - loss: 0.4041 - acc: 0.8516\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "INFO\t2019-03-27 17:57:00 +0000\tmaster-replica-0\t\t 16/254 [>.............................] - ETA: 0s - loss: 0.3522 - acc: 0.8467\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "INFO\t2019-03-27 17:57:00 +0000\tmaster-replica-0\t\t 33/254 [==>...........................] - ETA: 0s - loss: 0.3445 - acc: 0.8492\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "INFO\t2019-03-27 17:57:00 +0000\tmaster-replica-0\t\t 50/254 [====>.........................] - ETA: 0s - loss: 0.3336 - acc: 0.8500\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "INFO\t2019-03-27 17:57:00 +0000\tmaster-replica-0\t\t 65/254 [======>.......................] - ETA: 0s - loss: 0.3331 - acc: 0.8520\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "INFO\t2019-03-27 17:57:00 +0000\tmaster-replica-0\t\t 84/254 [========>.....................] - ETA: 0s - loss: 0.3301 - acc: 0.8520\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "INFO\t2019-03-27 17:57:00 +0000\tmaster-replica-0\t\t102/254 [===========>..................] - ETA: 0s - loss: 0.3289 - acc: 0.8513\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "INFO\t2019-03-27 17:57:00 +0000\tmaster-replica-0\t\t118/254 [============>.................] - ETA: 0s - loss: 0.3290 - acc: 0.8505\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "INFO\t2019-03-27 17:57:00 +0000\tmaster-replica-0\t\t134/254 [==============>...............] - ETA: 0s - loss: 0.3310 - acc: 0.8502\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "INFO\t2019-03-27 17:57:00 +0000\tmaster-replica-0\t\t154/254 [=================>............] - ETA: 0s - loss: 0.3283 - acc: 0.8517\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "INFO\t2019-03-27 17:57:00 +0000\tmaster-replica-0\t\t173/254 [===================>..........] - ETA: 0s - loss: 0.3270 - acc: 0.8511\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "INFO\t2019-03-27 17:57:00 +0000\tmaster-replica-0\t\t190/254 [=====================>........] - ETA: 0s - loss: 0.3266 - acc: 0.8501\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "INFO\t2019-03-27 17:57:00 +0000\tmaster-replica-0\t\t201/254 [======================>.......] - ETA: 0s - loss: 0.3260 - acc: 0.8504\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "INFO\t2019-03-27 17:57:00 +0000\tmaster-replica-0\t\t217/254 [========================>.....] - ETA: 0s - loss: 0.3281 - acc: 0.8502\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "INFO\t2019-03-27 17:57:00 +0000\tmaster-replica-0\t\t231/254 [==========================>...] - ETA: 0s - loss: 0.3281 - acc: 0.8502\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "INFO\t2019-03-27 17:57:00 +0000\tmaster-replica-0\t\t242/254 [===========================>..] - ETA: 0s - loss: 0.3270 - acc: 0.8508\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "INFO\t2019-03-27 17:57:00 +0000\tmaster-replica-0\t\t254/254 [==============================] - 1s 4ms/step - loss: 0.3281 - acc: 0.8504 - val_loss: 0.3239 - val_acc: 0.8521\n",
      "INFO\t2019-03-27 17:57:00 +0000\tmaster-replica-0\t\tEpoch 00020: LearningRateScheduler reducing learning rate to 0.010000019073486329.\n",
      "INFO\t2019-03-27 17:57:00 +0000\tmaster-replica-0\t\tEpoch 20/20\n",
      "INFO\t2019-03-27 17:57:00 +0000\tmaster-replica-0\t\t  1/254 [..............................] - ETA: 0s - loss: 0.2766 - acc: 0.8672\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "INFO\t2019-03-27 17:57:00 +0000\tmaster-replica-0\t\t 20/254 [=>............................] - ETA: 0s - loss: 0.3260 - acc: 0.8504\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "INFO\t2019-03-27 17:57:01 +0000\tmaster-replica-0\t\t 37/254 [===>..........................] - ETA: 0s - loss: 0.3271 - acc: 0.8476\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "INFO\t2019-03-27 17:57:01 +0000\tmaster-replica-0\t\t 58/254 [=====>........................] - ETA: 0s - loss: 0.3302 - acc: 0.8479\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "INFO\t2019-03-27 17:57:01 +0000\tmaster-replica-0\t\t 79/254 [========>.....................] - ETA: 0s - loss: 0.3354 - acc: 0.8473\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "INFO\t2019-03-27 17:57:01 +0000\tmaster-replica-0\t\t 98/254 [==========>...................] - ETA: 0s - loss: 0.3344 - acc: 0.8465\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "INFO\t2019-03-27 17:57:01 +0000\tmaster-replica-0\t\t119/254 [=============>................] - ETA: 0s - loss: 0.3318 - acc: 0.8491\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "INFO\t2019-03-27 17:57:01 +0000\tmaster-replica-0\t\t139/254 [===============>..............] - ETA: 0s - loss: 0.3314 - acc: 0.8502\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "INFO\t2019-03-27 17:57:01 +0000\tmaster-replica-0\t\t156/254 [=================>............] - ETA: 0s - loss: 0.3316 - acc: 0.8502\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "INFO\t2019-03-27 17:57:01 +0000\tmaster-replica-0\t\t175/254 [===================>..........] - ETA: 0s - loss: 0.3317 - acc: 0.8510\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "INFO\t2019-03-27 17:57:01 +0000\tmaster-replica-0\t\t192/254 [=====================>........] - ETA: 0s - loss: 0.3309 - acc: 0.8508\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "INFO\t2019-03-27 17:57:01 +0000\tmaster-replica-0\t\t212/254 [========================>.....] - ETA: 0s - loss: 0.3296 - acc: 0.8507\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "INFO\t2019-03-27 17:57:01 +0000\tmaster-replica-0\t\t231/254 [==========================>...] - ETA: 0s - loss: 0.3282 - acc: 0.8509\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "INFO\t2019-03-27 17:57:01 +0000\tmaster-replica-0\t\t250/254 [============================>.] - ETA: 0s - loss: 0.3294 - acc: 0.8508\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "INFO\t2019-03-27 17:57:01 +0000\tmaster-replica-0\t\t254/254 [==============================] - 1s 3ms/step - loss: 0.3294 - acc: 0.8508 - val_loss: 0.3282 - val_acc: 0.8519\n",
      "WARNING\t2019-03-27 17:57:03 +0000\tmaster-replica-0\t\tThis model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.RMSprop object at 0x7f3904fa0518>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "WARNING\t2019-03-27 17:57:03 +0000\tmaster-replica-0\t\t\n",
      "WARNING\t2019-03-27 17:57:03 +0000\tmaster-replica-0\t\tConsider using a TensorFlow optimizer from `tf.train`.\n",
      "WARNING\t2019-03-27 17:57:05 +0000\tmaster-replica-0\t\tFrom /usr/local/lib/python3.5/dist-packages/tensorflow/python/keras/engine/network.py:1436: update_checkpoint_state (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "WARNING\t2019-03-27 17:57:05 +0000\tmaster-replica-0\t\tInstructions for updating:\n",
      "WARNING\t2019-03-27 17:57:05 +0000\tmaster-replica-0\t\tUse tf.train.CheckpointManager to manage checkpoints rather than manually editing the Checkpoint proto.\n",
      "WARNING\t2019-03-27 17:57:05 +0000\tmaster-replica-0\t\tModel was compiled with an optimizer, but the optimizer is not from `tf.train` (e.g. `tf.train.AdagradOptimizer`). Only the serving graph was exported. The train and evaluate graphs were not added to the SavedModel.\n",
      "WARNING\t2019-03-27 17:57:10 +0000\tmaster-replica-0\t\tFrom /usr/local/lib/python3.5/dist-packages/tensorflow/python/saved_model/signature_def_utils_impl.py:205: build_tensor_info (from tensorflow.python.saved_model.utils_impl) is deprecated and will be removed in a future version.\n",
      "WARNING\t2019-03-27 17:57:10 +0000\tmaster-replica-0\t\tInstructions for updating:\n",
      "WARNING\t2019-03-27 17:57:10 +0000\tmaster-replica-0\t\tThis function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.utils.build_tensor_info or tf.compat.v1.saved_model.build_tensor_info.\n",
      "INFO\t2019-03-27 17:57:10 +0000\tmaster-replica-0\t\tSignatures INCLUDED in export for Classify: None\n",
      "INFO\t2019-03-27 17:57:10 +0000\tmaster-replica-0\t\tSignatures INCLUDED in export for Eval: None\n",
      "INFO\t2019-03-27 17:57:10 +0000\tmaster-replica-0\t\tSignatures INCLUDED in export for Predict: ['serving_default']\n",
      "INFO\t2019-03-27 17:57:10 +0000\tmaster-replica-0\t\tSignatures INCLUDED in export for Regress: None\n",
      "INFO\t2019-03-27 17:57:10 +0000\tmaster-replica-0\t\tSignatures INCLUDED in export for Train: None\n",
      "INFO\t2019-03-27 17:57:10 +0000\tmaster-replica-0\t\tNo assets to save.\n",
      "INFO\t2019-03-27 17:57:10 +0000\tmaster-replica-0\t\tNo assets to write.\n",
      "INFO\t2019-03-27 17:57:10 +0000\tmaster-replica-0\t\tSavedModel written to: gs://<your-bucket-name>/keras-job-dir/keras_export/1553709421/saved_model.pb\n",
      "INFO\t2019-03-27 17:57:11 +0000\tmaster-replica-0\t\tModel exported to:  gs://<your-bucket-name>/keras-job-dir/keras_export/1553709421\n",
      "INFO\t2019-03-27 17:57:11 +0000\tmaster-replica-0\t\tModule completed; cleaning up.\n",
      "INFO\t2019-03-27 17:57:11 +0000\tmaster-replica-0\t\tClean up finished.\n",
      "INFO\t2019-03-27 17:57:11 +0000\tmaster-replica-0\t\tTask completed successfully.\n",
      "endTime: '2019-03-27T18:01:46'\n",
      "jobId: my_first_keras_job\n",
      "startTime: '2019-03-27T17:55:34'\n",
      "state: SUCCEEDED\n"
     ]
    }
   ],
   "source": [
    "! gcloud ai-platform jobs submit training $JOB_NAME \\\n",
    "  --package-path trainer/ \\\n",
    "  --module-name trainer.task \\\n",
    "  --region $REGION \\\n",
    "  --python-version 3.5 \\\n",
    "  --runtime-version 1.13 \\\n",
    "  --job-dir $JOB_DIR \\\n",
    "  --stream-logs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "J2WGqwAzc3xM"
   },
   "source": [
    "### Hyperparameter tuning\n",
    "\n",
    "You can optionally perform hyperparameter tuning by using the included\n",
    "`hptuning_config.yaml` configuration file. This file tells AI Platform to tune the batch size and learning rate for training over multiple trials to maximize accuracy.\n",
    "\n",
    "In this example, the training code uses a [TensorBoard\n",
    "callback](https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/TensorBoard),\n",
    "which [creates TensorFlow `Summary`\n",
    "`Event`s](https://www.tensorflow.org/api_docs/python/tf/summary/FileWriter#add_summary)\n",
    "during training. AI Platform uses these events to track the metric you want to\n",
    "optimize. Learn more about [hyperparameter tuning in\n",
    "AI Platform Training](https://cloud.google.com/ml-engine/docs/tensorflow/hyperparameter-tuning-overview)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "JOB_NAME = 'my_first_keras_job'\n",
    "JOB_DIR = 'gs://mo_ml/lingh/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``` \n",
    "hptuning_config.yaml\n",
    "trainingInput:\n",
    "  hyperparameters:\n",
    "    goal: MAXIMIZE\n",
    "    maxTrials: 4\n",
    "    maxParallelTrials: 2\n",
    "    hyperparameterMetricTag: epoch_acc\n",
    "    params:\n",
    "    - parameterName: batch-size\n",
    "      type: INTEGER\n",
    "      minValue: 8\n",
    "      maxValue: 256\n",
    "      scaleType: UNIT_LINEAR_SCALE\n",
    "    - parameterName: learning-rate\n",
    "      type: DOUBLE\n",
    "      minValue: 0.01\n",
    "      maxValue: 0.1\n",
    "      scaleType: UNIT_LOG_SCALE```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4413_p7Bc3xM"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job [my_first_keras_job] submitted successfully.\n",
      "INFO\t2019-09-09 14:37:51 -0400\tservice\t\tValidating job requirements...\n",
      "INFO\t2019-09-09 14:37:52 -0400\tservice\t\tJob creation request has been successfully validated.\n",
      "INFO\t2019-09-09 14:37:53 -0400\tservice\t\tJob my_first_keras_job is queued.\n",
      "INFO\t2019-09-09 14:38:02 -0400\tservice\t1\tWaiting for job to be provisioned.\n",
      "INFO\t2019-09-09 14:38:02 -0400\tservice\t2\tWaiting for job to be provisioned.\n",
      "INFO\t2019-09-09 14:38:05 -0400\tservice\t2\tWaiting for training program to start.\n",
      "INFO\t2019-09-09 14:38:05 -0400\tservice\t1\tWaiting for training program to start.\n",
      "INFO\t2019-09-09 14:38:40 -0400\tmaster-replica-0\t2\tRunning task with arguments: --cluster={\"master\": [\"127.0.0.1:2222\"]} --task={\"type\": \"master\", \"index\": 0, \"trial\": \"2\"} --job={  \"package_uris\": [\"gs://mo_ml/lingh/packages/9fef4d587f7511880b857ce6206af1b88acb9c4b12e9f72266cf68d36e785c0f/trainer-0.0.0.tar.gz\"],  \"python_module\": \"trainer.task\",  \"hyperparameters\": {    \"goal\": \"MAXIMIZE\",    \"params\": [{      \"parameter_name\": \"batch-size\",      \"min_value\": 8.0,      \"max_value\": 256.0,      \"type\": \"INTEGER\",      \"scale_type\": \"UNIT_LINEAR_SCALE\"    }, {      \"parameter_name\": \"learning-rate\",      \"min_value\": 0.01,      \"max_value\": 0.1,      \"type\": \"DOUBLE\",      \"scale_type\": \"UNIT_LOG_SCALE\"    }],    \"max_trials\": 4,    \"max_parallel_trials\": 2,    \"hyperparameter_metric_tag\": \"epoch_acc\"  },  \"region\": \"us-east1\",  \"runtime_version\": \"1.13\",  \"job_dir\": \"gs://mo_ml/lingh/\",  \"run_on_raw_vm\": true,  \"python_version\": \"3.5\"} --hyperparams={\"batch-size\":\"114\",\"learning-rate\":\"0.039047817272779388\"}\n",
      "WARNING\t2019-09-09 14:38:58 -0400\tmaster-replica-0\t2\tFrom /usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "WARNING\t2019-09-09 14:38:58 -0400\tmaster-replica-0\t2\tInstructions for updating:\n",
      "WARNING\t2019-09-09 14:38:58 -0400\tmaster-replica-0\t2\tColocations handled automatically by placer.\n",
      "INFO\t2019-09-09 14:39:02 -0400\tmaster-replica-0\t2\tRunning module trainer.task.\n",
      "INFO\t2019-09-09 14:39:02 -0400\tmaster-replica-0\t2\tDownloading the package: gs://mo_ml/lingh/packages/9fef4d587f7511880b857ce6206af1b88acb9c4b12e9f72266cf68d36e785c0f/trainer-0.0.0.tar.gz\n",
      "INFO\t2019-09-09 14:39:02 -0400\tmaster-replica-0\t2\tRunning command: gsutil -q cp gs://mo_ml/lingh/packages/9fef4d587f7511880b857ce6206af1b88acb9c4b12e9f72266cf68d36e785c0f/trainer-0.0.0.tar.gz trainer-0.0.0.tar.gz\n",
      "INFO\t2019-09-09 14:39:04 -0400\tmaster-replica-0\t2\tInstalling the package: gs://mo_ml/lingh/packages/9fef4d587f7511880b857ce6206af1b88acb9c4b12e9f72266cf68d36e785c0f/trainer-0.0.0.tar.gz\n",
      "INFO\t2019-09-09 14:39:04 -0400\tmaster-replica-0\t2\tRunning command: pip3 install --user --upgrade --force-reinstall --no-deps trainer-0.0.0.tar.gz\n",
      "INFO\t2019-09-09 14:39:13 -0400\tmaster-replica-0\t2\tProcessing ./trainer-0.0.0.tar.gz\n",
      "INFO\t2019-09-09 14:39:13 -0400\tmaster-replica-0\t2\tGenerating grammar tables from /usr/lib/python3.5/lib2to3/Grammar.txt\n",
      "INFO\t2019-09-09 14:39:13 -0400\tmaster-replica-0\t2\tGenerating grammar tables from /usr/lib/python3.5/lib2to3/PatternGrammar.txt\n",
      "INFO\t2019-09-09 14:39:13 -0400\tmaster-replica-0\t2\tBuilding wheels for collected packages: trainer\n",
      "INFO\t2019-09-09 14:39:13 -0400\tmaster-replica-0\t2\t  Building wheel for trainer (setup.py): started\n",
      "INFO\t2019-09-09 14:39:14 -0400\tmaster-replica-0\t2\tGenerating grammar tables from /usr/lib/python3.5/lib2to3/Grammar.txt\n",
      "INFO\t2019-09-09 14:39:14 -0400\tmaster-replica-0\t2\tGenerating grammar tables from /usr/lib/python3.5/lib2to3/PatternGrammar.txt\n",
      "INFO\t2019-09-09 14:39:14 -0400\tmaster-replica-0\t2\t  Building wheel for trainer (setup.py): finished with status 'done'\n",
      "INFO\t2019-09-09 14:39:14 -0400\tmaster-replica-0\t2\t  Created wheel for trainer: filename=trainer-0.0.0-cp35-none-any.whl size=7836 sha256=0593f1bbb08e6d4d9d075f1a200ed07fb272f86c37840bb69b5b5370ed0d2aa8\n",
      "INFO\t2019-09-09 14:39:14 -0400\tmaster-replica-0\t2\t  Stored in directory: /root/.cache/pip/wheels/0d/1b/db/f8e86b296734f0b137e17e5d34862f4ae4faf8388755c6272f\n",
      "INFO\t2019-09-09 14:39:14 -0400\tmaster-replica-0\t2\tSuccessfully built trainer\n",
      "INFO\t2019-09-09 14:39:14 -0400\tmaster-replica-0\t2\tInstalling collected packages: trainer\n",
      "INFO\t2019-09-09 14:39:14 -0400\tmaster-replica-0\t2\tSuccessfully installed trainer-0.0.0\n",
      "INFO\t2019-09-09 14:39:14 -0400\tmaster-replica-0\t2\tRunning command: pip3 install --user trainer-0.0.0.tar.gz\n",
      "INFO\t2019-09-09 14:39:15 -0400\tmaster-replica-0\t2\tProcessing ./trainer-0.0.0.tar.gz\n",
      "INFO\t2019-09-09 14:39:15 -0400\tmaster-replica-0\t2\tGenerating grammar tables from /usr/lib/python3.5/lib2to3/Grammar.txt\n",
      "INFO\t2019-09-09 14:39:15 -0400\tmaster-replica-0\t2\tGenerating grammar tables from /usr/lib/python3.5/lib2to3/PatternGrammar.txt\n",
      "INFO\t2019-09-09 14:39:15 -0400\tmaster-replica-0\t2\tBuilding wheels for collected packages: trainer\n",
      "INFO\t2019-09-09 14:39:15 -0400\tmaster-replica-0\t2\t  Building wheel for trainer (setup.py): started\n",
      "INFO\t2019-09-09 14:39:16 -0400\tmaster-replica-0\t2\tGenerating grammar tables from /usr/lib/python3.5/lib2to3/Grammar.txt\n",
      "INFO\t2019-09-09 14:39:16 -0400\tmaster-replica-0\t2\tGenerating grammar tables from /usr/lib/python3.5/lib2to3/PatternGrammar.txt\n",
      "INFO\t2019-09-09 14:39:16 -0400\tmaster-replica-0\t2\t  Building wheel for trainer (setup.py): finished with status 'done'\n",
      "INFO\t2019-09-09 14:39:16 -0400\tmaster-replica-0\t2\t  Created wheel for trainer: filename=trainer-0.0.0-cp35-none-any.whl size=7836 sha256=d5e800dc7c95579a8e40d6309b199870c7632a08980f4317badb6b814474770e\n",
      "INFO\t2019-09-09 14:39:16 -0400\tmaster-replica-0\t2\t  Stored in directory: /root/.cache/pip/wheels/0d/1b/db/f8e86b296734f0b137e17e5d34862f4ae4faf8388755c6272f\n",
      "INFO\t2019-09-09 14:39:16 -0400\tmaster-replica-0\t2\tSuccessfully built trainer\n",
      "INFO\t2019-09-09 14:39:16 -0400\tmaster-replica-0\t2\tInstalling collected packages: trainer\n",
      "INFO\t2019-09-09 14:39:16 -0400\tmaster-replica-0\t2\t  Found existing installation: trainer 0.0.0\n",
      "INFO\t2019-09-09 14:39:16 -0400\tmaster-replica-0\t2\t    Uninstalling trainer-0.0.0:\n",
      "INFO\t2019-09-09 14:39:16 -0400\tmaster-replica-0\t2\t      Successfully uninstalled trainer-0.0.0\n",
      "INFO\t2019-09-09 14:39:16 -0400\tmaster-replica-0\t2\tSuccessfully installed trainer-0.0.0\n",
      "INFO\t2019-09-09 14:39:16 -0400\tmaster-replica-0\t2\tRunning command: python3 -m trainer.task --learning-rate 0.039047817272779388 --batch-size 114 --job-dir gs://mo_ml/lingh/2\n",
      "WARNING\t2019-09-09 14:39:21 -0400\tmaster-replica-0\t2\tFrom /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "WARNING\t2019-09-09 14:39:21 -0400\tmaster-replica-0\t2\tInstructions for updating:\n",
      "WARNING\t2019-09-09 14:39:21 -0400\tmaster-replica-0\t2\tColocations handled automatically by placer.\n",
      "INFO\t2019-09-09 14:39:21 -0400\tmaster-replica-0\t2\tYour CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
      "ERROR\t2019-09-09 14:39:21 -0400\tmaster-replica-0\t2\tUser settings:\n",
      "ERROR\t2019-09-09 14:39:21 -0400\tmaster-replica-0\t2\t   KMP_AFFINITY=granularity=fine,verbose,compact,1,0\n",
      "ERROR\t2019-09-09 14:39:21 -0400\tmaster-replica-0\t2\t   KMP_BLOCKTIME=0\n",
      "ERROR\t2019-09-09 14:39:21 -0400\tmaster-replica-0\t2\t   KMP_SETTINGS=1\n",
      "ERROR\t2019-09-09 14:39:21 -0400\tmaster-replica-0\t2\t   OMP_NUM_THREADS=4\n",
      "ERROR\t2019-09-09 14:39:21 -0400\tmaster-replica-0\t2\tEffective settings:\n",
      "ERROR\t2019-09-09 14:39:21 -0400\tmaster-replica-0\t2\t   KMP_ABORT_DELAY=0\n",
      "ERROR\t2019-09-09 14:39:21 -0400\tmaster-replica-0\t2\t   KMP_ADAPTIVE_LOCK_PROPS='1,1024'\n",
      "ERROR\t2019-09-09 14:39:21 -0400\tmaster-replica-0\t2\t   KMP_ALIGN_ALLOC=64\n",
      "ERROR\t2019-09-09 14:39:21 -0400\tmaster-replica-0\t2\t   KMP_ALL_THREADPRIVATE=128\n",
      "ERROR\t2019-09-09 14:39:21 -0400\tmaster-replica-0\t2\t   KMP_ATOMIC_MODE=2\n",
      "ERROR\t2019-09-09 14:39:21 -0400\tmaster-replica-0\t2\t   KMP_BLOCKTIME=0\n",
      "ERROR\t2019-09-09 14:39:21 -0400\tmaster-replica-0\t2\t   KMP_CPUINFO_FILE: value is not defined\n",
      "ERROR\t2019-09-09 14:39:21 -0400\tmaster-replica-0\t2\t   KMP_DETERMINISTIC_REDUCTION=false\n",
      "ERROR\t2019-09-09 14:39:21 -0400\tmaster-replica-0\t2\t   KMP_DEVICE_THREAD_LIMIT=2147483647\n",
      "ERROR\t2019-09-09 14:39:21 -0400\tmaster-replica-0\t2\t   KMP_DISP_HAND_THREAD=false\n",
      "ERROR\t2019-09-09 14:39:21 -0400\tmaster-replica-0\t2\t   KMP_DISP_NUM_BUFFERS=7\n",
      "ERROR\t2019-09-09 14:39:21 -0400\tmaster-replica-0\t2\t   KMP_DUPLICATE_LIB_OK=false\n",
      "ERROR\t2019-09-09 14:39:21 -0400\tmaster-replica-0\t2\t   KMP_FORCE_REDUCTION: value is not defined\n",
      "ERROR\t2019-09-09 14:39:21 -0400\tmaster-replica-0\t2\t   KMP_FOREIGN_THREADS_THREADPRIVATE=true\n",
      "ERROR\t2019-09-09 14:39:21 -0400\tmaster-replica-0\t2\t   KMP_FORKJOIN_BARRIER='2,2'\n",
      "ERROR\t2019-09-09 14:39:21 -0400\tmaster-replica-0\t2\t   KMP_FORKJOIN_BARRIER_PATTERN='hyper,hyper'\n",
      "ERROR\t2019-09-09 14:39:21 -0400\tmaster-replica-0\t2\t   KMP_FORKJOIN_FRAMES=true\n",
      "ERROR\t2019-09-09 14:39:21 -0400\tmaster-replica-0\t2\t   KMP_FORKJOIN_FRAMES_MODE=3\n",
      "ERROR\t2019-09-09 14:39:21 -0400\tmaster-replica-0\t2\t   KMP_GTID_MODE=3\n",
      "ERROR\t2019-09-09 14:39:21 -0400\tmaster-replica-0\t2\t   KMP_HANDLE_SIGNALS=false\n",
      "ERROR\t2019-09-09 14:39:21 -0400\tmaster-replica-0\t2\t   KMP_HOT_TEAMS_MAX_LEVEL=1\n",
      "ERROR\t2019-09-09 14:39:21 -0400\tmaster-replica-0\t2\t   KMP_HOT_TEAMS_MODE=0\n",
      "ERROR\t2019-09-09 14:39:21 -0400\tmaster-replica-0\t2\t   KMP_INIT_AT_FORK=true\n",
      "ERROR\t2019-09-09 14:39:21 -0400\tmaster-replica-0\t2\t   KMP_INIT_WAIT=2048\n",
      "ERROR\t2019-09-09 14:39:21 -0400\tmaster-replica-0\t2\t   KMP_ITT_PREPARE_DELAY=0\n",
      "ERROR\t2019-09-09 14:39:21 -0400\tmaster-replica-0\t2\t   KMP_LIBRARY=throughput\n",
      "ERROR\t2019-09-09 14:39:21 -0400\tmaster-replica-0\t2\t   KMP_LOCK_KIND=queuing\n",
      "ERROR\t2019-09-09 14:39:21 -0400\tmaster-replica-0\t2\t   KMP_MALLOC_POOL_INCR=1M\n",
      "ERROR\t2019-09-09 14:39:21 -0400\tmaster-replica-0\t2\t   KMP_NEXT_WAIT=1024\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR\t2019-09-09 14:39:21 -0400\tmaster-replica-0\t2\t   KMP_NUM_LOCKS_IN_BLOCK=1\n",
      "ERROR\t2019-09-09 14:39:21 -0400\tmaster-replica-0\t2\t   KMP_PLAIN_BARRIER='2,2'\n",
      "ERROR\t2019-09-09 14:39:21 -0400\tmaster-replica-0\t2\t   KMP_PLAIN_BARRIER_PATTERN='hyper,hyper'\n",
      "ERROR\t2019-09-09 14:39:21 -0400\tmaster-replica-0\t2\t   KMP_REDUCTION_BARRIER='1,1'\n",
      "ERROR\t2019-09-09 14:39:21 -0400\tmaster-replica-0\t2\t   KMP_REDUCTION_BARRIER_PATTERN='hyper,hyper'\n",
      "ERROR\t2019-09-09 14:39:21 -0400\tmaster-replica-0\t2\t   KMP_SCHEDULE='static,balanced;guided,iterative'\n",
      "ERROR\t2019-09-09 14:39:21 -0400\tmaster-replica-0\t2\t   KMP_SETTINGS=true\n",
      "ERROR\t2019-09-09 14:39:21 -0400\tmaster-replica-0\t2\t   KMP_SPIN_BACKOFF_PARAMS='4096,100'\n",
      "ERROR\t2019-09-09 14:39:21 -0400\tmaster-replica-0\t2\t   KMP_STACKOFFSET=64\n",
      "ERROR\t2019-09-09 14:39:21 -0400\tmaster-replica-0\t2\t   KMP_STACKPAD=0\n",
      "ERROR\t2019-09-09 14:39:21 -0400\tmaster-replica-0\t2\t   KMP_STACKSIZE=4M\n",
      "ERROR\t2019-09-09 14:39:21 -0400\tmaster-replica-0\t2\t   KMP_STORAGE_MAP=false\n",
      "ERROR\t2019-09-09 14:39:21 -0400\tmaster-replica-0\t2\t   KMP_TASKING=2\n",
      "ERROR\t2019-09-09 14:39:21 -0400\tmaster-replica-0\t2\t   KMP_TASKLOOP_MIN_TASKS=0\n",
      "ERROR\t2019-09-09 14:39:21 -0400\tmaster-replica-0\t2\t   KMP_TASK_STEALING_CONSTRAINT=1\n",
      "ERROR\t2019-09-09 14:39:21 -0400\tmaster-replica-0\t2\t   KMP_TEAMS_THREAD_LIMIT=4\n",
      "ERROR\t2019-09-09 14:39:21 -0400\tmaster-replica-0\t2\t   KMP_TOPOLOGY_METHOD=all\n",
      "ERROR\t2019-09-09 14:39:21 -0400\tmaster-replica-0\t2\t   KMP_USER_LEVEL_MWAIT=false\n",
      "ERROR\t2019-09-09 14:39:21 -0400\tmaster-replica-0\t2\t   KMP_VERSION=false\n",
      "ERROR\t2019-09-09 14:39:21 -0400\tmaster-replica-0\t2\t   KMP_WARNINGS=true\n",
      "ERROR\t2019-09-09 14:39:21 -0400\tmaster-replica-0\t2\t   OMP_AFFINITY_FORMAT='OMP: pid %P tid %T thread %n bound to OS proc set {%a}'\n",
      "ERROR\t2019-09-09 14:39:21 -0400\tmaster-replica-0\t2\t   OMP_ALLOCATOR=omp_default_mem_alloc\n",
      "ERROR\t2019-09-09 14:39:21 -0400\tmaster-replica-0\t2\t   OMP_CANCELLATION=false\n",
      "ERROR\t2019-09-09 14:39:21 -0400\tmaster-replica-0\t2\t   OMP_DEFAULT_DEVICE=0\n",
      "ERROR\t2019-09-09 14:39:21 -0400\tmaster-replica-0\t2\t   OMP_DISPLAY_AFFINITY=false\n",
      "ERROR\t2019-09-09 14:39:21 -0400\tmaster-replica-0\t2\t   OMP_DISPLAY_ENV=false\n",
      "ERROR\t2019-09-09 14:39:21 -0400\tmaster-replica-0\t2\t   OMP_DYNAMIC=false\n",
      "ERROR\t2019-09-09 14:39:21 -0400\tmaster-replica-0\t2\t   OMP_MAX_ACTIVE_LEVELS=2147483647\n",
      "ERROR\t2019-09-09 14:39:21 -0400\tmaster-replica-0\t2\t   OMP_MAX_TASK_PRIORITY=0\n",
      "ERROR\t2019-09-09 14:39:21 -0400\tmaster-replica-0\t2\t   OMP_NESTED=false\n",
      "ERROR\t2019-09-09 14:39:21 -0400\tmaster-replica-0\t2\t   OMP_NUM_THREADS='4'\n",
      "ERROR\t2019-09-09 14:39:21 -0400\tmaster-replica-0\t2\t   OMP_PLACES: value is not defined\n",
      "ERROR\t2019-09-09 14:39:21 -0400\tmaster-replica-0\t2\t   OMP_PROC_BIND='intel'\n",
      "ERROR\t2019-09-09 14:39:21 -0400\tmaster-replica-0\t2\t   OMP_SCHEDULE='static'\n",
      "ERROR\t2019-09-09 14:39:21 -0400\tmaster-replica-0\t2\t   OMP_STACKSIZE=4M\n",
      "ERROR\t2019-09-09 14:39:21 -0400\tmaster-replica-0\t2\t   OMP_TARGET_OFFLOAD=DEFAULT\n",
      "ERROR\t2019-09-09 14:39:21 -0400\tmaster-replica-0\t2\t   OMP_THREAD_LIMIT=2147483647\n",
      "ERROR\t2019-09-09 14:39:21 -0400\tmaster-replica-0\t2\t   OMP_TOOL=enabled\n",
      "ERROR\t2019-09-09 14:39:21 -0400\tmaster-replica-0\t2\t   OMP_TOOL_LIBRARIES: value is not defined\n",
      "ERROR\t2019-09-09 14:39:21 -0400\tmaster-replica-0\t2\t   OMP_WAIT_POLICY=PASSIVE\n",
      "ERROR\t2019-09-09 14:39:21 -0400\tmaster-replica-0\t2\t   KMP_AFFINITY='verbose,warnings,respect,granularity=fine,compact,1,0'\n",
      "INFO\t2019-09-09 14:39:21 -0400\tmaster-replica-0\t2\tCPU Frequency: 2300000000 Hz\n",
      "INFO\t2019-09-09 14:39:21 -0400\tmaster-replica-0\t2\tXLA service 0x58defc0 executing computations on platform Host. Devices:\n",
      "INFO\t2019-09-09 14:39:21 -0400\tmaster-replica-0\t2\t  StreamExecutor device (0): <undefined>, <undefined>\n",
      "ERROR\t2019-09-09 14:39:21 -0400\tmaster-replica-0\t2\tOMP: Info #212: KMP_AFFINITY: decoding x2APIC ids.\n",
      "ERROR\t2019-09-09 14:39:21 -0400\tmaster-replica-0\t2\tOMP: Info #210: KMP_AFFINITY: Affinity capable, using global cpuid leaf 11 info\n",
      "ERROR\t2019-09-09 14:39:21 -0400\tmaster-replica-0\t2\tOMP: Info #154: KMP_AFFINITY: Initial OS proc set respected: 0-3\n",
      "ERROR\t2019-09-09 14:39:21 -0400\tmaster-replica-0\t2\tOMP: Info #156: KMP_AFFINITY: 4 available OS procs\n",
      "ERROR\t2019-09-09 14:39:21 -0400\tmaster-replica-0\t2\tOMP: Info #157: KMP_AFFINITY: Uniform topology\n",
      "ERROR\t2019-09-09 14:39:21 -0400\tmaster-replica-0\t2\tOMP: Info #179: KMP_AFFINITY: 1 packages x 2 cores/pkg x 2 threads/core (2 total cores)\n",
      "ERROR\t2019-09-09 14:39:21 -0400\tmaster-replica-0\t2\tOMP: Info #214: KMP_AFFINITY: OS proc to physical thread map:\n",
      "ERROR\t2019-09-09 14:39:21 -0400\tmaster-replica-0\t2\tOMP: Info #171: KMP_AFFINITY: OS proc 0 maps to package 0 core 0 thread 0 \n",
      "ERROR\t2019-09-09 14:39:21 -0400\tmaster-replica-0\t2\tOMP: Info #171: KMP_AFFINITY: OS proc 2 maps to package 0 core 0 thread 1 \n",
      "ERROR\t2019-09-09 14:39:21 -0400\tmaster-replica-0\t2\tOMP: Info #171: KMP_AFFINITY: OS proc 1 maps to package 0 core 1 thread 0 \n",
      "ERROR\t2019-09-09 14:39:21 -0400\tmaster-replica-0\t2\tOMP: Info #171: KMP_AFFINITY: OS proc 3 maps to package 0 core 1 thread 1 \n",
      "ERROR\t2019-09-09 14:39:21 -0400\tmaster-replica-0\t2\tOMP: Info #250: KMP_AFFINITY: pid 396 tid 396 thread 0 bound to OS proc set 0\n",
      "INFO\t2019-09-09 14:39:21 -0400\tmaster-replica-0\t2\tCreating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n",
      "ERROR\t2019-09-09 14:39:21 -0400\tmaster-replica-0\t2\tOMP: Info #250: KMP_AFFINITY: pid 396 tid 420 thread 1 bound to OS proc set 1\n",
      "WARNING\t2019-09-09 14:39:21 -0400\tmaster-replica-0\t2\tFrom /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "WARNING\t2019-09-09 14:39:21 -0400\tmaster-replica-0\t2\tInstructions for updating:\n",
      "WARNING\t2019-09-09 14:39:21 -0400\tmaster-replica-0\t2\tUse tf.cast instead.\n",
      "ERROR\t2019-09-09 14:39:32 -0400\tmaster-replica-0\t2\tOMP: Info #250: KMP_AFFINITY: pid 396 tid 419 thread 2 bound to OS proc set 2\n",
      "ERROR\t2019-09-09 14:39:32 -0400\tmaster-replica-0\t2\tOMP: Info #250: KMP_AFFINITY: pid 396 tid 483 thread 3 bound to OS proc set 3\n",
      "ERROR\t2019-09-09 14:39:32 -0400\tmaster-replica-0\t2\tOMP: Info #250: KMP_AFFINITY: pid 396 tid 484 thread 4 bound to OS proc set 0\n",
      "ERROR\t2019-09-09 14:39:32 -0400\tmaster-replica-0\t2\tOMP: Info #250: KMP_AFFINITY: pid 396 tid 485 thread 5 bound to OS proc set 1\n",
      "ERROR\t2019-09-09 14:39:32 -0400\tmaster-replica-0\t2\tOMP: Info #250: KMP_AFFINITY: pid 396 tid 487 thread 7 bound to OS proc set 3\n",
      "ERROR\t2019-09-09 14:39:32 -0400\tmaster-replica-0\t2\tOMP: Info #250: KMP_AFFINITY: pid 396 tid 486 thread 6 bound to OS proc set 2\n",
      "ERROR\t2019-09-09 14:39:32 -0400\tmaster-replica-0\t2\tOMP: Info #250: KMP_AFFINITY: pid 396 tid 488 thread 8 bound to OS proc set 0\n",
      "INFO\t2019-09-09 14:39:32 -0400\tmaster-replica-0\t2\tEpoch 00001: LearningRateScheduler reducing learning rate to 0.04904781727277939.\n",
      "INFO\t2019-09-09 14:39:32 -0400\tmaster-replica-0\t2\tEpoch 1/20\n",
      "INFO\t2019-09-09 14:39:32 -0400\tmaster-replica-0\t2\t  1/285 [..............................] - ETA: 4:22 - loss: 0.7283 - acc: 0.210\n",
      "INFO\t2019-09-09 14:39:32 -0400\tmaster-replica-0\t2\t  6/285 [..............................] - ETA: 45s - loss: 3.5854 - acc: 0.653\n",
      "INFO\t2019-09-09 14:39:32 -0400\tmaster-replica-0\t2\t 10/285 [>.............................] - ETA: 28s - loss: 3.5368 - acc: 0.70\n",
      "INFO\t2019-09-09 14:39:32 -0400\tmaster-replica-0\t2\t 15/285 [>.............................] - ETA: 19s - loss: 3.6304 - acc: 0.72\n",
      "INFO\t2019-09-09 14:39:32 -0400\tmaster-replica-0\t2\t 22/285 [=>............................] - ETA: 13s - loss: 3.5871 - acc: 0.74\n",
      "INFO\t2019-09-09 14:39:32 -0400\tmaster-replica-0\t2\t 29/285 [==>...........................] - ETA: 10s - loss: 3.6329 - acc: 0.74\n",
      "INFO\t2019-09-09 14:39:32 -0400\tmaster-replica-0\t2\t 36/285 [==>...........................] - ETA: 8s - loss: 3.6688 - acc: 0.7517\n",
      "INFO\t2019-09-09 14:39:32 -0400\tmaster-replica-0\t2\t 44/285 [===>..........................] - ETA: 7s - loss: 3.7537 - acc: 0.750\n",
      "INFO\t2019-09-09 14:39:32 -0400\tmaster-replica-0\t2\t 50/285 [====>.........................] - ETA: 6s - loss: 3.8122 - acc: 0.748\n",
      "INFO\t2019-09-09 14:39:32 -0400\tmaster-replica-0\t2\t 58/285 [=====>........................] - ETA: 5s - loss: 3.8446 - acc: 0.748\n",
      "INFO\t2019-09-09 14:39:32 -0400\tmaster-replica-0\t2\t 64/285 [=====>........................] - ETA: 5s - loss: 3.8774 - acc: 0.747\n",
      "INFO\t2019-09-09 14:39:33 -0400\tmaster-replica-0\t2\t 72/285 [======>.......................] - ETA: 4s - loss: 3.8904 - acc: 0.748\n",
      "INFO\t2019-09-09 14:39:33 -0400\tmaster-replica-0\t2\t 80/285 [=======>......................] - ETA: 4s - loss: 3.8407 - acc: 0.752\n",
      "INFO\t2019-09-09 14:39:33 -0400\tmaster-replica-0\t2\t 87/285 [========>.....................] - ETA: 3s - loss: 3.8486 - acc: 0.752\n",
      "INFO\t2019-09-09 14:39:33 -0400\tmaster-replica-0\t2\t 93/285 [========>.....................] - ETA: 3s - loss: 3.8207 - acc: 0.755\n",
      "INFO\t2019-09-09 14:39:33 -0400\tmaster-replica-0\t2\t 99/285 [=========>....................] - ETA: 3s - loss: 3.8319 - acc: 0.754\n",
      "INFO\t2019-09-09 14:39:33 -0400\tmaster-replica-0\t2\t106/285 [==========>...................] - ETA: 3s - loss: 3.8550 - acc: 0.753\n",
      "INFO\t2019-09-09 14:39:33 -0400\tmaster-replica-0\t2\t114/285 [===========>..................] - ETA: 2s - loss: 3.8263 - acc: 0.756\n",
      "INFO\t2019-09-09 14:39:33 -0400\tmaster-replica-0\t2\t121/285 [===========>..................] - ETA: 2s - loss: 3.8305 - acc: 0.756\n",
      "INFO\t2019-09-09 14:39:33 -0400\tmaster-replica-0\t2\t128/285 [============>.................] - ETA: 2s - loss: 3.8342 - acc: 0.756\n",
      "INFO\t2019-09-09 14:39:33 -0400\tmaster-replica-0\t2\t132/285 [============>.................] - ETA: 2s - loss: 3.8444 - acc: 0.755\n",
      "INFO\t2019-09-09 14:39:33 -0400\tmaster-replica-0\t2\t138/285 [=============>................] - ETA: 2s - loss: 3.8432 - acc: 0.756\n",
      "INFO\t2019-09-09 14:39:33 -0400\tmaster-replica-0\t2\t145/285 [==============>...............] - ETA: 2s - loss: 3.8537 - acc: 0.755\n",
      "INFO\t2019-09-09 14:39:33 -0400\tmaster-replica-0\t2\t151/285 [==============>...............] - ETA: 1s - loss: 3.8513 - acc: 0.756\n",
      "INFO\t2019-09-09 14:39:33 -0400\tmaster-replica-0\t2\t159/285 [===============>..............] - ETA: 1s - loss: 3.8585 - acc: 0.755\n",
      "INFO\t2019-09-09 14:39:33 -0400\tmaster-replica-0\t2\t165/285 [================>.............] - ETA: 1s - loss: 3.8870 - acc: 0.754\n",
      "INFO\t2019-09-09 14:39:33 -0400\tmaster-replica-0\t2\t174/285 [=================>............] - ETA: 1s - loss: 3.8988 - acc: 0.753\n",
      "INFO\t2019-09-09 14:39:33 -0400\tmaster-replica-0\t2\t181/285 [==================>...........] - ETA: 1s - loss: 3.8980 - acc: 0.754\n",
      "INFO\t2019-09-09 14:39:33 -0400\tmaster-replica-0\t2\t189/285 [==================>...........] - ETA: 1s - loss: 3.8894 - acc: 0.754\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO\t2019-09-09 14:39:33 -0400\tmaster-replica-0\t2\t197/285 [===================>..........] - ETA: 1s - loss: 3.8814 - acc: 0.755\n",
      "INFO\t2019-09-09 14:39:34 -0400\tmaster-replica-0\t2\t204/285 [====================>.........] - ETA: 1s - loss: 3.8938 - acc: 0.754\n",
      "INFO\t2019-09-09 14:39:34 -0400\tmaster-replica-0\t2\t210/285 [=====================>........] - ETA: 0s - loss: 3.8923 - acc: 0.755\n",
      "INFO\t2019-09-09 14:39:34 -0400\tmaster-replica-0\t2\t215/285 [=====================>........] - ETA: 0s - loss: 3.8932 - acc: 0.755\n",
      "INFO\t2019-09-09 14:39:34 -0400\tmaster-replica-0\t2\t224/285 [======================>.......] - ETA: 0s - loss: 3.8800 - acc: 0.756\n",
      "INFO\t2019-09-09 14:39:34 -0400\tmaster-replica-0\t2\t231/285 [=======================>......] - ETA: 0s - loss: 3.8787 - acc: 0.756\n",
      "INFO\t2019-09-09 14:39:34 -0400\tmaster-replica-0\t2\t239/285 [========================>.....] - ETA: 0s - loss: 3.8702 - acc: 0.756\n",
      "INFO\t2019-09-09 14:39:34 -0400\tmaster-replica-0\t2\t244/285 [========================>.....] - ETA: 0s - loss: 3.8645 - acc: 0.757\n",
      "INFO\t2019-09-09 14:39:34 -0400\tmaster-replica-0\t2\t253/285 [=========================>....] - ETA: 0s - loss: 3.8600 - acc: 0.757\n",
      "INFO\t2019-09-09 14:39:34 -0400\tmaster-replica-0\t2\t262/285 [==========================>...] - ETA: 0s - loss: 3.8650 - acc: 0.757\n",
      "INFO\t2019-09-09 14:39:34 -0400\tmaster-replica-0\t2\t272/285 [===========================>..] - ETA: 0s - loss: 3.8633 - acc: 0.757\n",
      "INFO\t2019-09-09 14:39:34 -0400\tmaster-replica-0\t2\t277/285 [============================>.] - ETA: 0s - loss: 3.8599 - acc: 0.757\n",
      "WARNING\t2019-09-09 14:39:35 -0400\tmaster-replica-0\t2\tfile_cache is unavailable when using oauth2client >= 4.0.0 or google-auth\n",
      "INFO\t2019-09-09 14:39:35 -0400\tmaster-replica-0\t2\tAttempting refresh to obtain initial access_token\n",
      "INFO\t2019-09-09 14:39:36 -0400\tmaster-replica-0\t2\t284/285 [============================>.] - ETA: 0s - loss: 3.8723 - acc: 0.757\n",
      "INFO\t2019-09-09 14:39:36 -0400\tmaster-replica-0\t2\t285/285 [==============================] - 5s 17ms/step - loss: 3.8726 - acc: 0.7571 - val_loss: 3.8072 - val_acc: 0.7638\n",
      "INFO\t2019-09-09 14:39:36 -0400\tmaster-replica-0\t2\tEpoch 00002: LearningRateScheduler reducing learning rate to 0.044047817272779385.\n",
      "INFO\t2019-09-09 14:39:36 -0400\tmaster-replica-0\t2\tEpoch 2/20\n",
      "INFO\t2019-09-09 14:39:36 -0400\tmaster-replica-0\t2\t  1/285 [..............................] - ETA: 22s - loss: 4.3830 - acc: 0.72\n",
      "INFO\t2019-09-09 14:39:36 -0400\tmaster-replica-0\t2\t  9/285 [..............................] - ETA: 4s - loss: 3.5033 - acc: 0.7827\n",
      "INFO\t2019-09-09 14:39:36 -0400\tmaster-replica-0\t2\t 16/285 [>.............................] - ETA: 3s - loss: 3.6761 - acc: 0.771\n",
      "INFO\t2019-09-09 14:39:36 -0400\tmaster-replica-0\t2\t 29/285 [==>...........................] - ETA: 2s - loss: 3.7443 - acc: 0.767\n",
      "INFO\t2019-09-09 14:39:36 -0400\tmaster-replica-0\t2\t 40/285 [===>..........................] - ETA: 1s - loss: 3.7998 - acc: 0.764\n",
      "INFO\t2019-09-09 14:39:36 -0400\tmaster-replica-0\t2\t 52/285 [====>.........................] - ETA: 1s - loss: 3.8773 - acc: 0.759\n",
      "INFO\t2019-09-09 14:39:36 -0400\tmaster-replica-0\t2\t 63/285 [=====>........................] - ETA: 1s - loss: 3.9207 - acc: 0.756\n",
      "INFO\t2019-09-09 14:39:36 -0400\tmaster-replica-0\t2\t 77/285 [=======>......................] - ETA: 1s - loss: 3.8578 - acc: 0.760\n",
      "INFO\t2019-09-09 14:39:36 -0400\tmaster-replica-0\t2\t 88/285 [========>.....................] - ETA: 1s - loss: 3.8640 - acc: 0.760\n",
      "INFO\t2019-09-09 14:39:36 -0400\tmaster-replica-0\t2\t100/285 [=========>....................] - ETA: 1s - loss: 3.8966 - acc: 0.758\n",
      "INFO\t2019-09-09 14:39:36 -0400\tmaster-replica-0\t2\t108/285 [==========>...................] - ETA: 1s - loss: 3.8999 - acc: 0.758\n",
      "INFO\t2019-09-09 14:39:36 -0400\tmaster-replica-0\t2\t115/285 [===========>..................] - ETA: 0s - loss: 3.8961 - acc: 0.758\n",
      "INFO\t2019-09-09 14:39:36 -0400\tmaster-replica-0\t2\t126/285 [============>.................] - ETA: 0s - loss: 3.9151 - acc: 0.757\n",
      "INFO\t2019-09-09 14:39:37 -0400\tmaster-replica-0\t2\t137/285 [=============>................] - ETA: 0s - loss: 3.8948 - acc: 0.758\n",
      "INFO\t2019-09-09 14:39:37 -0400\tmaster-replica-0\t2\t146/285 [==============>...............] - ETA: 0s - loss: 3.8765 - acc: 0.759\n",
      "INFO\t2019-09-09 14:39:37 -0400\tmaster-replica-0\t2\t157/285 [===============>..............] - ETA: 0s - loss: 3.8643 - acc: 0.760\n",
      "INFO\t2019-09-09 14:39:37 -0400\tmaster-replica-0\t2\t167/285 [================>.............] - ETA: 0s - loss: 3.8665 - acc: 0.760\n",
      "INFO\t2019-09-09 14:39:37 -0400\tmaster-replica-0\t2\t177/285 [=================>............] - ETA: 0s - loss: 3.8710 - acc: 0.759\n",
      "INFO\t2019-09-09 14:39:37 -0400\tmaster-replica-0\t2\t188/285 [==================>...........] - ETA: 0s - loss: 3.8738 - acc: 0.759\n",
      "INFO\t2019-09-09 14:39:37 -0400\tmaster-replica-0\t2\t193/285 [===================>..........] - ETA: 0s - loss: 3.8782 - acc: 0.759\n",
      "INFO\t2019-09-09 14:39:37 -0400\tmaster-replica-0\t2\t201/285 [====================>.........] - ETA: 0s - loss: 3.8695 - acc: 0.759\n",
      "INFO\t2019-09-09 14:39:37 -0400\tmaster-replica-0\t2\t208/285 [====================>.........] - ETA: 0s - loss: 3.8807 - acc: 0.759\n",
      "INFO\t2019-09-09 14:39:37 -0400\tmaster-replica-0\t2\t216/285 [=====================>........] - ETA: 0s - loss: 3.8829 - acc: 0.759\n",
      "INFO\t2019-09-09 14:39:37 -0400\tmaster-replica-0\t2\t225/285 [======================>.......] - ETA: 0s - loss: 3.8916 - acc: 0.758\n",
      "INFO\t2019-09-09 14:39:37 -0400\tmaster-replica-0\t2\t232/285 [=======================>......] - ETA: 0s - loss: 3.8942 - acc: 0.758\n",
      "INFO\t2019-09-09 14:39:37 -0400\tmaster-replica-0\t2\t239/285 [========================>.....] - ETA: 0s - loss: 3.8843 - acc: 0.759\n",
      "INFO\t2019-09-09 14:39:37 -0400\tmaster-replica-0\t2\t248/285 [=========================>....] - ETA: 0s - loss: 3.8790 - acc: 0.759\n",
      "INFO\t2019-09-09 14:39:37 -0400\tmaster-replica-0\t2\t256/285 [=========================>....] - ETA: 0s - loss: 3.8815 - acc: 0.759\n",
      "INFO\t2019-09-09 14:39:37 -0400\tmaster-replica-0\t2\t266/285 [===========================>..] - ETA: 0s - loss: 3.8802 - acc: 0.759\n",
      "INFO\t2019-09-09 14:39:37 -0400\tmaster-replica-0\t2\t276/285 [============================>.] - ETA: 0s - loss: 3.8723 - acc: 0.759\n",
      "INFO\t2019-09-09 14:39:39 -0400\tmaster-replica-0\t2\t284/285 [============================>.] - ETA: 0s - loss: 3.8827 - acc: 0.759\n",
      "INFO\t2019-09-09 14:39:39 -0400\tmaster-replica-0\t2\t285/285 [==============================] - 3s 10ms/step - loss: 3.8804 - acc: 0.7592 - val_loss: 3.8072 - val_acc: 0.7638\n",
      "INFO\t2019-09-09 14:39:39 -0400\tmaster-replica-0\t2\tEpoch 00003: LearningRateScheduler reducing learning rate to 0.04154781727277939.\n",
      "INFO\t2019-09-09 14:39:39 -0400\tmaster-replica-0\t2\tEpoch 3/20\n",
      "INFO\t2019-09-09 14:39:39 -0400\tmaster-replica-0\t2\t  1/285 [..............................] - ETA: 24s - loss: 3.9588 - acc: 0.75\n",
      "INFO\t2019-09-09 14:39:39 -0400\tmaster-replica-0\t2\t 12/285 [>.............................] - ETA: 3s - loss: 3.6289 - acc: 0.7749\n",
      "INFO\t2019-09-09 14:39:39 -0400\tmaster-replica-0\t2\t 22/285 [=>............................] - ETA: 2s - loss: 3.7725 - acc: 0.765\n",
      "INFO\t2019-09-09 14:39:39 -0400\tmaster-replica-0\t2\t 32/285 [==>...........................] - ETA: 1s - loss: 3.7247 - acc: 0.768\n",
      "INFO\t2019-09-09 14:39:39 -0400\tmaster-replica-0\t2\t 41/285 [===>..........................] - ETA: 1s - loss: 3.8140 - acc: 0.763\n",
      "INFO\t2019-09-09 14:39:39 -0400\tmaster-replica-0\t2\t 49/285 [====>.........................] - ETA: 1s - loss: 3.8117 - acc: 0.763\n",
      "INFO\t2019-09-09 14:39:39 -0400\tmaster-replica-0\t2\t 58/285 [=====>........................] - ETA: 1s - loss: 3.8540 - acc: 0.760\n",
      "INFO\t2019-09-09 14:39:39 -0400\tmaster-replica-0\t2\t 64/285 [=====>........................] - ETA: 1s - loss: 3.8506 - acc: 0.761\n",
      "INFO\t2019-09-09 14:39:39 -0400\tmaster-replica-0\t2\t 72/285 [======>.......................] - ETA: 1s - loss: 3.8842 - acc: 0.759\n",
      "INFO\t2019-09-09 14:39:39 -0400\tmaster-replica-0\t2\t 77/285 [=======>......................] - ETA: 1s - loss: 3.9056 - acc: 0.757\n",
      "INFO\t2019-09-09 14:39:39 -0400\tmaster-replica-0\t2\t 88/285 [========>.....................] - ETA: 1s - loss: 3.9090 - acc: 0.757\n",
      "INFO\t2019-09-09 14:39:39 -0400\tmaster-replica-0\t2\t 99/285 [=========>....................] - ETA: 1s - loss: 3.8974 - acc: 0.758\n",
      "INFO\t2019-09-09 14:39:39 -0400\tmaster-replica-0\t2\t109/285 [==========>...................] - ETA: 1s - loss: 3.8823 - acc: 0.759\n",
      "INFO\t2019-09-09 14:39:39 -0400\tmaster-replica-0\t2\t120/285 [===========>..................] - ETA: 1s - loss: 3.8811 - acc: 0.759\n",
      "INFO\t2019-09-09 14:39:39 -0400\tmaster-replica-0\t2\t130/285 [============>.................] - ETA: 0s - loss: 3.9034 - acc: 0.757\n",
      "INFO\t2019-09-09 14:39:40 -0400\tmaster-replica-0\t2\t143/285 [==============>...............] - ETA: 0s - loss: 3.9064 - acc: 0.757\n",
      "INFO\t2019-09-09 14:39:40 -0400\tmaster-replica-0\t2\t150/285 [==============>...............] - ETA: 0s - loss: 3.9098 - acc: 0.757\n",
      "INFO\t2019-09-09 14:39:40 -0400\tmaster-replica-0\t2\t161/285 [===============>..............] - ETA: 0s - loss: 3.9053 - acc: 0.757\n",
      "INFO\t2019-09-09 14:39:40 -0400\tmaster-replica-0\t2\t170/285 [================>.............] - ETA: 0s - loss: 3.9148 - acc: 0.757\n",
      "INFO\t2019-09-09 14:39:40 -0400\tmaster-replica-0\t2\t179/285 [=================>............] - ETA: 0s - loss: 3.9027 - acc: 0.757\n",
      "INFO\t2019-09-09 14:39:40 -0400\tmaster-replica-0\t2\t188/285 [==================>...........] - ETA: 0s - loss: 3.8716 - acc: 0.759\n",
      "INFO\t2019-09-09 14:39:40 -0400\tmaster-replica-0\t2\t198/285 [===================>..........] - ETA: 0s - loss: 3.8889 - acc: 0.758\n",
      "INFO\t2019-09-09 14:39:40 -0400\tmaster-replica-0\t2\t208/285 [====================>.........] - ETA: 0s - loss: 3.8915 - acc: 0.758\n",
      "INFO\t2019-09-09 14:39:40 -0400\tmaster-replica-0\t2\t217/285 [=====================>........] - ETA: 0s - loss: 3.8872 - acc: 0.758\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO\t2019-09-09 14:39:40 -0400\tmaster-replica-0\t2\t224/285 [======================>.......] - ETA: 0s - loss: 3.8818 - acc: 0.759\n",
      "INFO\t2019-09-09 14:39:40 -0400\tmaster-replica-0\t2\t229/285 [=======================>......] - ETA: 0s - loss: 3.8755 - acc: 0.759\n",
      "INFO\t2019-09-09 14:39:40 -0400\tmaster-replica-0\t2\t241/285 [========================>.....] - ETA: 0s - loss: 3.8790 - acc: 0.759\n",
      "INFO\t2019-09-09 14:39:40 -0400\tmaster-replica-0\t2\t250/285 [=========================>....] - ETA: 0s - loss: 3.8825 - acc: 0.759\n",
      "INFO\t2019-09-09 14:39:40 -0400\tmaster-replica-0\t2\t261/285 [==========================>...] - ETA: 0s - loss: 3.8732 - acc: 0.759\n",
      "INFO\t2019-09-09 14:39:40 -0400\tmaster-replica-0\t2\t269/285 [===========================>..] - ETA: 0s - loss: 3.8816 - acc: 0.759\n",
      "INFO\t2019-09-09 14:39:40 -0400\tmaster-replica-0\t2\t276/285 [============================>.] - ETA: 0s - loss: 3.8799 - acc: 0.759\n",
      "INFO\t2019-09-09 14:39:41 -0400\tmaster-replica-0\t2\t282/285 [============================>.] - ETA: 0s - loss: 3.8841 - acc: 0.759\n",
      "INFO\t2019-09-09 14:39:41 -0400\tmaster-replica-0\t2\t285/285 [==============================] - 3s 10ms/step - loss: 3.8839 - acc: 0.7590 - val_loss: 3.8072 - val_acc: 0.7638\n",
      "INFO\t2019-09-09 14:39:41 -0400\tmaster-replica-0\t2\tEpoch 00004: LearningRateScheduler reducing learning rate to 0.04029781727277939.\n",
      "INFO\t2019-09-09 14:39:41 -0400\tmaster-replica-0\t2\tEpoch 4/20\n",
      "INFO\t2019-09-09 14:39:42 -0400\tmaster-replica-0\t2\t  1/285 [..............................] - ETA: 1s - loss: 3.8174 - acc: 0.763\n",
      "INFO\t2019-09-09 14:39:42 -0400\tmaster-replica-0\t2\t  9/285 [..............................] - ETA: 1s - loss: 3.7232 - acc: 0.769\n",
      "INFO\t2019-09-09 14:39:42 -0400\tmaster-replica-0\t2\t 20/285 [=>............................] - ETA: 1s - loss: 3.8387 - acc: 0.761\n",
      "INFO\t2019-09-09 14:39:42 -0400\tmaster-replica-0\t2\t 30/285 [==>...........................] - ETA: 1s - loss: 3.8693 - acc: 0.759\n",
      "INFO\t2019-09-09 14:39:42 -0400\tmaster-replica-0\t2\t 40/285 [===>..........................] - ETA: 1s - loss: 3.8881 - acc: 0.758\n",
      "INFO\t2019-09-09 14:39:42 -0400\tmaster-replica-0\t2\t 49/285 [====>.........................] - ETA: 1s - loss: 3.9155 - acc: 0.757\n",
      "INFO\t2019-09-09 14:39:42 -0400\tmaster-replica-0\t2\t 59/285 [=====>........................] - ETA: 1s - loss: 3.9133 - acc: 0.757\n",
      "INFO\t2019-09-09 14:39:42 -0400\tmaster-replica-0\t2\t 70/285 [======>.......................] - ETA: 1s - loss: 3.9568 - acc: 0.754\n",
      "INFO\t2019-09-09 14:39:42 -0400\tmaster-replica-0\t2\t 76/285 [=======>......................] - ETA: 1s - loss: 3.9737 - acc: 0.753\n",
      "INFO\t2019-09-09 14:39:42 -0400\tmaster-replica-0\t2\t 83/285 [=======>......................] - ETA: 1s - loss: 3.9520 - acc: 0.754\n",
      "INFO\t2019-09-09 14:39:42 -0400\tmaster-replica-0\t2\t 89/285 [========>.....................] - ETA: 1s - loss: 3.9207 - acc: 0.756\n",
      "INFO\t2019-09-09 14:39:42 -0400\tmaster-replica-0\t2\t 96/285 [=========>....................] - ETA: 1s - loss: 3.8999 - acc: 0.758\n",
      "INFO\t2019-09-09 14:39:42 -0400\tmaster-replica-0\t2\t101/285 [=========>....................] - ETA: 1s - loss: 3.8790 - acc: 0.759\n",
      "INFO\t2019-09-09 14:39:42 -0400\tmaster-replica-0\t2\t107/285 [==========>...................] - ETA: 1s - loss: 3.8888 - acc: 0.758\n",
      "INFO\t2019-09-09 14:39:42 -0400\tmaster-replica-0\t2\t115/285 [===========>..................] - ETA: 1s - loss: 3.8961 - acc: 0.758\n",
      "INFO\t2019-09-09 14:39:42 -0400\tmaster-replica-0\t2\t123/285 [===========>..................] - ETA: 1s - loss: 3.8784 - acc: 0.759\n",
      "INFO\t2019-09-09 14:39:42 -0400\tmaster-replica-0\t2\t130/285 [============>.................] - ETA: 1s - loss: 3.8686 - acc: 0.760\n",
      "INFO\t2019-09-09 14:39:42 -0400\tmaster-replica-0\t2\t142/285 [=============>................] - ETA: 0s - loss: 3.8613 - acc: 0.760\n",
      "INFO\t2019-09-09 14:39:42 -0400\tmaster-replica-0\t2\t155/285 [===============>..............] - ETA: 0s - loss: 3.8621 - acc: 0.760\n",
      "INFO\t2019-09-09 14:39:43 -0400\tmaster-replica-0\t2\t163/285 [================>.............] - ETA: 0s - loss: 3.8521 - acc: 0.761\n",
      "INFO\t2019-09-09 14:39:43 -0400\tmaster-replica-0\t2\t171/285 [=================>............] - ETA: 0s - loss: 3.8662 - acc: 0.760\n",
      "INFO\t2019-09-09 14:39:43 -0400\tmaster-replica-0\t2\t178/285 [=================>............] - ETA: 0s - loss: 3.8715 - acc: 0.759\n",
      "INFO\t2019-09-09 14:39:43 -0400\tmaster-replica-0\t2\t187/285 [==================>...........] - ETA: 0s - loss: 3.8794 - acc: 0.759\n",
      "INFO\t2019-09-09 14:39:43 -0400\tmaster-replica-0\t2\t194/285 [===================>..........] - ETA: 0s - loss: 3.8743 - acc: 0.759\n",
      "INFO\t2019-09-09 14:39:43 -0400\tmaster-replica-0\t2\t207/285 [====================>.........] - ETA: 0s - loss: 3.8769 - acc: 0.759\n",
      "INFO\t2019-09-09 14:39:43 -0400\tmaster-replica-0\t2\t217/285 [=====================>........] - ETA: 0s - loss: 3.8741 - acc: 0.759\n",
      "INFO\t2019-09-09 14:39:43 -0400\tmaster-replica-0\t2\t227/285 [======================>.......] - ETA: 0s - loss: 3.8698 - acc: 0.759\n",
      "INFO\t2019-09-09 14:39:43 -0400\tmaster-replica-0\t2\t232/285 [=======================>......] - ETA: 0s - loss: 3.8778 - acc: 0.759\n",
      "INFO\t2019-09-09 14:39:43 -0400\tmaster-replica-0\t2\t242/285 [========================>.....] - ETA: 0s - loss: 3.8776 - acc: 0.759\n",
      "INFO\t2019-09-09 14:39:43 -0400\tmaster-replica-0\t2\t248/285 [=========================>....] - ETA: 0s - loss: 3.8699 - acc: 0.759\n",
      "INFO\t2019-09-09 14:39:43 -0400\tmaster-replica-0\t2\t257/285 [==========================>...] - ETA: 0s - loss: 3.8890 - acc: 0.758\n",
      "INFO\t2019-09-09 14:39:43 -0400\tmaster-replica-0\t2\t263/285 [==========================>...] - ETA: 0s - loss: 3.8879 - acc: 0.758\n",
      "INFO\t2019-09-09 14:39:43 -0400\tmaster-replica-0\t2\t272/285 [===========================>..] - ETA: 0s - loss: 3.8928 - acc: 0.758\n",
      "INFO\t2019-09-09 14:39:44 -0400\tmaster-replica-0\t2\t277/285 [============================>.] - ETA: 0s - loss: 3.8843 - acc: 0.759\n",
      "INFO\t2019-09-09 14:39:44 -0400\tmaster-replica-0\t2\t285/285 [==============================] - 3s 10ms/step - loss: 3.8809 - acc: 0.7592 - val_loss: 3.8072 - val_acc: 0.7638\n",
      "INFO\t2019-09-09 14:39:44 -0400\tmaster-replica-0\t2\tEpoch 00005: LearningRateScheduler reducing learning rate to 0.03967281727277939.\n",
      "INFO\t2019-09-09 14:39:44 -0400\tmaster-replica-0\t2\tEpoch 5/20\n",
      "INFO\t2019-09-09 14:39:45 -0400\tmaster-replica-0\t2\t  1/285 [..............................] - ETA: 2s - loss: 3.3933 - acc: 0.789\n",
      "INFO\t2019-09-09 14:39:45 -0400\tmaster-replica-0\t2\t 12/285 [>.............................] - ETA: 1s - loss: 4.2416 - acc: 0.736\n",
      "INFO\t2019-09-09 14:39:45 -0400\tmaster-replica-0\t2\t 22/285 [=>............................] - ETA: 1s - loss: 4.0102 - acc: 0.751\n",
      "INFO\t2019-09-09 14:39:45 -0400\tmaster-replica-0\t2\t 29/285 [==>...........................] - ETA: 1s - loss: 3.9345 - acc: 0.755\n",
      "INFO\t2019-09-09 14:39:45 -0400\tmaster-replica-0\t2\t 40/285 [===>..........................] - ETA: 1s - loss: 3.8952 - acc: 0.758\n",
      "INFO\t2019-09-09 14:39:45 -0400\tmaster-replica-0\t2\t 50/285 [====>.........................] - ETA: 1s - loss: 3.8599 - acc: 0.760\n",
      "INFO\t2019-09-09 14:39:45 -0400\tmaster-replica-0\t2\t 61/285 [=====>........................] - ETA: 1s - loss: 3.8499 - acc: 0.761\n",
      "INFO\t2019-09-09 14:39:45 -0400\tmaster-replica-0\t2\t 72/285 [======>.......................] - ETA: 1s - loss: 3.7998 - acc: 0.764\n",
      "INFO\t2019-09-09 14:39:45 -0400\tmaster-replica-0\t2\t 81/285 [=======>......................] - ETA: 1s - loss: 3.7982 - acc: 0.764\n",
      "INFO\t2019-09-09 14:39:45 -0400\tmaster-replica-0\t2\t 93/285 [========>.....................] - ETA: 1s - loss: 3.8053 - acc: 0.763\n",
      "INFO\t2019-09-09 14:39:45 -0400\tmaster-replica-0\t2\t 99/285 [=========>....................] - ETA: 1s - loss: 3.8132 - acc: 0.763\n",
      "INFO\t2019-09-09 14:39:45 -0400\tmaster-replica-0\t2\t111/285 [==========>...................] - ETA: 0s - loss: 3.7983 - acc: 0.764\n",
      "INFO\t2019-09-09 14:39:45 -0400\tmaster-replica-0\t2\t117/285 [===========>..................] - ETA: 0s - loss: 3.8307 - acc: 0.762\n",
      "INFO\t2019-09-09 14:39:45 -0400\tmaster-replica-0\t2\t125/285 [============>.................] - ETA: 0s - loss: 3.8333 - acc: 0.762\n",
      "INFO\t2019-09-09 14:39:45 -0400\tmaster-replica-0\t2\t130/285 [============>.................] - ETA: 0s - loss: 3.8294 - acc: 0.762\n",
      "INFO\t2019-09-09 14:39:45 -0400\tmaster-replica-0\t2\t138/285 [=============>................] - ETA: 0s - loss: 3.8564 - acc: 0.760\n",
      "INFO\t2019-09-09 14:39:45 -0400\tmaster-replica-0\t2\t145/285 [==============>...............] - ETA: 0s - loss: 3.8798 - acc: 0.759\n",
      "INFO\t2019-09-09 14:39:45 -0400\tmaster-replica-0\t2\t151/285 [==============>...............] - ETA: 0s - loss: 3.8830 - acc: 0.759\n",
      "INFO\t2019-09-09 14:39:46 -0400\tmaster-replica-0\t2\t163/285 [================>.............] - ETA: 0s - loss: 3.8712 - acc: 0.759\n",
      "INFO\t2019-09-09 14:39:46 -0400\tmaster-replica-0\t2\t174/285 [=================>............] - ETA: 0s - loss: 3.8841 - acc: 0.759\n",
      "INFO\t2019-09-09 14:39:46 -0400\tmaster-replica-0\t2\t183/285 [==================>...........] - ETA: 0s - loss: 3.8847 - acc: 0.759\n",
      "INFO\t2019-09-09 14:39:46 -0400\tmaster-replica-0\t2\t189/285 [==================>...........] - ETA: 0s - loss: 3.8758 - acc: 0.759\n",
      "INFO\t2019-09-09 14:39:46 -0400\tmaster-replica-0\t2\t197/285 [===================>..........] - ETA: 0s - loss: 3.8806 - acc: 0.759\n",
      "INFO\t2019-09-09 14:39:46 -0400\tmaster-replica-0\t2\t204/285 [====================>.........] - ETA: 0s - loss: 3.8840 - acc: 0.759\n",
      "INFO\t2019-09-09 14:39:46 -0400\tmaster-replica-0\t2\t210/285 [=====================>........] - ETA: 0s - loss: 3.8902 - acc: 0.758\n",
      "INFO\t2019-09-09 14:39:46 -0400\tmaster-replica-0\t2\t223/285 [======================>.......] - ETA: 0s - loss: 3.8853 - acc: 0.758\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO\t2019-09-09 14:39:46 -0400\tmaster-replica-0\t2\t234/285 [=======================>......] - ETA: 0s - loss: 3.8839 - acc: 0.759\n",
      "INFO\t2019-09-09 14:39:46 -0400\tmaster-replica-0\t2\t246/285 [========================>.....] - ETA: 0s - loss: 3.8812 - acc: 0.759\n",
      "INFO\t2019-09-09 14:39:46 -0400\tmaster-replica-0\t2\t255/285 [=========================>....] - ETA: 0s - loss: 3.8923 - acc: 0.758\n",
      "INFO\t2019-09-09 14:39:46 -0400\tmaster-replica-0\t2\t263/285 [==========================>...] - ETA: 0s - loss: 3.8992 - acc: 0.758\n",
      "INFO\t2019-09-09 14:39:46 -0400\tmaster-replica-0\t2\t269/285 [===========================>..] - ETA: 0s - loss: 3.8963 - acc: 0.758\n",
      "INFO\t2019-09-09 14:39:47 -0400\tmaster-replica-0\t2\t281/285 [============================>.] - ETA: 0s - loss: 3.8824 - acc: 0.759\n",
      "INFO\t2019-09-09 14:39:47 -0400\tmaster-replica-0\t2\t285/285 [==============================] - 3s 10ms/step - loss: 3.8780 - acc: 0.7594 - val_loss: 3.8072 - val_acc: 0.7638\n",
      "INFO\t2019-09-09 14:39:47 -0400\tmaster-replica-0\t2\tEpoch 00006: LearningRateScheduler reducing learning rate to 0.03936031727277939.\n",
      "INFO\t2019-09-09 14:39:47 -0400\tmaster-replica-0\t2\tEpoch 6/20\n",
      "INFO\t2019-09-09 14:39:47 -0400\tmaster-replica-0\t2\t  1/285 [..............................] - ETA: 10s - loss: 4.1002 - acc: 0.74\n",
      "INFO\t2019-09-09 14:39:48 -0400\tmaster-replica-0\t2\t 10/285 [>.............................] - ETA: 2s - loss: 3.8457 - acc: 0.7614\n",
      "INFO\t2019-09-09 14:39:48 -0400\tmaster-replica-0\t2\t 18/285 [>.............................] - ETA: 2s - loss: 3.8646 - acc: 0.760\n",
      "INFO\t2019-09-09 14:39:48 -0400\tmaster-replica-0\t2\t 32/285 [==>...........................] - ETA: 1s - loss: 3.8484 - acc: 0.761\n",
      "INFO\t2019-09-09 14:39:48 -0400\tmaster-replica-0\t2\t 41/285 [===>..........................] - ETA: 1s - loss: 3.8795 - acc: 0.759\n",
      "INFO\t2019-09-09 14:39:48 -0400\tmaster-replica-0\t2\t 49/285 [====>.........................] - ETA: 1s - loss: 3.7972 - acc: 0.764\n",
      "INFO\t2019-09-09 14:39:48 -0400\tmaster-replica-0\t2\t 56/285 [====>.........................] - ETA: 1s - loss: 3.8705 - acc: 0.759\n",
      "INFO\t2019-09-09 14:39:48 -0400\tmaster-replica-0\t2\t 64/285 [=====>........................] - ETA: 1s - loss: 3.8550 - acc: 0.760\n",
      "INFO\t2019-09-09 14:39:48 -0400\tmaster-replica-0\t2\t 71/285 [======>.......................] - ETA: 1s - loss: 3.8692 - acc: 0.759\n",
      "INFO\t2019-09-09 14:39:48 -0400\tmaster-replica-0\t2\t 79/285 [=======>......................] - ETA: 1s - loss: 3.8819 - acc: 0.759\n",
      "INFO\t2019-09-09 14:39:48 -0400\tmaster-replica-0\t2\t 90/285 [========>.....................] - ETA: 1s - loss: 3.8881 - acc: 0.758\n",
      "INFO\t2019-09-09 14:39:48 -0400\tmaster-replica-0\t2\t 98/285 [=========>....................] - ETA: 1s - loss: 3.9026 - acc: 0.757\n",
      "INFO\t2019-09-09 14:39:48 -0400\tmaster-replica-0\t2\t110/285 [==========>...................] - ETA: 1s - loss: 3.8830 - acc: 0.759\n",
      "INFO\t2019-09-09 14:39:48 -0400\tmaster-replica-0\t2\t118/285 [===========>..................] - ETA: 1s - loss: 3.8809 - acc: 0.759\n",
      "INFO\t2019-09-09 14:39:48 -0400\tmaster-replica-0\t2\t129/285 [============>.................] - ETA: 0s - loss: 3.8909 - acc: 0.758\n",
      "INFO\t2019-09-09 14:39:48 -0400\tmaster-replica-0\t2\t138/285 [=============>................] - ETA: 0s - loss: 3.8830 - acc: 0.759\n",
      "INFO\t2019-09-09 14:39:48 -0400\tmaster-replica-0\t2\t149/285 [==============>...............] - ETA: 0s - loss: 3.8810 - acc: 0.759\n",
      "INFO\t2019-09-09 14:39:48 -0400\tmaster-replica-0\t2\t159/285 [===============>..............] - ETA: 0s - loss: 3.8628 - acc: 0.760\n",
      "INFO\t2019-09-09 14:39:48 -0400\tmaster-replica-0\t2\t167/285 [================>.............] - ETA: 0s - loss: 3.8615 - acc: 0.760\n",
      "INFO\t2019-09-09 14:39:48 -0400\tmaster-replica-0\t2\t175/285 [=================>............] - ETA: 0s - loss: 3.8586 - acc: 0.760\n",
      "INFO\t2019-09-09 14:39:49 -0400\tmaster-replica-0\t2\t185/285 [==================>...........] - ETA: 0s - loss: 3.8595 - acc: 0.760\n",
      "INFO\t2019-09-09 14:39:49 -0400\tmaster-replica-0\t2\t194/285 [===================>..........] - ETA: 0s - loss: 3.8561 - acc: 0.760\n",
      "INFO\t2019-09-09 14:39:49 -0400\tmaster-replica-0\t2\t204/285 [====================>.........] - ETA: 0s - loss: 3.8507 - acc: 0.761\n",
      "INFO\t2019-09-09 14:39:49 -0400\tmaster-replica-0\t2\t212/285 [=====================>........] - ETA: 0s - loss: 3.8661 - acc: 0.760\n",
      "INFO\t2019-09-09 14:39:49 -0400\tmaster-replica-0\t2\t223/285 [======================>.......] - ETA: 0s - loss: 3.8713 - acc: 0.759\n",
      "INFO\t2019-09-09 14:39:49 -0400\tmaster-replica-0\t2\t232/285 [=======================>......] - ETA: 0s - loss: 3.8772 - acc: 0.759\n",
      "INFO\t2019-09-09 14:39:49 -0400\tmaster-replica-0\t2\t239/285 [========================>.....] - ETA: 0s - loss: 3.8736 - acc: 0.759\n",
      "INFO\t2019-09-09 14:39:49 -0400\tmaster-replica-0\t2\t248/285 [=========================>....] - ETA: 0s - loss: 3.8716 - acc: 0.759\n",
      "INFO\t2019-09-09 14:39:49 -0400\tmaster-replica-0\t2\t259/285 [==========================>...] - ETA: 0s - loss: 3.8682 - acc: 0.760\n",
      "INFO\t2019-09-09 14:39:49 -0400\tmaster-replica-0\t2\t269/285 [===========================>..] - ETA: 0s - loss: 3.8674 - acc: 0.760\n",
      "INFO\t2019-09-09 14:39:50 -0400\tmaster-replica-0\t2\t279/285 [============================>.] - ETA: 0s - loss: 3.8818 - acc: 0.759\n",
      "INFO\t2019-09-09 14:39:50 -0400\tmaster-replica-0\t2\t285/285 [==============================] - 3s 10ms/step - loss: 3.8859 - acc: 0.7589 - val_loss: 3.8072 - val_acc: 0.7638\n",
      "INFO\t2019-09-09 14:39:50 -0400\tmaster-replica-0\t2\tEpoch 00007: LearningRateScheduler reducing learning rate to 0.039204067272779385.\n",
      "INFO\t2019-09-09 14:39:50 -0400\tmaster-replica-0\t2\tEpoch 7/20\n",
      "INFO\t2019-09-09 14:39:50 -0400\tmaster-replica-0\t2\t  1/285 [..............................] - ETA: 30s - loss: 3.2519 - acc: 0.79\n",
      "INFO\t2019-09-09 14:39:50 -0400\tmaster-replica-0\t2\t  7/285 [..............................] - ETA: 6s - loss: 3.8174 - acc: 0.7632\n",
      "INFO\t2019-09-09 14:39:50 -0400\tmaster-replica-0\t2\t 16/285 [>.............................] - ETA: 3s - loss: 3.9588 - acc: 0.754\n",
      "INFO\t2019-09-09 14:39:50 -0400\tmaster-replica-0\t2\t 26/285 [=>............................] - ETA: 2s - loss: 3.8174 - acc: 0.763\n",
      "INFO\t2019-09-09 14:39:50 -0400\tmaster-replica-0\t2\t 32/285 [==>...........................] - ETA: 2s - loss: 3.7556 - acc: 0.767\n",
      "INFO\t2019-09-09 14:39:51 -0400\tmaster-replica-0\t2\t 40/285 [===>..........................] - ETA: 2s - loss: 3.8139 - acc: 0.763\n",
      "INFO\t2019-09-09 14:39:51 -0400\tmaster-replica-0\t2\t 49/285 [====>.........................] - ETA: 2s - loss: 3.8117 - acc: 0.763\n",
      "INFO\t2019-09-09 14:39:51 -0400\tmaster-replica-0\t2\t 60/285 [=====>........................] - ETA: 1s - loss: 3.8339 - acc: 0.762\n",
      "INFO\t2019-09-09 14:39:51 -0400\tmaster-replica-0\t2\t 70/285 [======>.......................] - ETA: 1s - loss: 3.8114 - acc: 0.763\n",
      "INFO\t2019-09-09 14:39:51 -0400\tmaster-replica-0\t2\t 81/285 [=======>......................] - ETA: 1s - loss: 3.8366 - acc: 0.762\n",
      "INFO\t2019-09-09 14:39:51 -0400\tmaster-replica-0\t2\t 89/285 [========>.....................] - ETA: 1s - loss: 3.8429 - acc: 0.761\n",
      "INFO\t2019-09-09 14:39:51 -0400\tmaster-replica-0\t2\t 99/285 [=========>....................] - ETA: 1s - loss: 3.8246 - acc: 0.762\n",
      "INFO\t2019-09-09 14:39:51 -0400\tmaster-replica-0\t2\t109/285 [==========>...................] - ETA: 1s - loss: 3.8408 - acc: 0.761\n",
      "INFO\t2019-09-09 14:39:51 -0400\tmaster-replica-0\t2\t119/285 [===========>..................] - ETA: 1s - loss: 3.8555 - acc: 0.760\n",
      "INFO\t2019-09-09 14:39:51 -0400\tmaster-replica-0\t2\t126/285 [============>.................] - ETA: 1s - loss: 3.8455 - acc: 0.761\n",
      "INFO\t2019-09-09 14:39:51 -0400\tmaster-replica-0\t2\t136/285 [=============>................] - ETA: 0s - loss: 3.8590 - acc: 0.760\n",
      "INFO\t2019-09-09 14:39:51 -0400\tmaster-replica-0\t2\t145/285 [==============>...............] - ETA: 0s - loss: 3.8681 - acc: 0.760\n",
      "INFO\t2019-09-09 14:39:51 -0400\tmaster-replica-0\t2\t153/285 [===============>..............] - ETA: 0s - loss: 3.8581 - acc: 0.760\n",
      "INFO\t2019-09-09 14:39:51 -0400\tmaster-replica-0\t2\t160/285 [===============>..............] - ETA: 0s - loss: 3.8731 - acc: 0.759\n",
      "INFO\t2019-09-09 14:39:51 -0400\tmaster-replica-0\t2\t168/285 [================>.............] - ETA: 0s - loss: 3.8688 - acc: 0.760\n",
      "INFO\t2019-09-09 14:39:51 -0400\tmaster-replica-0\t2\t177/285 [=================>............] - ETA: 0s - loss: 3.8462 - acc: 0.761\n",
      "INFO\t2019-09-09 14:39:51 -0400\tmaster-replica-0\t2\t185/285 [==================>...........] - ETA: 0s - loss: 3.8526 - acc: 0.761\n",
      "INFO\t2019-09-09 14:39:51 -0400\tmaster-replica-0\t2\t197/285 [===================>..........] - ETA: 0s - loss: 3.8706 - acc: 0.759\n",
      "INFO\t2019-09-09 14:39:51 -0400\tmaster-replica-0\t2\t205/285 [====================>.........] - ETA: 0s - loss: 3.8726 - acc: 0.759\n",
      "INFO\t2019-09-09 14:39:52 -0400\tmaster-replica-0\t2\t216/285 [=====================>........] - ETA: 0s - loss: 3.8862 - acc: 0.758\n",
      "INFO\t2019-09-09 14:39:52 -0400\tmaster-replica-0\t2\t225/285 [======================>.......] - ETA: 0s - loss: 3.8778 - acc: 0.759\n",
      "INFO\t2019-09-09 14:39:52 -0400\tmaster-replica-0\t2\t238/285 [========================>.....] - ETA: 0s - loss: 3.8656 - acc: 0.760\n",
      "INFO\t2019-09-09 14:39:52 -0400\tmaster-replica-0\t2\t246/285 [========================>.....] - ETA: 0s - loss: 3.8772 - acc: 0.759\n",
      "INFO\t2019-09-09 14:39:52 -0400\tmaster-replica-0\t2\t255/285 [=========================>....] - ETA: 0s - loss: 3.8746 - acc: 0.759\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO\t2019-09-09 14:39:52 -0400\tmaster-replica-0\t2\t263/285 [==========================>...] - ETA: 0s - loss: 3.8664 - acc: 0.760\n",
      "INFO\t2019-09-09 14:39:53 -0400\tmaster-replica-0\t2\t274/285 [===========================>..] - ETA: 0s - loss: 3.8804 - acc: 0.759\n",
      "INFO\t2019-09-09 14:39:53 -0400\tmaster-replica-0\t2\t285/285 [==============================] - 3s 10ms/step - loss: 3.8765 - acc: 0.7595 - val_loss: 3.8072 - val_acc: 0.7638\n",
      "INFO\t2019-09-09 14:39:53 -0400\tmaster-replica-0\t2\tEpoch 00008: LearningRateScheduler reducing learning rate to 0.039125942272779386.\n",
      "INFO\t2019-09-09 14:39:53 -0400\tmaster-replica-0\t2\tEpoch 8/20\n",
      "INFO\t2019-09-09 14:39:53 -0400\tmaster-replica-0\t2\t  1/285 [..............................] - ETA: 2s - loss: 3.3933 - acc: 0.789\n",
      "INFO\t2019-09-09 14:39:53 -0400\tmaster-replica-0\t2\t 11/285 [>.............................] - ETA: 1s - loss: 4.2159 - acc: 0.738\n",
      "INFO\t2019-09-09 14:39:53 -0400\tmaster-replica-0\t2\t 25/285 [=>............................] - ETA: 1s - loss: 4.0324 - acc: 0.749\n",
      "INFO\t2019-09-09 14:39:53 -0400\tmaster-replica-0\t2\t 34/285 [==>...........................] - ETA: 1s - loss: 3.9671 - acc: 0.753\n",
      "INFO\t2019-09-09 14:39:53 -0400\tmaster-replica-0\t2\t 44/285 [===>..........................] - ETA: 1s - loss: 3.9942 - acc: 0.752\n",
      "INFO\t2019-09-09 14:39:53 -0400\tmaster-replica-0\t2\t 53/285 [====>.........................] - ETA: 1s - loss: 3.9642 - acc: 0.754\n",
      "INFO\t2019-09-09 14:39:53 -0400\tmaster-replica-0\t2\t 62/285 [=====>........................] - ETA: 1s - loss: 3.9816 - acc: 0.753\n",
      "INFO\t2019-09-09 14:39:53 -0400\tmaster-replica-0\t2\t 73/285 [======>.......................] - ETA: 1s - loss: 3.9763 - acc: 0.753\n",
      "INFO\t2019-09-09 14:39:53 -0400\tmaster-replica-0\t2\t 84/285 [=======>......................] - ETA: 1s - loss: 3.9622 - acc: 0.754\n",
      "INFO\t2019-09-09 14:39:53 -0400\tmaster-replica-0\t2\t 95/285 [=========>....................] - ETA: 0s - loss: 3.9350 - acc: 0.755\n",
      "INFO\t2019-09-09 14:39:53 -0400\tmaster-replica-0\t2\t104/285 [=========>....................] - ETA: 0s - loss: 3.9140 - acc: 0.757\n",
      "INFO\t2019-09-09 14:39:54 -0400\tmaster-replica-0\t2\t115/285 [===========>..................] - ETA: 0s - loss: 3.9072 - acc: 0.757\n",
      "INFO\t2019-09-09 14:39:54 -0400\tmaster-replica-0\t2\t122/285 [===========>..................] - ETA: 0s - loss: 3.9357 - acc: 0.755\n",
      "INFO\t2019-09-09 14:39:54 -0400\tmaster-replica-0\t2\t134/285 [=============>................] - ETA: 0s - loss: 3.9219 - acc: 0.756\n",
      "INFO\t2019-09-09 14:39:54 -0400\tmaster-replica-0\t2\t142/285 [=============>................] - ETA: 0s - loss: 3.9648 - acc: 0.754\n",
      "INFO\t2019-09-09 14:39:54 -0400\tmaster-replica-0\t2\t154/285 [===============>..............] - ETA: 0s - loss: 3.9478 - acc: 0.755\n",
      "INFO\t2019-09-09 14:39:54 -0400\tmaster-replica-0\t2\t160/285 [===============>..............] - ETA: 0s - loss: 3.9465 - acc: 0.755\n",
      "INFO\t2019-09-09 14:39:54 -0400\tmaster-replica-0\t2\t169/285 [================>.............] - ETA: 0s - loss: 3.9429 - acc: 0.755\n",
      "INFO\t2019-09-09 14:39:54 -0400\tmaster-replica-0\t2\t174/285 [=================>............] - ETA: 0s - loss: 3.9434 - acc: 0.755\n",
      "INFO\t2019-09-09 14:39:54 -0400\tmaster-replica-0\t2\t184/285 [==================>...........] - ETA: 0s - loss: 3.9496 - acc: 0.755\n",
      "INFO\t2019-09-09 14:39:54 -0400\tmaster-replica-0\t2\t192/285 [===================>..........] - ETA: 0s - loss: 3.9250 - acc: 0.756\n",
      "INFO\t2019-09-09 14:39:54 -0400\tmaster-replica-0\t2\t203/285 [====================>.........] - ETA: 0s - loss: 3.9386 - acc: 0.755\n",
      "INFO\t2019-09-09 14:39:54 -0400\tmaster-replica-0\t2\t211/285 [=====================>........] - ETA: 0s - loss: 3.9293 - acc: 0.756\n",
      "INFO\t2019-09-09 14:39:54 -0400\tmaster-replica-0\t2\t219/285 [======================>.......] - ETA: 0s - loss: 3.9375 - acc: 0.755\n",
      "INFO\t2019-09-09 14:39:54 -0400\tmaster-replica-0\t2\t228/285 [=======================>......] - ETA: 0s - loss: 3.9074 - acc: 0.757\n",
      "INFO\t2019-09-09 14:39:54 -0400\tmaster-replica-0\t2\t235/285 [=======================>......] - ETA: 0s - loss: 3.8945 - acc: 0.758\n",
      "INFO\t2019-09-09 14:39:54 -0400\tmaster-replica-0\t2\t243/285 [========================>.....] - ETA: 0s - loss: 3.8838 - acc: 0.759\n",
      "INFO\t2019-09-09 14:39:54 -0400\tmaster-replica-0\t2\t254/285 [=========================>....] - ETA: 0s - loss: 3.8909 - acc: 0.758\n",
      "INFO\t2019-09-09 14:39:54 -0400\tmaster-replica-0\t2\t262/285 [==========================>...] - ETA: 0s - loss: 3.8952 - acc: 0.758\n",
      "INFO\t2019-09-09 14:39:54 -0400\tmaster-replica-0\t2\t268/285 [===========================>..] - ETA: 0s - loss: 3.8881 - acc: 0.758\n",
      "INFO\t2019-09-09 14:39:56 -0400\tmaster-replica-0\t2\t275/285 [===========================>..] - ETA: 0s - loss: 3.8884 - acc: 0.758\n",
      "INFO\t2019-09-09 14:39:56 -0400\tmaster-replica-0\t2\t285/285 [==============================] - 3s 10ms/step - loss: 3.8854 - acc: 0.7589 - val_loss: 3.8072 - val_acc: 0.7638\n",
      "INFO\t2019-09-09 14:39:56 -0400\tmaster-replica-0\t2\tEpoch 00009: LearningRateScheduler reducing learning rate to 0.03908687977277939.\n",
      "INFO\t2019-09-09 14:39:56 -0400\tmaster-replica-0\t2\tEpoch 9/20\n",
      "INFO\t2019-09-09 14:39:56 -0400\tmaster-replica-0\t2\t  1/285 [..............................] - ETA: 1s - loss: 3.9588 - acc: 0.754\n",
      "INFO\t2019-09-09 14:39:56 -0400\tmaster-replica-0\t2\t 10/285 [>.............................] - ETA: 1s - loss: 3.8881 - acc: 0.758\n",
      "INFO\t2019-09-09 14:39:56 -0400\tmaster-replica-0\t2\t 21/285 [=>............................] - ETA: 1s - loss: 3.7972 - acc: 0.764\n",
      "INFO\t2019-09-09 14:39:56 -0400\tmaster-replica-0\t2\t 29/285 [==>...........................] - ETA: 1s - loss: 3.8711 - acc: 0.759\n",
      "INFO\t2019-09-09 14:39:56 -0400\tmaster-replica-0\t2\t 36/285 [==>...........................] - ETA: 1s - loss: 3.8999 - acc: 0.758\n",
      "INFO\t2019-09-09 14:39:56 -0400\tmaster-replica-0\t2\t 45/285 [===>..........................] - ETA: 1s - loss: 3.9086 - acc: 0.757\n",
      "INFO\t2019-09-09 14:39:56 -0400\tmaster-replica-0\t2\t 55/285 [====>.........................] - ETA: 1s - loss: 3.9254 - acc: 0.756\n",
      "INFO\t2019-09-09 14:39:56 -0400\tmaster-replica-0\t2\t 65/285 [=====>........................] - ETA: 1s - loss: 3.9066 - acc: 0.757\n",
      "INFO\t2019-09-09 14:39:56 -0400\tmaster-replica-0\t2\t 78/285 [=======>......................] - ETA: 1s - loss: 3.9081 - acc: 0.757\n",
      "INFO\t2019-09-09 14:39:56 -0400\tmaster-replica-0\t2\t 86/285 [========>.....................] - ETA: 1s - loss: 3.8865 - acc: 0.758\n",
      "INFO\t2019-09-09 14:39:56 -0400\tmaster-replica-0\t2\t 96/285 [=========>....................] - ETA: 1s - loss: 3.8984 - acc: 0.758\n",
      "INFO\t2019-09-09 14:39:56 -0400\tmaster-replica-0\t2\t104/285 [=========>....................] - ETA: 1s - loss: 3.9058 - acc: 0.757\n",
      "INFO\t2019-09-09 14:39:56 -0400\tmaster-replica-0\t2\t111/285 [==========>...................] - ETA: 0s - loss: 3.9041 - acc: 0.757\n",
      "INFO\t2019-09-09 14:39:56 -0400\tmaster-replica-0\t2\t117/285 [===========>..................] - ETA: 0s - loss: 3.8887 - acc: 0.758\n",
      "INFO\t2019-09-09 14:39:56 -0400\tmaster-replica-0\t2\t127/285 [============>.................] - ETA: 0s - loss: 3.9009 - acc: 0.758\n",
      "INFO\t2019-09-09 14:39:56 -0400\tmaster-replica-0\t2\t135/285 [=============>................] - ETA: 0s - loss: 3.9065 - acc: 0.757\n",
      "INFO\t2019-09-09 14:39:57 -0400\tmaster-replica-0\t2\t144/285 [==============>...............] - ETA: 0s - loss: 3.9176 - acc: 0.756\n",
      "INFO\t2019-09-09 14:39:57 -0400\tmaster-replica-0\t2\t152/285 [===============>..............] - ETA: 0s - loss: 3.9198 - acc: 0.756\n",
      "INFO\t2019-09-09 14:39:57 -0400\tmaster-replica-0\t2\t159/285 [===============>..............] - ETA: 0s - loss: 3.9081 - acc: 0.757\n",
      "INFO\t2019-09-09 14:39:57 -0400\tmaster-replica-0\t2\t170/285 [================>.............] - ETA: 0s - loss: 3.9056 - acc: 0.757\n",
      "INFO\t2019-09-09 14:39:57 -0400\tmaster-replica-0\t2\t177/285 [=================>............] - ETA: 0s - loss: 3.9045 - acc: 0.757\n",
      "INFO\t2019-09-09 14:39:57 -0400\tmaster-replica-0\t2\t187/285 [==================>...........] - ETA: 0s - loss: 3.9089 - acc: 0.757\n",
      "INFO\t2019-09-09 14:39:57 -0400\tmaster-replica-0\t2\t195/285 [===================>..........] - ETA: 0s - loss: 3.8907 - acc: 0.758\n",
      "INFO\t2019-09-09 14:39:57 -0400\tmaster-replica-0\t2\t204/285 [====================>.........] - ETA: 0s - loss: 3.8743 - acc: 0.759\n",
      "INFO\t2019-09-09 14:39:57 -0400\tmaster-replica-0\t2\t210/285 [=====================>........] - ETA: 0s - loss: 3.8780 - acc: 0.759\n",
      "INFO\t2019-09-09 14:39:57 -0400\tmaster-replica-0\t2\t218/285 [=====================>........] - ETA: 0s - loss: 3.8920 - acc: 0.758\n",
      "INFO\t2019-09-09 14:39:57 -0400\tmaster-replica-0\t2\t228/285 [=======================>......] - ETA: 0s - loss: 3.8974 - acc: 0.758\n",
      "INFO\t2019-09-09 14:39:57 -0400\tmaster-replica-0\t2\t237/285 [=======================>......] - ETA: 0s - loss: 3.8801 - acc: 0.759\n",
      "INFO\t2019-09-09 14:39:57 -0400\tmaster-replica-0\t2\t244/285 [========================>.....] - ETA: 0s - loss: 3.8800 - acc: 0.759\n",
      "INFO\t2019-09-09 14:39:57 -0400\tmaster-replica-0\t2\t252/285 [=========================>....] - ETA: 0s - loss: 3.8814 - acc: 0.759\n",
      "INFO\t2019-09-09 14:39:57 -0400\tmaster-replica-0\t2\t261/285 [==========================>...] - ETA: 0s - loss: 3.8770 - acc: 0.759\n",
      "INFO\t2019-09-09 14:39:57 -0400\tmaster-replica-0\t2\t270/285 [===========================>..] - ETA: 0s - loss: 3.8693 - acc: 0.759\n",
      "INFO\t2019-09-09 14:39:59 -0400\tmaster-replica-0\t2\t277/285 [============================>.] - ETA: 0s - loss: 3.8700 - acc: 0.759\n",
      "INFO\t2019-09-09 14:39:59 -0400\tmaster-replica-0\t2\t285/285 [==============================] - 3s 11ms/step - loss: 3.8720 - acc: 0.7598 - val_loss: 3.8072 - val_acc: 0.7638\n",
      "INFO\t2019-09-09 14:39:59 -0400\tmaster-replica-0\t2\tEpoch 00010: LearningRateScheduler reducing learning rate to 0.03906734852277939.\n",
      "INFO\t2019-09-09 14:39:59 -0400\tmaster-replica-0\t2\tEpoch 10/20\n",
      "INFO\t2019-09-09 14:39:59 -0400\tmaster-replica-0\t2\t  1/285 [..............................] - ETA: 1s - loss: 3.2519 - acc: 0.798\n",
      "INFO\t2019-09-09 14:39:59 -0400\tmaster-replica-0\t2\t  8/285 [..............................] - ETA: 2s - loss: 4.3830 - acc: 0.728\n",
      "INFO\t2019-09-09 14:39:59 -0400\tmaster-replica-0\t2\t 18/285 [>.............................] - ETA: 1s - loss: 4.1238 - acc: 0.744\n",
      "INFO\t2019-09-09 14:39:59 -0400\tmaster-replica-0\t2\t 26/285 [=>............................] - ETA: 1s - loss: 4.1818 - acc: 0.740\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO\t2019-09-09 14:39:59 -0400\tmaster-replica-0\t2\t 35/285 [==>...........................] - ETA: 1s - loss: 4.0719 - acc: 0.747\n",
      "INFO\t2019-09-09 14:39:59 -0400\tmaster-replica-0\t2\t 44/285 [===>..........................] - ETA: 1s - loss: 4.0231 - acc: 0.750\n",
      "INFO\t2019-09-09 14:39:59 -0400\tmaster-replica-0\t2\t 55/285 [====>.........................] - ETA: 1s - loss: 3.9948 - acc: 0.752\n",
      "INFO\t2019-09-09 14:39:59 -0400\tmaster-replica-0\t2\t 65/285 [=====>........................] - ETA: 1s - loss: 4.0154 - acc: 0.750\n",
      "INFO\t2019-09-09 14:39:59 -0400\tmaster-replica-0\t2\t 72/285 [======>.......................] - ETA: 1s - loss: 4.0119 - acc: 0.751\n",
      "INFO\t2019-09-09 14:39:59 -0400\tmaster-replica-0\t2\t 81/285 [=======>......................] - ETA: 1s - loss: 3.9780 - acc: 0.753\n",
      "INFO\t2019-09-09 14:39:59 -0400\tmaster-replica-0\t2\t 91/285 [========>.....................] - ETA: 1s - loss: 3.9495 - acc: 0.755\n",
      "INFO\t2019-09-09 14:40:00 -0400\tmaster-replica-0\t2\t101/285 [=========>....................] - ETA: 1s - loss: 3.9588 - acc: 0.754\n",
      "INFO\t2019-09-09 14:40:00 -0400\tmaster-replica-0\t2\t112/285 [==========>...................] - ETA: 0s - loss: 3.9121 - acc: 0.757\n",
      "INFO\t2019-09-09 14:40:00 -0400\tmaster-replica-0\t2\t116/285 [===========>..................] - ETA: 1s - loss: 3.9040 - acc: 0.757\n",
      "INFO\t2019-09-09 14:40:00 -0400\tmaster-replica-0\t2\t122/285 [===========>..................] - ETA: 1s - loss: 3.8847 - acc: 0.759\n",
      "INFO\t2019-09-09 14:40:00 -0400\tmaster-replica-0\t2\t131/285 [============>.................] - ETA: 0s - loss: 3.8844 - acc: 0.759\n",
      "INFO\t2019-09-09 14:40:00 -0400\tmaster-replica-0\t2\t142/285 [=============>................] - ETA: 0s - loss: 3.8593 - acc: 0.760\n",
      "INFO\t2019-09-09 14:40:00 -0400\tmaster-replica-0\t2\t151/285 [==============>...............] - ETA: 0s - loss: 3.8643 - acc: 0.760\n",
      "INFO\t2019-09-09 14:40:00 -0400\tmaster-replica-0\t2\t160/285 [===============>..............] - ETA: 0s - loss: 3.8519 - acc: 0.761\n",
      "INFO\t2019-09-09 14:40:00 -0400\tmaster-replica-0\t2\t168/285 [================>.............] - ETA: 0s - loss: 3.8494 - acc: 0.761\n",
      "INFO\t2019-09-09 14:40:00 -0400\tmaster-replica-0\t2\t178/285 [=================>............] - ETA: 0s - loss: 3.8516 - acc: 0.761\n",
      "INFO\t2019-09-09 14:40:00 -0400\tmaster-replica-0\t2\t186/285 [==================>...........] - ETA: 0s - loss: 3.8364 - acc: 0.762\n",
      "INFO\t2019-09-09 14:40:00 -0400\tmaster-replica-0\t2\t197/285 [===================>..........] - ETA: 0s - loss: 3.8497 - acc: 0.761\n",
      "INFO\t2019-09-09 14:40:00 -0400\tmaster-replica-0\t2\t206/285 [====================>.........] - ETA: 0s - loss: 3.8483 - acc: 0.761\n",
      "INFO\t2019-09-09 14:40:00 -0400\tmaster-replica-0\t2\t216/285 [=====================>........] - ETA: 0s - loss: 3.8495 - acc: 0.761\n",
      "INFO\t2019-09-09 14:40:00 -0400\tmaster-replica-0\t2\t223/285 [======================>.......] - ETA: 0s - loss: 3.8529 - acc: 0.761\n",
      "INFO\t2019-09-09 14:40:00 -0400\tmaster-replica-0\t2\t233/285 [=======================>......] - ETA: 0s - loss: 3.8599 - acc: 0.760\n",
      "INFO\t2019-09-09 14:40:00 -0400\tmaster-replica-0\t2\t241/285 [========================>.....] - ETA: 0s - loss: 3.8562 - acc: 0.760\n",
      "INFO\t2019-09-09 14:40:00 -0400\tmaster-replica-0\t2\t249/285 [=========================>....] - ETA: 0s - loss: 3.8685 - acc: 0.760\n",
      "INFO\t2019-09-09 14:40:00 -0400\tmaster-replica-0\t2\t259/285 [==========================>...] - ETA: 0s - loss: 3.8682 - acc: 0.760\n",
      "INFO\t2019-09-09 14:40:01 -0400\tmaster-replica-0\t2\t265/285 [==========================>...] - ETA: 0s - loss: 3.8761 - acc: 0.759\n",
      "INFO\t2019-09-09 14:40:01 -0400\tmaster-replica-0\t2\t273/285 [===========================>..] - ETA: 0s - loss: 3.8843 - acc: 0.759\n",
      "INFO\t2019-09-09 14:40:02 -0400\tmaster-replica-0\t2\t279/285 [============================>.] - ETA: 0s - loss: 3.8869 - acc: 0.758\n",
      "INFO\t2019-09-09 14:40:02 -0400\tmaster-replica-0\t2\t285/285 [==============================] - 3s 10ms/step - loss: 3.8904 - acc: 0.7586 - val_loss: 3.8072 - val_acc: 0.7638\n",
      "INFO\t2019-09-09 14:40:02 -0400\tmaster-replica-0\t2\tEpoch 00011: LearningRateScheduler reducing learning rate to 0.039057582897779386.\n",
      "INFO\t2019-09-09 14:40:02 -0400\tmaster-replica-0\t2\tEpoch 11/20\n",
      "INFO\t2019-09-09 14:40:02 -0400\tmaster-replica-0\t2\t  1/285 [..............................] - ETA: 2s - loss: 2.6863 - acc: 0.833\n",
      "INFO\t2019-09-09 14:40:02 -0400\tmaster-replica-0\t2\t  8/285 [..............................] - ETA: 2s - loss: 3.9235 - acc: 0.756\n",
      "INFO\t2019-09-09 14:40:02 -0400\tmaster-replica-0\t2\t 15/285 [>.............................] - ETA: 2s - loss: 3.8646 - acc: 0.760\n",
      "INFO\t2019-09-09 14:40:02 -0400\tmaster-replica-0\t2\t 26/285 [=>............................] - ETA: 1s - loss: 3.9153 - acc: 0.757\n",
      "INFO\t2019-09-09 14:40:02 -0400\tmaster-replica-0\t2\t 38/285 [===>..........................] - ETA: 1s - loss: 3.8658 - acc: 0.760\n",
      "INFO\t2019-09-09 14:40:02 -0400\tmaster-replica-0\t2\t 46/285 [===>..........................] - ETA: 1s - loss: 3.8605 - acc: 0.760\n",
      "INFO\t2019-09-09 14:40:02 -0400\tmaster-replica-0\t2\t 56/285 [====>.........................] - ETA: 1s - loss: 3.8780 - acc: 0.759\n",
      "INFO\t2019-09-09 14:40:02 -0400\tmaster-replica-0\t2\t 67/285 [======>.......................] - ETA: 1s - loss: 3.8470 - acc: 0.761\n",
      "INFO\t2019-09-09 14:40:02 -0400\tmaster-replica-0\t2\t 79/285 [=======>......................] - ETA: 1s - loss: 3.8514 - acc: 0.761\n",
      "INFO\t2019-09-09 14:40:02 -0400\tmaster-replica-0\t2\t 88/285 [========>.....................] - ETA: 1s - loss: 3.8287 - acc: 0.762\n",
      "INFO\t2019-09-09 14:40:02 -0400\tmaster-replica-0\t2\t100/285 [=========>....................] - ETA: 0s - loss: 3.8372 - acc: 0.761\n",
      "INFO\t2019-09-09 14:40:02 -0400\tmaster-replica-0\t2\t107/285 [==========>...................] - ETA: 0s - loss: 3.8412 - acc: 0.761\n",
      "INFO\t2019-09-09 14:40:02 -0400\tmaster-replica-0\t2\t115/285 [===========>..................] - ETA: 0s - loss: 3.8715 - acc: 0.759\n",
      "INFO\t2019-09-09 14:40:02 -0400\tmaster-replica-0\t2\t123/285 [===========>..................] - ETA: 0s - loss: 3.8772 - acc: 0.759\n",
      "INFO\t2019-09-09 14:40:02 -0400\tmaster-replica-0\t2\t133/285 [=============>................] - ETA: 0s - loss: 3.8929 - acc: 0.758\n",
      "INFO\t2019-09-09 14:40:03 -0400\tmaster-replica-0\t2\t139/285 [=============>................] - ETA: 0s - loss: 3.8734 - acc: 0.759\n",
      "INFO\t2019-09-09 14:40:03 -0400\tmaster-replica-0\t2\t148/285 [==============>...............] - ETA: 0s - loss: 3.8767 - acc: 0.759\n",
      "INFO\t2019-09-09 14:40:03 -0400\tmaster-replica-0\t2\t157/285 [===============>..............] - ETA: 0s - loss: 3.8643 - acc: 0.760\n",
      "INFO\t2019-09-09 14:40:03 -0400\tmaster-replica-0\t2\t164/285 [================>.............] - ETA: 0s - loss: 3.8692 - acc: 0.759\n",
      "INFO\t2019-09-09 14:40:03 -0400\tmaster-replica-0\t2\t176/285 [=================>............] - ETA: 0s - loss: 3.8801 - acc: 0.759\n",
      "INFO\t2019-09-09 14:40:03 -0400\tmaster-replica-0\t2\t180/285 [=================>............] - ETA: 0s - loss: 3.8748 - acc: 0.759\n",
      "INFO\t2019-09-09 14:40:03 -0400\tmaster-replica-0\t2\t191/285 [===================>..........] - ETA: 0s - loss: 3.8767 - acc: 0.759\n",
      "INFO\t2019-09-09 14:40:03 -0400\tmaster-replica-0\t2\t199/285 [===================>..........] - ETA: 0s - loss: 3.8714 - acc: 0.759\n",
      "INFO\t2019-09-09 14:40:03 -0400\tmaster-replica-0\t2\t208/285 [====================>.........] - ETA: 0s - loss: 3.8773 - acc: 0.759\n",
      "INFO\t2019-09-09 14:40:03 -0400\tmaster-replica-0\t2\t220/285 [======================>.......] - ETA: 0s - loss: 3.8817 - acc: 0.759\n",
      "INFO\t2019-09-09 14:40:03 -0400\tmaster-replica-0\t2\t231/285 [=======================>......] - ETA: 0s - loss: 3.8750 - acc: 0.759\n",
      "INFO\t2019-09-09 14:40:03 -0400\tmaster-replica-0\t2\t243/285 [========================>.....] - ETA: 0s - loss: 3.8966 - acc: 0.758\n",
      "INFO\t2019-09-09 14:40:03 -0400\tmaster-replica-0\t2\t253/285 [=========================>....] - ETA: 0s - loss: 3.8912 - acc: 0.758\n",
      "INFO\t2019-09-09 14:40:03 -0400\tmaster-replica-0\t2\t266/285 [===========================>..] - ETA: 0s - loss: 3.8887 - acc: 0.758\n",
      "INFO\t2019-09-09 14:40:04 -0400\tmaster-replica-0\t2\t277/285 [============================>.] - ETA: 0s - loss: 3.8915 - acc: 0.758\n",
      "INFO\t2019-09-09 14:40:04 -0400\tmaster-replica-0\t2\t285/285 [==============================] - 3s 10ms/step - loss: 3.8814 - acc: 0.7592 - val_loss: 3.8072 - val_acc: 0.7638\n",
      "INFO\t2019-09-09 14:40:04 -0400\tmaster-replica-0\t2\tEpoch 00012: LearningRateScheduler reducing learning rate to 0.03905270008527939.\n",
      "INFO\t2019-09-09 14:40:04 -0400\tmaster-replica-0\t2\tEpoch 12/20\n",
      "INFO\t2019-09-09 14:40:04 -0400\tmaster-replica-0\t2\t  1/285 [..............................] - ETA: 4s - loss: 3.5347 - acc: 0.780\n",
      "INFO\t2019-09-09 14:40:04 -0400\tmaster-replica-0\t2\t 14/285 [>.............................] - ETA: 1s - loss: 3.8275 - acc: 0.762\n",
      "INFO\t2019-09-09 14:40:05 -0400\tmaster-replica-0\t2\t 24/285 [=>............................] - ETA: 1s - loss: 3.8351 - acc: 0.762\n",
      "INFO\t2019-09-09 14:40:05 -0400\tmaster-replica-0\t2\t 37/285 [==>...........................] - ETA: 1s - loss: 3.9474 - acc: 0.755\n",
      "INFO\t2019-09-09 14:40:05 -0400\tmaster-replica-0\t2\t 47/285 [===>..........................] - ETA: 1s - loss: 3.9077 - acc: 0.757\n",
      "INFO\t2019-09-09 14:40:05 -0400\tmaster-replica-0\t2\t 59/285 [=====>........................] - ETA: 1s - loss: 3.9013 - acc: 0.758\n",
      "INFO\t2019-09-09 14:40:05 -0400\tmaster-replica-0\t2\t 70/285 [======>.......................] - ETA: 1s - loss: 3.9205 - acc: 0.756\n",
      "INFO\t2019-09-09 14:40:05 -0400\tmaster-replica-0\t2\t 82/285 [=======>......................] - ETA: 0s - loss: 3.9295 - acc: 0.756\n",
      "INFO\t2019-09-09 14:40:05 -0400\tmaster-replica-0\t2\t 92/285 [========>.....................] - ETA: 0s - loss: 3.9127 - acc: 0.757\n",
      "INFO\t2019-09-09 14:40:05 -0400\tmaster-replica-0\t2\t105/285 [==========>...................] - ETA: 0s - loss: 3.9332 - acc: 0.756\n",
      "INFO\t2019-09-09 14:40:05 -0400\tmaster-replica-0\t2\t115/285 [===========>..................] - ETA: 0s - loss: 3.9465 - acc: 0.755\n",
      "INFO\t2019-09-09 14:40:05 -0400\tmaster-replica-0\t2\t127/285 [============>.................] - ETA: 0s - loss: 3.9566 - acc: 0.754\n",
      "INFO\t2019-09-09 14:40:05 -0400\tmaster-replica-0\t2\t137/285 [=============>................] - ETA: 0s - loss: 3.9258 - acc: 0.756\n",
      "INFO\t2019-09-09 14:40:05 -0400\tmaster-replica-0\t2\t149/285 [==============>...............] - ETA: 0s - loss: 3.9247 - acc: 0.756\n",
      "INFO\t2019-09-09 14:40:05 -0400\tmaster-replica-0\t2\t159/285 [===============>..............] - ETA: 0s - loss: 3.9348 - acc: 0.755\n",
      "INFO\t2019-09-09 14:40:05 -0400\tmaster-replica-0\t2\t172/285 [=================>............] - ETA: 0s - loss: 3.9235 - acc: 0.756\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO\t2019-09-09 14:40:05 -0400\tmaster-replica-0\t2\t182/285 [==================>...........] - ETA: 0s - loss: 3.9130 - acc: 0.757\n",
      "INFO\t2019-09-09 14:40:05 -0400\tmaster-replica-0\t2\t195/285 [===================>..........] - ETA: 0s - loss: 3.9030 - acc: 0.757\n",
      "INFO\t2019-09-09 14:40:05 -0400\tmaster-replica-0\t2\t207/285 [====================>.........] - ETA: 0s - loss: 3.8974 - acc: 0.758\n",
      "INFO\t2019-09-09 14:40:05 -0400\tmaster-replica-0\t2\t217/285 [=====================>........] - ETA: 0s - loss: 3.8924 - acc: 0.758\n",
      "INFO\t2019-09-09 14:40:05 -0400\tmaster-replica-0\t2\t228/285 [=======================>......] - ETA: 0s - loss: 3.8919 - acc: 0.758\n",
      "INFO\t2019-09-09 14:40:06 -0400\tmaster-replica-0\t2\t239/285 [========================>.....] - ETA: 0s - loss: 3.8961 - acc: 0.758\n",
      "INFO\t2019-09-09 14:40:06 -0400\tmaster-replica-0\t2\t252/285 [=========================>....] - ETA: 0s - loss: 3.8870 - acc: 0.758\n",
      "INFO\t2019-09-09 14:40:06 -0400\tmaster-replica-0\t2\t262/285 [==========================>...] - ETA: 0s - loss: 3.8822 - acc: 0.759\n",
      "INFO\t2019-09-09 14:40:07 -0400\tmaster-replica-0\t2\t275/285 [===========================>..] - ETA: 0s - loss: 3.8719 - acc: 0.759\n",
      "INFO\t2019-09-09 14:40:07 -0400\tmaster-replica-0\t2\t285/285 [==============================] - 2s 8ms/step - loss: 3.8819 - acc: 0.7592 - val_loss: 3.8072 - val_acc: 0.7638\n",
      "INFO\t2019-09-09 14:40:07 -0400\tmaster-replica-0\t2\tEpoch 00013: LearningRateScheduler reducing learning rate to 0.039050258679029386.\n",
      "INFO\t2019-09-09 14:40:07 -0400\tmaster-replica-0\t2\tEpoch 13/20\n",
      "INFO\t2019-09-09 14:40:07 -0400\tmaster-replica-0\t2\t  1/285 [..............................] - ETA: 1s - loss: 3.6761 - acc: 0.771\n",
      "INFO\t2019-09-09 14:40:07 -0400\tmaster-replica-0\t2\t 11/285 [>.............................] - ETA: 1s - loss: 3.6375 - acc: 0.774\n",
      "INFO\t2019-09-09 14:40:07 -0400\tmaster-replica-0\t2\t 24/285 [=>............................] - ETA: 1s - loss: 3.6702 - acc: 0.772\n",
      "INFO\t2019-09-09 14:40:07 -0400\tmaster-replica-0\t2\t 34/285 [==>...........................] - ETA: 1s - loss: 3.7925 - acc: 0.764\n",
      "INFO\t2019-09-09 14:40:07 -0400\tmaster-replica-0\t2\t 46/285 [===>..........................] - ETA: 1s - loss: 3.8359 - acc: 0.762\n",
      "INFO\t2019-09-09 14:40:07 -0400\tmaster-replica-0\t2\t 56/285 [====>.........................] - ETA: 1s - loss: 3.8881 - acc: 0.758\n",
      "INFO\t2019-09-09 14:40:07 -0400\tmaster-replica-0\t2\t 68/285 [======>.......................] - ETA: 1s - loss: 3.9131 - acc: 0.757\n",
      "INFO\t2019-09-09 14:40:07 -0400\tmaster-replica-0\t2\t 79/285 [=======>......................] - ETA: 0s - loss: 3.8908 - acc: 0.758\n",
      "INFO\t2019-09-09 14:40:07 -0400\tmaster-replica-0\t2\t 89/285 [========>.....................] - ETA: 0s - loss: 3.8381 - acc: 0.761\n",
      "INFO\t2019-09-09 14:40:07 -0400\tmaster-replica-0\t2\t101/285 [=========>....................] - ETA: 0s - loss: 3.8286 - acc: 0.762\n",
      "INFO\t2019-09-09 14:40:07 -0400\tmaster-replica-0\t2\t112/285 [==========>...................] - ETA: 0s - loss: 3.8238 - acc: 0.762\n",
      "INFO\t2019-09-09 14:40:07 -0400\tmaster-replica-0\t2\t124/285 [============>.................] - ETA: 0s - loss: 3.8311 - acc: 0.762\n",
      "INFO\t2019-09-09 14:40:07 -0400\tmaster-replica-0\t2\t134/285 [=============>................] - ETA: 0s - loss: 3.8512 - acc: 0.761\n",
      "INFO\t2019-09-09 14:40:08 -0400\tmaster-replica-0\t2\t146/285 [==============>...............] - ETA: 0s - loss: 3.8387 - acc: 0.761\n",
      "INFO\t2019-09-09 14:40:08 -0400\tmaster-replica-0\t2\t156/285 [===============>..............] - ETA: 0s - loss: 3.8329 - acc: 0.762\n",
      "INFO\t2019-09-09 14:40:08 -0400\tmaster-replica-0\t2\t169/285 [================>.............] - ETA: 0s - loss: 3.8200 - acc: 0.763\n",
      "INFO\t2019-09-09 14:40:08 -0400\tmaster-replica-0\t2\t179/285 [=================>............] - ETA: 0s - loss: 3.8206 - acc: 0.763\n",
      "INFO\t2019-09-09 14:40:08 -0400\tmaster-replica-0\t2\t192/285 [===================>..........] - ETA: 0s - loss: 3.8565 - acc: 0.760\n",
      "INFO\t2019-09-09 14:40:08 -0400\tmaster-replica-0\t2\t202/285 [====================>.........] - ETA: 0s - loss: 3.8629 - acc: 0.760\n",
      "INFO\t2019-09-09 14:40:08 -0400\tmaster-replica-0\t2\t215/285 [=====================>........] - ETA: 0s - loss: 3.8444 - acc: 0.761\n",
      "INFO\t2019-09-09 14:40:08 -0400\tmaster-replica-0\t2\t226/285 [======================>.......] - ETA: 0s - loss: 3.8462 - acc: 0.761\n",
      "INFO\t2019-09-09 14:40:08 -0400\tmaster-replica-0\t2\t239/285 [========================>.....] - ETA: 0s - loss: 3.8346 - acc: 0.762\n",
      "INFO\t2019-09-09 14:40:08 -0400\tmaster-replica-0\t2\t249/285 [=========================>....] - ETA: 0s - loss: 3.8402 - acc: 0.761\n",
      "INFO\t2019-09-09 14:40:08 -0400\tmaster-replica-0\t2\t262/285 [==========================>...] - ETA: 0s - loss: 3.8547 - acc: 0.760\n",
      "INFO\t2019-09-09 14:40:09 -0400\tmaster-replica-0\t2\t272/285 [===========================>..] - ETA: 0s - loss: 3.8606 - acc: 0.760\n",
      "INFO\t2019-09-09 14:40:09 -0400\tmaster-replica-0\t2\t285/285 [==============================] - 2s 8ms/step - loss: 3.8680 - acc: 0.7600 - val_loss: 3.8072 - val_acc: 0.7638\n",
      "INFO\t2019-09-09 14:40:09 -0400\tmaster-replica-0\t2\tEpoch 00014: LearningRateScheduler reducing learning rate to 0.03904903797590439.\n",
      "INFO\t2019-09-09 14:40:09 -0400\tmaster-replica-0\t2\tEpoch 14/20\n",
      "INFO\t2019-09-09 14:40:09 -0400\tmaster-replica-0\t2\t  1/285 [..............................] - ETA: 26s - loss: 4.1002 - acc: 0.74\n",
      "INFO\t2019-09-09 14:40:09 -0400\tmaster-replica-0\t2\t 12/285 [>.............................] - ETA: 3s - loss: 4.1120 - acc: 0.7449\n",
      "INFO\t2019-09-09 14:40:09 -0400\tmaster-replica-0\t2\t 24/285 [=>............................] - ETA: 2s - loss: 4.0001 - acc: 0.751\n",
      "INFO\t2019-09-09 14:40:09 -0400\tmaster-replica-0\t2\t 37/285 [==>...........................] - ETA: 1s - loss: 3.9627 - acc: 0.754\n",
      "INFO\t2019-09-09 14:40:09 -0400\tmaster-replica-0\t2\t 47/285 [===>..........................] - ETA: 1s - loss: 3.9348 - acc: 0.755\n",
      "INFO\t2019-09-09 14:40:10 -0400\tmaster-replica-0\t2\t 59/285 [=====>........................] - ETA: 1s - loss: 3.9373 - acc: 0.755\n",
      "INFO\t2019-09-09 14:40:10 -0400\tmaster-replica-0\t2\t 70/285 [======>.......................] - ETA: 1s - loss: 3.9124 - acc: 0.757\n",
      "INFO\t2019-09-09 14:40:10 -0400\tmaster-replica-0\t2\t 82/285 [=======>......................] - ETA: 1s - loss: 3.9019 - acc: 0.757\n",
      "INFO\t2019-09-09 14:40:10 -0400\tmaster-replica-0\t2\t 92/285 [========>.....................] - ETA: 1s - loss: 3.8989 - acc: 0.758\n",
      "INFO\t2019-09-09 14:40:10 -0400\tmaster-replica-0\t2\t105/285 [==========>...................] - ETA: 0s - loss: 3.9521 - acc: 0.754\n",
      "INFO\t2019-09-09 14:40:10 -0400\tmaster-replica-0\t2\t115/285 [===========>..................] - ETA: 0s - loss: 3.9453 - acc: 0.755\n",
      "INFO\t2019-09-09 14:40:10 -0400\tmaster-replica-0\t2\t128/285 [============>.................] - ETA: 0s - loss: 3.9246 - acc: 0.756\n",
      "INFO\t2019-09-09 14:40:10 -0400\tmaster-replica-0\t2\t137/285 [=============>................] - ETA: 0s - loss: 3.9330 - acc: 0.756\n",
      "INFO\t2019-09-09 14:40:10 -0400\tmaster-replica-0\t2\t149/285 [==============>...............] - ETA: 0s - loss: 3.9474 - acc: 0.755\n",
      "INFO\t2019-09-09 14:40:10 -0400\tmaster-replica-0\t2\t160/285 [===============>..............] - ETA: 0s - loss: 3.9341 - acc: 0.755\n",
      "INFO\t2019-09-09 14:40:10 -0400\tmaster-replica-0\t2\t172/285 [=================>............] - ETA: 0s - loss: 3.9251 - acc: 0.756\n",
      "INFO\t2019-09-09 14:40:10 -0400\tmaster-replica-0\t2\t182/285 [==================>...........] - ETA: 0s - loss: 3.9161 - acc: 0.757\n",
      "INFO\t2019-09-09 14:40:10 -0400\tmaster-replica-0\t2\t195/285 [===================>..........] - ETA: 0s - loss: 3.9124 - acc: 0.757\n",
      "INFO\t2019-09-09 14:40:10 -0400\tmaster-replica-0\t2\t205/285 [====================>.........] - ETA: 0s - loss: 3.9202 - acc: 0.756\n",
      "INFO\t2019-09-09 14:40:10 -0400\tmaster-replica-0\t2\t217/285 [=====================>........] - ETA: 0s - loss: 3.9210 - acc: 0.756\n",
      "INFO\t2019-09-09 14:40:10 -0400\tmaster-replica-0\t2\t229/285 [=======================>......] - ETA: 0s - loss: 3.9131 - acc: 0.757\n",
      "INFO\t2019-09-09 14:40:10 -0400\tmaster-replica-0\t2\t241/285 [========================>.....] - ETA: 0s - loss: 3.9008 - acc: 0.758\n",
      "INFO\t2019-09-09 14:40:10 -0400\tmaster-replica-0\t2\t254/285 [=========================>....] - ETA: 0s - loss: 3.9004 - acc: 0.758\n",
      "INFO\t2019-09-09 14:40:10 -0400\tmaster-replica-0\t2\t264/285 [==========================>...] - ETA: 0s - loss: 3.8972 - acc: 0.758\n",
      "INFO\t2019-09-09 14:40:12 -0400\tmaster-replica-0\t2\t277/285 [============================>.] - ETA: 0s - loss: 3.8991 - acc: 0.758\n",
      "INFO\t2019-09-09 14:40:12 -0400\tmaster-replica-0\t2\t285/285 [==============================] - 2s 9ms/step - loss: 3.8973 - acc: 0.7582 - val_loss: 3.8072 - val_acc: 0.7638\n",
      "INFO\t2019-09-09 14:40:12 -0400\tmaster-replica-0\t2\tEpoch 00015: LearningRateScheduler reducing learning rate to 0.03904842762434189.\n",
      "INFO\t2019-09-09 14:40:12 -0400\tmaster-replica-0\t2\tEpoch 15/20\n",
      "INFO\t2019-09-09 14:40:12 -0400\tmaster-replica-0\t2\t  1/285 [..............................] - ETA: 17s - loss: 3.9588 - acc: 0.75\n",
      "INFO\t2019-09-09 14:40:12 -0400\tmaster-replica-0\t2\t 12/285 [>.............................] - ETA: 2s - loss: 3.7703 - acc: 0.7661\n",
      "INFO\t2019-09-09 14:40:12 -0400\tmaster-replica-0\t2\t 24/285 [=>............................] - ETA: 1s - loss: 3.8233 - acc: 0.762\n",
      "INFO\t2019-09-09 14:40:12 -0400\tmaster-replica-0\t2\t 37/285 [==>...........................] - ETA: 1s - loss: 3.8060 - acc: 0.763\n",
      "INFO\t2019-09-09 14:40:12 -0400\tmaster-replica-0\t2\t 48/285 [====>.........................] - ETA: 1s - loss: 3.7615 - acc: 0.766\n",
      "INFO\t2019-09-09 14:40:12 -0400\tmaster-replica-0\t2\t 61/285 [=====>........................] - ETA: 1s - loss: 3.8267 - acc: 0.762\n",
      "INFO\t2019-09-09 14:40:12 -0400\tmaster-replica-0\t2\t 72/285 [======>.......................] - ETA: 1s - loss: 3.8528 - acc: 0.761\n",
      "INFO\t2019-09-09 14:40:12 -0400\tmaster-replica-0\t2\t 85/285 [=======>......................] - ETA: 1s - loss: 3.9106 - acc: 0.757\n",
      "INFO\t2019-09-09 14:40:12 -0400\tmaster-replica-0\t2\t 96/285 [=========>....................] - ETA: 0s - loss: 3.9294 - acc: 0.756\n",
      "INFO\t2019-09-09 14:40:12 -0400\tmaster-replica-0\t2\t108/285 [==========>...................] - ETA: 0s - loss: 3.9353 - acc: 0.755\n",
      "INFO\t2019-09-09 14:40:12 -0400\tmaster-replica-0\t2\t119/285 [===========>..................] - ETA: 0s - loss: 3.9244 - acc: 0.756\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO\t2019-09-09 14:40:12 -0400\tmaster-replica-0\t2\t132/285 [============>.................] - ETA: 0s - loss: 3.9085 - acc: 0.757\n",
      "INFO\t2019-09-09 14:40:12 -0400\tmaster-replica-0\t2\t141/285 [=============>................] - ETA: 0s - loss: 3.9117 - acc: 0.757\n",
      "INFO\t2019-09-09 14:40:12 -0400\tmaster-replica-0\t2\t153/285 [===============>..............] - ETA: 0s - loss: 3.8794 - acc: 0.759\n",
      "INFO\t2019-09-09 14:40:12 -0400\tmaster-replica-0\t2\t162/285 [================>.............] - ETA: 0s - loss: 3.8812 - acc: 0.759\n",
      "INFO\t2019-09-09 14:40:12 -0400\tmaster-replica-0\t2\t175/285 [=================>............] - ETA: 0s - loss: 3.8675 - acc: 0.760\n",
      "INFO\t2019-09-09 14:40:12 -0400\tmaster-replica-0\t2\t185/285 [==================>...........] - ETA: 0s - loss: 3.8633 - acc: 0.760\n",
      "INFO\t2019-09-09 14:40:13 -0400\tmaster-replica-0\t2\t198/285 [===================>..........] - ETA: 0s - loss: 3.8703 - acc: 0.759\n",
      "INFO\t2019-09-09 14:40:13 -0400\tmaster-replica-0\t2\t208/285 [====================>.........] - ETA: 0s - loss: 3.8569 - acc: 0.760\n",
      "INFO\t2019-09-09 14:40:13 -0400\tmaster-replica-0\t2\t219/285 [======================>.......] - ETA: 0s - loss: 3.8646 - acc: 0.760\n",
      "INFO\t2019-09-09 14:40:13 -0400\tmaster-replica-0\t2\t229/285 [=======================>......] - ETA: 0s - loss: 3.8656 - acc: 0.760\n",
      "INFO\t2019-09-09 14:40:13 -0400\tmaster-replica-0\t2\t241/285 [========================>.....] - ETA: 0s - loss: 3.8544 - acc: 0.760\n",
      "INFO\t2019-09-09 14:40:13 -0400\tmaster-replica-0\t2\t251/285 [=========================>....] - ETA: 0s - loss: 3.8512 - acc: 0.761\n",
      "INFO\t2019-09-09 14:40:13 -0400\tmaster-replica-0\t2\t263/285 [==========================>...] - ETA: 0s - loss: 3.8615 - acc: 0.760\n",
      "INFO\t2019-09-09 14:40:14 -0400\tmaster-replica-0\t2\t273/285 [===========================>..] - ETA: 0s - loss: 3.8573 - acc: 0.760\n",
      "INFO\t2019-09-09 14:40:14 -0400\tmaster-replica-0\t2\t285/285 [==============================] - 2s 8ms/step - loss: 3.8621 - acc: 0.7604 - val_loss: 3.8072 - val_acc: 0.7638\n",
      "INFO\t2019-09-09 14:40:14 -0400\tmaster-replica-0\t2\tEpoch 00016: LearningRateScheduler reducing learning rate to 0.03904812244856064.\n",
      "INFO\t2019-09-09 14:40:14 -0400\tmaster-replica-0\t2\tEpoch 16/20\n",
      "INFO\t2019-09-09 14:40:14 -0400\tmaster-replica-0\t2\t  1/285 [..............................] - ETA: 1s - loss: 4.6658 - acc: 0.710\n",
      "INFO\t2019-09-09 14:40:14 -0400\tmaster-replica-0\t2\t 11/285 [>.............................] - ETA: 1s - loss: 4.2288 - acc: 0.737\n",
      "INFO\t2019-09-09 14:40:14 -0400\tmaster-replica-0\t2\t 21/285 [=>............................] - ETA: 1s - loss: 3.9117 - acc: 0.757\n",
      "INFO\t2019-09-09 14:40:14 -0400\tmaster-replica-0\t2\t 32/285 [==>...........................] - ETA: 1s - loss: 3.8837 - acc: 0.759\n",
      "INFO\t2019-09-09 14:40:14 -0400\tmaster-replica-0\t2\t 40/285 [===>..........................] - ETA: 1s - loss: 3.9058 - acc: 0.757\n",
      "INFO\t2019-09-09 14:40:14 -0400\tmaster-replica-0\t2\t 49/285 [====>.........................] - ETA: 1s - loss: 3.9329 - acc: 0.756\n",
      "INFO\t2019-09-09 14:40:14 -0400\tmaster-replica-0\t2\t 59/285 [=====>........................] - ETA: 1s - loss: 3.9756 - acc: 0.753\n",
      "INFO\t2019-09-09 14:40:14 -0400\tmaster-replica-0\t2\t 68/285 [======>.......................] - ETA: 1s - loss: 4.0150 - acc: 0.750\n",
      "INFO\t2019-09-09 14:40:14 -0400\tmaster-replica-0\t2\t 80/285 [=======>......................] - ETA: 1s - loss: 3.9588 - acc: 0.754\n",
      "INFO\t2019-09-09 14:40:14 -0400\tmaster-replica-0\t2\t 90/285 [========>.....................] - ETA: 1s - loss: 4.0028 - acc: 0.751\n",
      "INFO\t2019-09-09 14:40:15 -0400\tmaster-replica-0\t2\t102/285 [=========>....................] - ETA: 0s - loss: 3.9782 - acc: 0.753\n",
      "INFO\t2019-09-09 14:40:15 -0400\tmaster-replica-0\t2\t112/285 [==========>...................] - ETA: 0s - loss: 3.9752 - acc: 0.753\n",
      "INFO\t2019-09-09 14:40:15 -0400\tmaster-replica-0\t2\t123/285 [===========>..................] - ETA: 0s - loss: 3.9715 - acc: 0.753\n",
      "INFO\t2019-09-09 14:40:15 -0400\tmaster-replica-0\t2\t133/285 [=============>................] - ETA: 0s - loss: 3.9067 - acc: 0.757\n",
      "INFO\t2019-09-09 14:40:15 -0400\tmaster-replica-0\t2\t138/285 [=============>................] - ETA: 0s - loss: 3.9076 - acc: 0.757\n",
      "INFO\t2019-09-09 14:40:15 -0400\tmaster-replica-0\t2\t142/285 [=============>................] - ETA: 0s - loss: 3.9100 - acc: 0.757\n",
      "INFO\t2019-09-09 14:40:15 -0400\tmaster-replica-0\t2\t148/285 [==============>...............] - ETA: 0s - loss: 3.9111 - acc: 0.757\n",
      "INFO\t2019-09-09 14:40:15 -0400\tmaster-replica-0\t2\t153/285 [===============>..............] - ETA: 0s - loss: 3.9117 - acc: 0.757\n",
      "INFO\t2019-09-09 14:40:15 -0400\tmaster-replica-0\t2\t158/285 [===============>..............] - ETA: 0s - loss: 3.8998 - acc: 0.758\n",
      "INFO\t2019-09-09 14:40:15 -0400\tmaster-replica-0\t2\t163/285 [================>.............] - ETA: 0s - loss: 3.8998 - acc: 0.758\n",
      "INFO\t2019-09-09 14:40:15 -0400\tmaster-replica-0\t2\t174/285 [=================>............] - ETA: 0s - loss: 3.9150 - acc: 0.757\n",
      "INFO\t2019-09-09 14:40:15 -0400\tmaster-replica-0\t2\t181/285 [==================>...........] - ETA: 0s - loss: 3.9034 - acc: 0.757\n",
      "INFO\t2019-09-09 14:40:15 -0400\tmaster-replica-0\t2\t193/285 [===================>..........] - ETA: 0s - loss: 3.9017 - acc: 0.757\n",
      "INFO\t2019-09-09 14:40:15 -0400\tmaster-replica-0\t2\t204/285 [====================>.........] - ETA: 0s - loss: 3.9172 - acc: 0.757\n",
      "INFO\t2019-09-09 14:40:15 -0400\tmaster-replica-0\t2\t217/285 [=====================>........] - ETA: 0s - loss: 3.9263 - acc: 0.756\n",
      "INFO\t2019-09-09 14:40:15 -0400\tmaster-replica-0\t2\t228/285 [=======================>......] - ETA: 0s - loss: 3.9160 - acc: 0.757\n",
      "INFO\t2019-09-09 14:40:15 -0400\tmaster-replica-0\t2\t239/285 [========================>.....] - ETA: 0s - loss: 3.9180 - acc: 0.756\n",
      "INFO\t2019-09-09 14:40:15 -0400\tmaster-replica-0\t2\t251/285 [=========================>....] - ETA: 0s - loss: 3.9093 - acc: 0.757\n",
      "INFO\t2019-09-09 14:40:16 -0400\tmaster-replica-0\t2\t265/285 [==========================>...] - ETA: 0s - loss: 3.9049 - acc: 0.757\n",
      "INFO\t2019-09-09 14:40:17 -0400\tmaster-replica-0\t2\t276/285 [============================>.] - ETA: 0s - loss: 3.9066 - acc: 0.757\n",
      "INFO\t2019-09-09 14:40:17 -0400\tmaster-replica-0\t2\t285/285 [==============================] - 3s 10ms/step - loss: 3.9053 - acc: 0.7577 - val_loss: 3.8072 - val_acc: 0.7638\n",
      "INFO\t2019-09-09 14:40:17 -0400\tmaster-replica-0\t2\tEpoch 00017: LearningRateScheduler reducing learning rate to 0.039047969860670016.\n",
      "INFO\t2019-09-09 14:40:17 -0400\tmaster-replica-0\t2\tEpoch 17/20\n",
      "INFO\t2019-09-09 14:40:17 -0400\tmaster-replica-0\t2\t  1/285 [..............................] - ETA: 1s - loss: 4.2416 - acc: 0.736\n",
      "INFO\t2019-09-09 14:40:17 -0400\tmaster-replica-0\t2\t 12/285 [>.............................] - ETA: 1s - loss: 3.5465 - acc: 0.780\n",
      "INFO\t2019-09-09 14:40:17 -0400\tmaster-replica-0\t2\t 25/285 [=>............................] - ETA: 1s - loss: 3.7665 - acc: 0.766\n",
      "INFO\t2019-09-09 14:40:17 -0400\tmaster-replica-0\t2\t 37/285 [==>...........................] - ETA: 1s - loss: 3.8442 - acc: 0.761\n",
      "INFO\t2019-09-09 14:40:17 -0400\tmaster-replica-0\t2\t 51/285 [====>.........................] - ETA: 0s - loss: 3.7786 - acc: 0.765\n",
      "INFO\t2019-09-09 14:40:17 -0400\tmaster-replica-0\t2\t 63/285 [=====>........................] - ETA: 0s - loss: 3.7815 - acc: 0.765\n",
      "INFO\t2019-09-09 14:40:17 -0400\tmaster-replica-0\t2\t 76/285 [=======>......................] - ETA: 0s - loss: 3.8193 - acc: 0.763\n",
      "INFO\t2019-09-09 14:40:17 -0400\tmaster-replica-0\t2\t 88/285 [========>.....................] - ETA: 0s - loss: 3.8399 - acc: 0.761\n",
      "INFO\t2019-09-09 14:40:17 -0400\tmaster-replica-0\t2\t101/285 [=========>....................] - ETA: 0s - loss: 3.8566 - acc: 0.760\n",
      "INFO\t2019-09-09 14:40:17 -0400\tmaster-replica-0\t2\t112/285 [==========>...................] - ETA: 0s - loss: 3.8604 - acc: 0.760\n",
      "INFO\t2019-09-09 14:40:17 -0400\tmaster-replica-0\t2\t126/285 [============>.................] - ETA: 0s - loss: 3.8780 - acc: 0.759\n",
      "INFO\t2019-09-09 14:40:17 -0400\tmaster-replica-0\t2\t137/285 [=============>................] - ETA: 0s - loss: 3.8866 - acc: 0.758\n",
      "INFO\t2019-09-09 14:40:17 -0400\tmaster-replica-0\t2\t150/285 [==============>...............] - ETA: 0s - loss: 3.9032 - acc: 0.757\n",
      "INFO\t2019-09-09 14:40:17 -0400\tmaster-replica-0\t2\t161/285 [===============>..............] - ETA: 0s - loss: 3.8921 - acc: 0.758\n",
      "INFO\t2019-09-09 14:40:18 -0400\tmaster-replica-0\t2\t174/285 [=================>............] - ETA: 0s - loss: 3.9036 - acc: 0.757\n",
      "INFO\t2019-09-09 14:40:18 -0400\tmaster-replica-0\t2\t186/285 [==================>...........] - ETA: 0s - loss: 3.8973 - acc: 0.758\n",
      "INFO\t2019-09-09 14:40:18 -0400\tmaster-replica-0\t2\t200/285 [====================>.........] - ETA: 0s - loss: 3.8690 - acc: 0.760\n",
      "INFO\t2019-09-09 14:40:18 -0400\tmaster-replica-0\t2\t213/285 [=====================>........] - ETA: 0s - loss: 3.8712 - acc: 0.759\n",
      "INFO\t2019-09-09 14:40:18 -0400\tmaster-replica-0\t2\t225/285 [======================>.......] - ETA: 0s - loss: 3.8627 - acc: 0.760\n",
      "INFO\t2019-09-09 14:40:18 -0400\tmaster-replica-0\t2\t238/285 [========================>.....] - ETA: 0s - loss: 3.8745 - acc: 0.759\n",
      "INFO\t2019-09-09 14:40:18 -0400\tmaster-replica-0\t2\t250/285 [=========================>....] - ETA: 0s - loss: 3.8734 - acc: 0.759\n",
      "INFO\t2019-09-09 14:40:18 -0400\tmaster-replica-0\t2\t263/285 [==========================>...] - ETA: 0s - loss: 3.8734 - acc: 0.759\n",
      "INFO\t2019-09-09 14:40:19 -0400\tmaster-replica-0\t2\t275/285 [===========================>..] - ETA: 0s - loss: 3.8719 - acc: 0.759\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO\t2019-09-09 14:40:19 -0400\tmaster-replica-0\t2\t285/285 [==============================] - 2s 8ms/step - loss: 3.8671 - acc: 0.7601 - val_loss: 3.8072 - val_acc: 0.7638\n",
      "INFO\t2019-09-09 14:40:19 -0400\tmaster-replica-0\t2\tEpoch 00018: LearningRateScheduler reducing learning rate to 0.0390478935667247.\n",
      "INFO\t2019-09-09 14:40:19 -0400\tmaster-replica-0\t2\tEpoch 18/20\n",
      "INFO\t2019-09-09 14:40:19 -0400\tmaster-replica-0\t2\t  1/285 [..............................] - ETA: 1s - loss: 3.3933 - acc: 0.789\n",
      "INFO\t2019-09-09 14:40:19 -0400\tmaster-replica-0\t2\t 13/285 [>.............................] - ETA: 1s - loss: 3.9480 - acc: 0.755\n",
      "INFO\t2019-09-09 14:40:19 -0400\tmaster-replica-0\t2\t 26/285 [=>............................] - ETA: 1s - loss: 4.0350 - acc: 0.749\n",
      "INFO\t2019-09-09 14:40:19 -0400\tmaster-replica-0\t2\t 36/285 [==>...........................] - ETA: 1s - loss: 3.9313 - acc: 0.756\n",
      "INFO\t2019-09-09 14:40:19 -0400\tmaster-replica-0\t2\t 46/285 [===>..........................] - ETA: 1s - loss: 3.8974 - acc: 0.758\n",
      "INFO\t2019-09-09 14:40:19 -0400\tmaster-replica-0\t2\t 57/285 [=====>........................] - ETA: 1s - loss: 3.8298 - acc: 0.762\n",
      "INFO\t2019-09-09 14:40:19 -0400\tmaster-replica-0\t2\t 70/285 [======>.......................] - ETA: 0s - loss: 3.7710 - acc: 0.766\n",
      "INFO\t2019-09-09 14:40:19 -0400\tmaster-replica-0\t2\t 81/285 [=======>......................] - ETA: 0s - loss: 3.8000 - acc: 0.764\n",
      "INFO\t2019-09-09 14:40:19 -0400\tmaster-replica-0\t2\t 94/285 [========>.....................] - ETA: 0s - loss: 3.8340 - acc: 0.762\n",
      "INFO\t2019-09-09 14:40:19 -0400\tmaster-replica-0\t2\t105/285 [==========>...................] - ETA: 0s - loss: 3.8390 - acc: 0.761\n",
      "INFO\t2019-09-09 14:40:20 -0400\tmaster-replica-0\t2\t119/285 [===========>..................] - ETA: 0s - loss: 3.8424 - acc: 0.761\n",
      "INFO\t2019-09-09 14:40:20 -0400\tmaster-replica-0\t2\t130/285 [============>.................] - ETA: 0s - loss: 3.8305 - acc: 0.762\n",
      "INFO\t2019-09-09 14:40:20 -0400\tmaster-replica-0\t2\t143/285 [==============>...............] - ETA: 0s - loss: 3.8441 - acc: 0.761\n",
      "INFO\t2019-09-09 14:40:20 -0400\tmaster-replica-0\t2\t154/285 [===============>..............] - ETA: 0s - loss: 3.8239 - acc: 0.762\n",
      "INFO\t2019-09-09 14:40:20 -0400\tmaster-replica-0\t2\t168/285 [================>.............] - ETA: 0s - loss: 3.8452 - acc: 0.761\n",
      "INFO\t2019-09-09 14:40:20 -0400\tmaster-replica-0\t2\t179/285 [=================>............] - ETA: 0s - loss: 3.8538 - acc: 0.760\n",
      "INFO\t2019-09-09 14:40:20 -0400\tmaster-replica-0\t2\t191/285 [===================>..........] - ETA: 0s - loss: 3.8663 - acc: 0.760\n",
      "INFO\t2019-09-09 14:40:20 -0400\tmaster-replica-0\t2\t202/285 [====================>.........] - ETA: 0s - loss: 3.8832 - acc: 0.759\n",
      "INFO\t2019-09-09 14:40:20 -0400\tmaster-replica-0\t2\t216/285 [=====================>........] - ETA: 0s - loss: 3.8934 - acc: 0.758\n",
      "INFO\t2019-09-09 14:40:20 -0400\tmaster-replica-0\t2\t226/285 [======================>.......] - ETA: 0s - loss: 3.8981 - acc: 0.758\n",
      "INFO\t2019-09-09 14:40:20 -0400\tmaster-replica-0\t2\t239/285 [========================>.....] - ETA: 0s - loss: 3.9032 - acc: 0.757\n",
      "INFO\t2019-09-09 14:40:20 -0400\tmaster-replica-0\t2\t249/285 [=========================>....] - ETA: 0s - loss: 3.8969 - acc: 0.758\n",
      "INFO\t2019-09-09 14:40:20 -0400\tmaster-replica-0\t2\t261/285 [==========================>...] - ETA: 0s - loss: 3.8955 - acc: 0.758\n",
      "INFO\t2019-09-09 14:40:21 -0400\tmaster-replica-0\t2\t274/285 [===========================>..] - ETA: 0s - loss: 3.8912 - acc: 0.758\n",
      "INFO\t2019-09-09 14:40:21 -0400\tmaster-replica-0\t2\t285/285 [==============================] - 2s 8ms/step - loss: 3.8904 - acc: 0.7586 - val_loss: 3.8072 - val_acc: 0.7638\n",
      "INFO\t2019-09-09 14:40:21 -0400\tmaster-replica-0\t2\tEpoch 00019: LearningRateScheduler reducing learning rate to 0.039047855419752045.\n",
      "INFO\t2019-09-09 14:40:21 -0400\tmaster-replica-0\t2\tEpoch 19/20\n",
      "INFO\t2019-09-09 14:40:21 -0400\tmaster-replica-0\t2\t  1/285 [..............................] - ETA: 7s - loss: 4.3830 - acc: 0.728\n",
      "INFO\t2019-09-09 14:40:21 -0400\tmaster-replica-0\t2\t 14/285 [>.............................] - ETA: 1s - loss: 3.7367 - acc: 0.768\n",
      "INFO\t2019-09-09 14:40:21 -0400\tmaster-replica-0\t2\t 25/285 [=>............................] - ETA: 1s - loss: 3.7948 - acc: 0.764\n",
      "INFO\t2019-09-09 14:40:21 -0400\tmaster-replica-0\t2\t 37/285 [==>...........................] - ETA: 1s - loss: 3.8748 - acc: 0.759\n",
      "INFO\t2019-09-09 14:40:22 -0400\tmaster-replica-0\t2\t 47/285 [===>..........................] - ETA: 1s - loss: 3.8505 - acc: 0.761\n",
      "INFO\t2019-09-09 14:40:22 -0400\tmaster-replica-0\t2\t 59/285 [=====>........................] - ETA: 1s - loss: 3.8510 - acc: 0.761\n",
      "INFO\t2019-09-09 14:40:22 -0400\tmaster-replica-0\t2\t 72/285 [======>.......................] - ETA: 0s - loss: 3.8862 - acc: 0.758\n",
      "INFO\t2019-09-09 14:40:22 -0400\tmaster-replica-0\t2\t 85/285 [=======>......................] - ETA: 0s - loss: 3.8940 - acc: 0.758\n",
      "INFO\t2019-09-09 14:40:22 -0400\tmaster-replica-0\t2\t 96/285 [=========>....................] - ETA: 0s - loss: 3.8557 - acc: 0.760\n",
      "INFO\t2019-09-09 14:40:22 -0400\tmaster-replica-0\t2\t109/285 [==========>...................] - ETA: 0s - loss: 3.8564 - acc: 0.760\n",
      "INFO\t2019-09-09 14:40:22 -0400\tmaster-replica-0\t2\t118/285 [===========>..................] - ETA: 0s - loss: 3.8450 - acc: 0.761\n",
      "INFO\t2019-09-09 14:40:22 -0400\tmaster-replica-0\t2\t131/285 [============>.................] - ETA: 0s - loss: 3.8844 - acc: 0.759\n",
      "INFO\t2019-09-09 14:40:22 -0400\tmaster-replica-0\t2\t142/285 [=============>................] - ETA: 0s - loss: 3.9041 - acc: 0.757\n",
      "INFO\t2019-09-09 14:40:22 -0400\tmaster-replica-0\t2\t155/285 [===============>..............] - ETA: 0s - loss: 3.9105 - acc: 0.757\n",
      "INFO\t2019-09-09 14:40:22 -0400\tmaster-replica-0\t2\t166/285 [================>.............] - ETA: 0s - loss: 3.9137 - acc: 0.757\n",
      "INFO\t2019-09-09 14:40:22 -0400\tmaster-replica-0\t2\t178/285 [=================>............] - ETA: 0s - loss: 3.9366 - acc: 0.755\n",
      "INFO\t2019-09-09 14:40:22 -0400\tmaster-replica-0\t2\t187/285 [==================>...........] - ETA: 0s - loss: 3.9271 - acc: 0.756\n",
      "INFO\t2019-09-09 14:40:22 -0400\tmaster-replica-0\t2\t200/285 [====================>.........] - ETA: 0s - loss: 3.9313 - acc: 0.756\n",
      "INFO\t2019-09-09 14:40:22 -0400\tmaster-replica-0\t2\t211/285 [=====================>........] - ETA: 0s - loss: 3.9300 - acc: 0.756\n",
      "INFO\t2019-09-09 14:40:22 -0400\tmaster-replica-0\t2\t224/285 [======================>.......] - ETA: 0s - loss: 3.9191 - acc: 0.756\n",
      "INFO\t2019-09-09 14:40:22 -0400\tmaster-replica-0\t2\t234/285 [=======================>......] - ETA: 0s - loss: 3.9020 - acc: 0.757\n",
      "INFO\t2019-09-09 14:40:22 -0400\tmaster-replica-0\t2\t247/285 [=========================>....] - ETA: 0s - loss: 3.8999 - acc: 0.758\n",
      "INFO\t2019-09-09 14:40:22 -0400\tmaster-replica-0\t2\t258/285 [==========================>...] - ETA: 0s - loss: 3.9024 - acc: 0.757\n",
      "INFO\t2019-09-09 14:40:23 -0400\tmaster-replica-0\t2\t271/285 [===========================>..] - ETA: 0s - loss: 3.9004 - acc: 0.758\n",
      "INFO\t2019-09-09 14:40:24 -0400\tmaster-replica-0\t2\t281/285 [============================>.] - ETA: 0s - loss: 3.8859 - acc: 0.758\n",
      "INFO\t2019-09-09 14:40:24 -0400\tmaster-replica-0\t2\t285/285 [==============================] - 3s 9ms/step - loss: 3.8824 - acc: 0.7591 - val_loss: 3.8072 - val_acc: 0.7638\n",
      "INFO\t2019-09-09 14:40:24 -0400\tmaster-replica-0\t2\tEpoch 00020: LearningRateScheduler reducing learning rate to 0.03904783634626571.\n",
      "INFO\t2019-09-09 14:40:24 -0400\tmaster-replica-0\t2\tEpoch 20/20\n",
      "INFO\t2019-09-09 14:40:24 -0400\tmaster-replica-0\t2\t  1/285 [..............................] - ETA: 5s - loss: 2.9691 - acc: 0.815\n",
      "INFO\t2019-09-09 14:40:24 -0400\tmaster-replica-0\t2\t 14/285 [>.............................] - ETA: 1s - loss: 3.6660 - acc: 0.772\n",
      "INFO\t2019-09-09 14:40:24 -0400\tmaster-replica-0\t2\t 27/285 [=>............................] - ETA: 1s - loss: 3.7913 - acc: 0.764\n",
      "INFO\t2019-09-09 14:40:24 -0400\tmaster-replica-0\t2\t 41/285 [===>..........................] - ETA: 1s - loss: 3.8209 - acc: 0.762\n",
      "INFO\t2019-09-09 14:40:24 -0400\tmaster-replica-0\t2\t 53/285 [====>.........................] - ETA: 1s - loss: 3.7774 - acc: 0.765\n",
      "INFO\t2019-09-09 14:40:24 -0400\tmaster-replica-0\t2\t 67/285 [======>.......................] - ETA: 0s - loss: 3.7584 - acc: 0.766\n",
      "INFO\t2019-09-09 14:40:24 -0400\tmaster-replica-0\t2\t 78/285 [=======>......................] - ETA: 0s - loss: 3.7884 - acc: 0.765\n",
      "INFO\t2019-09-09 14:40:24 -0400\tmaster-replica-0\t2\t 92/285 [========>.....................] - ETA: 0s - loss: 3.7944 - acc: 0.764\n",
      "INFO\t2019-09-09 14:40:24 -0400\tmaster-replica-0\t2\t104/285 [=========>....................] - ETA: 0s - loss: 3.7889 - acc: 0.764\n",
      "INFO\t2019-09-09 14:40:24 -0400\tmaster-replica-0\t2\t119/285 [===========>..................] - ETA: 0s - loss: 3.7972 - acc: 0.764\n",
      "INFO\t2019-09-09 14:40:24 -0400\tmaster-replica-0\t2\t132/285 [============>.................] - ETA: 0s - loss: 3.8239 - acc: 0.762\n",
      "INFO\t2019-09-09 14:40:25 -0400\tmaster-replica-0\t2\t147/285 [==============>...............] - ETA: 0s - loss: 3.8203 - acc: 0.763\n",
      "INFO\t2019-09-09 14:40:25 -0400\tmaster-replica-0\t2\t159/285 [===============>..............] - ETA: 0s - loss: 3.8139 - acc: 0.763\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO\t2019-09-09 14:40:25 -0400\tmaster-replica-0\t2\t173/285 [=================>............] - ETA: 0s - loss: 3.8436 - acc: 0.761\n",
      "INFO\t2019-09-09 14:40:25 -0400\tmaster-replica-0\t2\t185/285 [==================>...........] - ETA: 0s - loss: 3.8381 - acc: 0.761\n",
      "INFO\t2019-09-09 14:40:25 -0400\tmaster-replica-0\t2\t198/285 [===================>..........] - ETA: 0s - loss: 3.8346 - acc: 0.762\n",
      "INFO\t2019-09-09 14:40:25 -0400\tmaster-replica-0\t2\t210/285 [=====================>........] - ETA: 0s - loss: 3.8323 - acc: 0.762\n",
      "INFO\t2019-09-09 14:40:25 -0400\tmaster-replica-0\t2\t224/285 [======================>.......] - ETA: 0s - loss: 3.8376 - acc: 0.761\n",
      "INFO\t2019-09-09 14:40:25 -0400\tmaster-replica-0\t2\t235/285 [=======================>......] - ETA: 0s - loss: 3.8692 - acc: 0.759\n",
      "INFO\t2019-09-09 14:40:25 -0400\tmaster-replica-0\t2\t248/285 [=========================>....] - ETA: 0s - loss: 3.8853 - acc: 0.758\n",
      "INFO\t2019-09-09 14:40:25 -0400\tmaster-replica-0\t2\t260/285 [==========================>...] - ETA: 0s - loss: 3.8811 - acc: 0.759\n",
      "INFO\t2019-09-09 14:40:26 -0400\tmaster-replica-0\t2\t274/285 [===========================>..] - ETA: 0s - loss: 3.8752 - acc: 0.759\n",
      "INFO\t2019-09-09 14:40:26 -0400\tmaster-replica-0\t2\t285/285 [==============================] - 2s 8ms/step - loss: 3.8725 - acc: 0.7597 - val_loss: 3.8072 - val_acc: 0.7638\n",
      "WARNING\t2019-09-09 14:40:33 -0400\tmaster-replica-0\t2\tThis model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.RMSprop object at 0x7fa943738588>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "WARNING\t2019-09-09 14:40:33 -0400\tmaster-replica-0\t2\t\n",
      "WARNING\t2019-09-09 14:40:33 -0400\tmaster-replica-0\t2\tConsider using a TensorFlow optimizer from `tf.train`.\n",
      "WARNING\t2019-09-09 14:40:37 -0400\tmaster-replica-0\t2\tFrom /usr/local/lib/python3.5/dist-packages/tensorflow/python/keras/engine/network.py:1436: update_checkpoint_state (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "WARNING\t2019-09-09 14:40:37 -0400\tmaster-replica-0\t2\tInstructions for updating:\n",
      "WARNING\t2019-09-09 14:40:37 -0400\tmaster-replica-0\t2\tUse tf.train.CheckpointManager to manage checkpoints rather than manually editing the Checkpoint proto.\n",
      "WARNING\t2019-09-09 14:40:39 -0400\tmaster-replica-0\t2\tModel was compiled with an optimizer, but the optimizer is not from `tf.train` (e.g. `tf.train.AdagradOptimizer`). Only the serving graph was exported. The train and evaluate graphs were not added to the SavedModel.\n",
      "WARNING\t2019-09-09 14:40:47 -0400\tmaster-replica-0\t1\tFrom /usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "WARNING\t2019-09-09 14:40:47 -0400\tmaster-replica-0\t1\tInstructions for updating:\n",
      "WARNING\t2019-09-09 14:40:47 -0400\tmaster-replica-0\t1\tColocations handled automatically by placer.\n",
      "WARNING\t2019-09-09 14:40:51 -0400\tmaster-replica-0\t2\tFrom /usr/local/lib/python3.5/dist-packages/tensorflow/python/saved_model/signature_def_utils_impl.py:205: build_tensor_info (from tensorflow.python.saved_model.utils_impl) is deprecated and will be removed in a future version.\n",
      "WARNING\t2019-09-09 14:40:51 -0400\tmaster-replica-0\t2\tInstructions for updating:\n",
      "WARNING\t2019-09-09 14:40:51 -0400\tmaster-replica-0\t2\tThis function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.utils.build_tensor_info or tf.compat.v1.saved_model.build_tensor_info.\n",
      "INFO\t2019-09-09 14:40:51 -0400\tmaster-replica-0\t2\tSignatures INCLUDED in export for Regress: None\n",
      "INFO\t2019-09-09 14:40:51 -0400\tmaster-replica-0\t2\tSignatures INCLUDED in export for Train: None\n",
      "INFO\t2019-09-09 14:40:51 -0400\tmaster-replica-0\t2\tSignatures INCLUDED in export for Predict: ['serving_default']\n",
      "INFO\t2019-09-09 14:40:51 -0400\tmaster-replica-0\t2\tSignatures INCLUDED in export for Classify: None\n",
      "INFO\t2019-09-09 14:40:51 -0400\tmaster-replica-0\t2\tSignatures INCLUDED in export for Eval: None\n",
      "INFO\t2019-09-09 14:40:51 -0400\tmaster-replica-0\t2\tNo assets to save.\n",
      "INFO\t2019-09-09 14:40:51 -0400\tmaster-replica-0\t2\tNo assets to write.\n",
      "INFO\t2019-09-09 14:40:52 -0400\tmaster-replica-0\t2\tSavedModel written to: gs://mo_ml/lingh/2/keras_export/1568054429/saved_model.pb\n",
      "INFO\t2019-09-09 14:40:54 -0400\tmaster-replica-0\t2\tWARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "INFO\t2019-09-09 14:40:54 -0400\tmaster-replica-0\t2\tFor more information, please see:\n",
      "INFO\t2019-09-09 14:40:54 -0400\tmaster-replica-0\t2\t  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "INFO\t2019-09-09 14:40:54 -0400\tmaster-replica-0\t2\t  * https://github.com/tensorflow/addons\n",
      "INFO\t2019-09-09 14:40:54 -0400\tmaster-replica-0\t2\tIf you depend on functionality not listed there, please file an issue.\n",
      "INFO\t2019-09-09 14:40:54 -0400\tmaster-replica-0\t2\tModel exported to: gs://mo_ml/lingh/2/keras_export\n",
      "INFO\t2019-09-09 14:40:55 -0400\tmaster-replica-0\t2\tModule completed; cleaning up.\n",
      "INFO\t2019-09-09 14:40:55 -0400\tmaster-replica-0\t2\tClean up finished.\n",
      "INFO\t2019-09-09 14:40:55 -0400\tmaster-replica-0\t2\tTask completed successfully.\n",
      "INFO\t2019-09-09 14:40:58 -0400\tmaster-replica-0\t1\tRunning module trainer.task.\n",
      "INFO\t2019-09-09 14:40:58 -0400\tmaster-replica-0\t1\tDownloading the package: gs://mo_ml/lingh/packages/9fef4d587f7511880b857ce6206af1b88acb9c4b12e9f72266cf68d36e785c0f/trainer-0.0.0.tar.gz\n",
      "INFO\t2019-09-09 14:40:58 -0400\tmaster-replica-0\t1\tRunning command: gsutil -q cp gs://mo_ml/lingh/packages/9fef4d587f7511880b857ce6206af1b88acb9c4b12e9f72266cf68d36e785c0f/trainer-0.0.0.tar.gz trainer-0.0.0.tar.gz\n",
      "INFO\t2019-09-09 14:41:00 -0400\tmaster-replica-0\t1\tInstalling the package: gs://mo_ml/lingh/packages/9fef4d587f7511880b857ce6206af1b88acb9c4b12e9f72266cf68d36e785c0f/trainer-0.0.0.tar.gz\n",
      "INFO\t2019-09-09 14:41:00 -0400\tmaster-replica-0\t1\tRunning command: pip3 install --user --upgrade --force-reinstall --no-deps trainer-0.0.0.tar.gz\n",
      "INFO\t2019-09-09 14:41:02 -0400\tmaster-replica-0\t1\tProcessing ./trainer-0.0.0.tar.gz\n",
      "INFO\t2019-09-09 14:41:03 -0400\tmaster-replica-0\t1\tGenerating grammar tables from /usr/lib/python3.5/lib2to3/Grammar.txt\n",
      "INFO\t2019-09-09 14:41:03 -0400\tmaster-replica-0\t1\tGenerating grammar tables from /usr/lib/python3.5/lib2to3/PatternGrammar.txt\n",
      "INFO\t2019-09-09 14:41:03 -0400\tmaster-replica-0\t1\tBuilding wheels for collected packages: trainer\n",
      "INFO\t2019-09-09 14:41:03 -0400\tmaster-replica-0\t1\t  Building wheel for trainer (setup.py): started\n",
      "INFO\t2019-09-09 14:41:04 -0400\tmaster-replica-0\t1\tGenerating grammar tables from /usr/lib/python3.5/lib2to3/Grammar.txt\n",
      "INFO\t2019-09-09 14:41:04 -0400\tmaster-replica-0\t1\tGenerating grammar tables from /usr/lib/python3.5/lib2to3/PatternGrammar.txt\n",
      "INFO\t2019-09-09 14:41:04 -0400\tmaster-replica-0\t1\t  Building wheel for trainer (setup.py): finished with status 'done'\n",
      "INFO\t2019-09-09 14:41:04 -0400\tmaster-replica-0\t1\t  Created wheel for trainer: filename=trainer-0.0.0-cp35-none-any.whl size=7836 sha256=a8c98726fb707f57db2412df959988f5c333d3837927c3d7688394cc48df1812\n",
      "INFO\t2019-09-09 14:41:04 -0400\tmaster-replica-0\t1\t  Stored in directory: /root/.cache/pip/wheels/0d/1b/db/f8e86b296734f0b137e17e5d34862f4ae4faf8388755c6272f\n",
      "INFO\t2019-09-09 14:41:04 -0400\tmaster-replica-0\t1\tSuccessfully built trainer\n",
      "INFO\t2019-09-09 14:41:04 -0400\tmaster-replica-0\t1\tInstalling collected packages: trainer\n",
      "INFO\t2019-09-09 14:41:04 -0400\tmaster-replica-0\t1\tSuccessfully installed trainer-0.0.0\n",
      "INFO\t2019-09-09 14:41:04 -0400\tmaster-replica-0\t1\tRunning command: pip3 install --user trainer-0.0.0.tar.gz\n",
      "INFO\t2019-09-09 14:41:05 -0400\tmaster-replica-0\t1\tProcessing ./trainer-0.0.0.tar.gz\n",
      "INFO\t2019-09-09 14:41:05 -0400\tmaster-replica-0\t1\tGenerating grammar tables from /usr/lib/python3.5/lib2to3/Grammar.txt\n",
      "INFO\t2019-09-09 14:41:05 -0400\tmaster-replica-0\t1\tGenerating grammar tables from /usr/lib/python3.5/lib2to3/PatternGrammar.txt\n",
      "INFO\t2019-09-09 14:41:05 -0400\tmaster-replica-0\t1\tBuilding wheels for collected packages: trainer\n",
      "INFO\t2019-09-09 14:41:05 -0400\tmaster-replica-0\t1\t  Building wheel for trainer (setup.py): started\n",
      "INFO\t2019-09-09 14:41:06 -0400\tmaster-replica-0\t1\tGenerating grammar tables from /usr/lib/python3.5/lib2to3/Grammar.txt\n",
      "INFO\t2019-09-09 14:41:06 -0400\tmaster-replica-0\t1\tGenerating grammar tables from /usr/lib/python3.5/lib2to3/PatternGrammar.txt\n",
      "INFO\t2019-09-09 14:41:06 -0400\tmaster-replica-0\t1\t  Building wheel for trainer (setup.py): finished with status 'done'\n",
      "INFO\t2019-09-09 14:41:06 -0400\tmaster-replica-0\t1\t  Created wheel for trainer: filename=trainer-0.0.0-cp35-none-any.whl size=7836 sha256=5a52451adf0ab7f1261fb6eb10d5c560e95b2a3d2231e2959a2f6a507eb188fc\n",
      "INFO\t2019-09-09 14:41:06 -0400\tmaster-replica-0\t1\t  Stored in directory: /root/.cache/pip/wheels/0d/1b/db/f8e86b296734f0b137e17e5d34862f4ae4faf8388755c6272f\n",
      "INFO\t2019-09-09 14:41:06 -0400\tmaster-replica-0\t1\tSuccessfully built trainer\n",
      "INFO\t2019-09-09 14:41:07 -0400\tmaster-replica-0\t1\tInstalling collected packages: trainer\n",
      "INFO\t2019-09-09 14:41:07 -0400\tmaster-replica-0\t1\t  Found existing installation: trainer 0.0.0\n",
      "INFO\t2019-09-09 14:41:07 -0400\tmaster-replica-0\t1\t    Uninstalling trainer-0.0.0:\n",
      "INFO\t2019-09-09 14:41:07 -0400\tmaster-replica-0\t1\t      Successfully uninstalled trainer-0.0.0\n",
      "INFO\t2019-09-09 14:41:07 -0400\tmaster-replica-0\t1\tSuccessfully installed trainer-0.0.0\n",
      "INFO\t2019-09-09 14:41:07 -0400\tmaster-replica-0\t1\tRunning command: python3 -m trainer.task --batch-size 239 --learning-rate 0.084125972102502125 --job-dir gs://mo_ml/lingh/1\n",
      "WARNING\t2019-09-09 14:41:10 -0400\tmaster-replica-0\t1\tFrom /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "WARNING\t2019-09-09 14:41:10 -0400\tmaster-replica-0\t1\tInstructions for updating:\n",
      "WARNING\t2019-09-09 14:41:10 -0400\tmaster-replica-0\t1\tColocations handled automatically by placer.\n",
      "INFO\t2019-09-09 14:41:10 -0400\tmaster-replica-0\t1\tYour CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
      "ERROR\t2019-09-09 14:41:10 -0400\tmaster-replica-0\t1\tUser settings:\n",
      "ERROR\t2019-09-09 14:41:10 -0400\tmaster-replica-0\t1\t   KMP_AFFINITY=granularity=fine,verbose,compact,1,0\n",
      "ERROR\t2019-09-09 14:41:10 -0400\tmaster-replica-0\t1\t   KMP_BLOCKTIME=0\n",
      "ERROR\t2019-09-09 14:41:10 -0400\tmaster-replica-0\t1\t   KMP_SETTINGS=1\n",
      "ERROR\t2019-09-09 14:41:10 -0400\tmaster-replica-0\t1\t   OMP_NUM_THREADS=4\n",
      "ERROR\t2019-09-09 14:41:10 -0400\tmaster-replica-0\t1\tEffective settings:\n",
      "ERROR\t2019-09-09 14:41:10 -0400\tmaster-replica-0\t1\t   KMP_ABORT_DELAY=0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR\t2019-09-09 14:41:10 -0400\tmaster-replica-0\t1\t   KMP_ADAPTIVE_LOCK_PROPS='1,1024'\n",
      "ERROR\t2019-09-09 14:41:10 -0400\tmaster-replica-0\t1\t   KMP_ALIGN_ALLOC=64\n",
      "ERROR\t2019-09-09 14:41:10 -0400\tmaster-replica-0\t1\t   KMP_ALL_THREADPRIVATE=128\n",
      "ERROR\t2019-09-09 14:41:10 -0400\tmaster-replica-0\t1\t   KMP_ATOMIC_MODE=2\n",
      "ERROR\t2019-09-09 14:41:10 -0400\tmaster-replica-0\t1\t   KMP_BLOCKTIME=0\n",
      "ERROR\t2019-09-09 14:41:10 -0400\tmaster-replica-0\t1\t   KMP_CPUINFO_FILE: value is not defined\n",
      "ERROR\t2019-09-09 14:41:10 -0400\tmaster-replica-0\t1\t   KMP_DETERMINISTIC_REDUCTION=false\n",
      "ERROR\t2019-09-09 14:41:10 -0400\tmaster-replica-0\t1\t   KMP_DEVICE_THREAD_LIMIT=2147483647\n",
      "ERROR\t2019-09-09 14:41:10 -0400\tmaster-replica-0\t1\t   KMP_DISP_HAND_THREAD=false\n",
      "ERROR\t2019-09-09 14:41:10 -0400\tmaster-replica-0\t1\t   KMP_DISP_NUM_BUFFERS=7\n",
      "ERROR\t2019-09-09 14:41:10 -0400\tmaster-replica-0\t1\t   KMP_DUPLICATE_LIB_OK=false\n",
      "ERROR\t2019-09-09 14:41:10 -0400\tmaster-replica-0\t1\t   KMP_FORCE_REDUCTION: value is not defined\n",
      "ERROR\t2019-09-09 14:41:10 -0400\tmaster-replica-0\t1\t   KMP_FOREIGN_THREADS_THREADPRIVATE=true\n",
      "ERROR\t2019-09-09 14:41:10 -0400\tmaster-replica-0\t1\t   KMP_FORKJOIN_BARRIER='2,2'\n",
      "ERROR\t2019-09-09 14:41:10 -0400\tmaster-replica-0\t1\t   KMP_FORKJOIN_BARRIER_PATTERN='hyper,hyper'\n",
      "ERROR\t2019-09-09 14:41:10 -0400\tmaster-replica-0\t1\t   KMP_FORKJOIN_FRAMES=true\n",
      "ERROR\t2019-09-09 14:41:10 -0400\tmaster-replica-0\t1\t   KMP_FORKJOIN_FRAMES_MODE=3\n",
      "ERROR\t2019-09-09 14:41:10 -0400\tmaster-replica-0\t1\t   KMP_GTID_MODE=3\n",
      "ERROR\t2019-09-09 14:41:10 -0400\tmaster-replica-0\t1\t   KMP_HANDLE_SIGNALS=false\n",
      "ERROR\t2019-09-09 14:41:10 -0400\tmaster-replica-0\t1\t   KMP_HOT_TEAMS_MAX_LEVEL=1\n",
      "ERROR\t2019-09-09 14:41:10 -0400\tmaster-replica-0\t1\t   KMP_HOT_TEAMS_MODE=0\n",
      "ERROR\t2019-09-09 14:41:10 -0400\tmaster-replica-0\t1\t   KMP_INIT_AT_FORK=true\n",
      "ERROR\t2019-09-09 14:41:10 -0400\tmaster-replica-0\t1\t   KMP_INIT_WAIT=2048\n",
      "ERROR\t2019-09-09 14:41:10 -0400\tmaster-replica-0\t1\t   KMP_ITT_PREPARE_DELAY=0\n",
      "ERROR\t2019-09-09 14:41:10 -0400\tmaster-replica-0\t1\t   KMP_LIBRARY=throughput\n",
      "ERROR\t2019-09-09 14:41:10 -0400\tmaster-replica-0\t1\t   KMP_LOCK_KIND=queuing\n",
      "ERROR\t2019-09-09 14:41:10 -0400\tmaster-replica-0\t1\t   KMP_MALLOC_POOL_INCR=1M\n",
      "ERROR\t2019-09-09 14:41:10 -0400\tmaster-replica-0\t1\t   KMP_NEXT_WAIT=1024\n",
      "ERROR\t2019-09-09 14:41:10 -0400\tmaster-replica-0\t1\t   KMP_NUM_LOCKS_IN_BLOCK=1\n",
      "ERROR\t2019-09-09 14:41:10 -0400\tmaster-replica-0\t1\t   KMP_PLAIN_BARRIER='2,2'\n",
      "ERROR\t2019-09-09 14:41:10 -0400\tmaster-replica-0\t1\t   KMP_PLAIN_BARRIER_PATTERN='hyper,hyper'\n",
      "ERROR\t2019-09-09 14:41:10 -0400\tmaster-replica-0\t1\t   KMP_REDUCTION_BARRIER='1,1'\n",
      "ERROR\t2019-09-09 14:41:10 -0400\tmaster-replica-0\t1\t   KMP_REDUCTION_BARRIER_PATTERN='hyper,hyper'\n",
      "ERROR\t2019-09-09 14:41:10 -0400\tmaster-replica-0\t1\t   KMP_SCHEDULE='static,balanced;guided,iterative'\n",
      "ERROR\t2019-09-09 14:41:10 -0400\tmaster-replica-0\t1\t   KMP_SETTINGS=true\n",
      "ERROR\t2019-09-09 14:41:10 -0400\tmaster-replica-0\t1\t   KMP_SPIN_BACKOFF_PARAMS='4096,100'\n",
      "ERROR\t2019-09-09 14:41:10 -0400\tmaster-replica-0\t1\t   KMP_STACKOFFSET=64\n",
      "ERROR\t2019-09-09 14:41:10 -0400\tmaster-replica-0\t1\t   KMP_STACKPAD=0\n",
      "ERROR\t2019-09-09 14:41:10 -0400\tmaster-replica-0\t1\t   KMP_STACKSIZE=4M\n",
      "ERROR\t2019-09-09 14:41:10 -0400\tmaster-replica-0\t1\t   KMP_STORAGE_MAP=false\n",
      "ERROR\t2019-09-09 14:41:10 -0400\tmaster-replica-0\t1\t   KMP_TASKING=2\n",
      "ERROR\t2019-09-09 14:41:10 -0400\tmaster-replica-0\t1\t   KMP_TASKLOOP_MIN_TASKS=0\n",
      "ERROR\t2019-09-09 14:41:10 -0400\tmaster-replica-0\t1\t   KMP_TASK_STEALING_CONSTRAINT=1\n",
      "ERROR\t2019-09-09 14:41:10 -0400\tmaster-replica-0\t1\t   KMP_TEAMS_THREAD_LIMIT=4\n",
      "ERROR\t2019-09-09 14:41:10 -0400\tmaster-replica-0\t1\t   KMP_TOPOLOGY_METHOD=all\n",
      "ERROR\t2019-09-09 14:41:10 -0400\tmaster-replica-0\t1\t   KMP_USER_LEVEL_MWAIT=false\n",
      "ERROR\t2019-09-09 14:41:10 -0400\tmaster-replica-0\t1\t   KMP_VERSION=false\n",
      "ERROR\t2019-09-09 14:41:10 -0400\tmaster-replica-0\t1\t   KMP_WARNINGS=true\n",
      "ERROR\t2019-09-09 14:41:10 -0400\tmaster-replica-0\t1\t   OMP_AFFINITY_FORMAT='OMP: pid %P tid %T thread %n bound to OS proc set {%a}'\n",
      "ERROR\t2019-09-09 14:41:10 -0400\tmaster-replica-0\t1\t   OMP_ALLOCATOR=omp_default_mem_alloc\n",
      "ERROR\t2019-09-09 14:41:10 -0400\tmaster-replica-0\t1\t   OMP_CANCELLATION=false\n",
      "ERROR\t2019-09-09 14:41:10 -0400\tmaster-replica-0\t1\t   OMP_DEFAULT_DEVICE=0\n",
      "ERROR\t2019-09-09 14:41:10 -0400\tmaster-replica-0\t1\t   OMP_DISPLAY_AFFINITY=false\n",
      "ERROR\t2019-09-09 14:41:10 -0400\tmaster-replica-0\t1\t   OMP_DISPLAY_ENV=false\n",
      "ERROR\t2019-09-09 14:41:10 -0400\tmaster-replica-0\t1\t   OMP_DYNAMIC=false\n",
      "ERROR\t2019-09-09 14:41:10 -0400\tmaster-replica-0\t1\t   OMP_MAX_ACTIVE_LEVELS=2147483647\n",
      "ERROR\t2019-09-09 14:41:10 -0400\tmaster-replica-0\t1\t   OMP_MAX_TASK_PRIORITY=0\n",
      "ERROR\t2019-09-09 14:41:10 -0400\tmaster-replica-0\t1\t   OMP_NESTED=false\n",
      "ERROR\t2019-09-09 14:41:10 -0400\tmaster-replica-0\t1\t   OMP_NUM_THREADS='4'\n",
      "ERROR\t2019-09-09 14:41:10 -0400\tmaster-replica-0\t1\t   OMP_PLACES: value is not defined\n",
      "ERROR\t2019-09-09 14:41:10 -0400\tmaster-replica-0\t1\t   OMP_PROC_BIND='intel'\n",
      "ERROR\t2019-09-09 14:41:10 -0400\tmaster-replica-0\t1\t   OMP_SCHEDULE='static'\n",
      "ERROR\t2019-09-09 14:41:10 -0400\tmaster-replica-0\t1\t   OMP_STACKSIZE=4M\n",
      "ERROR\t2019-09-09 14:41:10 -0400\tmaster-replica-0\t1\t   OMP_TARGET_OFFLOAD=DEFAULT\n",
      "ERROR\t2019-09-09 14:41:10 -0400\tmaster-replica-0\t1\t   OMP_THREAD_LIMIT=2147483647\n",
      "ERROR\t2019-09-09 14:41:10 -0400\tmaster-replica-0\t1\t   OMP_TOOL=enabled\n",
      "ERROR\t2019-09-09 14:41:10 -0400\tmaster-replica-0\t1\t   OMP_TOOL_LIBRARIES: value is not defined\n",
      "ERROR\t2019-09-09 14:41:10 -0400\tmaster-replica-0\t1\t   OMP_WAIT_POLICY=PASSIVE\n",
      "ERROR\t2019-09-09 14:41:10 -0400\tmaster-replica-0\t1\t   KMP_AFFINITY='verbose,warnings,respect,granularity=fine,compact,1,0'\n",
      "INFO\t2019-09-09 14:41:10 -0400\tmaster-replica-0\t1\tCPU Frequency: 2300000000 Hz\n",
      "INFO\t2019-09-09 14:41:10 -0400\tmaster-replica-0\t1\tXLA service 0x4cdb2e0 executing computations on platform Host. Devices:\n",
      "INFO\t2019-09-09 14:41:10 -0400\tmaster-replica-0\t1\t  StreamExecutor device (0): <undefined>, <undefined>\n",
      "ERROR\t2019-09-09 14:41:10 -0400\tmaster-replica-0\t1\tOMP: Info #212: KMP_AFFINITY: decoding x2APIC ids.\n",
      "ERROR\t2019-09-09 14:41:10 -0400\tmaster-replica-0\t1\tOMP: Info #210: KMP_AFFINITY: Affinity capable, using global cpuid leaf 11 info\n",
      "ERROR\t2019-09-09 14:41:10 -0400\tmaster-replica-0\t1\tOMP: Info #154: KMP_AFFINITY: Initial OS proc set respected: 0-3\n",
      "ERROR\t2019-09-09 14:41:10 -0400\tmaster-replica-0\t1\tOMP: Info #156: KMP_AFFINITY: 4 available OS procs\n",
      "ERROR\t2019-09-09 14:41:10 -0400\tmaster-replica-0\t1\tOMP: Info #157: KMP_AFFINITY: Uniform topology\n",
      "ERROR\t2019-09-09 14:41:10 -0400\tmaster-replica-0\t1\tOMP: Info #179: KMP_AFFINITY: 1 packages x 2 cores/pkg x 2 threads/core (2 total cores)\n",
      "ERROR\t2019-09-09 14:41:10 -0400\tmaster-replica-0\t1\tOMP: Info #214: KMP_AFFINITY: OS proc to physical thread map:\n",
      "ERROR\t2019-09-09 14:41:10 -0400\tmaster-replica-0\t1\tOMP: Info #171: KMP_AFFINITY: OS proc 0 maps to package 0 core 0 thread 0 \n",
      "ERROR\t2019-09-09 14:41:10 -0400\tmaster-replica-0\t1\tOMP: Info #171: KMP_AFFINITY: OS proc 2 maps to package 0 core 0 thread 1 \n",
      "ERROR\t2019-09-09 14:41:10 -0400\tmaster-replica-0\t1\tOMP: Info #171: KMP_AFFINITY: OS proc 1 maps to package 0 core 1 thread 0 \n",
      "ERROR\t2019-09-09 14:41:10 -0400\tmaster-replica-0\t1\tOMP: Info #171: KMP_AFFINITY: OS proc 3 maps to package 0 core 1 thread 1 \n",
      "ERROR\t2019-09-09 14:41:10 -0400\tmaster-replica-0\t1\tOMP: Info #250: KMP_AFFINITY: pid 397 tid 397 thread 0 bound to OS proc set 0\n",
      "INFO\t2019-09-09 14:41:10 -0400\tmaster-replica-0\t1\tCreating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n",
      "ERROR\t2019-09-09 14:41:11 -0400\tmaster-replica-0\t1\tOMP: Info #250: KMP_AFFINITY: pid 397 tid 420 thread 1 bound to OS proc set 1\n",
      "WARNING\t2019-09-09 14:41:11 -0400\tmaster-replica-0\t1\tFrom /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "WARNING\t2019-09-09 14:41:11 -0400\tmaster-replica-0\t1\tInstructions for updating:\n",
      "WARNING\t2019-09-09 14:41:11 -0400\tmaster-replica-0\t1\tUse tf.cast instead.\n",
      "ERROR\t2019-09-09 14:41:17 -0400\tmaster-replica-0\t1\tOMP: Info #250: KMP_AFFINITY: pid 397 tid 421 thread 2 bound to OS proc set 2\n",
      "ERROR\t2019-09-09 14:41:17 -0400\tmaster-replica-0\t1\tOMP: Info #250: KMP_AFFINITY: pid 397 tid 484 thread 3 bound to OS proc set 3\n",
      "ERROR\t2019-09-09 14:41:17 -0400\tmaster-replica-0\t1\tOMP: Info #250: KMP_AFFINITY: pid 397 tid 485 thread 4 bound to OS proc set 0\n",
      "ERROR\t2019-09-09 14:41:17 -0400\tmaster-replica-0\t1\tOMP: Info #250: KMP_AFFINITY: pid 397 tid 486 thread 5 bound to OS proc set 1\n",
      "ERROR\t2019-09-09 14:41:17 -0400\tmaster-replica-0\t1\tOMP: Info #250: KMP_AFFINITY: pid 397 tid 487 thread 6 bound to OS proc set 2\n",
      "ERROR\t2019-09-09 14:41:17 -0400\tmaster-replica-0\t1\tOMP: Info #250: KMP_AFFINITY: pid 397 tid 488 thread 7 bound to OS proc set 3\n",
      "ERROR\t2019-09-09 14:41:17 -0400\tmaster-replica-0\t1\tOMP: Info #250: KMP_AFFINITY: pid 397 tid 489 thread 8 bound to OS proc set 0\n",
      "INFO\t2019-09-09 14:41:17 -0400\tmaster-replica-0\t1\tEpoch 00001: LearningRateScheduler reducing learning rate to 0.09412597210250212.\n",
      "INFO\t2019-09-09 14:41:17 -0400\tmaster-replica-0\t1\tEpoch 1/20\n",
      "INFO\t2019-09-09 14:41:17 -0400\tmaster-replica-0\t1\t  1/136 [..............................] - ETA: 2:02 - loss: 0.7555 - acc: 0.263\n",
      "INFO\t2019-09-09 14:41:17 -0400\tmaster-replica-0\t1\t  7/136 [>.............................] - ETA: 17s - loss: 3.6822 - acc: 0.673\n",
      "INFO\t2019-09-09 14:41:17 -0400\tmaster-replica-0\t1\t 12/136 [=>............................] - ETA: 10s - loss: 3.5979 - acc: 0.71\n",
      "INFO\t2019-09-09 14:41:17 -0400\tmaster-replica-0\t1\t 18/136 [==>...........................] - ETA: 7s - loss: 3.6875 - acc: 0.7329\n",
      "INFO\t2019-09-09 14:41:17 -0400\tmaster-replica-0\t1\t 24/136 [====>.........................] - ETA: 5s - loss: 3.7912 - acc: 0.736\n",
      "INFO\t2019-09-09 14:41:17 -0400\tmaster-replica-0\t1\t 32/136 [======>.......................] - ETA: 3s - loss: 3.7370 - acc: 0.746\n",
      "INFO\t2019-09-09 14:41:17 -0400\tmaster-replica-0\t1\t 36/136 [======>.......................] - ETA: 3s - loss: 3.7433 - acc: 0.748\n",
      "INFO\t2019-09-09 14:41:17 -0400\tmaster-replica-0\t1\t 40/136 [=======>......................] - ETA: 3s - loss: 3.7567 - acc: 0.749\n",
      "INFO\t2019-09-09 14:41:17 -0400\tmaster-replica-0\t1\t 47/136 [=========>....................] - ETA: 2s - loss: 3.8056 - acc: 0.749\n",
      "INFO\t2019-09-09 14:41:17 -0400\tmaster-replica-0\t1\t 51/136 [==========>...................] - ETA: 2s - loss: 3.8007 - acc: 0.750\n",
      "INFO\t2019-09-09 14:41:17 -0400\tmaster-replica-0\t1\t 55/136 [===========>..................] - ETA: 2s - loss: 3.8222 - acc: 0.750\n",
      "INFO\t2019-09-09 14:41:17 -0400\tmaster-replica-0\t1\t 61/136 [============>.................] - ETA: 1s - loss: 3.8332 - acc: 0.750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO\t2019-09-09 14:41:17 -0400\tmaster-replica-0\t1\t 66/136 [=============>................] - ETA: 1s - loss: 3.8177 - acc: 0.752\n",
      "INFO\t2019-09-09 14:41:17 -0400\tmaster-replica-0\t1\t 74/136 [===============>..............] - ETA: 1s - loss: 3.7941 - acc: 0.755\n",
      "INFO\t2019-09-09 14:41:18 -0400\tmaster-replica-0\t1\t 78/136 [================>.............] - ETA: 1s - loss: 3.8079 - acc: 0.754\n",
      "INFO\t2019-09-09 14:41:18 -0400\tmaster-replica-0\t1\t 82/136 [=================>............] - ETA: 1s - loss: 3.8270 - acc: 0.754\n",
      "INFO\t2019-09-09 14:41:18 -0400\tmaster-replica-0\t1\t 88/136 [==================>...........] - ETA: 1s - loss: 3.8496 - acc: 0.753\n",
      "INFO\t2019-09-09 14:41:18 -0400\tmaster-replica-0\t1\t 94/136 [===================>..........] - ETA: 0s - loss: 3.8557 - acc: 0.753\n",
      "INFO\t2019-09-09 14:41:18 -0400\tmaster-replica-0\t1\t 99/136 [====================>.........] - ETA: 0s - loss: 3.8367 - acc: 0.755\n",
      "INFO\t2019-09-09 14:41:18 -0400\tmaster-replica-0\t1\t104/136 [=====================>........] - ETA: 0s - loss: 3.8280 - acc: 0.755\n",
      "INFO\t2019-09-09 14:41:18 -0400\tmaster-replica-0\t1\t110/136 [=======================>......] - ETA: 0s - loss: 3.8240 - acc: 0.756\n",
      "INFO\t2019-09-09 14:41:18 -0400\tmaster-replica-0\t1\t114/136 [========================>.....] - ETA: 0s - loss: 3.8288 - acc: 0.756\n",
      "INFO\t2019-09-09 14:41:18 -0400\tmaster-replica-0\t1\t119/136 [=========================>....] - ETA: 0s - loss: 3.8464 - acc: 0.755\n",
      "INFO\t2019-09-09 14:41:18 -0400\tmaster-replica-0\t1\t125/136 [==========================>...] - ETA: 0s - loss: 3.8501 - acc: 0.755\n",
      "WARNING\t2019-09-09 14:41:19 -0400\tmaster-replica-0\t1\tfile_cache is unavailable when using oauth2client >= 4.0.0 or google-auth\n",
      "INFO\t2019-09-09 14:41:19 -0400\tmaster-replica-0\t1\tAttempting refresh to obtain initial access_token\n",
      "INFO\t2019-09-09 14:41:21 -0400\tmaster-replica-0\t1\t131/136 [===========================>..] - ETA: 0s - loss: 3.8570 - acc: 0.755\n",
      "INFO\t2019-09-09 14:41:21 -0400\tmaster-replica-0\t1\t136/136 [==============================] - 5s 36ms/step - loss: 3.8546 - acc: 0.7558 - val_loss: 3.8072 - val_acc: 0.7638\n",
      "INFO\t2019-09-09 14:41:21 -0400\tmaster-replica-0\t1\tEpoch 00002: LearningRateScheduler reducing learning rate to 0.08912597210250213.\n",
      "INFO\t2019-09-09 14:41:21 -0400\tmaster-replica-0\t1\tEpoch 2/20\n",
      "INFO\t2019-09-09 14:41:21 -0400\tmaster-replica-0\t1\t  1/136 [..............................] - ETA: 12s - loss: 4.9231 - acc: 0.69\n",
      "INFO\t2019-09-09 14:41:21 -0400\tmaster-replica-0\t1\t  4/136 [..............................] - ETA: 4s - loss: 4.2487 - acc: 0.7364\n",
      "INFO\t2019-09-09 14:41:21 -0400\tmaster-replica-0\t1\t  7/136 [>.............................] - ETA: 3s - loss: 4.0946 - acc: 0.746\n",
      "INFO\t2019-09-09 14:41:21 -0400\tmaster-replica-0\t1\t 12/136 [=>............................] - ETA: 2s - loss: 4.0183 - acc: 0.750\n",
      "INFO\t2019-09-09 14:41:21 -0400\tmaster-replica-0\t1\t 18/136 [==>...........................] - ETA: 2s - loss: 3.8815 - acc: 0.759\n",
      "INFO\t2019-09-09 14:41:21 -0400\tmaster-replica-0\t1\t 23/136 [====>.........................] - ETA: 1s - loss: 3.9144 - acc: 0.757\n",
      "INFO\t2019-09-09 14:41:21 -0400\tmaster-replica-0\t1\t 28/136 [=====>........................] - ETA: 1s - loss: 3.9091 - acc: 0.757\n",
      "INFO\t2019-09-09 14:41:21 -0400\tmaster-replica-0\t1\t 35/136 [======>.......................] - ETA: 1s - loss: 3.9982 - acc: 0.751\n",
      "INFO\t2019-09-09 14:41:21 -0400\tmaster-replica-0\t1\t 40/136 [=======>......................] - ETA: 1s - loss: 3.9891 - acc: 0.752\n",
      "INFO\t2019-09-09 14:41:21 -0400\tmaster-replica-0\t1\t 47/136 [=========>....................] - ETA: 1s - loss: 3.9746 - acc: 0.753\n",
      "INFO\t2019-09-09 14:41:21 -0400\tmaster-replica-0\t1\t 53/136 [==========>...................] - ETA: 1s - loss: 3.9217 - acc: 0.756\n",
      "INFO\t2019-09-09 14:41:21 -0400\tmaster-replica-0\t1\t 55/136 [===========>..................] - ETA: 1s - loss: 3.9066 - acc: 0.757\n",
      "INFO\t2019-09-09 14:41:21 -0400\tmaster-replica-0\t1\t 61/136 [============>.................] - ETA: 0s - loss: 3.9060 - acc: 0.757\n",
      "INFO\t2019-09-09 14:41:22 -0400\tmaster-replica-0\t1\t 67/136 [=============>................] - ETA: 0s - loss: 3.8813 - acc: 0.759\n",
      "INFO\t2019-09-09 14:41:22 -0400\tmaster-replica-0\t1\t 71/136 [==============>...............] - ETA: 0s - loss: 3.9077 - acc: 0.757\n",
      "INFO\t2019-09-09 14:41:22 -0400\tmaster-replica-0\t1\t 77/136 [===============>..............] - ETA: 0s - loss: 3.8984 - acc: 0.758\n",
      "INFO\t2019-09-09 14:41:22 -0400\tmaster-replica-0\t1\t 83/136 [=================>............] - ETA: 0s - loss: 3.9042 - acc: 0.757\n",
      "INFO\t2019-09-09 14:41:22 -0400\tmaster-replica-0\t1\t 86/136 [=================>............] - ETA: 0s - loss: 3.9084 - acc: 0.757\n",
      "INFO\t2019-09-09 14:41:22 -0400\tmaster-replica-0\t1\t 92/136 [===================>..........] - ETA: 0s - loss: 3.8866 - acc: 0.758\n",
      "INFO\t2019-09-09 14:41:22 -0400\tmaster-replica-0\t1\t 99/136 [====================>.........] - ETA: 0s - loss: 3.9054 - acc: 0.757\n",
      "INFO\t2019-09-09 14:41:22 -0400\tmaster-replica-0\t1\t104/136 [=====================>........] - ETA: 0s - loss: 3.8817 - acc: 0.759\n",
      "INFO\t2019-09-09 14:41:22 -0400\tmaster-replica-0\t1\t111/136 [=======================>......] - ETA: 0s - loss: 3.8726 - acc: 0.759\n",
      "INFO\t2019-09-09 14:41:22 -0400\tmaster-replica-0\t1\t117/136 [========================>.....] - ETA: 0s - loss: 3.8763 - acc: 0.759\n",
      "INFO\t2019-09-09 14:41:22 -0400\tmaster-replica-0\t1\t124/136 [==========================>...] - ETA: 0s - loss: 3.8854 - acc: 0.758\n",
      "INFO\t2019-09-09 14:41:23 -0400\tmaster-replica-0\t1\t131/136 [===========================>..] - ETA: 0s - loss: 3.8878 - acc: 0.758\n",
      "INFO\t2019-09-09 14:41:23 -0400\tmaster-replica-0\t1\t136/136 [==============================] - 3s 18ms/step - loss: 3.8857 - acc: 0.7589 - val_loss: 3.8072 - val_acc: 0.7638\n",
      "INFO\t2019-09-09 14:41:23 -0400\tmaster-replica-0\t1\tEpoch 00003: LearningRateScheduler reducing learning rate to 0.08662597210250213.\n",
      "INFO\t2019-09-09 14:41:23 -0400\tmaster-replica-0\t1\tEpoch 3/20\n",
      "INFO\t2019-09-09 14:41:23 -0400\tmaster-replica-0\t1\t  1/136 [..............................] - ETA: 0s - loss: 3.7766 - acc: 0.765\n",
      "INFO\t2019-09-09 14:41:23 -0400\tmaster-replica-0\t1\t  9/136 [>.............................] - ETA: 0s - loss: 3.5668 - acc: 0.778\n",
      "INFO\t2019-09-09 14:41:23 -0400\tmaster-replica-0\t1\t 15/136 [==>...........................] - ETA: 0s - loss: 3.7227 - acc: 0.769\n",
      "INFO\t2019-09-09 14:41:23 -0400\tmaster-replica-0\t1\t 23/136 [====>.........................] - ETA: 0s - loss: 3.7854 - acc: 0.765\n",
      "INFO\t2019-09-09 14:41:23 -0400\tmaster-replica-0\t1\t 30/136 [=====>........................] - ETA: 0s - loss: 3.8598 - acc: 0.760\n",
      "INFO\t2019-09-09 14:41:24 -0400\tmaster-replica-0\t1\t 37/136 [=======>......................] - ETA: 0s - loss: 3.8386 - acc: 0.761\n",
      "INFO\t2019-09-09 14:41:24 -0400\tmaster-replica-0\t1\t 44/136 [========>.....................] - ETA: 0s - loss: 3.8349 - acc: 0.762\n",
      "INFO\t2019-09-09 14:41:24 -0400\tmaster-replica-0\t1\t 50/136 [==========>...................] - ETA: 0s - loss: 3.8643 - acc: 0.760\n",
      "INFO\t2019-09-09 14:41:24 -0400\tmaster-replica-0\t1\t 58/136 [===========>..................] - ETA: 0s - loss: 3.8417 - acc: 0.761\n",
      "INFO\t2019-09-09 14:41:24 -0400\tmaster-replica-0\t1\t 65/136 [=============>................] - ETA: 0s - loss: 3.8752 - acc: 0.759\n",
      "INFO\t2019-09-09 14:41:24 -0400\tmaster-replica-0\t1\t 73/136 [===============>..............] - ETA: 0s - loss: 3.8810 - acc: 0.759\n",
      "INFO\t2019-09-09 14:41:24 -0400\tmaster-replica-0\t1\t 79/136 [================>.............] - ETA: 0s - loss: 3.8765 - acc: 0.759\n",
      "INFO\t2019-09-09 14:41:24 -0400\tmaster-replica-0\t1\t 86/136 [=================>............] - ETA: 0s - loss: 3.8723 - acc: 0.759\n",
      "INFO\t2019-09-09 14:41:24 -0400\tmaster-replica-0\t1\t 92/136 [===================>..........] - ETA: 0s - loss: 3.8683 - acc: 0.760\n",
      "INFO\t2019-09-09 14:41:24 -0400\tmaster-replica-0\t1\t100/136 [=====================>........] - ETA: 0s - loss: 3.8717 - acc: 0.759\n",
      "INFO\t2019-09-09 14:41:24 -0400\tmaster-replica-0\t1\t106/136 [======================>.......] - ETA: 0s - loss: 3.8829 - acc: 0.759\n",
      "INFO\t2019-09-09 14:41:24 -0400\tmaster-replica-0\t1\t114/136 [========================>.....] - ETA: 0s - loss: 3.8802 - acc: 0.759\n",
      "INFO\t2019-09-09 14:41:24 -0400\tmaster-replica-0\t1\t120/136 [=========================>....] - ETA: 0s - loss: 3.8789 - acc: 0.759\n",
      "INFO\t2019-09-09 14:41:24 -0400\tmaster-replica-0\t1\t128/136 [===========================>..] - ETA: 0s - loss: 3.8694 - acc: 0.759\n",
      "INFO\t2019-09-09 14:41:25 -0400\tmaster-replica-0\t1\t135/136 [============================>.] - ETA: 0s - loss: 3.8765 - acc: 0.759\n",
      "INFO\t2019-09-09 14:41:25 -0400\tmaster-replica-0\t1\t136/136 [==============================] - 2s 16ms/step - loss: 3.8778 - acc: 0.7594 - val_loss: 3.8072 - val_acc: 0.7638\n",
      "INFO\t2019-09-09 14:41:25 -0400\tmaster-replica-0\t1\tEpoch 00004: LearningRateScheduler reducing learning rate to 0.08537597210250213.\n",
      "INFO\t2019-09-09 14:41:25 -0400\tmaster-replica-0\t1\tEpoch 4/20\n",
      "INFO\t2019-09-09 14:41:26 -0400\tmaster-replica-0\t1\t  1/136 [..............................] - ETA: 11s - loss: 3.9789 - acc: 0.75\n",
      "INFO\t2019-09-09 14:41:26 -0400\tmaster-replica-0\t1\t  9/136 [>.............................] - ETA: 2s - loss: 3.5668 - acc: 0.7787\n",
      "INFO\t2019-09-09 14:41:26 -0400\tmaster-replica-0\t1\t 15/136 [==>...........................] - ETA: 1s - loss: 3.7496 - acc: 0.767\n",
      "INFO\t2019-09-09 14:41:26 -0400\tmaster-replica-0\t1\t 23/136 [====>.........................] - ETA: 1s - loss: 3.7942 - acc: 0.764\n",
      "INFO\t2019-09-09 14:41:26 -0400\tmaster-replica-0\t1\t 29/136 [=====>........................] - ETA: 1s - loss: 3.7929 - acc: 0.764\n",
      "INFO\t2019-09-09 14:41:26 -0400\tmaster-replica-0\t1\t 37/136 [=======>......................] - ETA: 0s - loss: 3.8167 - acc: 0.763\n",
      "INFO\t2019-09-09 14:41:26 -0400\tmaster-replica-0\t1\t 43/136 [========>.....................] - ETA: 0s - loss: 3.8582 - acc: 0.760\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO\t2019-09-09 14:41:26 -0400\tmaster-replica-0\t1\t 51/136 [==========>...................] - ETA: 0s - loss: 3.8771 - acc: 0.759\n",
      "INFO\t2019-09-09 14:41:26 -0400\tmaster-replica-0\t1\t 57/136 [===========>..................] - ETA: 0s - loss: 3.9174 - acc: 0.757\n",
      "INFO\t2019-09-09 14:41:26 -0400\tmaster-replica-0\t1\t 65/136 [=============>................] - ETA: 0s - loss: 3.8804 - acc: 0.759\n",
      "INFO\t2019-09-09 14:41:26 -0400\tmaster-replica-0\t1\t 73/136 [===============>..............] - ETA: 0s - loss: 3.8616 - acc: 0.760\n",
      "INFO\t2019-09-09 14:41:26 -0400\tmaster-replica-0\t1\t 80/136 [================>.............] - ETA: 0s - loss: 3.8576 - acc: 0.760\n",
      "INFO\t2019-09-09 14:41:26 -0400\tmaster-replica-0\t1\t 88/136 [==================>...........] - ETA: 0s - loss: 3.8732 - acc: 0.759\n",
      "INFO\t2019-09-09 14:41:26 -0400\tmaster-replica-0\t1\t 95/136 [===================>..........] - ETA: 0s - loss: 3.8952 - acc: 0.758\n",
      "INFO\t2019-09-09 14:41:26 -0400\tmaster-replica-0\t1\t103/136 [=====================>........] - ETA: 0s - loss: 3.8964 - acc: 0.758\n",
      "INFO\t2019-09-09 14:41:26 -0400\tmaster-replica-0\t1\t109/136 [=======================>......] - ETA: 0s - loss: 3.9078 - acc: 0.757\n",
      "INFO\t2019-09-09 14:41:26 -0400\tmaster-replica-0\t1\t117/136 [========================>.....] - ETA: 0s - loss: 3.8890 - acc: 0.758\n",
      "INFO\t2019-09-09 14:41:26 -0400\tmaster-replica-0\t1\t124/136 [==========================>...] - ETA: 0s - loss: 3.8919 - acc: 0.758\n",
      "INFO\t2019-09-09 14:41:28 -0400\tmaster-replica-0\t1\t132/136 [============================>.] - ETA: 0s - loss: 3.8890 - acc: 0.758\n",
      "INFO\t2019-09-09 14:41:28 -0400\tmaster-replica-0\t1\t136/136 [==============================] - 2s 17ms/step - loss: 3.8852 - acc: 0.7590 - val_loss: 3.8072 - val_acc: 0.7638\n",
      "INFO\t2019-09-09 14:41:28 -0400\tmaster-replica-0\t1\tEpoch 00005: LearningRateScheduler reducing learning rate to 0.08475097210250213.\n",
      "INFO\t2019-09-09 14:41:28 -0400\tmaster-replica-0\t1\tEpoch 5/20\n",
      "INFO\t2019-09-09 14:41:28 -0400\tmaster-replica-0\t1\t  1/136 [..............................] - ETA: 13s - loss: 3.3045 - acc: 0.79\n",
      "INFO\t2019-09-09 14:41:28 -0400\tmaster-replica-0\t1\t  9/136 [>.............................] - ETA: 2s - loss: 3.7841 - acc: 0.7652\n",
      "INFO\t2019-09-09 14:41:28 -0400\tmaster-replica-0\t1\t 15/136 [==>...........................] - ETA: 1s - loss: 3.8036 - acc: 0.764\n",
      "INFO\t2019-09-09 14:41:28 -0400\tmaster-replica-0\t1\t 23/136 [====>.........................] - ETA: 1s - loss: 3.8147 - acc: 0.763\n",
      "INFO\t2019-09-09 14:41:28 -0400\tmaster-replica-0\t1\t 30/136 [=====>........................] - ETA: 1s - loss: 3.7834 - acc: 0.765\n",
      "INFO\t2019-09-09 14:41:28 -0400\tmaster-replica-0\t1\t 38/136 [=======>......................] - ETA: 0s - loss: 3.8387 - acc: 0.761\n",
      "INFO\t2019-09-09 14:41:28 -0400\tmaster-replica-0\t1\t 44/136 [========>.....................] - ETA: 0s - loss: 3.8195 - acc: 0.763\n",
      "INFO\t2019-09-09 14:41:28 -0400\tmaster-replica-0\t1\t 52/136 [==========>...................] - ETA: 0s - loss: 3.8298 - acc: 0.762\n",
      "INFO\t2019-09-09 14:41:28 -0400\tmaster-replica-0\t1\t 58/136 [===========>..................] - ETA: 0s - loss: 3.8394 - acc: 0.761\n",
      "INFO\t2019-09-09 14:41:28 -0400\tmaster-replica-0\t1\t 66/136 [=============>................] - ETA: 0s - loss: 3.8451 - acc: 0.761\n",
      "INFO\t2019-09-09 14:41:28 -0400\tmaster-replica-0\t1\t 73/136 [===============>..............] - ETA: 0s - loss: 3.8875 - acc: 0.758\n",
      "INFO\t2019-09-09 14:41:28 -0400\tmaster-replica-0\t1\t 80/136 [================>.............] - ETA: 0s - loss: 3.8837 - acc: 0.759\n",
      "INFO\t2019-09-09 14:41:28 -0400\tmaster-replica-0\t1\t 87/136 [==================>...........] - ETA: 0s - loss: 3.8890 - acc: 0.758\n",
      "INFO\t2019-09-09 14:41:29 -0400\tmaster-replica-0\t1\t 95/136 [===================>..........] - ETA: 0s - loss: 3.8781 - acc: 0.759\n",
      "INFO\t2019-09-09 14:41:29 -0400\tmaster-replica-0\t1\t103/136 [=====================>........] - ETA: 0s - loss: 3.8820 - acc: 0.759\n",
      "INFO\t2019-09-09 14:41:29 -0400\tmaster-replica-0\t1\t110/136 [=======================>......] - ETA: 0s - loss: 3.9084 - acc: 0.757\n",
      "INFO\t2019-09-09 14:41:29 -0400\tmaster-replica-0\t1\t118/136 [=========================>....] - ETA: 0s - loss: 3.9064 - acc: 0.757\n",
      "INFO\t2019-09-09 14:41:29 -0400\tmaster-replica-0\t1\t124/136 [==========================>...] - ETA: 0s - loss: 3.8887 - acc: 0.758\n",
      "INFO\t2019-09-09 14:41:30 -0400\tmaster-replica-0\t1\t131/136 [===========================>..] - ETA: 0s - loss: 3.8873 - acc: 0.758\n",
      "INFO\t2019-09-09 14:41:30 -0400\tmaster-replica-0\t1\t136/136 [==============================] - 3s 20ms/step - loss: 3.8788 - acc: 0.7594 - val_loss: 3.8072 - val_acc: 0.7638\n",
      "INFO\t2019-09-09 14:41:30 -0400\tmaster-replica-0\t1\tEpoch 00006: LearningRateScheduler reducing learning rate to 0.08443847210250212.\n",
      "INFO\t2019-09-09 14:41:30 -0400\tmaster-replica-0\t1\tEpoch 6/20\n",
      "INFO\t2019-09-09 14:41:31 -0400\tmaster-replica-0\t1\t  1/136 [..............................] - ETA: 5s - loss: 3.7766 - acc: 0.765\n",
      "INFO\t2019-09-09 14:41:31 -0400\tmaster-replica-0\t1\t  9/136 [>.............................] - ETA: 1s - loss: 3.9115 - acc: 0.757\n",
      "INFO\t2019-09-09 14:41:31 -0400\tmaster-replica-0\t1\t 16/136 [==>...........................] - ETA: 1s - loss: 3.9789 - acc: 0.753\n",
      "INFO\t2019-09-09 14:41:31 -0400\tmaster-replica-0\t1\t 24/136 [====>.........................] - ETA: 0s - loss: 3.8806 - acc: 0.759\n",
      "INFO\t2019-09-09 14:41:31 -0400\tmaster-replica-0\t1\t 31/136 [=====>........................] - ETA: 0s - loss: 3.8006 - acc: 0.764\n",
      "INFO\t2019-09-09 14:41:31 -0400\tmaster-replica-0\t1\t 39/136 [=======>......................] - ETA: 0s - loss: 3.7766 - acc: 0.765\n",
      "INFO\t2019-09-09 14:41:31 -0400\tmaster-replica-0\t1\t 46/136 [=========>....................] - ETA: 0s - loss: 3.7928 - acc: 0.764\n",
      "INFO\t2019-09-09 14:41:31 -0400\tmaster-replica-0\t1\t 54/136 [==========>...................] - ETA: 0s - loss: 3.8029 - acc: 0.764\n",
      "INFO\t2019-09-09 14:41:31 -0400\tmaster-replica-0\t1\t 61/136 [============>.................] - ETA: 0s - loss: 3.8087 - acc: 0.763\n",
      "INFO\t2019-09-09 14:41:31 -0400\tmaster-replica-0\t1\t 69/136 [==============>...............] - ETA: 0s - loss: 3.8255 - acc: 0.762\n",
      "INFO\t2019-09-09 14:41:31 -0400\tmaster-replica-0\t1\t 76/136 [===============>..............] - ETA: 0s - loss: 3.8441 - acc: 0.761\n",
      "INFO\t2019-09-09 14:41:31 -0400\tmaster-replica-0\t1\t 83/136 [=================>............] - ETA: 0s - loss: 3.8538 - acc: 0.760\n",
      "INFO\t2019-09-09 14:41:31 -0400\tmaster-replica-0\t1\t 90/136 [==================>...........] - ETA: 0s - loss: 3.8441 - acc: 0.761\n",
      "INFO\t2019-09-09 14:41:31 -0400\tmaster-replica-0\t1\t 97/136 [====================>.........] - ETA: 0s - loss: 3.8357 - acc: 0.762\n",
      "INFO\t2019-09-09 14:41:31 -0400\tmaster-replica-0\t1\t105/136 [======================>.......] - ETA: 0s - loss: 3.8550 - acc: 0.760\n",
      "INFO\t2019-09-09 14:41:31 -0400\tmaster-replica-0\t1\t112/136 [=======================>......] - ETA: 0s - loss: 3.8766 - acc: 0.759\n",
      "INFO\t2019-09-09 14:41:31 -0400\tmaster-replica-0\t1\t120/136 [=========================>....] - ETA: 0s - loss: 3.8783 - acc: 0.759\n",
      "INFO\t2019-09-09 14:41:31 -0400\tmaster-replica-0\t1\t127/136 [===========================>..] - ETA: 0s - loss: 3.8749 - acc: 0.759\n",
      "INFO\t2019-09-09 14:41:32 -0400\tmaster-replica-0\t1\t135/136 [============================>.] - ETA: 0s - loss: 3.8715 - acc: 0.759\n",
      "INFO\t2019-09-09 14:41:32 -0400\tmaster-replica-0\t1\t136/136 [==============================] - 2s 15ms/step - loss: 3.8813 - acc: 0.7592 - val_loss: 3.8072 - val_acc: 0.7638\n",
      "INFO\t2019-09-09 14:41:32 -0400\tmaster-replica-0\t1\tEpoch 00007: LearningRateScheduler reducing learning rate to 0.08428222210250212.\n",
      "INFO\t2019-09-09 14:41:32 -0400\tmaster-replica-0\t1\tEpoch 7/20\n",
      "INFO\t2019-09-09 14:41:33 -0400\tmaster-replica-0\t1\t  1/136 [..............................] - ETA: 1s - loss: 3.9789 - acc: 0.753\n",
      "INFO\t2019-09-09 14:41:33 -0400\tmaster-replica-0\t1\t  9/136 [>.............................] - ETA: 0s - loss: 4.0689 - acc: 0.747\n",
      "INFO\t2019-09-09 14:41:33 -0400\tmaster-replica-0\t1\t 13/136 [=>............................] - ETA: 1s - loss: 3.9530 - acc: 0.754\n",
      "INFO\t2019-09-09 14:41:33 -0400\tmaster-replica-0\t1\t 18/136 [==>...........................] - ETA: 1s - loss: 3.9040 - acc: 0.757\n",
      "INFO\t2019-09-09 14:41:33 -0400\tmaster-replica-0\t1\t 23/136 [====>.........................] - ETA: 1s - loss: 3.8411 - acc: 0.761\n",
      "INFO\t2019-09-09 14:41:33 -0400\tmaster-replica-0\t1\t 31/136 [=====>........................] - ETA: 0s - loss: 3.8267 - acc: 0.762\n",
      "INFO\t2019-09-09 14:41:33 -0400\tmaster-replica-0\t1\t 38/136 [=======>......................] - ETA: 0s - loss: 3.8103 - acc: 0.763\n",
      "INFO\t2019-09-09 14:41:33 -0400\tmaster-replica-0\t1\t 45/136 [========>.....................] - ETA: 0s - loss: 3.7871 - acc: 0.765\n",
      "INFO\t2019-09-09 14:41:33 -0400\tmaster-replica-0\t1\t 51/136 [==========>...................] - ETA: 0s - loss: 3.7898 - acc: 0.764\n",
      "INFO\t2019-09-09 14:41:33 -0400\tmaster-replica-0\t1\t 59/136 [============>.................] - ETA: 0s - loss: 3.7835 - acc: 0.765\n",
      "INFO\t2019-09-09 14:41:33 -0400\tmaster-replica-0\t1\t 65/136 [=============>................] - ETA: 0s - loss: 3.7642 - acc: 0.766\n",
      "INFO\t2019-09-09 14:41:33 -0400\tmaster-replica-0\t1\t 73/136 [===============>..............] - ETA: 0s - loss: 3.7988 - acc: 0.764\n",
      "INFO\t2019-09-09 14:41:33 -0400\tmaster-replica-0\t1\t 80/136 [================>.............] - ETA: 0s - loss: 3.8053 - acc: 0.763\n",
      "INFO\t2019-09-09 14:41:33 -0400\tmaster-replica-0\t1\t 87/136 [==================>...........] - ETA: 0s - loss: 3.8371 - acc: 0.761\n",
      "INFO\t2019-09-09 14:41:33 -0400\tmaster-replica-0\t1\t 91/136 [===================>..........] - ETA: 0s - loss: 3.8285 - acc: 0.762\n",
      "INFO\t2019-09-09 14:41:33 -0400\tmaster-replica-0\t1\t 95/136 [===================>..........] - ETA: 0s - loss: 3.8341 - acc: 0.762\n",
      "INFO\t2019-09-09 14:41:33 -0400\tmaster-replica-0\t1\t100/136 [=====================>........] - ETA: 0s - loss: 3.8292 - acc: 0.762\n",
      "INFO\t2019-09-09 14:41:33 -0400\tmaster-replica-0\t1\t102/136 [=====================>........] - ETA: 0s - loss: 3.8335 - acc: 0.762\n",
      "INFO\t2019-09-09 14:41:34 -0400\tmaster-replica-0\t1\t107/136 [======================>.......] - ETA: 0s - loss: 3.8592 - acc: 0.760\n",
      "INFO\t2019-09-09 14:41:34 -0400\tmaster-replica-0\t1\t110/136 [=======================>......] - ETA: 0s - loss: 3.8649 - acc: 0.760\n",
      "INFO\t2019-09-09 14:41:34 -0400\tmaster-replica-0\t1\t112/136 [=======================>......] - ETA: 0s - loss: 3.8627 - acc: 0.760\n",
      "INFO\t2019-09-09 14:41:34 -0400\tmaster-replica-0\t1\t118/136 [=========================>....] - ETA: 0s - loss: 3.8498 - acc: 0.761\n",
      "INFO\t2019-09-09 14:41:34 -0400\tmaster-replica-0\t1\t121/136 [=========================>....] - ETA: 0s - loss: 3.8469 - acc: 0.761\n",
      "INFO\t2019-09-09 14:41:34 -0400\tmaster-replica-0\t1\t128/136 [===========================>..] - ETA: 0s - loss: 3.8646 - acc: 0.760\n",
      "INFO\t2019-09-09 14:41:35 -0400\tmaster-replica-0\t1\t134/136 [============================>.] - ETA: 0s - loss: 3.8833 - acc: 0.759\n",
      "INFO\t2019-09-09 14:41:35 -0400\tmaster-replica-0\t1\t136/136 [==============================] - 3s 18ms/step - loss: 3.8818 - acc: 0.7592 - val_loss: 3.8072 - val_acc: 0.7638\n",
      "INFO\t2019-09-09 14:41:35 -0400\tmaster-replica-0\t1\tEpoch 00008: LearningRateScheduler reducing learning rate to 0.08420409710250212.\n",
      "INFO\t2019-09-09 14:41:35 -0400\tmaster-replica-0\t1\tEpoch 8/20\n",
      "INFO\t2019-09-09 14:41:35 -0400\tmaster-replica-0\t1\t  1/136 [..............................] - ETA: 11s - loss: 3.8441 - acc: 0.76\n",
      "INFO\t2019-09-09 14:41:35 -0400\tmaster-replica-0\t1\t  9/136 [>.............................] - ETA: 2s - loss: 3.8366 - acc: 0.7620\n",
      "INFO\t2019-09-09 14:41:35 -0400\tmaster-replica-0\t1\t 15/136 [==>...........................] - ETA: 1s - loss: 3.8441 - acc: 0.761\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO\t2019-09-09 14:41:35 -0400\tmaster-replica-0\t1\t 23/136 [====>.........................] - ETA: 1s - loss: 3.8646 - acc: 0.760\n",
      "INFO\t2019-09-09 14:41:35 -0400\tmaster-replica-0\t1\t 29/136 [=====>........................] - ETA: 1s - loss: 3.8510 - acc: 0.761\n",
      "INFO\t2019-09-09 14:41:35 -0400\tmaster-replica-0\t1\t 37/136 [=======>......................] - ETA: 0s - loss: 3.8641 - acc: 0.760\n",
      "INFO\t2019-09-09 14:41:35 -0400\tmaster-replica-0\t1\t 44/136 [========>.....................] - ETA: 0s - loss: 3.8931 - acc: 0.758\n",
      "INFO\t2019-09-09 14:41:35 -0400\tmaster-replica-0\t1\t 52/136 [==========>...................] - ETA: 0s - loss: 3.8687 - acc: 0.760\n",
      "INFO\t2019-09-09 14:41:36 -0400\tmaster-replica-0\t1\t 60/136 [============>.................] - ETA: 0s - loss: 3.8553 - acc: 0.760\n",
      "INFO\t2019-09-09 14:41:36 -0400\tmaster-replica-0\t1\t 68/136 [==============>...............] - ETA: 0s - loss: 3.8460 - acc: 0.761\n",
      "INFO\t2019-09-09 14:41:36 -0400\tmaster-replica-0\t1\t 75/136 [===============>..............] - ETA: 0s - loss: 3.8396 - acc: 0.761\n",
      "INFO\t2019-09-09 14:41:36 -0400\tmaster-replica-0\t1\t 82/136 [=================>............] - ETA: 0s - loss: 3.8202 - acc: 0.763\n",
      "INFO\t2019-09-09 14:41:36 -0400\tmaster-replica-0\t1\t 89/136 [==================>...........] - ETA: 0s - loss: 3.8357 - acc: 0.762\n",
      "INFO\t2019-09-09 14:41:36 -0400\tmaster-replica-0\t1\t 97/136 [====================>.........] - ETA: 0s - loss: 3.8677 - acc: 0.760\n",
      "INFO\t2019-09-09 14:41:36 -0400\tmaster-replica-0\t1\t103/136 [=====================>........] - ETA: 0s - loss: 3.8637 - acc: 0.760\n",
      "INFO\t2019-09-09 14:41:36 -0400\tmaster-replica-0\t1\t111/136 [=======================>......] - ETA: 0s - loss: 3.8617 - acc: 0.760\n",
      "INFO\t2019-09-09 14:41:36 -0400\tmaster-replica-0\t1\t119/136 [=========================>....] - ETA: 0s - loss: 3.8696 - acc: 0.759\n",
      "INFO\t2019-09-09 14:41:36 -0400\tmaster-replica-0\t1\t126/136 [==========================>...] - ETA: 0s - loss: 3.8831 - acc: 0.759\n",
      "INFO\t2019-09-09 14:41:37 -0400\tmaster-replica-0\t1\t134/136 [============================>.] - ETA: 0s - loss: 3.8813 - acc: 0.759\n",
      "INFO\t2019-09-09 14:41:37 -0400\tmaster-replica-0\t1\t136/136 [==============================] - 2s 17ms/step - loss: 3.8768 - acc: 0.7595 - val_loss: 3.8072 - val_acc: 0.7638\n",
      "INFO\t2019-09-09 14:41:37 -0400\tmaster-replica-0\t1\tEpoch 00009: LearningRateScheduler reducing learning rate to 0.08416503460250213.\n",
      "INFO\t2019-09-09 14:41:37 -0400\tmaster-replica-0\t1\tEpoch 9/20\n",
      "INFO\t2019-09-09 14:41:37 -0400\tmaster-replica-0\t1\t  1/136 [..............................] - ETA: 0s - loss: 3.7092 - acc: 0.769\n",
      "INFO\t2019-09-09 14:41:37 -0400\tmaster-replica-0\t1\t  7/136 [>.............................] - ETA: 1s - loss: 3.9308 - acc: 0.756\n",
      "INFO\t2019-09-09 14:41:38 -0400\tmaster-replica-0\t1\t 15/136 [==>...........................] - ETA: 0s - loss: 3.7766 - acc: 0.765\n",
      "INFO\t2019-09-09 14:41:38 -0400\tmaster-replica-0\t1\t 22/136 [===>..........................] - ETA: 0s - loss: 3.8226 - acc: 0.762\n",
      "INFO\t2019-09-09 14:41:38 -0400\tmaster-replica-0\t1\t 29/136 [=====>........................] - ETA: 0s - loss: 3.8696 - acc: 0.759\n",
      "INFO\t2019-09-09 14:41:38 -0400\tmaster-replica-0\t1\t 37/136 [=======>......................] - ETA: 0s - loss: 3.8714 - acc: 0.759\n",
      "INFO\t2019-09-09 14:41:38 -0400\tmaster-replica-0\t1\t 44/136 [========>.....................] - ETA: 0s - loss: 3.9207 - acc: 0.756\n",
      "INFO\t2019-09-09 14:41:38 -0400\tmaster-replica-0\t1\t 51/136 [==========>...................] - ETA: 0s - loss: 3.8586 - acc: 0.760\n",
      "INFO\t2019-09-09 14:41:38 -0400\tmaster-replica-0\t1\t 58/136 [===========>..................] - ETA: 0s - loss: 3.9103 - acc: 0.757\n",
      "INFO\t2019-09-09 14:41:38 -0400\tmaster-replica-0\t1\t 66/136 [=============>................] - ETA: 0s - loss: 3.8890 - acc: 0.758\n",
      "INFO\t2019-09-09 14:41:38 -0400\tmaster-replica-0\t1\t 72/136 [==============>...............] - ETA: 0s - loss: 3.8872 - acc: 0.758\n",
      "INFO\t2019-09-09 14:41:38 -0400\tmaster-replica-0\t1\t 80/136 [================>.............] - ETA: 0s - loss: 3.8828 - acc: 0.759\n",
      "INFO\t2019-09-09 14:41:38 -0400\tmaster-replica-0\t1\t 87/136 [==================>...........] - ETA: 0s - loss: 3.8875 - acc: 0.758\n",
      "INFO\t2019-09-09 14:41:38 -0400\tmaster-replica-0\t1\t 94/136 [===================>..........] - ETA: 0s - loss: 3.8929 - acc: 0.758\n",
      "INFO\t2019-09-09 14:41:38 -0400\tmaster-replica-0\t1\t102/136 [=====================>........] - ETA: 0s - loss: 3.8996 - acc: 0.758\n",
      "INFO\t2019-09-09 14:41:38 -0400\tmaster-replica-0\t1\t108/136 [======================>.......] - ETA: 0s - loss: 3.9034 - acc: 0.757\n",
      "INFO\t2019-09-09 14:41:38 -0400\tmaster-replica-0\t1\t116/136 [========================>.....] - ETA: 0s - loss: 3.8964 - acc: 0.758\n",
      "INFO\t2019-09-09 14:41:38 -0400\tmaster-replica-0\t1\t123/136 [==========================>...] - ETA: 0s - loss: 3.8956 - acc: 0.758\n",
      "INFO\t2019-09-09 14:41:40 -0400\tmaster-replica-0\t1\t131/136 [===========================>..] - ETA: 0s - loss: 3.8827 - acc: 0.759\n",
      "INFO\t2019-09-09 14:41:40 -0400\tmaster-replica-0\t1\t136/136 [==============================] - 2s 17ms/step - loss: 3.8887 - acc: 0.7587 - val_loss: 3.8072 - val_acc: 0.7638\n",
      "INFO\t2019-09-09 14:41:40 -0400\tmaster-replica-0\t1\tEpoch 00010: LearningRateScheduler reducing learning rate to 0.08414550335250212.\n",
      "INFO\t2019-09-09 14:41:40 -0400\tmaster-replica-0\t1\tEpoch 10/20\n",
      "INFO\t2019-09-09 14:41:40 -0400\tmaster-replica-0\t1\t  1/136 [..............................] - ETA: 1s - loss: 3.9115 - acc: 0.757\n",
      "INFO\t2019-09-09 14:41:40 -0400\tmaster-replica-0\t1\t  9/136 [>.............................] - ETA: 0s - loss: 3.9640 - acc: 0.754\n",
      "INFO\t2019-09-09 14:41:40 -0400\tmaster-replica-0\t1\t 16/136 [==>...........................] - ETA: 0s - loss: 3.9705 - acc: 0.753\n",
      "INFO\t2019-09-09 14:41:40 -0400\tmaster-replica-0\t1\t 23/136 [====>.........................] - ETA: 0s - loss: 3.9350 - acc: 0.755\n",
      "INFO\t2019-09-09 14:41:40 -0400\tmaster-replica-0\t1\t 29/136 [=====>........................] - ETA: 0s - loss: 3.8603 - acc: 0.760\n",
      "INFO\t2019-09-09 14:41:40 -0400\tmaster-replica-0\t1\t 37/136 [=======>......................] - ETA: 0s - loss: 3.8969 - acc: 0.758\n",
      "INFO\t2019-09-09 14:41:40 -0400\tmaster-replica-0\t1\t 43/136 [========>.....................] - ETA: 0s - loss: 3.9099 - acc: 0.757\n",
      "INFO\t2019-09-09 14:41:40 -0400\tmaster-replica-0\t1\t 51/136 [==========>...................] - ETA: 0s - loss: 3.9340 - acc: 0.755\n",
      "INFO\t2019-09-09 14:41:40 -0400\tmaster-replica-0\t1\t 57/136 [===========>..................] - ETA: 0s - loss: 3.9293 - acc: 0.756\n",
      "INFO\t2019-09-09 14:41:40 -0400\tmaster-replica-0\t1\t 65/136 [=============>................] - ETA: 0s - loss: 3.9291 - acc: 0.756\n",
      "INFO\t2019-09-09 14:41:40 -0400\tmaster-replica-0\t1\t 71/136 [==============>...............] - ETA: 0s - loss: 3.9324 - acc: 0.756\n",
      "INFO\t2019-09-09 14:41:40 -0400\tmaster-replica-0\t1\t 79/136 [================>.............] - ETA: 0s - loss: 3.9047 - acc: 0.757\n",
      "INFO\t2019-09-09 14:41:40 -0400\tmaster-replica-0\t1\t 86/136 [=================>............] - ETA: 0s - loss: 3.8825 - acc: 0.759\n",
      "INFO\t2019-09-09 14:41:40 -0400\tmaster-replica-0\t1\t 94/136 [===================>..........] - ETA: 0s - loss: 3.8778 - acc: 0.759\n",
      "INFO\t2019-09-09 14:41:40 -0400\tmaster-replica-0\t1\t103/136 [=====================>........] - ETA: 0s - loss: 3.8722 - acc: 0.759\n",
      "INFO\t2019-09-09 14:41:41 -0400\tmaster-replica-0\t1\t110/136 [=======================>......] - ETA: 0s - loss: 3.8717 - acc: 0.759\n",
      "INFO\t2019-09-09 14:41:41 -0400\tmaster-replica-0\t1\t118/136 [=========================>....] - ETA: 0s - loss: 3.8761 - acc: 0.759\n",
      "INFO\t2019-09-09 14:41:41 -0400\tmaster-replica-0\t1\t124/136 [==========================>...] - ETA: 0s - loss: 3.8669 - acc: 0.760\n",
      "INFO\t2019-09-09 14:41:42 -0400\tmaster-replica-0\t1\t132/136 [============================>.] - ETA: 0s - loss: 3.8722 - acc: 0.759\n",
      "INFO\t2019-09-09 14:41:42 -0400\tmaster-replica-0\t1\t136/136 [==============================] - 2s 16ms/step - loss: 3.8778 - acc: 0.7594 - val_loss: 3.8072 - val_acc: 0.7638\n",
      "INFO\t2019-09-09 14:41:42 -0400\tmaster-replica-0\t1\tEpoch 00011: LearningRateScheduler reducing learning rate to 0.08413573772750213.\n",
      "INFO\t2019-09-09 14:41:42 -0400\tmaster-replica-0\t1\tEpoch 11/20\n",
      "INFO\t2019-09-09 14:41:42 -0400\tmaster-replica-0\t1\t  1/136 [..............................] - ETA: 0s - loss: 3.9789 - acc: 0.753\n",
      "INFO\t2019-09-09 14:41:42 -0400\tmaster-replica-0\t1\t  9/136 [>.............................] - ETA: 0s - loss: 3.8591 - acc: 0.760\n",
      "INFO\t2019-09-09 14:41:42 -0400\tmaster-replica-0\t1\t 15/136 [==>...........................] - ETA: 0s - loss: 3.8216 - acc: 0.762\n",
      "INFO\t2019-09-09 14:41:42 -0400\tmaster-replica-0\t1\t 22/136 [===>..........................] - ETA: 0s - loss: 3.8992 - acc: 0.758\n",
      "INFO\t2019-09-09 14:41:42 -0400\tmaster-replica-0\t1\t 30/136 [=====>........................] - ETA: 0s - loss: 3.9340 - acc: 0.755\n",
      "INFO\t2019-09-09 14:41:42 -0400\tmaster-replica-0\t1\t 37/136 [=======>......................] - ETA: 0s - loss: 3.9680 - acc: 0.753\n",
      "INFO\t2019-09-09 14:41:42 -0400\tmaster-replica-0\t1\t 45/136 [========>.....................] - ETA: 0s - loss: 3.9250 - acc: 0.756\n",
      "INFO\t2019-09-09 14:41:42 -0400\tmaster-replica-0\t1\t 52/136 [==========>...................] - ETA: 0s - loss: 3.8933 - acc: 0.758\n",
      "INFO\t2019-09-09 14:41:42 -0400\tmaster-replica-0\t1\t 59/136 [============>.................] - ETA: 0s - loss: 3.8829 - acc: 0.759\n",
      "INFO\t2019-09-09 14:41:42 -0400\tmaster-replica-0\t1\t 65/136 [=============>................] - ETA: 0s - loss: 3.8752 - acc: 0.759\n",
      "INFO\t2019-09-09 14:41:42 -0400\tmaster-replica-0\t1\t 73/136 [===============>..............] - ETA: 0s - loss: 3.8598 - acc: 0.760\n",
      "INFO\t2019-09-09 14:41:42 -0400\tmaster-replica-0\t1\t 80/136 [================>.............] - ETA: 0s - loss: 3.8727 - acc: 0.759\n",
      "INFO\t2019-09-09 14:41:43 -0400\tmaster-replica-0\t1\t 88/136 [==================>...........] - ETA: 0s - loss: 3.8717 - acc: 0.759\n",
      "INFO\t2019-09-09 14:41:43 -0400\tmaster-replica-0\t1\t 95/136 [===================>..........] - ETA: 0s - loss: 3.8675 - acc: 0.760\n",
      "INFO\t2019-09-09 14:41:43 -0400\tmaster-replica-0\t1\t102/136 [=====================>........] - ETA: 0s - loss: 3.8560 - acc: 0.760\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO\t2019-09-09 14:41:43 -0400\tmaster-replica-0\t1\t110/136 [=======================>......] - ETA: 0s - loss: 3.8815 - acc: 0.759\n",
      "INFO\t2019-09-09 14:41:43 -0400\tmaster-replica-0\t1\t116/136 [========================>.....] - ETA: 0s - loss: 3.8789 - acc: 0.759\n",
      "INFO\t2019-09-09 14:41:43 -0400\tmaster-replica-0\t1\t123/136 [==========================>...] - ETA: 0s - loss: 3.8660 - acc: 0.760\n",
      "INFO\t2019-09-09 14:41:44 -0400\tmaster-replica-0\t1\t130/136 [===========================>..] - ETA: 0s - loss: 3.8716 - acc: 0.759\n",
      "INFO\t2019-09-09 14:41:44 -0400\tmaster-replica-0\t1\t136/136 [==============================] - 2s 16ms/step - loss: 3.8753 - acc: 0.7596 - val_loss: 3.8072 - val_acc: 0.7638\n",
      "INFO\t2019-09-09 14:41:44 -0400\tmaster-replica-0\t1\tEpoch 00012: LearningRateScheduler reducing learning rate to 0.08413085491500212.\n",
      "INFO\t2019-09-09 14:41:44 -0400\tmaster-replica-0\t1\tEpoch 12/20\n",
      "INFO\t2019-09-09 14:41:44 -0400\tmaster-replica-0\t1\t  1/136 [..............................] - ETA: 5s - loss: 4.6533 - acc: 0.711\n",
      "INFO\t2019-09-09 14:41:44 -0400\tmaster-replica-0\t1\t  8/136 [>.............................] - ETA: 1s - loss: 3.7935 - acc: 0.764\n",
      "INFO\t2019-09-09 14:41:44 -0400\tmaster-replica-0\t1\t 14/136 [==>...........................] - ETA: 1s - loss: 3.7285 - acc: 0.768\n",
      "INFO\t2019-09-09 14:41:44 -0400\tmaster-replica-0\t1\t 21/136 [===>..........................] - ETA: 1s - loss: 3.8376 - acc: 0.761\n",
      "INFO\t2019-09-09 14:41:44 -0400\tmaster-replica-0\t1\t 27/136 [====>.........................] - ETA: 1s - loss: 3.8640 - acc: 0.760\n",
      "INFO\t2019-09-09 14:41:44 -0400\tmaster-replica-0\t1\t 33/136 [======>.......................] - ETA: 0s - loss: 3.8318 - acc: 0.762\n",
      "INFO\t2019-09-09 14:41:44 -0400\tmaster-replica-0\t1\t 38/136 [=======>......................] - ETA: 0s - loss: 3.8334 - acc: 0.762\n",
      "INFO\t2019-09-09 14:41:44 -0400\tmaster-replica-0\t1\t 44/136 [========>.....................] - ETA: 0s - loss: 3.8272 - acc: 0.762\n",
      "INFO\t2019-09-09 14:41:44 -0400\tmaster-replica-0\t1\t 50/136 [==========>...................] - ETA: 0s - loss: 3.8562 - acc: 0.760\n",
      "INFO\t2019-09-09 14:41:44 -0400\tmaster-replica-0\t1\t 58/136 [===========>..................] - ETA: 0s - loss: 3.8557 - acc: 0.760\n",
      "INFO\t2019-09-09 14:41:45 -0400\tmaster-replica-0\t1\t 64/136 [=============>................] - ETA: 0s - loss: 3.8841 - acc: 0.759\n",
      "INFO\t2019-09-09 14:41:45 -0400\tmaster-replica-0\t1\t 72/136 [==============>...............] - ETA: 0s - loss: 3.8619 - acc: 0.760\n",
      "INFO\t2019-09-09 14:41:45 -0400\tmaster-replica-0\t1\t 79/136 [================>.............] - ETA: 0s - loss: 3.8628 - acc: 0.760\n",
      "INFO\t2019-09-09 14:41:45 -0400\tmaster-replica-0\t1\t 86/136 [=================>............] - ETA: 0s - loss: 3.8574 - acc: 0.760\n",
      "INFO\t2019-09-09 14:41:45 -0400\tmaster-replica-0\t1\t 94/136 [===================>..........] - ETA: 0s - loss: 3.8685 - acc: 0.760\n",
      "INFO\t2019-09-09 14:41:45 -0400\tmaster-replica-0\t1\t100/136 [=====================>........] - ETA: 0s - loss: 3.8603 - acc: 0.760\n",
      "INFO\t2019-09-09 14:41:45 -0400\tmaster-replica-0\t1\t108/136 [======================>.......] - ETA: 0s - loss: 3.8703 - acc: 0.759\n",
      "INFO\t2019-09-09 14:41:45 -0400\tmaster-replica-0\t1\t115/136 [========================>.....] - ETA: 0s - loss: 3.8646 - acc: 0.760\n",
      "INFO\t2019-09-09 14:41:45 -0400\tmaster-replica-0\t1\t123/136 [==========================>...] - ETA: 0s - loss: 3.8770 - acc: 0.759\n",
      "INFO\t2019-09-09 14:41:46 -0400\tmaster-replica-0\t1\t129/136 [===========================>..] - ETA: 0s - loss: 3.8812 - acc: 0.759\n",
      "INFO\t2019-09-09 14:41:46 -0400\tmaster-replica-0\t1\t136/136 [==============================] - 2s 15ms/step - loss: 3.8932 - acc: 0.7585 - val_loss: 3.8072 - val_acc: 0.7638\n",
      "INFO\t2019-09-09 14:41:46 -0400\tmaster-replica-0\t1\tEpoch 00013: LearningRateScheduler reducing learning rate to 0.08412841350875212.\n",
      "INFO\t2019-09-09 14:41:46 -0400\tmaster-replica-0\t1\tEpoch 13/20\n",
      "INFO\t2019-09-09 14:41:46 -0400\tmaster-replica-0\t1\t  1/136 [..............................] - ETA: 0s - loss: 3.3720 - acc: 0.790\n",
      "INFO\t2019-09-09 14:41:46 -0400\tmaster-replica-0\t1\t  7/136 [>.............................] - ETA: 1s - loss: 3.7766 - acc: 0.765\n",
      "INFO\t2019-09-09 14:41:46 -0400\tmaster-replica-0\t1\t 15/136 [==>...........................] - ETA: 0s - loss: 3.8800 - acc: 0.759\n",
      "INFO\t2019-09-09 14:41:46 -0400\tmaster-replica-0\t1\t 21/136 [===>..........................] - ETA: 0s - loss: 3.9147 - acc: 0.757\n",
      "INFO\t2019-09-09 14:41:46 -0400\tmaster-replica-0\t1\t 28/136 [=====>........................] - ETA: 0s - loss: 3.9260 - acc: 0.756\n",
      "INFO\t2019-09-09 14:41:46 -0400\tmaster-replica-0\t1\t 34/136 [======>.......................] - ETA: 0s - loss: 3.8996 - acc: 0.758\n",
      "INFO\t2019-09-09 14:41:46 -0400\tmaster-replica-0\t1\t 42/136 [========>.....................] - ETA: 0s - loss: 3.9227 - acc: 0.756\n",
      "INFO\t2019-09-09 14:41:46 -0400\tmaster-replica-0\t1\t 48/136 [=========>....................] - ETA: 0s - loss: 3.9508 - acc: 0.754\n",
      "INFO\t2019-09-09 14:41:46 -0400\tmaster-replica-0\t1\t 56/136 [===========>..................] - ETA: 0s - loss: 3.9681 - acc: 0.753\n",
      "INFO\t2019-09-09 14:41:47 -0400\tmaster-replica-0\t1\t 63/136 [============>.................] - ETA: 0s - loss: 3.9383 - acc: 0.755\n",
      "INFO\t2019-09-09 14:41:47 -0400\tmaster-replica-0\t1\t 71/136 [==============>...............] - ETA: 0s - loss: 3.9372 - acc: 0.755\n",
      "INFO\t2019-09-09 14:41:47 -0400\tmaster-replica-0\t1\t 78/136 [================>.............] - ETA: 0s - loss: 3.9331 - acc: 0.756\n",
      "INFO\t2019-09-09 14:41:47 -0400\tmaster-replica-0\t1\t 86/136 [=================>............] - ETA: 0s - loss: 3.9484 - acc: 0.755\n",
      "INFO\t2019-09-09 14:41:47 -0400\tmaster-replica-0\t1\t 93/136 [===================>..........] - ETA: 0s - loss: 3.9485 - acc: 0.755\n",
      "INFO\t2019-09-09 14:41:47 -0400\tmaster-replica-0\t1\t100/136 [=====================>........] - ETA: 0s - loss: 3.9425 - acc: 0.755\n",
      "INFO\t2019-09-09 14:41:47 -0400\tmaster-replica-0\t1\t108/136 [======================>.......] - ETA: 0s - loss: 3.9346 - acc: 0.755\n",
      "INFO\t2019-09-09 14:41:47 -0400\tmaster-replica-0\t1\t115/136 [========================>.....] - ETA: 0s - loss: 3.9185 - acc: 0.756\n",
      "INFO\t2019-09-09 14:41:47 -0400\tmaster-replica-0\t1\t123/136 [==========================>...] - ETA: 0s - loss: 3.9066 - acc: 0.757\n",
      "INFO\t2019-09-09 14:41:48 -0400\tmaster-replica-0\t1\t129/136 [===========================>..] - ETA: 0s - loss: 3.9005 - acc: 0.758\n",
      "INFO\t2019-09-09 14:41:48 -0400\tmaster-replica-0\t1\t136/136 [==============================] - 2s 16ms/step - loss: 3.8842 - acc: 0.7590 - val_loss: 3.8072 - val_acc: 0.7638\n",
      "INFO\t2019-09-09 14:41:48 -0400\tmaster-replica-0\t1\tEpoch 00014: LearningRateScheduler reducing learning rate to 0.08412719280562712.\n",
      "INFO\t2019-09-09 14:41:48 -0400\tmaster-replica-0\t1\tEpoch 14/20\n",
      "INFO\t2019-09-09 14:41:48 -0400\tmaster-replica-0\t1\t  1/136 [..............................] - ETA: 13s - loss: 3.7766 - acc: 0.76\n",
      "INFO\t2019-09-09 14:41:48 -0400\tmaster-replica-0\t1\t  9/136 [>.............................] - ETA: 2s - loss: 3.7242 - acc: 0.7689\n",
      "INFO\t2019-09-09 14:41:48 -0400\tmaster-replica-0\t1\t 15/136 [==>...........................] - ETA: 1s - loss: 3.8486 - acc: 0.761\n",
      "INFO\t2019-09-09 14:41:48 -0400\tmaster-replica-0\t1\t 23/136 [====>.........................] - ETA: 1s - loss: 3.7854 - acc: 0.765\n",
      "INFO\t2019-09-09 14:41:49 -0400\tmaster-replica-0\t1\t 30/136 [=====>........................] - ETA: 1s - loss: 3.8171 - acc: 0.763\n",
      "INFO\t2019-09-09 14:41:49 -0400\tmaster-replica-0\t1\t 38/136 [=======>......................] - ETA: 0s - loss: 3.8405 - acc: 0.761\n",
      "INFO\t2019-09-09 14:41:49 -0400\tmaster-replica-0\t1\t 45/136 [========>.....................] - ETA: 0s - loss: 3.8201 - acc: 0.763\n",
      "INFO\t2019-09-09 14:41:49 -0400\tmaster-replica-0\t1\t 53/136 [==========>...................] - ETA: 0s - loss: 3.8492 - acc: 0.761\n",
      "INFO\t2019-09-09 14:41:49 -0400\tmaster-replica-0\t1\t 59/136 [============>.................] - ETA: 0s - loss: 3.8726 - acc: 0.759\n",
      "INFO\t2019-09-09 14:41:49 -0400\tmaster-replica-0\t1\t 67/136 [=============>................] - ETA: 0s - loss: 3.8743 - acc: 0.759\n",
      "INFO\t2019-09-09 14:41:49 -0400\tmaster-replica-0\t1\t 73/136 [===============>..............] - ETA: 0s - loss: 3.8533 - acc: 0.760\n",
      "INFO\t2019-09-09 14:41:49 -0400\tmaster-replica-0\t1\t 80/136 [================>.............] - ETA: 0s - loss: 3.8398 - acc: 0.761\n",
      "INFO\t2019-09-09 14:41:49 -0400\tmaster-replica-0\t1\t 86/136 [=================>............] - ETA: 0s - loss: 3.8464 - acc: 0.761\n",
      "INFO\t2019-09-09 14:41:49 -0400\tmaster-replica-0\t1\t 94/136 [===================>..........] - ETA: 0s - loss: 3.8541 - acc: 0.760\n",
      "INFO\t2019-09-09 14:41:49 -0400\tmaster-replica-0\t1\t101/136 [=====================>........] - ETA: 0s - loss: 3.8654 - acc: 0.760\n",
      "INFO\t2019-09-09 14:41:49 -0400\tmaster-replica-0\t1\t109/136 [=======================>......] - ETA: 0s - loss: 3.8663 - acc: 0.760\n",
      "INFO\t2019-09-09 14:41:49 -0400\tmaster-replica-0\t1\t117/136 [========================>.....] - ETA: 0s - loss: 3.8608 - acc: 0.760\n",
      "INFO\t2019-09-09 14:41:49 -0400\tmaster-replica-0\t1\t123/136 [==========================>...] - ETA: 0s - loss: 3.8583 - acc: 0.760\n",
      "INFO\t2019-09-09 14:41:50 -0400\tmaster-replica-0\t1\t130/136 [===========================>..] - ETA: 0s - loss: 3.8560 - acc: 0.760\n",
      "INFO\t2019-09-09 14:41:50 -0400\tmaster-replica-0\t1\t136/136 [==============================] - 2s 16ms/step - loss: 3.8733 - acc: 0.7597 - val_loss: 3.8072 - val_acc: 0.7638\n",
      "INFO\t2019-09-09 14:41:50 -0400\tmaster-replica-0\t1\tEpoch 00015: LearningRateScheduler reducing learning rate to 0.08412658245406462.\n",
      "INFO\t2019-09-09 14:41:50 -0400\tmaster-replica-0\t1\tEpoch 15/20\n",
      "INFO\t2019-09-09 14:41:50 -0400\tmaster-replica-0\t1\t  1/136 [..............................] - ETA: 1s - loss: 3.4394 - acc: 0.786\n",
      "INFO\t2019-09-09 14:41:50 -0400\tmaster-replica-0\t1\t  9/136 [>.............................] - ETA: 0s - loss: 3.9490 - acc: 0.755\n",
      "INFO\t2019-09-09 14:41:51 -0400\tmaster-replica-0\t1\t 16/136 [==>...........................] - ETA: 0s - loss: 3.9832 - acc: 0.752\n",
      "INFO\t2019-09-09 14:41:51 -0400\tmaster-replica-0\t1\t 24/136 [====>.........................] - ETA: 0s - loss: 3.9565 - acc: 0.754\n",
      "INFO\t2019-09-09 14:41:51 -0400\tmaster-replica-0\t1\t 30/136 [=====>........................] - ETA: 0s - loss: 3.9182 - acc: 0.756\n",
      "INFO\t2019-09-09 14:41:51 -0400\tmaster-replica-0\t1\t 38/136 [=======>......................] - ETA: 0s - loss: 3.8867 - acc: 0.758\n",
      "INFO\t2019-09-09 14:41:51 -0400\tmaster-replica-0\t1\t 44/136 [========>.....................] - ETA: 0s - loss: 3.8625 - acc: 0.760\n",
      "INFO\t2019-09-09 14:41:51 -0400\tmaster-replica-0\t1\t 51/136 [==========>...................] - ETA: 0s - loss: 3.8784 - acc: 0.759\n",
      "INFO\t2019-09-09 14:41:51 -0400\tmaster-replica-0\t1\t 57/136 [===========>..................] - ETA: 0s - loss: 3.8606 - acc: 0.760\n",
      "INFO\t2019-09-09 14:41:51 -0400\tmaster-replica-0\t1\t 65/136 [=============>................] - ETA: 0s - loss: 3.8627 - acc: 0.760\n",
      "INFO\t2019-09-09 14:41:51 -0400\tmaster-replica-0\t1\t 71/136 [==============>...............] - ETA: 0s - loss: 3.8773 - acc: 0.759\n",
      "INFO\t2019-09-09 14:41:51 -0400\tmaster-replica-0\t1\t 79/136 [================>.............] - ETA: 0s - loss: 3.8791 - acc: 0.759\n",
      "INFO\t2019-09-09 14:41:51 -0400\tmaster-replica-0\t1\t 87/136 [==================>...........] - ETA: 0s - loss: 3.8681 - acc: 0.760\n",
      "INFO\t2019-09-09 14:41:51 -0400\tmaster-replica-0\t1\t 94/136 [===================>..........] - ETA: 0s - loss: 3.8771 - acc: 0.759\n",
      "INFO\t2019-09-09 14:41:51 -0400\tmaster-replica-0\t1\t102/136 [=====================>........] - ETA: 0s - loss: 3.8864 - acc: 0.758\n",
      "INFO\t2019-09-09 14:41:51 -0400\tmaster-replica-0\t1\t108/136 [======================>.......] - ETA: 0s - loss: 3.8934 - acc: 0.758\n",
      "INFO\t2019-09-09 14:41:51 -0400\tmaster-replica-0\t1\t116/136 [========================>.....] - ETA: 0s - loss: 3.8929 - acc: 0.758\n",
      "INFO\t2019-09-09 14:41:51 -0400\tmaster-replica-0\t1\t122/136 [=========================>....] - ETA: 0s - loss: 3.8977 - acc: 0.758\n",
      "INFO\t2019-09-09 14:41:52 -0400\tmaster-replica-0\t1\t130/136 [===========================>..] - ETA: 0s - loss: 3.8985 - acc: 0.758\n",
      "INFO\t2019-09-09 14:41:52 -0400\tmaster-replica-0\t1\t136/136 [==============================] - 2s 16ms/step - loss: 3.8832 - acc: 0.7591 - val_loss: 3.8072 - val_acc: 0.7638\n",
      "INFO\t2019-09-09 14:41:53 -0400\tmaster-replica-0\t1\tEpoch 00016: LearningRateScheduler reducing learning rate to 0.08412627727828338.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO\t2019-09-09 14:41:53 -0400\tmaster-replica-0\t1\tEpoch 16/20\n",
      "INFO\t2019-09-09 14:41:53 -0400\tmaster-replica-0\t1\t  1/136 [..............................] - ETA: 10s - loss: 4.2487 - acc: 0.73\n",
      "INFO\t2019-09-09 14:41:53 -0400\tmaster-replica-0\t1\t  7/136 [>.............................] - ETA: 2s - loss: 3.6899 - acc: 0.7711\n",
      "INFO\t2019-09-09 14:41:53 -0400\tmaster-replica-0\t1\t 14/136 [==>...........................] - ETA: 1s - loss: 3.7236 - acc: 0.769\n",
      "INFO\t2019-09-09 14:41:53 -0400\tmaster-replica-0\t1\t 22/136 [===>..........................] - ETA: 1s - loss: 3.8103 - acc: 0.763\n",
      "INFO\t2019-09-09 14:41:53 -0400\tmaster-replica-0\t1\t 28/136 [=====>........................] - ETA: 1s - loss: 3.8465 - acc: 0.761\n",
      "INFO\t2019-09-09 14:41:53 -0400\tmaster-replica-0\t1\t 35/136 [======>.......................] - ETA: 1s - loss: 3.8614 - acc: 0.760\n",
      "INFO\t2019-09-09 14:41:53 -0400\tmaster-replica-0\t1\t 42/136 [========>.....................] - ETA: 0s - loss: 3.8954 - acc: 0.758\n",
      "INFO\t2019-09-09 14:41:53 -0400\tmaster-replica-0\t1\t 49/136 [=========>....................] - ETA: 0s - loss: 3.8881 - acc: 0.758\n",
      "INFO\t2019-09-09 14:41:53 -0400\tmaster-replica-0\t1\t 55/136 [===========>..................] - ETA: 0s - loss: 3.8882 - acc: 0.758\n",
      "INFO\t2019-09-09 14:41:53 -0400\tmaster-replica-0\t1\t 63/136 [============>.................] - ETA: 0s - loss: 3.8826 - acc: 0.759\n",
      "INFO\t2019-09-09 14:41:53 -0400\tmaster-replica-0\t1\t 70/136 [==============>...............] - ETA: 0s - loss: 3.8884 - acc: 0.758\n",
      "INFO\t2019-09-09 14:41:53 -0400\tmaster-replica-0\t1\t 76/136 [===============>..............] - ETA: 0s - loss: 3.8778 - acc: 0.759\n",
      "INFO\t2019-09-09 14:41:53 -0400\tmaster-replica-0\t1\t 83/136 [=================>............] - ETA: 0s - loss: 3.8806 - acc: 0.759\n",
      "INFO\t2019-09-09 14:41:53 -0400\tmaster-replica-0\t1\t 89/136 [==================>...........] - ETA: 0s - loss: 3.8668 - acc: 0.760\n",
      "INFO\t2019-09-09 14:41:53 -0400\tmaster-replica-0\t1\t 95/136 [===================>..........] - ETA: 0s - loss: 3.8639 - acc: 0.760\n",
      "INFO\t2019-09-09 14:41:53 -0400\tmaster-replica-0\t1\t101/136 [=====================>........] - ETA: 0s - loss: 3.8781 - acc: 0.759\n",
      "INFO\t2019-09-09 14:41:53 -0400\tmaster-replica-0\t1\t109/136 [=======================>......] - ETA: 0s - loss: 3.8694 - acc: 0.759\n",
      "INFO\t2019-09-09 14:41:54 -0400\tmaster-replica-0\t1\t116/136 [========================>.....] - ETA: 0s - loss: 3.8586 - acc: 0.760\n",
      "INFO\t2019-09-09 14:41:54 -0400\tmaster-replica-0\t1\t124/136 [==========================>...] - ETA: 0s - loss: 3.8691 - acc: 0.760\n",
      "INFO\t2019-09-09 14:41:55 -0400\tmaster-replica-0\t1\t131/136 [===========================>..] - ETA: 0s - loss: 3.8724 - acc: 0.759\n",
      "INFO\t2019-09-09 14:41:55 -0400\tmaster-replica-0\t1\t136/136 [==============================] - 2s 17ms/step - loss: 3.8768 - acc: 0.7595 - val_loss: 3.8072 - val_acc: 0.7638\n",
      "INFO\t2019-09-09 14:41:55 -0400\tmaster-replica-0\t1\tEpoch 00017: LearningRateScheduler reducing learning rate to 0.08412612469039275.\n",
      "INFO\t2019-09-09 14:41:55 -0400\tmaster-replica-0\t1\tEpoch 17/20\n",
      "INFO\t2019-09-09 14:41:55 -0400\tmaster-replica-0\t1\t  1/136 [..............................] - ETA: 0s - loss: 4.1813 - acc: 0.740\n",
      "INFO\t2019-09-09 14:41:55 -0400\tmaster-replica-0\t1\t  8/136 [>.............................] - ETA: 0s - loss: 4.0380 - acc: 0.749\n",
      "INFO\t2019-09-09 14:41:55 -0400\tmaster-replica-0\t1\t 15/136 [==>...........................] - ETA: 0s - loss: 4.0149 - acc: 0.750\n",
      "INFO\t2019-09-09 14:41:55 -0400\tmaster-replica-0\t1\t 23/136 [====>.........................] - ETA: 0s - loss: 3.9819 - acc: 0.753\n",
      "INFO\t2019-09-09 14:41:55 -0400\tmaster-replica-0\t1\t 30/136 [=====>........................] - ETA: 0s - loss: 3.9744 - acc: 0.753\n",
      "INFO\t2019-09-09 14:41:55 -0400\tmaster-replica-0\t1\t 38/136 [=======>......................] - ETA: 0s - loss: 3.9825 - acc: 0.752\n",
      "INFO\t2019-09-09 14:41:55 -0400\tmaster-replica-0\t1\t 45/136 [========>.....................] - ETA: 0s - loss: 3.9535 - acc: 0.754\n",
      "INFO\t2019-09-09 14:41:55 -0400\tmaster-replica-0\t1\t 53/136 [==========>...................] - ETA: 0s - loss: 3.9433 - acc: 0.755\n",
      "INFO\t2019-09-09 14:41:55 -0400\tmaster-replica-0\t1\t 60/136 [============>.................] - ETA: 0s - loss: 3.9475 - acc: 0.755\n",
      "INFO\t2019-09-09 14:41:55 -0400\tmaster-replica-0\t1\t 68/136 [==============>...............] - ETA: 0s - loss: 3.9442 - acc: 0.755\n",
      "INFO\t2019-09-09 14:41:55 -0400\tmaster-replica-0\t1\t 75/136 [===============>..............] - ETA: 0s - loss: 3.9412 - acc: 0.755\n",
      "INFO\t2019-09-09 14:41:55 -0400\tmaster-replica-0\t1\t 83/136 [=================>............] - ETA: 0s - loss: 3.9489 - acc: 0.755\n",
      "INFO\t2019-09-09 14:41:55 -0400\tmaster-replica-0\t1\t 90/136 [==================>...........] - ETA: 0s - loss: 3.9392 - acc: 0.755\n",
      "INFO\t2019-09-09 14:41:55 -0400\tmaster-replica-0\t1\t 98/136 [====================>.........] - ETA: 0s - loss: 3.9321 - acc: 0.756\n",
      "INFO\t2019-09-09 14:41:56 -0400\tmaster-replica-0\t1\t105/136 [======================>.......] - ETA: 0s - loss: 3.9218 - acc: 0.756\n",
      "INFO\t2019-09-09 14:41:56 -0400\tmaster-replica-0\t1\t113/136 [=======================>......] - ETA: 0s - loss: 3.9008 - acc: 0.758\n",
      "INFO\t2019-09-09 14:41:56 -0400\tmaster-replica-0\t1\t119/136 [=========================>....] - ETA: 0s - loss: 3.8934 - acc: 0.758\n",
      "INFO\t2019-09-09 14:41:56 -0400\tmaster-replica-0\t1\t127/136 [===========================>..] - ETA: 0s - loss: 3.9030 - acc: 0.757\n",
      "INFO\t2019-09-09 14:41:57 -0400\tmaster-replica-0\t1\t134/136 [============================>.] - ETA: 0s - loss: 3.8934 - acc: 0.758\n",
      "INFO\t2019-09-09 14:41:57 -0400\tmaster-replica-0\t1\t136/136 [==============================] - 2s 17ms/step - loss: 3.8857 - acc: 0.7589 - val_loss: 3.8072 - val_acc: 0.7638\n",
      "INFO\t2019-09-09 14:41:57 -0400\tmaster-replica-0\t1\tEpoch 00018: LearningRateScheduler reducing learning rate to 0.08412604839644744.\n",
      "INFO\t2019-09-09 14:41:57 -0400\tmaster-replica-0\t1\tEpoch 18/20\n",
      "INFO\t2019-09-09 14:41:57 -0400\tmaster-replica-0\t1\t  1/136 [..............................] - ETA: 4s - loss: 4.0464 - acc: 0.749\n",
      "INFO\t2019-09-09 14:41:57 -0400\tmaster-replica-0\t1\t  8/136 [>.............................] - ETA: 1s - loss: 3.8272 - acc: 0.762\n",
      "INFO\t2019-09-09 14:41:57 -0400\tmaster-replica-0\t1\t 15/136 [==>...........................] - ETA: 1s - loss: 3.8620 - acc: 0.760\n",
      "INFO\t2019-09-09 14:41:57 -0400\tmaster-replica-0\t1\t 22/136 [===>..........................] - ETA: 1s - loss: 3.8778 - acc: 0.759\n",
      "INFO\t2019-09-09 14:41:57 -0400\tmaster-replica-0\t1\t 29/136 [=====>........................] - ETA: 0s - loss: 3.8162 - acc: 0.763\n",
      "INFO\t2019-09-09 14:41:57 -0400\tmaster-replica-0\t1\t 37/136 [=======>......................] - ETA: 0s - loss: 3.8659 - acc: 0.760\n",
      "INFO\t2019-09-09 14:41:57 -0400\tmaster-replica-0\t1\t 43/136 [========>.....................] - ETA: 0s - loss: 3.8409 - acc: 0.761\n",
      "INFO\t2019-09-09 14:41:57 -0400\tmaster-replica-0\t1\t 51/136 [==========>...................] - ETA: 0s - loss: 3.8652 - acc: 0.760\n",
      "INFO\t2019-09-09 14:41:58 -0400\tmaster-replica-0\t1\t 58/136 [===========>..................] - ETA: 0s - loss: 3.8836 - acc: 0.759\n",
      "INFO\t2019-09-09 14:41:58 -0400\tmaster-replica-0\t1\t 66/136 [=============>................] - ETA: 0s - loss: 3.8870 - acc: 0.758\n",
      "INFO\t2019-09-09 14:41:58 -0400\tmaster-replica-0\t1\t 73/136 [===============>..............] - ETA: 0s - loss: 3.8690 - acc: 0.760\n",
      "INFO\t2019-09-09 14:41:58 -0400\tmaster-replica-0\t1\t 82/136 [=================>............] - ETA: 0s - loss: 3.8679 - acc: 0.760\n",
      "INFO\t2019-09-09 14:41:58 -0400\tmaster-replica-0\t1\t 90/136 [==================>...........] - ETA: 0s - loss: 3.8725 - acc: 0.759\n",
      "INFO\t2019-09-09 14:41:58 -0400\tmaster-replica-0\t1\t 97/136 [====================>.........] - ETA: 0s - loss: 3.8642 - acc: 0.760\n",
      "INFO\t2019-09-09 14:41:58 -0400\tmaster-replica-0\t1\t105/136 [======================>.......] - ETA: 0s - loss: 3.8800 - acc: 0.759\n",
      "INFO\t2019-09-09 14:41:58 -0400\tmaster-replica-0\t1\t112/136 [=======================>......] - ETA: 0s - loss: 3.8868 - acc: 0.758\n",
      "INFO\t2019-09-09 14:41:58 -0400\tmaster-replica-0\t1\t120/136 [=========================>....] - ETA: 0s - loss: 3.8817 - acc: 0.759\n",
      "INFO\t2019-09-09 14:41:59 -0400\tmaster-replica-0\t1\t127/136 [===========================>..] - ETA: 0s - loss: 3.8828 - acc: 0.759\n",
      "INFO\t2019-09-09 14:41:59 -0400\tmaster-replica-0\t1\t136/136 [==============================] - 2s 15ms/step - loss: 3.8822 - acc: 0.7591 - val_loss: 3.8072 - val_acc: 0.7638\n",
      "INFO\t2019-09-09 14:41:59 -0400\tmaster-replica-0\t1\tEpoch 00019: LearningRateScheduler reducing learning rate to 0.08412601024947478.\n",
      "INFO\t2019-09-09 14:41:59 -0400\tmaster-replica-0\t1\tEpoch 19/20\n",
      "INFO\t2019-09-09 14:41:59 -0400\tmaster-replica-0\t1\t  1/136 [..............................] - ETA: 0s - loss: 4.1138 - acc: 0.744\n",
      "INFO\t2019-09-09 14:41:59 -0400\tmaster-replica-0\t1\t 10/136 [=>............................] - ETA: 0s - loss: 3.9317 - acc: 0.756\n",
      "INFO\t2019-09-09 14:41:59 -0400\tmaster-replica-0\t1\t 17/136 [==>...........................] - ETA: 0s - loss: 3.9551 - acc: 0.754\n",
      "INFO\t2019-09-09 14:41:59 -0400\tmaster-replica-0\t1\t 23/136 [====>.........................] - ETA: 0s - loss: 3.9438 - acc: 0.755\n",
      "INFO\t2019-09-09 14:41:59 -0400\tmaster-replica-0\t1\t 31/136 [=====>........................] - ETA: 0s - loss: 3.8985 - acc: 0.758\n",
      "INFO\t2019-09-09 14:41:59 -0400\tmaster-replica-0\t1\t 38/136 [=======>......................] - ETA: 0s - loss: 3.8671 - acc: 0.760\n",
      "INFO\t2019-09-09 14:41:59 -0400\tmaster-replica-0\t1\t 47/136 [=========>....................] - ETA: 0s - loss: 3.8541 - acc: 0.760\n",
      "INFO\t2019-09-09 14:42:00 -0400\tmaster-replica-0\t1\t 54/136 [==========>...................] - ETA: 0s - loss: 3.8191 - acc: 0.763\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO\t2019-09-09 14:42:00 -0400\tmaster-replica-0\t1\t 62/136 [============>.................] - ETA: 0s - loss: 3.8723 - acc: 0.759\n",
      "INFO\t2019-09-09 14:42:00 -0400\tmaster-replica-0\t1\t 69/136 [==============>...............] - ETA: 0s - loss: 3.8558 - acc: 0.760\n",
      "INFO\t2019-09-09 14:42:00 -0400\tmaster-replica-0\t1\t 77/136 [===============>..............] - ETA: 0s - loss: 3.8607 - acc: 0.760\n",
      "INFO\t2019-09-09 14:42:00 -0400\tmaster-replica-0\t1\t 85/136 [=================>............] - ETA: 0s - loss: 3.8766 - acc: 0.759\n",
      "INFO\t2019-09-09 14:42:00 -0400\tmaster-replica-0\t1\t 92/136 [===================>..........] - ETA: 0s - loss: 3.8697 - acc: 0.759\n",
      "INFO\t2019-09-09 14:42:00 -0400\tmaster-replica-0\t1\t101/136 [=====================>........] - ETA: 0s - loss: 3.8855 - acc: 0.758\n",
      "INFO\t2019-09-09 14:42:00 -0400\tmaster-replica-0\t1\t108/136 [======================>.......] - ETA: 0s - loss: 3.8847 - acc: 0.759\n",
      "INFO\t2019-09-09 14:42:00 -0400\tmaster-replica-0\t1\t117/136 [========================>.....] - ETA: 0s - loss: 3.8792 - acc: 0.759\n",
      "INFO\t2019-09-09 14:42:00 -0400\tmaster-replica-0\t1\t123/136 [==========================>...] - ETA: 0s - loss: 3.8978 - acc: 0.758\n",
      "INFO\t2019-09-09 14:42:01 -0400\tmaster-replica-0\t1\t132/136 [============================>.] - ETA: 0s - loss: 3.8900 - acc: 0.758\n",
      "INFO\t2019-09-09 14:42:01 -0400\tmaster-replica-0\t1\t136/136 [==============================] - 2s 15ms/step - loss: 3.8847 - acc: 0.7590 - val_loss: 3.8072 - val_acc: 0.7638\n",
      "INFO\t2019-09-09 14:42:01 -0400\tmaster-replica-0\t1\tEpoch 00020: LearningRateScheduler reducing learning rate to 0.08412599117598846.\n",
      "INFO\t2019-09-09 14:42:01 -0400\tmaster-replica-0\t1\tEpoch 20/20\n",
      "INFO\t2019-09-09 14:42:01 -0400\tmaster-replica-0\t1\t  1/136 [..............................] - ETA: 10s - loss: 3.6417 - acc: 0.77\n",
      "INFO\t2019-09-09 14:42:01 -0400\tmaster-replica-0\t1\t  8/136 [>.............................] - ETA: 2s - loss: 3.7935 - acc: 0.7646\n",
      "INFO\t2019-09-09 14:42:01 -0400\tmaster-replica-0\t1\t 15/136 [==>...........................] - ETA: 1s - loss: 3.9430 - acc: 0.755\n",
      "INFO\t2019-09-09 14:42:01 -0400\tmaster-replica-0\t1\t 24/136 [====>.........................] - ETA: 1s - loss: 3.8975 - acc: 0.758\n",
      "INFO\t2019-09-09 14:42:01 -0400\tmaster-replica-0\t1\t 31/136 [=====>........................] - ETA: 0s - loss: 3.9115 - acc: 0.757\n",
      "INFO\t2019-09-09 14:42:01 -0400\tmaster-replica-0\t1\t 40/136 [=======>......................] - ETA: 0s - loss: 3.8643 - acc: 0.760\n",
      "INFO\t2019-09-09 14:42:02 -0400\tmaster-replica-0\t1\t 47/136 [=========>....................] - ETA: 0s - loss: 3.8369 - acc: 0.762\n",
      "INFO\t2019-09-09 14:42:02 -0400\tmaster-replica-0\t1\t 56/136 [===========>..................] - ETA: 0s - loss: 3.8585 - acc: 0.760\n",
      "INFO\t2019-09-09 14:42:02 -0400\tmaster-replica-0\t1\t 64/136 [=============>................] - ETA: 0s - loss: 3.8525 - acc: 0.761\n",
      "INFO\t2019-09-09 14:42:02 -0400\tmaster-replica-0\t1\t 73/136 [===============>..............] - ETA: 0s - loss: 3.8976 - acc: 0.758\n",
      "INFO\t2019-09-09 14:42:02 -0400\tmaster-replica-0\t1\t 80/136 [================>.............] - ETA: 0s - loss: 3.8778 - acc: 0.759\n",
      "INFO\t2019-09-09 14:42:02 -0400\tmaster-replica-0\t1\t 89/136 [==================>...........] - ETA: 0s - loss: 3.8873 - acc: 0.758\n",
      "INFO\t2019-09-09 14:42:02 -0400\tmaster-replica-0\t1\t 97/136 [====================>.........] - ETA: 0s - loss: 3.8670 - acc: 0.760\n",
      "INFO\t2019-09-09 14:42:02 -0400\tmaster-replica-0\t1\t106/136 [======================>.......] - ETA: 0s - loss: 3.8632 - acc: 0.760\n",
      "INFO\t2019-09-09 14:42:02 -0400\tmaster-replica-0\t1\t113/136 [=======================>......] - ETA: 0s - loss: 3.8715 - acc: 0.759\n",
      "INFO\t2019-09-09 14:42:02 -0400\tmaster-replica-0\t1\t122/136 [=========================>....] - ETA: 0s - loss: 3.8817 - acc: 0.759\n",
      "INFO\t2019-09-09 14:42:03 -0400\tmaster-replica-0\t1\t129/136 [===========================>..] - ETA: 0s - loss: 3.8828 - acc: 0.759\n",
      "INFO\t2019-09-09 14:42:03 -0400\tmaster-replica-0\t1\t136/136 [==============================] - 2s 16ms/step - loss: 3.8798 - acc: 0.7593 - val_loss: 3.8072 - val_acc: 0.7638\n",
      "WARNING\t2019-09-09 14:42:14 -0400\tmaster-replica-0\t1\tThis model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.RMSprop object at 0x7f9ba0ed2470>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "WARNING\t2019-09-09 14:42:14 -0400\tmaster-replica-0\t1\t\n",
      "WARNING\t2019-09-09 14:42:14 -0400\tmaster-replica-0\t1\tConsider using a TensorFlow optimizer from `tf.train`.\n",
      "WARNING\t2019-09-09 14:42:18 -0400\tmaster-replica-0\t1\tFrom /usr/local/lib/python3.5/dist-packages/tensorflow/python/keras/engine/network.py:1436: update_checkpoint_state (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "WARNING\t2019-09-09 14:42:18 -0400\tmaster-replica-0\t1\tInstructions for updating:\n",
      "WARNING\t2019-09-09 14:42:18 -0400\tmaster-replica-0\t1\tUse tf.train.CheckpointManager to manage checkpoints rather than manually editing the Checkpoint proto.\n",
      "WARNING\t2019-09-09 14:42:20 -0400\tmaster-replica-0\t1\tModel was compiled with an optimizer, but the optimizer is not from `tf.train` (e.g. `tf.train.AdagradOptimizer`). Only the serving graph was exported. The train and evaluate graphs were not added to the SavedModel.\n",
      "WARNING\t2019-09-09 14:42:33 -0400\tmaster-replica-0\t1\tFrom /usr/local/lib/python3.5/dist-packages/tensorflow/python/saved_model/signature_def_utils_impl.py:205: build_tensor_info (from tensorflow.python.saved_model.utils_impl) is deprecated and will be removed in a future version.\n",
      "WARNING\t2019-09-09 14:42:33 -0400\tmaster-replica-0\t1\tInstructions for updating:\n",
      "WARNING\t2019-09-09 14:42:33 -0400\tmaster-replica-0\t1\tThis function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.utils.build_tensor_info or tf.compat.v1.saved_model.build_tensor_info.\n",
      "INFO\t2019-09-09 14:42:33 -0400\tmaster-replica-0\t1\tSignatures INCLUDED in export for Train: None\n",
      "INFO\t2019-09-09 14:42:33 -0400\tmaster-replica-0\t1\tSignatures INCLUDED in export for Classify: None\n",
      "INFO\t2019-09-09 14:42:33 -0400\tmaster-replica-0\t1\tSignatures INCLUDED in export for Eval: None\n",
      "INFO\t2019-09-09 14:42:33 -0400\tmaster-replica-0\t1\tSignatures INCLUDED in export for Regress: None\n",
      "INFO\t2019-09-09 14:42:33 -0400\tmaster-replica-0\t1\tSignatures INCLUDED in export for Predict: ['serving_default']\n",
      "INFO\t2019-09-09 14:42:33 -0400\tmaster-replica-0\t1\tNo assets to save.\n",
      "INFO\t2019-09-09 14:42:33 -0400\tmaster-replica-0\t1\tNo assets to write.\n",
      "INFO\t2019-09-09 14:42:34 -0400\tmaster-replica-0\t1\tSavedModel written to: gs://mo_ml/lingh/1/keras_export/1568054530/saved_model.pb\n",
      "INFO\t2019-09-09 14:42:36 -0400\tmaster-replica-0\t1\tWARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "INFO\t2019-09-09 14:42:36 -0400\tmaster-replica-0\t1\tFor more information, please see:\n",
      "INFO\t2019-09-09 14:42:36 -0400\tmaster-replica-0\t1\t  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "INFO\t2019-09-09 14:42:36 -0400\tmaster-replica-0\t1\t  * https://github.com/tensorflow/addons\n",
      "INFO\t2019-09-09 14:42:36 -0400\tmaster-replica-0\t1\tIf you depend on functionality not listed there, please file an issue.\n",
      "INFO\t2019-09-09 14:42:36 -0400\tmaster-replica-0\t1\tModel exported to: gs://mo_ml/lingh/1/keras_export\n",
      "INFO\t2019-09-09 14:42:36 -0400\tmaster-replica-0\t1\tModule completed; cleaning up.\n",
      "INFO\t2019-09-09 14:42:36 -0400\tmaster-replica-0\t1\tClean up finished.\n",
      "INFO\t2019-09-09 14:42:36 -0400\tmaster-replica-0\t1\tTask completed successfully.\n",
      "INFO\t2019-09-09 14:45:13 -0400\tservice\t2\tJob completed successfully.\n",
      "INFO\t2019-09-09 14:46:08 -0400\tservice\t1\tJob completed successfully.\n",
      "INFO\t2019-09-09 14:46:33 -0400\tservice\t3\tWaiting for job to be provisioned.\n",
      "INFO\t2019-09-09 14:46:35 -0400\tservice\t3\tWaiting for training program to start.\n",
      "INFO\t2019-09-09 14:47:08 -0400\tservice\t4\tWaiting for job to be provisioned.\n",
      "INFO\t2019-09-09 14:47:10 -0400\tservice\t4\tWaiting for training program to start.\n",
      "INFO\t2019-09-09 14:47:10 -0400\tmaster-replica-0\t3\tRunning task with arguments: --cluster={\"master\": [\"127.0.0.1:2222\"]} --task={\"type\": \"master\", \"index\": 0, \"trial\": \"3\"} --job={  \"package_uris\": [\"gs://mo_ml/lingh/packages/9fef4d587f7511880b857ce6206af1b88acb9c4b12e9f72266cf68d36e785c0f/trainer-0.0.0.tar.gz\"],  \"python_module\": \"trainer.task\",  \"hyperparameters\": {    \"goal\": \"MAXIMIZE\",    \"params\": [{      \"parameter_name\": \"batch-size\",      \"min_value\": 8.0,      \"max_value\": 256.0,      \"type\": \"INTEGER\",      \"scale_type\": \"UNIT_LINEAR_SCALE\"    }, {      \"parameter_name\": \"learning-rate\",      \"min_value\": 0.01,      \"max_value\": 0.1,      \"type\": \"DOUBLE\",      \"scale_type\": \"UNIT_LOG_SCALE\"    }],    \"max_trials\": 4,    \"max_parallel_trials\": 2,    \"hyperparameter_metric_tag\": \"epoch_acc\"  },  \"region\": \"us-east1\",  \"runtime_version\": \"1.13\",  \"job_dir\": \"gs://mo_ml/lingh/\",  \"run_on_raw_vm\": true,  \"python_version\": \"3.5\"} --hyperparams={\"batch-size\":\"153\",\"learning-rate\":\"0.098808025997460816\"}\n",
      "WARNING\t2019-09-09 14:47:28 -0400\tmaster-replica-0\t3\tFrom /usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "WARNING\t2019-09-09 14:47:28 -0400\tmaster-replica-0\t3\tInstructions for updating:\n",
      "WARNING\t2019-09-09 14:47:28 -0400\tmaster-replica-0\t3\tColocations handled automatically by placer.\n",
      "INFO\t2019-09-09 14:47:33 -0400\tmaster-replica-0\t3\tRunning module trainer.task.\n",
      "INFO\t2019-09-09 14:47:33 -0400\tmaster-replica-0\t3\tDownloading the package: gs://mo_ml/lingh/packages/9fef4d587f7511880b857ce6206af1b88acb9c4b12e9f72266cf68d36e785c0f/trainer-0.0.0.tar.gz\n",
      "INFO\t2019-09-09 14:47:33 -0400\tmaster-replica-0\t3\tRunning command: gsutil -q cp gs://mo_ml/lingh/packages/9fef4d587f7511880b857ce6206af1b88acb9c4b12e9f72266cf68d36e785c0f/trainer-0.0.0.tar.gz trainer-0.0.0.tar.gz\n",
      "INFO\t2019-09-09 14:47:34 -0400\tmaster-replica-0\t3\tInstalling the package: gs://mo_ml/lingh/packages/9fef4d587f7511880b857ce6206af1b88acb9c4b12e9f72266cf68d36e785c0f/trainer-0.0.0.tar.gz\n",
      "INFO\t2019-09-09 14:47:34 -0400\tmaster-replica-0\t3\tRunning command: pip3 install --user --upgrade --force-reinstall --no-deps trainer-0.0.0.tar.gz\n",
      "INFO\t2019-09-09 14:47:43 -0400\tmaster-replica-0\t4\tRunning task with arguments: --cluster={\"master\": [\"127.0.0.1:2222\"]} --task={\"type\": \"master\", \"index\": 0, \"trial\": \"4\"} --job={  \"package_uris\": [\"gs://mo_ml/lingh/packages/9fef4d587f7511880b857ce6206af1b88acb9c4b12e9f72266cf68d36e785c0f/trainer-0.0.0.tar.gz\"],  \"python_module\": \"trainer.task\",  \"hyperparameters\": {    \"goal\": \"MAXIMIZE\",    \"params\": [{      \"parameter_name\": \"batch-size\",      \"min_value\": 8.0,      \"max_value\": 256.0,      \"type\": \"INTEGER\",      \"scale_type\": \"UNIT_LINEAR_SCALE\"    }, {      \"parameter_name\": \"learning-rate\",      \"min_value\": 0.01,      \"max_value\": 0.1,      \"type\": \"DOUBLE\",      \"scale_type\": \"UNIT_LOG_SCALE\"    }],    \"max_trials\": 4,    \"max_parallel_trials\": 2,    \"hyperparameter_metric_tag\": \"epoch_acc\"  },  \"region\": \"us-east1\",  \"runtime_version\": \"1.13\",  \"job_dir\": \"gs://mo_ml/lingh/\",  \"run_on_raw_vm\": true,  \"python_version\": \"3.5\"} --hyperparams={\"batch-size\":\"73\",\"learning-rate\":\"0.036664031487059351\"}\n",
      "INFO\t2019-09-09 14:47:44 -0400\tmaster-replica-0\t3\tProcessing ./trainer-0.0.0.tar.gz\n",
      "INFO\t2019-09-09 14:47:44 -0400\tmaster-replica-0\t3\tGenerating grammar tables from /usr/lib/python3.5/lib2to3/Grammar.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO\t2019-09-09 14:47:44 -0400\tmaster-replica-0\t3\tGenerating grammar tables from /usr/lib/python3.5/lib2to3/PatternGrammar.txt\n",
      "INFO\t2019-09-09 14:47:44 -0400\tmaster-replica-0\t3\tBuilding wheels for collected packages: trainer\n",
      "INFO\t2019-09-09 14:47:44 -0400\tmaster-replica-0\t3\t  Building wheel for trainer (setup.py): started\n",
      "INFO\t2019-09-09 14:47:45 -0400\tmaster-replica-0\t3\tGenerating grammar tables from /usr/lib/python3.5/lib2to3/Grammar.txt\n",
      "INFO\t2019-09-09 14:47:45 -0400\tmaster-replica-0\t3\tGenerating grammar tables from /usr/lib/python3.5/lib2to3/PatternGrammar.txt\n",
      "INFO\t2019-09-09 14:47:45 -0400\tmaster-replica-0\t3\t  Building wheel for trainer (setup.py): finished with status 'done'\n",
      "INFO\t2019-09-09 14:47:45 -0400\tmaster-replica-0\t3\t  Created wheel for trainer: filename=trainer-0.0.0-cp35-none-any.whl size=7836 sha256=e33c7c975af1329fc2943ef5da4ab310d942ab600f927e0ec14c25b6ffbdd839\n",
      "INFO\t2019-09-09 14:47:45 -0400\tmaster-replica-0\t3\t  Stored in directory: /root/.cache/pip/wheels/0d/1b/db/f8e86b296734f0b137e17e5d34862f4ae4faf8388755c6272f\n",
      "INFO\t2019-09-09 14:47:45 -0400\tmaster-replica-0\t3\tSuccessfully built trainer\n",
      "INFO\t2019-09-09 14:47:45 -0400\tmaster-replica-0\t3\tInstalling collected packages: trainer\n",
      "INFO\t2019-09-09 14:47:45 -0400\tmaster-replica-0\t3\tSuccessfully installed trainer-0.0.0\n",
      "INFO\t2019-09-09 14:47:45 -0400\tmaster-replica-0\t3\tRunning command: pip3 install --user trainer-0.0.0.tar.gz\n",
      "INFO\t2019-09-09 14:47:46 -0400\tmaster-replica-0\t3\tProcessing ./trainer-0.0.0.tar.gz\n",
      "INFO\t2019-09-09 14:47:46 -0400\tmaster-replica-0\t3\tGenerating grammar tables from /usr/lib/python3.5/lib2to3/Grammar.txt\n",
      "INFO\t2019-09-09 14:47:46 -0400\tmaster-replica-0\t3\tGenerating grammar tables from /usr/lib/python3.5/lib2to3/PatternGrammar.txt\n",
      "INFO\t2019-09-09 14:47:46 -0400\tmaster-replica-0\t3\tBuilding wheels for collected packages: trainer\n",
      "INFO\t2019-09-09 14:47:46 -0400\tmaster-replica-0\t3\t  Building wheel for trainer (setup.py): started\n",
      "INFO\t2019-09-09 14:47:46 -0400\tmaster-replica-0\t3\tGenerating grammar tables from /usr/lib/python3.5/lib2to3/Grammar.txt\n",
      "INFO\t2019-09-09 14:47:47 -0400\tmaster-replica-0\t3\tGenerating grammar tables from /usr/lib/python3.5/lib2to3/PatternGrammar.txt\n",
      "INFO\t2019-09-09 14:47:47 -0400\tmaster-replica-0\t3\t  Building wheel for trainer (setup.py): finished with status 'done'\n",
      "INFO\t2019-09-09 14:47:47 -0400\tmaster-replica-0\t3\t  Created wheel for trainer: filename=trainer-0.0.0-cp35-none-any.whl size=7836 sha256=4aff02c2e96c76dd20cc1e547d29408221062da3d3e70268acee0b0dde530288\n",
      "INFO\t2019-09-09 14:47:47 -0400\tmaster-replica-0\t3\t  Stored in directory: /root/.cache/pip/wheels/0d/1b/db/f8e86b296734f0b137e17e5d34862f4ae4faf8388755c6272f\n",
      "INFO\t2019-09-09 14:47:47 -0400\tmaster-replica-0\t3\tSuccessfully built trainer\n",
      "INFO\t2019-09-09 14:47:47 -0400\tmaster-replica-0\t3\tInstalling collected packages: trainer\n",
      "INFO\t2019-09-09 14:47:47 -0400\tmaster-replica-0\t3\t  Found existing installation: trainer 0.0.0\n",
      "INFO\t2019-09-09 14:47:47 -0400\tmaster-replica-0\t3\t    Uninstalling trainer-0.0.0:\n",
      "INFO\t2019-09-09 14:47:47 -0400\tmaster-replica-0\t3\t      Successfully uninstalled trainer-0.0.0\n",
      "INFO\t2019-09-09 14:47:47 -0400\tmaster-replica-0\t3\tSuccessfully installed trainer-0.0.0\n",
      "INFO\t2019-09-09 14:47:47 -0400\tmaster-replica-0\t3\tRunning command: python3 -m trainer.task --batch-size 153 --learning-rate 0.098808025997460816 --job-dir gs://mo_ml/lingh/3\n",
      "WARNING\t2019-09-09 14:47:52 -0400\tmaster-replica-0\t3\tFrom /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "WARNING\t2019-09-09 14:47:52 -0400\tmaster-replica-0\t3\tInstructions for updating:\n",
      "WARNING\t2019-09-09 14:47:52 -0400\tmaster-replica-0\t3\tColocations handled automatically by placer.\n",
      "INFO\t2019-09-09 14:47:52 -0400\tmaster-replica-0\t3\tYour CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
      "ERROR\t2019-09-09 14:47:52 -0400\tmaster-replica-0\t3\tUser settings:\n",
      "ERROR\t2019-09-09 14:47:52 -0400\tmaster-replica-0\t3\t   KMP_AFFINITY=granularity=fine,verbose,compact,1,0\n",
      "ERROR\t2019-09-09 14:47:52 -0400\tmaster-replica-0\t3\t   KMP_BLOCKTIME=0\n",
      "ERROR\t2019-09-09 14:47:52 -0400\tmaster-replica-0\t3\t   KMP_SETTINGS=1\n",
      "ERROR\t2019-09-09 14:47:52 -0400\tmaster-replica-0\t3\t   OMP_NUM_THREADS=4\n",
      "ERROR\t2019-09-09 14:47:52 -0400\tmaster-replica-0\t3\tEffective settings:\n",
      "ERROR\t2019-09-09 14:47:52 -0400\tmaster-replica-0\t3\t   KMP_ABORT_DELAY=0\n",
      "ERROR\t2019-09-09 14:47:52 -0400\tmaster-replica-0\t3\t   KMP_ADAPTIVE_LOCK_PROPS='1,1024'\n",
      "ERROR\t2019-09-09 14:47:52 -0400\tmaster-replica-0\t3\t   KMP_ALIGN_ALLOC=64\n",
      "ERROR\t2019-09-09 14:47:52 -0400\tmaster-replica-0\t3\t   KMP_ALL_THREADPRIVATE=128\n",
      "ERROR\t2019-09-09 14:47:52 -0400\tmaster-replica-0\t3\t   KMP_ATOMIC_MODE=2\n",
      "ERROR\t2019-09-09 14:47:52 -0400\tmaster-replica-0\t3\t   KMP_BLOCKTIME=0\n",
      "ERROR\t2019-09-09 14:47:52 -0400\tmaster-replica-0\t3\t   KMP_CPUINFO_FILE: value is not defined\n",
      "ERROR\t2019-09-09 14:47:52 -0400\tmaster-replica-0\t3\t   KMP_DETERMINISTIC_REDUCTION=false\n",
      "ERROR\t2019-09-09 14:47:52 -0400\tmaster-replica-0\t3\t   KMP_DEVICE_THREAD_LIMIT=2147483647\n",
      "ERROR\t2019-09-09 14:47:52 -0400\tmaster-replica-0\t3\t   KMP_DISP_HAND_THREAD=false\n",
      "ERROR\t2019-09-09 14:47:52 -0400\tmaster-replica-0\t3\t   KMP_DISP_NUM_BUFFERS=7\n",
      "ERROR\t2019-09-09 14:47:52 -0400\tmaster-replica-0\t3\t   KMP_DUPLICATE_LIB_OK=false\n",
      "ERROR\t2019-09-09 14:47:52 -0400\tmaster-replica-0\t3\t   KMP_FORCE_REDUCTION: value is not defined\n",
      "ERROR\t2019-09-09 14:47:52 -0400\tmaster-replica-0\t3\t   KMP_FOREIGN_THREADS_THREADPRIVATE=true\n",
      "ERROR\t2019-09-09 14:47:52 -0400\tmaster-replica-0\t3\t   KMP_FORKJOIN_BARRIER='2,2'\n",
      "ERROR\t2019-09-09 14:47:52 -0400\tmaster-replica-0\t3\t   KMP_FORKJOIN_BARRIER_PATTERN='hyper,hyper'\n",
      "ERROR\t2019-09-09 14:47:52 -0400\tmaster-replica-0\t3\t   KMP_FORKJOIN_FRAMES=true\n",
      "ERROR\t2019-09-09 14:47:52 -0400\tmaster-replica-0\t3\t   KMP_FORKJOIN_FRAMES_MODE=3\n",
      "ERROR\t2019-09-09 14:47:52 -0400\tmaster-replica-0\t3\t   KMP_GTID_MODE=3\n",
      "ERROR\t2019-09-09 14:47:52 -0400\tmaster-replica-0\t3\t   KMP_HANDLE_SIGNALS=false\n",
      "ERROR\t2019-09-09 14:47:52 -0400\tmaster-replica-0\t3\t   KMP_HOT_TEAMS_MAX_LEVEL=1\n",
      "ERROR\t2019-09-09 14:47:52 -0400\tmaster-replica-0\t3\t   KMP_HOT_TEAMS_MODE=0\n",
      "ERROR\t2019-09-09 14:47:52 -0400\tmaster-replica-0\t3\t   KMP_INIT_AT_FORK=true\n",
      "ERROR\t2019-09-09 14:47:52 -0400\tmaster-replica-0\t3\t   KMP_INIT_WAIT=2048\n",
      "ERROR\t2019-09-09 14:47:52 -0400\tmaster-replica-0\t3\t   KMP_ITT_PREPARE_DELAY=0\n",
      "ERROR\t2019-09-09 14:47:52 -0400\tmaster-replica-0\t3\t   KMP_LIBRARY=throughput\n",
      "ERROR\t2019-09-09 14:47:52 -0400\tmaster-replica-0\t3\t   KMP_LOCK_KIND=queuing\n",
      "ERROR\t2019-09-09 14:47:52 -0400\tmaster-replica-0\t3\t   KMP_MALLOC_POOL_INCR=1M\n",
      "ERROR\t2019-09-09 14:47:52 -0400\tmaster-replica-0\t3\t   KMP_NEXT_WAIT=1024\n",
      "ERROR\t2019-09-09 14:47:52 -0400\tmaster-replica-0\t3\t   KMP_NUM_LOCKS_IN_BLOCK=1\n",
      "ERROR\t2019-09-09 14:47:52 -0400\tmaster-replica-0\t3\t   KMP_PLAIN_BARRIER='2,2'\n",
      "ERROR\t2019-09-09 14:47:52 -0400\tmaster-replica-0\t3\t   KMP_PLAIN_BARRIER_PATTERN='hyper,hyper'\n",
      "ERROR\t2019-09-09 14:47:52 -0400\tmaster-replica-0\t3\t   KMP_REDUCTION_BARRIER='1,1'\n",
      "ERROR\t2019-09-09 14:47:52 -0400\tmaster-replica-0\t3\t   KMP_REDUCTION_BARRIER_PATTERN='hyper,hyper'\n",
      "ERROR\t2019-09-09 14:47:52 -0400\tmaster-replica-0\t3\t   KMP_SCHEDULE='static,balanced;guided,iterative'\n",
      "ERROR\t2019-09-09 14:47:52 -0400\tmaster-replica-0\t3\t   KMP_SETTINGS=true\n",
      "ERROR\t2019-09-09 14:47:52 -0400\tmaster-replica-0\t3\t   KMP_SPIN_BACKOFF_PARAMS='4096,100'\n",
      "ERROR\t2019-09-09 14:47:52 -0400\tmaster-replica-0\t3\t   KMP_STACKOFFSET=64\n",
      "ERROR\t2019-09-09 14:47:52 -0400\tmaster-replica-0\t3\t   KMP_STACKPAD=0\n",
      "ERROR\t2019-09-09 14:47:52 -0400\tmaster-replica-0\t3\t   KMP_STACKSIZE=4M\n",
      "ERROR\t2019-09-09 14:47:52 -0400\tmaster-replica-0\t3\t   KMP_STORAGE_MAP=false\n",
      "ERROR\t2019-09-09 14:47:52 -0400\tmaster-replica-0\t3\t   KMP_TASKING=2\n",
      "ERROR\t2019-09-09 14:47:52 -0400\tmaster-replica-0\t3\t   KMP_TASKLOOP_MIN_TASKS=0\n",
      "ERROR\t2019-09-09 14:47:52 -0400\tmaster-replica-0\t3\t   KMP_TASK_STEALING_CONSTRAINT=1\n",
      "ERROR\t2019-09-09 14:47:52 -0400\tmaster-replica-0\t3\t   KMP_TEAMS_THREAD_LIMIT=4\n",
      "ERROR\t2019-09-09 14:47:52 -0400\tmaster-replica-0\t3\t   KMP_TOPOLOGY_METHOD=all\n",
      "ERROR\t2019-09-09 14:47:52 -0400\tmaster-replica-0\t3\t   KMP_USER_LEVEL_MWAIT=false\n",
      "ERROR\t2019-09-09 14:47:52 -0400\tmaster-replica-0\t3\t   KMP_VERSION=false\n",
      "ERROR\t2019-09-09 14:47:52 -0400\tmaster-replica-0\t3\t   KMP_WARNINGS=true\n",
      "ERROR\t2019-09-09 14:47:52 -0400\tmaster-replica-0\t3\t   OMP_AFFINITY_FORMAT='OMP: pid %P tid %T thread %n bound to OS proc set {%a}'\n",
      "ERROR\t2019-09-09 14:47:52 -0400\tmaster-replica-0\t3\t   OMP_ALLOCATOR=omp_default_mem_alloc\n",
      "ERROR\t2019-09-09 14:47:52 -0400\tmaster-replica-0\t3\t   OMP_CANCELLATION=false\n",
      "ERROR\t2019-09-09 14:47:52 -0400\tmaster-replica-0\t3\t   OMP_DEFAULT_DEVICE=0\n",
      "ERROR\t2019-09-09 14:47:52 -0400\tmaster-replica-0\t3\t   OMP_DISPLAY_AFFINITY=false\n",
      "ERROR\t2019-09-09 14:47:52 -0400\tmaster-replica-0\t3\t   OMP_DISPLAY_ENV=false\n",
      "ERROR\t2019-09-09 14:47:52 -0400\tmaster-replica-0\t3\t   OMP_DYNAMIC=false\n",
      "ERROR\t2019-09-09 14:47:52 -0400\tmaster-replica-0\t3\t   OMP_MAX_ACTIVE_LEVELS=2147483647\n",
      "ERROR\t2019-09-09 14:47:52 -0400\tmaster-replica-0\t3\t   OMP_MAX_TASK_PRIORITY=0\n",
      "ERROR\t2019-09-09 14:47:52 -0400\tmaster-replica-0\t3\t   OMP_NESTED=false\n",
      "ERROR\t2019-09-09 14:47:52 -0400\tmaster-replica-0\t3\t   OMP_NUM_THREADS='4'\n",
      "ERROR\t2019-09-09 14:47:52 -0400\tmaster-replica-0\t3\t   OMP_PLACES: value is not defined\n",
      "ERROR\t2019-09-09 14:47:52 -0400\tmaster-replica-0\t3\t   OMP_PROC_BIND='intel'\n",
      "ERROR\t2019-09-09 14:47:52 -0400\tmaster-replica-0\t3\t   OMP_SCHEDULE='static'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR\t2019-09-09 14:47:52 -0400\tmaster-replica-0\t3\t   OMP_STACKSIZE=4M\n",
      "ERROR\t2019-09-09 14:47:52 -0400\tmaster-replica-0\t3\t   OMP_TARGET_OFFLOAD=DEFAULT\n",
      "ERROR\t2019-09-09 14:47:52 -0400\tmaster-replica-0\t3\t   OMP_THREAD_LIMIT=2147483647\n",
      "ERROR\t2019-09-09 14:47:52 -0400\tmaster-replica-0\t3\t   OMP_TOOL=enabled\n",
      "ERROR\t2019-09-09 14:47:52 -0400\tmaster-replica-0\t3\t   OMP_TOOL_LIBRARIES: value is not defined\n",
      "ERROR\t2019-09-09 14:47:52 -0400\tmaster-replica-0\t3\t   OMP_WAIT_POLICY=PASSIVE\n",
      "ERROR\t2019-09-09 14:47:52 -0400\tmaster-replica-0\t3\t   KMP_AFFINITY='verbose,warnings,respect,granularity=fine,compact,1,0'\n",
      "INFO\t2019-09-09 14:47:52 -0400\tmaster-replica-0\t3\tCPU Frequency: 2300000000 Hz\n",
      "INFO\t2019-09-09 14:47:52 -0400\tmaster-replica-0\t3\tXLA service 0x460d790 executing computations on platform Host. Devices:\n",
      "INFO\t2019-09-09 14:47:52 -0400\tmaster-replica-0\t3\t  StreamExecutor device (0): <undefined>, <undefined>\n",
      "ERROR\t2019-09-09 14:47:52 -0400\tmaster-replica-0\t3\tOMP: Info #212: KMP_AFFINITY: decoding x2APIC ids.\n",
      "ERROR\t2019-09-09 14:47:52 -0400\tmaster-replica-0\t3\tOMP: Info #210: KMP_AFFINITY: Affinity capable, using global cpuid leaf 11 info\n",
      "ERROR\t2019-09-09 14:47:52 -0400\tmaster-replica-0\t3\tOMP: Info #154: KMP_AFFINITY: Initial OS proc set respected: 0-3\n",
      "ERROR\t2019-09-09 14:47:52 -0400\tmaster-replica-0\t3\tOMP: Info #156: KMP_AFFINITY: 4 available OS procs\n",
      "ERROR\t2019-09-09 14:47:52 -0400\tmaster-replica-0\t3\tOMP: Info #157: KMP_AFFINITY: Uniform topology\n",
      "ERROR\t2019-09-09 14:47:52 -0400\tmaster-replica-0\t3\tOMP: Info #179: KMP_AFFINITY: 1 packages x 2 cores/pkg x 2 threads/core (2 total cores)\n",
      "ERROR\t2019-09-09 14:47:52 -0400\tmaster-replica-0\t3\tOMP: Info #214: KMP_AFFINITY: OS proc to physical thread map:\n",
      "ERROR\t2019-09-09 14:47:52 -0400\tmaster-replica-0\t3\tOMP: Info #171: KMP_AFFINITY: OS proc 0 maps to package 0 core 0 thread 0 \n",
      "ERROR\t2019-09-09 14:47:52 -0400\tmaster-replica-0\t3\tOMP: Info #171: KMP_AFFINITY: OS proc 2 maps to package 0 core 0 thread 1 \n",
      "ERROR\t2019-09-09 14:47:52 -0400\tmaster-replica-0\t3\tOMP: Info #171: KMP_AFFINITY: OS proc 1 maps to package 0 core 1 thread 0 \n",
      "ERROR\t2019-09-09 14:47:52 -0400\tmaster-replica-0\t3\tOMP: Info #171: KMP_AFFINITY: OS proc 3 maps to package 0 core 1 thread 1 \n",
      "ERROR\t2019-09-09 14:47:52 -0400\tmaster-replica-0\t3\tOMP: Info #250: KMP_AFFINITY: pid 396 tid 396 thread 0 bound to OS proc set 0\n",
      "INFO\t2019-09-09 14:47:52 -0400\tmaster-replica-0\t3\tCreating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n",
      "ERROR\t2019-09-09 14:47:52 -0400\tmaster-replica-0\t3\tOMP: Info #250: KMP_AFFINITY: pid 396 tid 420 thread 1 bound to OS proc set 1\n",
      "WARNING\t2019-09-09 14:47:52 -0400\tmaster-replica-0\t3\tFrom /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "WARNING\t2019-09-09 14:47:52 -0400\tmaster-replica-0\t3\tInstructions for updating:\n",
      "WARNING\t2019-09-09 14:47:52 -0400\tmaster-replica-0\t3\tUse tf.cast instead.\n",
      "ERROR\t2019-09-09 14:47:58 -0400\tmaster-replica-0\t3\tOMP: Info #250: KMP_AFFINITY: pid 396 tid 419 thread 2 bound to OS proc set 2\n",
      "ERROR\t2019-09-09 14:47:58 -0400\tmaster-replica-0\t3\tOMP: Info #250: KMP_AFFINITY: pid 396 tid 483 thread 3 bound to OS proc set 3\n",
      "ERROR\t2019-09-09 14:47:58 -0400\tmaster-replica-0\t3\tOMP: Info #250: KMP_AFFINITY: pid 396 tid 484 thread 4 bound to OS proc set 0\n",
      "ERROR\t2019-09-09 14:47:58 -0400\tmaster-replica-0\t3\tOMP: Info #250: KMP_AFFINITY: pid 396 tid 485 thread 5 bound to OS proc set 1\n",
      "ERROR\t2019-09-09 14:47:58 -0400\tmaster-replica-0\t3\tOMP: Info #250: KMP_AFFINITY: pid 396 tid 486 thread 6 bound to OS proc set 2\n",
      "ERROR\t2019-09-09 14:47:58 -0400\tmaster-replica-0\t3\tOMP: Info #250: KMP_AFFINITY: pid 396 tid 487 thread 7 bound to OS proc set 3\n",
      "ERROR\t2019-09-09 14:47:58 -0400\tmaster-replica-0\t3\tOMP: Info #250: KMP_AFFINITY: pid 396 tid 488 thread 8 bound to OS proc set 0\n",
      "INFO\t2019-09-09 14:47:58 -0400\tmaster-replica-0\t3\tEpoch 00001: LearningRateScheduler reducing learning rate to 0.10880802599746081.\n",
      "INFO\t2019-09-09 14:47:58 -0400\tmaster-replica-0\t3\tEpoch 1/20\n",
      "INFO\t2019-09-09 14:47:58 -0400\tmaster-replica-0\t3\t  1/212 [..............................] - ETA: 3:10 - loss: 0.7143 - acc: 0.307\n",
      "INFO\t2019-09-09 14:47:58 -0400\tmaster-replica-0\t3\t 10/212 [>.............................] - ETA: 19s - loss: 3.8007 - acc: 0.699\n",
      "INFO\t2019-09-09 14:47:58 -0400\tmaster-replica-0\t3\t 22/212 [==>...........................] - ETA: 8s - loss: 3.8393 - acc: 0.7323\n",
      "INFO\t2019-09-09 14:47:58 -0400\tmaster-replica-0\t3\t 31/212 [===>..........................] - ETA: 6s - loss: 3.9073 - acc: 0.736\n",
      "INFO\t2019-09-09 14:47:58 -0400\tmaster-replica-0\t3\t 42/212 [====>.........................] - ETA: 4s - loss: 3.9073 - acc: 0.742\n",
      "INFO\t2019-09-09 14:47:59 -0400\tmaster-replica-0\t3\t 51/212 [======>.......................] - ETA: 3s - loss: 3.8602 - acc: 0.747\n",
      "INFO\t2019-09-09 14:47:59 -0400\tmaster-replica-0\t3\t 62/212 [=======>......................] - ETA: 2s - loss: 3.8703 - acc: 0.749\n",
      "INFO\t2019-09-09 14:47:59 -0400\tmaster-replica-0\t3\t 71/212 [=========>....................] - ETA: 2s - loss: 3.8827 - acc: 0.750\n",
      "INFO\t2019-09-09 14:47:59 -0400\tmaster-replica-0\t3\t 81/212 [==========>...................] - ETA: 2s - loss: 3.8989 - acc: 0.750\n",
      "INFO\t2019-09-09 14:47:59 -0400\tmaster-replica-0\t3\t 91/212 [===========>..................] - ETA: 1s - loss: 3.8814 - acc: 0.752\n",
      "INFO\t2019-09-09 14:47:59 -0400\tmaster-replica-0\t3\t102/212 [=============>................] - ETA: 1s - loss: 3.9121 - acc: 0.750\n",
      "INFO\t2019-09-09 14:47:59 -0400\tmaster-replica-0\t3\t112/212 [==============>...............] - ETA: 1s - loss: 3.9052 - acc: 0.751\n",
      "INFO\t2019-09-09 14:47:59 -0400\tmaster-replica-0\t3\t123/212 [================>.............] - ETA: 1s - loss: 3.8985 - acc: 0.752\n",
      "INFO\t2019-09-09 14:47:59 -0400\tmaster-replica-0\t3\t132/212 [=================>............] - ETA: 0s - loss: 3.9009 - acc: 0.753\n",
      "INFO\t2019-09-09 14:47:59 -0400\tmaster-replica-0\t3\t143/212 [===================>..........] - ETA: 0s - loss: 3.8955 - acc: 0.753\n",
      "INFO\t2019-09-09 14:47:59 -0400\tmaster-replica-0\t3\t154/212 [====================>.........] - ETA: 0s - loss: 3.8854 - acc: 0.754\n",
      "INFO\t2019-09-09 14:47:59 -0400\tmaster-replica-0\t3\t165/212 [======================>.......] - ETA: 0s - loss: 3.8645 - acc: 0.756\n",
      "INFO\t2019-09-09 14:47:59 -0400\tmaster-replica-0\t3\t176/212 [=======================>......] - ETA: 0s - loss: 3.8618 - acc: 0.756\n",
      "INFO\t2019-09-09 14:47:59 -0400\tmaster-replica-0\t3\t186/212 [=========================>....] - ETA: 0s - loss: 3.8615 - acc: 0.756\n",
      "INFO\t2019-09-09 14:47:59 -0400\tmaster-replica-0\t3\t197/212 [==========================>...] - ETA: 0s - loss: 3.8646 - acc: 0.756\n",
      "WARNING\t2019-09-09 14:48:01 -0400\tmaster-replica-0\t4\tFrom /usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "WARNING\t2019-09-09 14:48:01 -0400\tmaster-replica-0\t4\tInstructions for updating:\n",
      "WARNING\t2019-09-09 14:48:01 -0400\tmaster-replica-0\t4\tColocations handled automatically by placer.\n",
      "WARNING\t2019-09-09 14:48:02 -0400\tmaster-replica-0\t3\tfile_cache is unavailable when using oauth2client >= 4.0.0 or google-auth\n",
      "INFO\t2019-09-09 14:48:02 -0400\tmaster-replica-0\t3\tAttempting refresh to obtain initial access_token\n",
      "INFO\t2019-09-09 14:48:03 -0400\tmaster-replica-0\t3\t207/212 [============================>.] - ETA: 0s - loss: 3.8697 - acc: 0.756\n",
      "INFO\t2019-09-09 14:48:03 -0400\tmaster-replica-0\t3\t212/212 [==============================] - 5s 26ms/step - loss: 3.8644 - acc: 0.7572 - val_loss: 3.8072 - val_acc: 0.7638\n",
      "INFO\t2019-09-09 14:48:03 -0400\tmaster-replica-0\t3\tEpoch 00002: LearningRateScheduler reducing learning rate to 0.10380802599746082.\n",
      "INFO\t2019-09-09 14:48:03 -0400\tmaster-replica-0\t3\tEpoch 2/20\n",
      "INFO\t2019-09-09 14:48:03 -0400\tmaster-replica-0\t3\t  1/212 [..............................] - ETA: 14s - loss: 4.3192 - acc: 0.73\n",
      "INFO\t2019-09-09 14:48:03 -0400\tmaster-replica-0\t3\t  6/212 [..............................] - ETA: 4s - loss: 3.7749 - acc: 0.7658\n",
      "INFO\t2019-09-09 14:48:03 -0400\tmaster-replica-0\t3\t 14/212 [>.............................] - ETA: 2s - loss: 3.7172 - acc: 0.769\n",
      "INFO\t2019-09-09 14:48:03 -0400\tmaster-replica-0\t3\t 22/212 [==>...........................] - ETA: 1s - loss: 3.8643 - acc: 0.760\n",
      "INFO\t2019-09-09 14:48:03 -0400\tmaster-replica-0\t3\t 27/212 [==>...........................] - ETA: 1s - loss: 3.8666 - acc: 0.760\n",
      "INFO\t2019-09-09 14:48:03 -0400\tmaster-replica-0\t3\t 35/212 [===>..........................] - ETA: 1s - loss: 3.8437 - acc: 0.761\n",
      "INFO\t2019-09-09 14:48:03 -0400\tmaster-replica-0\t3\t 42/212 [====>.........................] - ETA: 1s - loss: 3.8126 - acc: 0.763\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO\t2019-09-09 14:48:03 -0400\tmaster-replica-0\t3\t 51/212 [======>.......................] - ETA: 1s - loss: 3.8131 - acc: 0.763\n",
      "INFO\t2019-09-09 14:48:03 -0400\tmaster-replica-0\t3\t 57/212 [=======>......................] - ETA: 1s - loss: 3.8036 - acc: 0.764\n",
      "INFO\t2019-09-09 14:48:03 -0400\tmaster-replica-0\t3\t 62/212 [=======>......................] - ETA: 1s - loss: 3.7942 - acc: 0.764\n",
      "INFO\t2019-09-09 14:48:03 -0400\tmaster-replica-0\t3\t 66/212 [========>.....................] - ETA: 1s - loss: 3.7989 - acc: 0.764\n",
      "INFO\t2019-09-09 14:48:04 -0400\tmaster-replica-0\t3\t 73/212 [=========>....................] - ETA: 1s - loss: 3.8315 - acc: 0.762\n",
      "INFO\t2019-09-09 14:48:04 -0400\tmaster-replica-0\t3\t 81/212 [==========>...................] - ETA: 1s - loss: 3.8172 - acc: 0.763\n",
      "INFO\t2019-09-09 14:48:04 -0400\tmaster-replica-0\t3\t 90/212 [===========>..................] - ETA: 1s - loss: 3.8206 - acc: 0.763\n",
      "INFO\t2019-09-09 14:48:04 -0400\tmaster-replica-0\t3\t 96/212 [============>.................] - ETA: 0s - loss: 3.8144 - acc: 0.763\n",
      "INFO\t2019-09-09 14:48:04 -0400\tmaster-replica-0\t3\t107/212 [==============>...............] - ETA: 0s - loss: 3.8279 - acc: 0.762\n",
      "INFO\t2019-09-09 14:48:04 -0400\tmaster-replica-0\t3\t112/212 [==============>...............] - ETA: 0s - loss: 3.8414 - acc: 0.761\n",
      "INFO\t2019-09-09 14:48:04 -0400\tmaster-replica-0\t3\t118/212 [===============>..............] - ETA: 0s - loss: 3.8461 - acc: 0.761\n",
      "INFO\t2019-09-09 14:48:04 -0400\tmaster-replica-0\t3\t127/212 [================>.............] - ETA: 0s - loss: 3.8381 - acc: 0.761\n",
      "INFO\t2019-09-09 14:48:04 -0400\tmaster-replica-0\t3\t134/212 [=================>............] - ETA: 0s - loss: 3.8436 - acc: 0.761\n",
      "INFO\t2019-09-09 14:48:04 -0400\tmaster-replica-0\t3\t141/212 [==================>...........] - ETA: 0s - loss: 3.8433 - acc: 0.761\n",
      "INFO\t2019-09-09 14:48:04 -0400\tmaster-replica-0\t3\t148/212 [===================>..........] - ETA: 0s - loss: 3.8601 - acc: 0.760\n",
      "INFO\t2019-09-09 14:48:04 -0400\tmaster-replica-0\t3\t154/212 [====================>.........] - ETA: 0s - loss: 3.8630 - acc: 0.760\n",
      "INFO\t2019-09-09 14:48:04 -0400\tmaster-replica-0\t3\t160/212 [=====================>........] - ETA: 0s - loss: 3.8722 - acc: 0.759\n",
      "INFO\t2019-09-09 14:48:04 -0400\tmaster-replica-0\t3\t168/212 [======================>.......] - ETA: 0s - loss: 3.8834 - acc: 0.759\n",
      "INFO\t2019-09-09 14:48:04 -0400\tmaster-replica-0\t3\t173/212 [=======================>......] - ETA: 0s - loss: 3.8826 - acc: 0.759\n",
      "INFO\t2019-09-09 14:48:04 -0400\tmaster-replica-0\t3\t181/212 [========================>.....] - ETA: 0s - loss: 3.8833 - acc: 0.759\n",
      "INFO\t2019-09-09 14:48:04 -0400\tmaster-replica-0\t3\t188/212 [=========================>....] - ETA: 0s - loss: 3.8799 - acc: 0.759\n",
      "INFO\t2019-09-09 14:48:04 -0400\tmaster-replica-0\t3\t195/212 [==========================>...] - ETA: 0s - loss: 3.8876 - acc: 0.758\n",
      "INFO\t2019-09-09 14:48:04 -0400\tmaster-replica-0\t3\t203/212 [===========================>..] - ETA: 0s - loss: 3.8823 - acc: 0.759\n",
      "INFO\t2019-09-09 14:48:05 -0400\tmaster-replica-0\t4\tRunning module trainer.task.\n",
      "INFO\t2019-09-09 14:48:05 -0400\tmaster-replica-0\t4\tDownloading the package: gs://mo_ml/lingh/packages/9fef4d587f7511880b857ce6206af1b88acb9c4b12e9f72266cf68d36e785c0f/trainer-0.0.0.tar.gz\n",
      "INFO\t2019-09-09 14:48:05 -0400\tmaster-replica-0\t4\tRunning command: gsutil -q cp gs://mo_ml/lingh/packages/9fef4d587f7511880b857ce6206af1b88acb9c4b12e9f72266cf68d36e785c0f/trainer-0.0.0.tar.gz trainer-0.0.0.tar.gz\n",
      "INFO\t2019-09-09 14:48:06 -0400\tmaster-replica-0\t3\t209/212 [============================>.] - ETA: 0s - loss: 3.8868 - acc: 0.758\n",
      "INFO\t2019-09-09 14:48:06 -0400\tmaster-replica-0\t3\t212/212 [==============================] - 3s 14ms/step - loss: 3.8894 - acc: 0.7587 - val_loss: 3.8072 - val_acc: 0.7638\n",
      "INFO\t2019-09-09 14:48:06 -0400\tmaster-replica-0\t3\tEpoch 00003: LearningRateScheduler reducing learning rate to 0.10130802599746082.\n",
      "INFO\t2019-09-09 14:48:06 -0400\tmaster-replica-0\t3\tEpoch 3/20\n",
      "INFO\t2019-09-09 14:48:06 -0400\tmaster-replica-0\t3\t  1/212 [..............................] - ETA: 15s - loss: 2.6337 - acc: 0.83\n",
      "INFO\t2019-09-09 14:48:06 -0400\tmaster-replica-0\t3\t 10/212 [>.............................] - ETA: 2s - loss: 3.4975 - acc: 0.7830\n",
      "INFO\t2019-09-09 14:48:06 -0400\tmaster-replica-0\t3\t 18/212 [=>............................] - ETA: 1s - loss: 3.7223 - acc: 0.769\n",
      "INFO\t2019-09-09 14:48:06 -0400\tmaster-replica-0\t3\t 24/212 [==>...........................] - ETA: 1s - loss: 3.7135 - acc: 0.769\n",
      "INFO\t2019-09-09 14:48:06 -0400\tmaster-replica-0\t3\t 31/212 [===>..........................] - ETA: 1s - loss: 3.7041 - acc: 0.770\n",
      "INFO\t2019-09-09 14:48:06 -0400\tmaster-replica-0\t3\t 38/212 [====>.........................] - ETA: 1s - loss: 3.7149 - acc: 0.769\n",
      "INFO\t2019-09-09 14:48:06 -0400\tmaster-replica-0\t3\t 43/212 [=====>........................] - ETA: 1s - loss: 3.7435 - acc: 0.767\n",
      "INFO\t2019-09-09 14:48:06 -0400\tmaster-replica-0\t3\t 49/212 [=====>........................] - ETA: 1s - loss: 3.7301 - acc: 0.768\n",
      "INFO\t2019-09-09 14:48:06 -0400\tmaster-replica-0\t3\t 57/212 [=======>......................] - ETA: 1s - loss: 3.7130 - acc: 0.769\n",
      "INFO\t2019-09-09 14:48:06 -0400\tmaster-replica-0\t3\t 65/212 [========>.....................] - ETA: 1s - loss: 3.7439 - acc: 0.767\n",
      "INFO\t2019-09-09 14:48:06 -0400\tmaster-replica-0\t3\t 72/212 [=========>....................] - ETA: 1s - loss: 3.7545 - acc: 0.767\n",
      "INFO\t2019-09-09 14:48:06 -0400\tmaster-replica-0\t3\t 82/212 [==========>...................] - ETA: 1s - loss: 3.7899 - acc: 0.764\n",
      "INFO\t2019-09-09 14:48:06 -0400\tmaster-replica-0\t3\t 90/212 [===========>..................] - ETA: 0s - loss: 3.7843 - acc: 0.765\n",
      "INFO\t2019-09-09 14:48:07 -0400\tmaster-replica-0\t3\t 95/212 [============>.................] - ETA: 0s - loss: 3.7925 - acc: 0.764\n",
      "INFO\t2019-09-09 14:48:07 -0400\tmaster-replica-0\t3\t104/212 [=============>................] - ETA: 0s - loss: 3.7945 - acc: 0.764\n",
      "INFO\t2019-09-09 14:48:07 -0400\tmaster-replica-0\t3\t110/212 [==============>...............] - ETA: 0s - loss: 3.8011 - acc: 0.764\n",
      "INFO\t2019-09-09 14:48:07 -0400\tmaster-replica-0\t3\t120/212 [===============>..............] - ETA: 0s - loss: 3.8329 - acc: 0.762\n",
      "INFO\t2019-09-09 14:48:07 -0400\tmaster-replica-0\t3\t126/212 [================>.............] - ETA: 0s - loss: 3.8368 - acc: 0.762\n",
      "INFO\t2019-09-09 14:48:07 -0400\tmaster-replica-0\t3\t135/212 [==================>...........] - ETA: 0s - loss: 3.8510 - acc: 0.761\n",
      "INFO\t2019-09-09 14:48:07 -0400\tmaster-replica-0\t3\t141/212 [==================>...........] - ETA: 0s - loss: 3.8590 - acc: 0.760\n",
      "INFO\t2019-09-09 14:48:07 -0400\tmaster-replica-0\t3\t146/212 [===================>..........] - ETA: 0s - loss: 3.8574 - acc: 0.760\n",
      "INFO\t2019-09-09 14:48:07 -0400\tmaster-replica-0\t4\tInstalling the package: gs://mo_ml/lingh/packages/9fef4d587f7511880b857ce6206af1b88acb9c4b12e9f72266cf68d36e785c0f/trainer-0.0.0.tar.gz\n",
      "INFO\t2019-09-09 14:48:07 -0400\tmaster-replica-0\t4\tRunning command: pip3 install --user --upgrade --force-reinstall --no-deps trainer-0.0.0.tar.gz\n",
      "INFO\t2019-09-09 14:48:07 -0400\tmaster-replica-0\t3\t151/212 [====================>.........] - ETA: 0s - loss: 3.8497 - acc: 0.761\n",
      "INFO\t2019-09-09 14:48:07 -0400\tmaster-replica-0\t3\t158/212 [=====================>........] - ETA: 0s - loss: 3.8692 - acc: 0.759\n",
      "INFO\t2019-09-09 14:48:07 -0400\tmaster-replica-0\t3\t165/212 [======================>.......] - ETA: 0s - loss: 3.8755 - acc: 0.759\n",
      "INFO\t2019-09-09 14:48:07 -0400\tmaster-replica-0\t3\t173/212 [=======================>......] - ETA: 0s - loss: 3.8771 - acc: 0.759\n",
      "INFO\t2019-09-09 14:48:07 -0400\tmaster-replica-0\t3\t182/212 [========================>.....] - ETA: 0s - loss: 3.8787 - acc: 0.759\n",
      "INFO\t2019-09-09 14:48:07 -0400\tmaster-replica-0\t3\t189/212 [=========================>....] - ETA: 0s - loss: 3.8800 - acc: 0.759\n",
      "INFO\t2019-09-09 14:48:07 -0400\tmaster-replica-0\t3\t198/212 [===========================>..] - ETA: 0s - loss: 3.8771 - acc: 0.759\n",
      "INFO\t2019-09-09 14:48:08 -0400\tmaster-replica-0\t3\t204/212 [===========================>..] - ETA: 0s - loss: 3.8792 - acc: 0.759\n",
      "INFO\t2019-09-09 14:48:08 -0400\tmaster-replica-0\t3\t212/212 [==============================] - 3s 13ms/step - loss: 3.8740 - acc: 0.7596 - val_loss: 3.8072 - val_acc: 0.7638\n",
      "INFO\t2019-09-09 14:48:08 -0400\tmaster-replica-0\t3\tEpoch 00004: LearningRateScheduler reducing learning rate to 0.10005802599746082.\n",
      "INFO\t2019-09-09 14:48:08 -0400\tmaster-replica-0\t3\tEpoch 4/20\n",
      "INFO\t2019-09-09 14:48:09 -0400\tmaster-replica-0\t3\t  1/212 [..............................] - ETA: 17s - loss: 4.2139 - acc: 0.73\n",
      "INFO\t2019-09-09 14:48:09 -0400\tmaster-replica-0\t3\t  7/212 [..............................] - ETA: 4s - loss: 4.2139 - acc: 0.7386\n",
      "INFO\t2019-09-09 14:48:09 -0400\tmaster-replica-0\t3\t 15/212 [=>............................] - ETA: 2s - loss: 4.0664 - acc: 0.747\n",
      "INFO\t2019-09-09 14:48:09 -0400\tmaster-replica-0\t3\t 24/212 [==>...........................] - ETA: 1s - loss: 3.9769 - acc: 0.753\n",
      "INFO\t2019-09-09 14:48:09 -0400\tmaster-replica-0\t3\t 31/212 [===>..........................] - ETA: 1s - loss: 3.9454 - acc: 0.755\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO\t2019-09-09 14:48:09 -0400\tmaster-replica-0\t3\t 40/212 [====>.........................] - ETA: 1s - loss: 3.8873 - acc: 0.758\n",
      "INFO\t2019-09-09 14:48:09 -0400\tmaster-replica-0\t3\t 47/212 [=====>........................] - ETA: 1s - loss: 3.8844 - acc: 0.759\n",
      "INFO\t2019-09-09 14:48:09 -0400\tmaster-replica-0\t3\t 56/212 [======>.......................] - ETA: 1s - loss: 3.9204 - acc: 0.756\n",
      "INFO\t2019-09-09 14:48:09 -0400\tmaster-replica-0\t3\t 62/212 [=======>......................] - ETA: 1s - loss: 3.9250 - acc: 0.756\n",
      "INFO\t2019-09-09 14:48:09 -0400\tmaster-replica-0\t3\t 71/212 [=========>....................] - ETA: 1s - loss: 3.9527 - acc: 0.754\n",
      "INFO\t2019-09-09 14:48:09 -0400\tmaster-replica-0\t3\t 78/212 [==========>...................] - ETA: 1s - loss: 3.9397 - acc: 0.755\n",
      "INFO\t2019-09-09 14:48:09 -0400\tmaster-replica-0\t3\t 86/212 [===========>..................] - ETA: 0s - loss: 3.9419 - acc: 0.755\n",
      "INFO\t2019-09-09 14:48:09 -0400\tmaster-replica-0\t3\t 91/212 [===========>..................] - ETA: 0s - loss: 3.9291 - acc: 0.756\n",
      "INFO\t2019-09-09 14:48:09 -0400\tmaster-replica-0\t3\t 98/212 [============>.................] - ETA: 0s - loss: 3.9054 - acc: 0.757\n",
      "INFO\t2019-09-09 14:48:09 -0400\tmaster-replica-0\t3\t102/212 [=============>................] - ETA: 0s - loss: 3.9061 - acc: 0.757\n",
      "INFO\t2019-09-09 14:48:09 -0400\tmaster-replica-0\t3\t110/212 [==============>...............] - ETA: 0s - loss: 3.9065 - acc: 0.757\n",
      "INFO\t2019-09-09 14:48:09 -0400\tmaster-replica-0\t3\t118/212 [===============>..............] - ETA: 0s - loss: 3.8934 - acc: 0.758\n",
      "INFO\t2019-09-09 14:48:09 -0400\tmaster-replica-0\t3\t127/212 [================>.............] - ETA: 0s - loss: 3.8871 - acc: 0.758\n",
      "INFO\t2019-09-09 14:48:09 -0400\tmaster-replica-0\t3\t135/212 [==================>...........] - ETA: 0s - loss: 3.8963 - acc: 0.758\n",
      "INFO\t2019-09-09 14:48:10 -0400\tmaster-replica-0\t3\t143/212 [===================>..........] - ETA: 0s - loss: 3.8993 - acc: 0.758\n",
      "INFO\t2019-09-09 14:48:10 -0400\tmaster-replica-0\t3\t150/212 [====================>.........] - ETA: 0s - loss: 3.8887 - acc: 0.758\n",
      "INFO\t2019-09-09 14:48:10 -0400\tmaster-replica-0\t3\t155/212 [====================>.........] - ETA: 0s - loss: 3.8876 - acc: 0.758\n",
      "INFO\t2019-09-09 14:48:10 -0400\tmaster-replica-0\t3\t163/212 [======================>.......] - ETA: 0s - loss: 3.8765 - acc: 0.759\n",
      "INFO\t2019-09-09 14:48:10 -0400\tmaster-replica-0\t3\t171/212 [=======================>......] - ETA: 0s - loss: 3.8831 - acc: 0.759\n",
      "INFO\t2019-09-09 14:48:10 -0400\tmaster-replica-0\t3\t181/212 [========================>.....] - ETA: 0s - loss: 3.8967 - acc: 0.758\n",
      "INFO\t2019-09-09 14:48:10 -0400\tmaster-replica-0\t3\t187/212 [=========================>....] - ETA: 0s - loss: 3.8995 - acc: 0.758\n",
      "INFO\t2019-09-09 14:48:10 -0400\tmaster-replica-0\t3\t194/212 [==========================>...] - ETA: 0s - loss: 3.8902 - acc: 0.758\n",
      "INFO\t2019-09-09 14:48:10 -0400\tmaster-replica-0\t3\t201/212 [===========================>..] - ETA: 0s - loss: 3.8853 - acc: 0.759\n",
      "INFO\t2019-09-09 14:48:11 -0400\tmaster-replica-0\t3\t209/212 [============================>.] - ETA: 0s - loss: 3.8787 - acc: 0.759\n",
      "INFO\t2019-09-09 14:48:11 -0400\tmaster-replica-0\t3\t212/212 [==============================] - 3s 13ms/step - loss: 3.8819 - acc: 0.7592 - val_loss: 3.8072 - val_acc: 0.7638\n",
      "INFO\t2019-09-09 14:48:11 -0400\tmaster-replica-0\t3\tEpoch 00005: LearningRateScheduler reducing learning rate to 0.09943302599746082.\n",
      "INFO\t2019-09-09 14:48:11 -0400\tmaster-replica-0\t3\tEpoch 5/20\n",
      "INFO\t2019-09-09 14:48:11 -0400\tmaster-replica-0\t3\t  1/212 [..............................] - ETA: 1s - loss: 4.0032 - acc: 0.751\n",
      "INFO\t2019-09-09 14:48:11 -0400\tmaster-replica-0\t3\t  9/212 [>.............................] - ETA: 1s - loss: 3.9330 - acc: 0.756\n",
      "INFO\t2019-09-09 14:48:11 -0400\tmaster-replica-0\t3\t 15/212 [=>............................] - ETA: 1s - loss: 3.9540 - acc: 0.754\n",
      "INFO\t2019-09-09 14:48:11 -0400\tmaster-replica-0\t3\t 21/212 [=>............................] - ETA: 1s - loss: 4.0233 - acc: 0.750\n",
      "INFO\t2019-09-09 14:48:11 -0400\tmaster-replica-0\t3\t 27/212 [==>...........................] - ETA: 1s - loss: 3.9993 - acc: 0.751\n",
      "INFO\t2019-09-09 14:48:11 -0400\tmaster-replica-0\t3\t 36/212 [====>.........................] - ETA: 1s - loss: 3.9447 - acc: 0.755\n",
      "INFO\t2019-09-09 14:48:11 -0400\tmaster-replica-0\t3\t 46/212 [=====>........................] - ETA: 1s - loss: 3.9070 - acc: 0.757\n",
      "INFO\t2019-09-09 14:48:12 -0400\tmaster-replica-0\t3\t 54/212 [======>.......................] - ETA: 1s - loss: 3.8803 - acc: 0.759\n",
      "INFO\t2019-09-09 14:48:12 -0400\tmaster-replica-0\t3\t 60/212 [=======>......................] - ETA: 1s - loss: 3.8346 - acc: 0.762\n",
      "INFO\t2019-09-09 14:48:12 -0400\tmaster-replica-0\t3\t 68/212 [========>.....................] - ETA: 1s - loss: 3.8653 - acc: 0.760\n",
      "INFO\t2019-09-09 14:48:12 -0400\tmaster-replica-0\t3\t 78/212 [==========>...................] - ETA: 0s - loss: 3.8830 - acc: 0.759\n",
      "INFO\t2019-09-09 14:48:12 -0400\tmaster-replica-0\t3\t 86/212 [===========>..................] - ETA: 0s - loss: 3.9162 - acc: 0.757\n",
      "INFO\t2019-09-09 14:48:12 -0400\tmaster-replica-0\t3\t 96/212 [============>.................] - ETA: 0s - loss: 3.9198 - acc: 0.756\n",
      "INFO\t2019-09-09 14:48:12 -0400\tmaster-replica-0\t3\t102/212 [=============>................] - ETA: 0s - loss: 3.9102 - acc: 0.757\n",
      "INFO\t2019-09-09 14:48:12 -0400\tmaster-replica-0\t3\t111/212 [==============>...............] - ETA: 0s - loss: 3.9083 - acc: 0.757\n",
      "INFO\t2019-09-09 14:48:12 -0400\tmaster-replica-0\t3\t120/212 [===============>..............] - ETA: 0s - loss: 3.9145 - acc: 0.757\n",
      "INFO\t2019-09-09 14:48:12 -0400\tmaster-replica-0\t3\t125/212 [================>.............] - ETA: 0s - loss: 3.8936 - acc: 0.758\n",
      "INFO\t2019-09-09 14:48:12 -0400\tmaster-replica-0\t3\t131/212 [=================>............] - ETA: 0s - loss: 3.8858 - acc: 0.758\n",
      "INFO\t2019-09-09 14:48:12 -0400\tmaster-replica-0\t3\t138/212 [==================>...........] - ETA: 0s - loss: 3.8833 - acc: 0.759\n",
      "INFO\t2019-09-09 14:48:12 -0400\tmaster-replica-0\t3\t147/212 [===================>..........] - ETA: 0s - loss: 3.8857 - acc: 0.758\n",
      "INFO\t2019-09-09 14:48:12 -0400\tmaster-replica-0\t3\t156/212 [=====================>........] - ETA: 0s - loss: 3.8864 - acc: 0.758\n",
      "INFO\t2019-09-09 14:48:12 -0400\tmaster-replica-0\t3\t165/212 [======================>.......] - ETA: 0s - loss: 3.8749 - acc: 0.759\n",
      "INFO\t2019-09-09 14:48:12 -0400\tmaster-replica-0\t3\t172/212 [=======================>......] - ETA: 0s - loss: 3.8801 - acc: 0.759\n",
      "INFO\t2019-09-09 14:48:12 -0400\tmaster-replica-0\t3\t179/212 [========================>.....] - ETA: 0s - loss: 3.8802 - acc: 0.759\n",
      "INFO\t2019-09-09 14:48:12 -0400\tmaster-replica-0\t3\t187/212 [=========================>....] - ETA: 0s - loss: 3.8787 - acc: 0.759\n",
      "INFO\t2019-09-09 14:48:13 -0400\tmaster-replica-0\t3\t192/212 [==========================>...] - ETA: 0s - loss: 3.8759 - acc: 0.759\n",
      "INFO\t2019-09-09 14:48:13 -0400\tmaster-replica-0\t3\t200/212 [===========================>..] - ETA: 0s - loss: 3.8805 - acc: 0.759\n",
      "INFO\t2019-09-09 14:48:13 -0400\tmaster-replica-0\t3\t203/212 [===========================>..] - ETA: 0s - loss: 3.8849 - acc: 0.759\n",
      "INFO\t2019-09-09 14:48:15 -0400\tmaster-replica-0\t3\t210/212 [============================>.] - ETA: 0s - loss: 3.8823 - acc: 0.759\n",
      "INFO\t2019-09-09 14:48:15 -0400\tmaster-replica-0\t3\t212/212 [==============================] - 4s 19ms/step - loss: 3.8854 - acc: 0.7589 - val_loss: 3.8072 - val_acc: 0.7638\n",
      "INFO\t2019-09-09 14:48:15 -0400\tmaster-replica-0\t3\tEpoch 00006: LearningRateScheduler reducing learning rate to 0.09912052599746081.\n",
      "INFO\t2019-09-09 14:48:15 -0400\tmaster-replica-0\t3\tEpoch 6/20\n",
      "INFO\t2019-09-09 14:48:15 -0400\tmaster-replica-0\t3\t  1/212 [..............................] - ETA: 20s - loss: 3.2658 - acc: 0.79\n",
      "INFO\t2019-09-09 14:48:15 -0400\tmaster-replica-0\t3\t  7/212 [..............................] - ETA: 4s - loss: 3.8075 - acc: 0.7638\n",
      "INFO\t2019-09-09 14:48:15 -0400\tmaster-replica-0\t3\t 13/212 [>.............................] - ETA: 3s - loss: 4.0032 - acc: 0.751\n",
      "INFO\t2019-09-09 14:48:15 -0400\tmaster-replica-0\t3\t 22/212 [==>...........................] - ETA: 2s - loss: 3.8835 - acc: 0.759\n",
      "INFO\t2019-09-09 14:48:15 -0400\tmaster-replica-0\t3\t 27/212 [==>...........................] - ETA: 2s - loss: 3.8861 - acc: 0.758\n",
      "INFO\t2019-09-09 14:48:15 -0400\tmaster-replica-0\t3\t 32/212 [===>..........................] - ETA: 2s - loss: 3.9439 - acc: 0.755\n",
      "INFO\t2019-09-09 14:48:16 -0400\tmaster-replica-0\t3\t 40/212 [====>.........................] - ETA: 1s - loss: 3.8899 - acc: 0.758\n",
      "INFO\t2019-09-09 14:48:16 -0400\tmaster-replica-0\t3\t 49/212 [=====>........................] - ETA: 1s - loss: 3.8935 - acc: 0.758\n",
      "INFO\t2019-09-09 14:48:16 -0400\tmaster-replica-0\t3\t 57/212 [=======>......................] - ETA: 1s - loss: 3.9163 - acc: 0.757\n",
      "INFO\t2019-09-09 14:48:16 -0400\tmaster-replica-0\t3\t 64/212 [========>.....................] - ETA: 1s - loss: 3.8764 - acc: 0.759\n",
      "INFO\t2019-09-09 14:48:16 -0400\tmaster-replica-0\t3\t 71/212 [=========>....................] - ETA: 1s - loss: 3.8860 - acc: 0.758\n",
      "INFO\t2019-09-09 14:48:16 -0400\tmaster-replica-0\t3\t 81/212 [==========>...................] - ETA: 1s - loss: 3.9199 - acc: 0.756\n",
      "INFO\t2019-09-09 14:48:16 -0400\tmaster-replica-0\t3\t 87/212 [===========>..................] - ETA: 1s - loss: 3.9087 - acc: 0.757\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO\t2019-09-09 14:48:16 -0400\tmaster-replica-0\t3\t 96/212 [============>.................] - ETA: 0s - loss: 3.8891 - acc: 0.758\n",
      "INFO\t2019-09-09 14:48:16 -0400\tmaster-replica-0\t3\t104/212 [=============>................] - ETA: 0s - loss: 3.8928 - acc: 0.758\n",
      "INFO\t2019-09-09 14:48:16 -0400\tmaster-replica-0\t3\t112/212 [==============>...............] - ETA: 0s - loss: 3.8809 - acc: 0.759\n",
      "INFO\t2019-09-09 14:48:16 -0400\tmaster-replica-0\t3\t119/212 [===============>..............] - ETA: 0s - loss: 3.8916 - acc: 0.758\n",
      "INFO\t2019-09-09 14:48:16 -0400\tmaster-replica-0\t3\t127/212 [================>.............] - ETA: 0s - loss: 3.8871 - acc: 0.758\n",
      "INFO\t2019-09-09 14:48:16 -0400\tmaster-replica-0\t3\t137/212 [==================>...........] - ETA: 0s - loss: 3.8663 - acc: 0.760\n",
      "INFO\t2019-09-09 14:48:16 -0400\tmaster-replica-0\t3\t142/212 [===================>..........] - ETA: 0s - loss: 3.8696 - acc: 0.759\n",
      "INFO\t2019-09-09 14:48:16 -0400\tmaster-replica-0\t3\t149/212 [====================>.........] - ETA: 0s - loss: 3.8936 - acc: 0.758\n",
      "INFO\t2019-09-09 14:48:16 -0400\tmaster-replica-0\t3\t158/212 [=====================>........] - ETA: 0s - loss: 3.8898 - acc: 0.758\n",
      "INFO\t2019-09-09 14:48:16 -0400\tmaster-replica-0\t3\t162/212 [=====================>........] - ETA: 0s - loss: 3.8809 - acc: 0.759\n",
      "INFO\t2019-09-09 14:48:16 -0400\tmaster-replica-0\t3\t169/212 [======================>.......] - ETA: 0s - loss: 3.8885 - acc: 0.758\n",
      "INFO\t2019-09-09 14:48:17 -0400\tmaster-replica-0\t3\t181/212 [========================>.....] - ETA: 0s - loss: 3.8914 - acc: 0.758\n",
      "INFO\t2019-09-09 14:48:17 -0400\tmaster-replica-0\t3\t190/212 [=========================>....] - ETA: 0s - loss: 3.8845 - acc: 0.759\n",
      "INFO\t2019-09-09 14:48:17 -0400\tmaster-replica-0\t3\t200/212 [===========================>..] - ETA: 0s - loss: 3.8873 - acc: 0.758\n",
      "INFO\t2019-09-09 14:48:17 -0400\tmaster-replica-0\t4\tProcessing ./trainer-0.0.0.tar.gz\n",
      "INFO\t2019-09-09 14:48:17 -0400\tmaster-replica-0\t4\tGenerating grammar tables from /usr/lib/python3.5/lib2to3/Grammar.txt\n",
      "INFO\t2019-09-09 14:48:17 -0400\tmaster-replica-0\t4\tGenerating grammar tables from /usr/lib/python3.5/lib2to3/PatternGrammar.txt\n",
      "INFO\t2019-09-09 14:48:17 -0400\tmaster-replica-0\t4\tBuilding wheels for collected packages: trainer\n",
      "INFO\t2019-09-09 14:48:17 -0400\tmaster-replica-0\t4\t  Building wheel for trainer (setup.py): started\n",
      "INFO\t2019-09-09 14:48:18 -0400\tmaster-replica-0\t3\t207/212 [============================>.] - ETA: 0s - loss: 3.8805 - acc: 0.759\n",
      "INFO\t2019-09-09 14:48:18 -0400\tmaster-replica-0\t3\t212/212 [==============================] - 3s 13ms/step - loss: 3.8795 - acc: 0.7593 - val_loss: 3.8072 - val_acc: 0.7638\n",
      "INFO\t2019-09-09 14:48:18 -0400\tmaster-replica-0\t4\tGenerating grammar tables from /usr/lib/python3.5/lib2to3/Grammar.txt\n",
      "INFO\t2019-09-09 14:48:18 -0400\tmaster-replica-0\t3\tEpoch 00007: LearningRateScheduler reducing learning rate to 0.09896427599746081.\n",
      "INFO\t2019-09-09 14:48:18 -0400\tmaster-replica-0\t3\tEpoch 7/20\n",
      "INFO\t2019-09-09 14:48:18 -0400\tmaster-replica-0\t4\tGenerating grammar tables from /usr/lib/python3.5/lib2to3/PatternGrammar.txt\n",
      "INFO\t2019-09-09 14:48:18 -0400\tmaster-replica-0\t3\t  1/212 [..............................] - ETA: 9s - loss: 3.0551 - acc: 0.810\n",
      "INFO\t2019-09-09 14:48:18 -0400\tmaster-replica-0\t3\t 11/212 [>.............................] - ETA: 1s - loss: 3.7542 - acc: 0.767\n",
      "INFO\t2019-09-09 14:48:18 -0400\tmaster-replica-0\t4\t  Building wheel for trainer (setup.py): finished with status 'done'\n",
      "INFO\t2019-09-09 14:48:18 -0400\tmaster-replica-0\t4\t  Created wheel for trainer: filename=trainer-0.0.0-cp35-none-any.whl size=7836 sha256=28ddd27744e2823519fb7c94b6109e37639f7cacbae5c12c08c0fc18f7bda454\n",
      "INFO\t2019-09-09 14:48:18 -0400\tmaster-replica-0\t4\t  Stored in directory: /root/.cache/pip/wheels/0d/1b/db/f8e86b296734f0b137e17e5d34862f4ae4faf8388755c6272f\n",
      "INFO\t2019-09-09 14:48:18 -0400\tmaster-replica-0\t4\tSuccessfully built trainer\n",
      "INFO\t2019-09-09 14:48:18 -0400\tmaster-replica-0\t4\tInstalling collected packages: trainer\n",
      "INFO\t2019-09-09 14:48:18 -0400\tmaster-replica-0\t4\tSuccessfully installed trainer-0.0.0\n",
      "INFO\t2019-09-09 14:48:18 -0400\tmaster-replica-0\t3\t 20/212 [=>............................] - ETA: 1s - loss: 3.8768 - acc: 0.759\n",
      "INFO\t2019-09-09 14:48:18 -0400\tmaster-replica-0\t3\t 31/212 [===>..........................] - ETA: 1s - loss: 3.8741 - acc: 0.759\n",
      "INFO\t2019-09-09 14:48:18 -0400\tmaster-replica-0\t3\t 40/212 [====>.........................] - ETA: 1s - loss: 3.7978 - acc: 0.764\n",
      "INFO\t2019-09-09 14:48:18 -0400\tmaster-replica-0\t3\t 50/212 [======>.......................] - ETA: 1s - loss: 3.8473 - acc: 0.761\n",
      "INFO\t2019-09-09 14:48:18 -0400\tmaster-replica-0\t3\t 59/212 [=======>......................] - ETA: 0s - loss: 3.8496 - acc: 0.761\n",
      "INFO\t2019-09-09 14:48:18 -0400\tmaster-replica-0\t4\tRunning command: pip3 install --user trainer-0.0.0.tar.gz\n",
      "INFO\t2019-09-09 14:48:18 -0400\tmaster-replica-0\t3\t 69/212 [========>.....................] - ETA: 0s - loss: 3.8337 - acc: 0.762\n",
      "INFO\t2019-09-09 14:48:18 -0400\tmaster-replica-0\t3\t 75/212 [=========>....................] - ETA: 0s - loss: 3.8417 - acc: 0.761\n",
      "INFO\t2019-09-09 14:48:18 -0400\tmaster-replica-0\t3\t 84/212 [==========>...................] - ETA: 0s - loss: 3.8502 - acc: 0.761\n",
      "INFO\t2019-09-09 14:48:18 -0400\tmaster-replica-0\t3\t 91/212 [===========>..................] - ETA: 0s - loss: 3.8654 - acc: 0.760\n",
      "INFO\t2019-09-09 14:48:18 -0400\tmaster-replica-0\t3\t100/212 [=============>................] - ETA: 0s - loss: 3.8926 - acc: 0.758\n",
      "INFO\t2019-09-09 14:48:18 -0400\tmaster-replica-0\t3\t107/212 [==============>...............] - ETA: 0s - loss: 3.8703 - acc: 0.759\n",
      "INFO\t2019-09-09 14:48:19 -0400\tmaster-replica-0\t3\t116/212 [===============>..............] - ETA: 0s - loss: 3.8651 - acc: 0.760\n",
      "INFO\t2019-09-09 14:48:19 -0400\tmaster-replica-0\t3\t124/212 [================>.............] - ETA: 0s - loss: 3.8511 - acc: 0.761\n",
      "INFO\t2019-09-09 14:48:19 -0400\tmaster-replica-0\t3\t130/212 [=================>............] - ETA: 0s - loss: 3.8460 - acc: 0.761\n",
      "INFO\t2019-09-09 14:48:19 -0400\tmaster-replica-0\t3\t139/212 [==================>...........] - ETA: 0s - loss: 3.8683 - acc: 0.760\n",
      "INFO\t2019-09-09 14:48:19 -0400\tmaster-replica-0\t4\tProcessing ./trainer-0.0.0.tar.gz\n",
      "INFO\t2019-09-09 14:48:19 -0400\tmaster-replica-0\t3\t144/212 [===================>..........] - ETA: 0s - loss: 3.8803 - acc: 0.759\n",
      "INFO\t2019-09-09 14:48:19 -0400\tmaster-replica-0\t3\t153/212 [====================>.........] - ETA: 0s - loss: 3.8786 - acc: 0.759\n",
      "INFO\t2019-09-09 14:48:19 -0400\tmaster-replica-0\t3\t162/212 [=====================>........] - ETA: 0s - loss: 3.8874 - acc: 0.758\n",
      "INFO\t2019-09-09 14:48:19 -0400\tmaster-replica-0\t3\t171/212 [=======================>......] - ETA: 0s - loss: 3.8991 - acc: 0.758\n",
      "INFO\t2019-09-09 14:48:19 -0400\tmaster-replica-0\t3\t176/212 [=======================>......] - ETA: 0s - loss: 3.8990 - acc: 0.758\n",
      "INFO\t2019-09-09 14:48:19 -0400\tmaster-replica-0\t3\t182/212 [========================>.....] - ETA: 0s - loss: 3.9048 - acc: 0.757\n",
      "INFO\t2019-09-09 14:48:19 -0400\tmaster-replica-0\t4\tGenerating grammar tables from /usr/lib/python3.5/lib2to3/Grammar.txt\n",
      "INFO\t2019-09-09 14:48:19 -0400\tmaster-replica-0\t4\tGenerating grammar tables from /usr/lib/python3.5/lib2to3/PatternGrammar.txt\n",
      "INFO\t2019-09-09 14:48:19 -0400\tmaster-replica-0\t3\t189/212 [=========================>....] - ETA: 0s - loss: 3.9006 - acc: 0.758\n",
      "INFO\t2019-09-09 14:48:19 -0400\tmaster-replica-0\t4\tBuilding wheels for collected packages: trainer\n",
      "INFO\t2019-09-09 14:48:19 -0400\tmaster-replica-0\t4\t  Building wheel for trainer (setup.py): started\n",
      "INFO\t2019-09-09 14:48:19 -0400\tmaster-replica-0\t3\t198/212 [===========================>..] - ETA: 0s - loss: 3.9016 - acc: 0.757\n",
      "INFO\t2019-09-09 14:48:19 -0400\tmaster-replica-0\t4\tGenerating grammar tables from /usr/lib/python3.5/lib2to3/Grammar.txt\n",
      "INFO\t2019-09-09 14:48:19 -0400\tmaster-replica-0\t4\tGenerating grammar tables from /usr/lib/python3.5/lib2to3/PatternGrammar.txt\n",
      "INFO\t2019-09-09 14:48:20 -0400\tmaster-replica-0\t4\t  Building wheel for trainer (setup.py): finished with status 'done'\n",
      "INFO\t2019-09-09 14:48:20 -0400\tmaster-replica-0\t4\t  Created wheel for trainer: filename=trainer-0.0.0-cp35-none-any.whl size=7836 sha256=0a172a782739f3610f158cdafa87ff77a61547a529f3714a23b083e27811375e\n",
      "INFO\t2019-09-09 14:48:20 -0400\tmaster-replica-0\t4\t  Stored in directory: /root/.cache/pip/wheels/0d/1b/db/f8e86b296734f0b137e17e5d34862f4ae4faf8388755c6272f\n",
      "INFO\t2019-09-09 14:48:20 -0400\tmaster-replica-0\t4\tSuccessfully built trainer\n",
      "INFO\t2019-09-09 14:48:20 -0400\tmaster-replica-0\t4\tInstalling collected packages: trainer\n",
      "INFO\t2019-09-09 14:48:20 -0400\tmaster-replica-0\t4\t  Found existing installation: trainer 0.0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO\t2019-09-09 14:48:20 -0400\tmaster-replica-0\t4\t    Uninstalling trainer-0.0.0:\n",
      "INFO\t2019-09-09 14:48:20 -0400\tmaster-replica-0\t4\t      Successfully uninstalled trainer-0.0.0\n",
      "INFO\t2019-09-09 14:48:20 -0400\tmaster-replica-0\t4\tSuccessfully installed trainer-0.0.0\n",
      "INFO\t2019-09-09 14:48:20 -0400\tmaster-replica-0\t4\tRunning command: python3 -m trainer.task --learning-rate 0.036664031487059351 --batch-size 73 --job-dir gs://mo_ml/lingh/4\n",
      "INFO\t2019-09-09 14:48:20 -0400\tmaster-replica-0\t3\t209/212 [============================>.] - ETA: 0s - loss: 3.8983 - acc: 0.758\n",
      "INFO\t2019-09-09 14:48:20 -0400\tmaster-replica-0\t3\t212/212 [==============================] - 3s 12ms/step - loss: 3.8949 - acc: 0.7584 - val_loss: 3.8072 - val_acc: 0.7638\n",
      "INFO\t2019-09-09 14:48:20 -0400\tmaster-replica-0\t3\tEpoch 00008: LearningRateScheduler reducing learning rate to 0.09888615099746081.\n",
      "INFO\t2019-09-09 14:48:20 -0400\tmaster-replica-0\t3\tEpoch 8/20\n",
      "INFO\t2019-09-09 14:48:20 -0400\tmaster-replica-0\t3\t  1/212 [..............................] - ETA: 16s - loss: 3.3711 - acc: 0.79\n",
      "INFO\t2019-09-09 14:48:20 -0400\tmaster-replica-0\t3\t  6/212 [..............................] - ETA: 4s - loss: 3.4062 - acc: 0.7887\n",
      "INFO\t2019-09-09 14:48:21 -0400\tmaster-replica-0\t3\t 15/212 [=>............................] - ETA: 2s - loss: 3.4975 - acc: 0.783\n",
      "INFO\t2019-09-09 14:48:21 -0400\tmaster-replica-0\t3\t 22/212 [==>...........................] - ETA: 2s - loss: 3.5722 - acc: 0.778\n",
      "INFO\t2019-09-09 14:48:21 -0400\tmaster-replica-0\t3\t 28/212 [==>...........................] - ETA: 1s - loss: 3.6307 - acc: 0.774\n",
      "INFO\t2019-09-09 14:48:21 -0400\tmaster-replica-0\t3\t 38/212 [====>.........................] - ETA: 1s - loss: 3.7537 - acc: 0.767\n",
      "INFO\t2019-09-09 14:48:21 -0400\tmaster-replica-0\t3\t 46/212 [=====>........................] - ETA: 1s - loss: 3.8017 - acc: 0.764\n",
      "INFO\t2019-09-09 14:48:21 -0400\tmaster-replica-0\t3\t 52/212 [======>.......................] - ETA: 1s - loss: 3.7824 - acc: 0.765\n",
      "INFO\t2019-09-09 14:48:21 -0400\tmaster-replica-0\t3\t 61/212 [=======>......................] - ETA: 1s - loss: 3.8098 - acc: 0.763\n",
      "INFO\t2019-09-09 14:48:21 -0400\tmaster-replica-0\t3\t 71/212 [=========>....................] - ETA: 1s - loss: 3.8133 - acc: 0.763\n",
      "INFO\t2019-09-09 14:48:21 -0400\tmaster-replica-0\t3\t 75/212 [=========>....................] - ETA: 1s - loss: 3.8487 - acc: 0.761\n",
      "INFO\t2019-09-09 14:48:21 -0400\tmaster-replica-0\t3\t 84/212 [==========>...................] - ETA: 1s - loss: 3.8075 - acc: 0.763\n",
      "INFO\t2019-09-09 14:48:21 -0400\tmaster-replica-0\t3\t 90/212 [===========>..................] - ETA: 0s - loss: 3.8089 - acc: 0.763\n",
      "INFO\t2019-09-09 14:48:21 -0400\tmaster-replica-0\t3\t 98/212 [============>.................] - ETA: 0s - loss: 3.8333 - acc: 0.762\n",
      "INFO\t2019-09-09 14:48:21 -0400\tmaster-replica-0\t3\t105/212 [=============>................] - ETA: 0s - loss: 3.7945 - acc: 0.764\n",
      "INFO\t2019-09-09 14:48:21 -0400\tmaster-replica-0\t3\t113/212 [==============>...............] - ETA: 0s - loss: 3.8065 - acc: 0.763\n",
      "INFO\t2019-09-09 14:48:21 -0400\tmaster-replica-0\t3\t121/212 [================>.............] - ETA: 0s - loss: 3.8238 - acc: 0.762\n",
      "INFO\t2019-09-09 14:48:21 -0400\tmaster-replica-0\t3\t128/212 [=================>............] - ETA: 0s - loss: 3.8205 - acc: 0.763\n",
      "INFO\t2019-09-09 14:48:21 -0400\tmaster-replica-0\t3\t135/212 [==================>...........] - ETA: 0s - loss: 3.8268 - acc: 0.762\n",
      "INFO\t2019-09-09 14:48:21 -0400\tmaster-replica-0\t3\t142/212 [===================>..........] - ETA: 0s - loss: 3.8504 - acc: 0.761\n",
      "INFO\t2019-09-09 14:48:21 -0400\tmaster-replica-0\t3\t150/212 [====================>.........] - ETA: 0s - loss: 3.8571 - acc: 0.760\n",
      "INFO\t2019-09-09 14:48:22 -0400\tmaster-replica-0\t3\t157/212 [=====================>........] - ETA: 0s - loss: 3.8629 - acc: 0.760\n",
      "INFO\t2019-09-09 14:48:22 -0400\tmaster-replica-0\t3\t165/212 [======================>.......] - ETA: 0s - loss: 3.8717 - acc: 0.759\n",
      "INFO\t2019-09-09 14:48:22 -0400\tmaster-replica-0\t3\t173/212 [=======================>......] - ETA: 0s - loss: 3.8680 - acc: 0.760\n",
      "INFO\t2019-09-09 14:48:22 -0400\tmaster-replica-0\t3\t180/212 [========================>.....] - ETA: 0s - loss: 3.8674 - acc: 0.760\n",
      "INFO\t2019-09-09 14:48:22 -0400\tmaster-replica-0\t3\t187/212 [=========================>....] - ETA: 0s - loss: 3.8629 - acc: 0.760\n",
      "INFO\t2019-09-09 14:48:22 -0400\tmaster-replica-0\t3\t192/212 [==========================>...] - ETA: 0s - loss: 3.8545 - acc: 0.760\n",
      "INFO\t2019-09-09 14:48:22 -0400\tmaster-replica-0\t3\t198/212 [===========================>..] - ETA: 0s - loss: 3.8760 - acc: 0.759\n",
      "INFO\t2019-09-09 14:48:23 -0400\tmaster-replica-0\t3\t207/212 [============================>.] - ETA: 0s - loss: 3.8724 - acc: 0.759\n",
      "INFO\t2019-09-09 14:48:23 -0400\tmaster-replica-0\t3\t212/212 [==============================] - 3s 13ms/step - loss: 3.8725 - acc: 0.7597 - val_loss: 3.8072 - val_acc: 0.7638\n",
      "INFO\t2019-09-09 14:48:23 -0400\tmaster-replica-0\t3\tEpoch 00009: LearningRateScheduler reducing learning rate to 0.09884708849746082.\n",
      "INFO\t2019-09-09 14:48:23 -0400\tmaster-replica-0\t3\tEpoch 9/20\n",
      "INFO\t2019-09-09 14:48:23 -0400\tmaster-replica-0\t3\t  1/212 [..............................] - ETA: 15s - loss: 3.7925 - acc: 0.76\n",
      "INFO\t2019-09-09 14:48:23 -0400\tmaster-replica-0\t3\t  9/212 [>.............................] - ETA: 2s - loss: 3.7808 - acc: 0.7654\n",
      "INFO\t2019-09-09 14:48:23 -0400\tmaster-replica-0\t3\t 15/212 [=>............................] - ETA: 2s - loss: 3.7082 - acc: 0.769\n",
      "INFO\t2019-09-09 14:48:23 -0400\tmaster-replica-0\t3\t 22/212 [==>...........................] - ETA: 2s - loss: 3.7686 - acc: 0.766\n",
      "INFO\t2019-09-09 14:48:23 -0400\tmaster-replica-0\t3\t 28/212 [==>...........................] - ETA: 1s - loss: 3.8226 - acc: 0.762\n",
      "INFO\t2019-09-09 14:48:23 -0400\tmaster-replica-0\t3\t 36/212 [====>.........................] - ETA: 1s - loss: 3.7837 - acc: 0.765\n",
      "INFO\t2019-09-09 14:48:24 -0400\tmaster-replica-0\t3\t 43/212 [=====>........................] - ETA: 1s - loss: 3.8537 - acc: 0.760\n",
      "INFO\t2019-09-09 14:48:24 -0400\tmaster-replica-0\t3\t 52/212 [======>.......................] - ETA: 1s - loss: 3.8269 - acc: 0.762\n",
      "INFO\t2019-09-09 14:48:24 -0400\tmaster-replica-0\t3\t 59/212 [=======>......................] - ETA: 1s - loss: 3.8639 - acc: 0.760\n",
      "INFO\t2019-09-09 14:48:24 -0400\tmaster-replica-0\t3\t 67/212 [========>.....................] - ETA: 1s - loss: 3.8758 - acc: 0.759\n",
      "INFO\t2019-09-09 14:48:24 -0400\tmaster-replica-0\t3\t 72/212 [=========>....................] - ETA: 1s - loss: 3.8847 - acc: 0.759\n",
      "INFO\t2019-09-09 14:48:24 -0400\tmaster-replica-0\t3\t 78/212 [==========>...................] - ETA: 1s - loss: 3.9140 - acc: 0.757\n",
      "INFO\t2019-09-09 14:48:24 -0400\tmaster-replica-0\t3\t 87/212 [===========>..................] - ETA: 1s - loss: 3.9293 - acc: 0.756\n",
      "INFO\t2019-09-09 14:48:24 -0400\tmaster-replica-0\t3\t 91/212 [===========>..................] - ETA: 1s - loss: 3.9337 - acc: 0.755\n",
      "INFO\t2019-09-09 14:48:24 -0400\tmaster-replica-0\t3\t 99/212 [=============>................] - ETA: 0s - loss: 3.9085 - acc: 0.757\n",
      "INFO\t2019-09-09 14:48:24 -0400\tmaster-replica-0\t3\t107/212 [==============>...............] - ETA: 0s - loss: 3.9097 - acc: 0.757\n",
      "INFO\t2019-09-09 14:48:24 -0400\tmaster-replica-0\t3\t117/212 [===============>..............] - ETA: 0s - loss: 3.9213 - acc: 0.756\n",
      "INFO\t2019-09-09 14:48:24 -0400\tmaster-replica-0\t3\t123/212 [================>.............] - ETA: 0s - loss: 3.9252 - acc: 0.756\n",
      "INFO\t2019-09-09 14:48:24 -0400\tmaster-replica-0\t3\t132/212 [=================>............] - ETA: 0s - loss: 3.9513 - acc: 0.754\n",
      "INFO\t2019-09-09 14:48:24 -0400\tmaster-replica-0\t3\t140/212 [==================>...........] - ETA: 0s - loss: 3.9475 - acc: 0.755\n",
      "INFO\t2019-09-09 14:48:24 -0400\tmaster-replica-0\t3\t147/212 [===================>..........] - ETA: 0s - loss: 3.9430 - acc: 0.755\n",
      "INFO\t2019-09-09 14:48:24 -0400\tmaster-replica-0\t3\t153/212 [====================>.........] - ETA: 0s - loss: 3.9447 - acc: 0.755\n",
      "INFO\t2019-09-09 14:48:24 -0400\tmaster-replica-0\t3\t162/212 [=====================>........] - ETA: 0s - loss: 3.9245 - acc: 0.756\n",
      "INFO\t2019-09-09 14:48:24 -0400\tmaster-replica-0\t3\t170/212 [=======================>......] - ETA: 0s - loss: 3.9078 - acc: 0.757\n",
      "INFO\t2019-09-09 14:48:25 -0400\tmaster-replica-0\t3\t179/212 [========================>.....] - ETA: 0s - loss: 3.8896 - acc: 0.758\n",
      "INFO\t2019-09-09 14:48:25 -0400\tmaster-replica-0\t3\t187/212 [=========================>....] - ETA: 0s - loss: 3.8764 - acc: 0.759\n",
      "INFO\t2019-09-09 14:48:25 -0400\tmaster-replica-0\t3\t197/212 [==========================>...] - ETA: 0s - loss: 3.8797 - acc: 0.759\n",
      "INFO\t2019-09-09 14:48:25 -0400\tmaster-replica-0\t3\t204/212 [===========================>..] - ETA: 0s - loss: 3.8870 - acc: 0.758\n",
      "WARNING\t2019-09-09 14:48:25 -0400\tmaster-replica-0\t4\tFrom /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "WARNING\t2019-09-09 14:48:25 -0400\tmaster-replica-0\t4\tInstructions for updating:\n",
      "WARNING\t2019-09-09 14:48:25 -0400\tmaster-replica-0\t4\tColocations handled automatically by placer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO\t2019-09-09 14:48:25 -0400\tmaster-replica-0\t4\tYour CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
      "ERROR\t2019-09-09 14:48:25 -0400\tmaster-replica-0\t4\tUser settings:\n",
      "ERROR\t2019-09-09 14:48:25 -0400\tmaster-replica-0\t4\t   KMP_AFFINITY=granularity=fine,verbose,compact,1,0\n",
      "ERROR\t2019-09-09 14:48:25 -0400\tmaster-replica-0\t4\t   KMP_BLOCKTIME=0\n",
      "ERROR\t2019-09-09 14:48:25 -0400\tmaster-replica-0\t4\t   KMP_SETTINGS=1\n",
      "ERROR\t2019-09-09 14:48:25 -0400\tmaster-replica-0\t4\t   OMP_NUM_THREADS=4\n",
      "ERROR\t2019-09-09 14:48:25 -0400\tmaster-replica-0\t4\tEffective settings:\n",
      "ERROR\t2019-09-09 14:48:25 -0400\tmaster-replica-0\t4\t   KMP_ABORT_DELAY=0\n",
      "ERROR\t2019-09-09 14:48:25 -0400\tmaster-replica-0\t4\t   KMP_ADAPTIVE_LOCK_PROPS='1,1024'\n",
      "ERROR\t2019-09-09 14:48:25 -0400\tmaster-replica-0\t4\t   KMP_ALIGN_ALLOC=64\n",
      "ERROR\t2019-09-09 14:48:25 -0400\tmaster-replica-0\t4\t   KMP_ALL_THREADPRIVATE=128\n",
      "ERROR\t2019-09-09 14:48:25 -0400\tmaster-replica-0\t4\t   KMP_ATOMIC_MODE=2\n",
      "ERROR\t2019-09-09 14:48:25 -0400\tmaster-replica-0\t4\t   KMP_BLOCKTIME=0\n",
      "ERROR\t2019-09-09 14:48:25 -0400\tmaster-replica-0\t4\t   KMP_CPUINFO_FILE: value is not defined\n",
      "ERROR\t2019-09-09 14:48:25 -0400\tmaster-replica-0\t4\t   KMP_DETERMINISTIC_REDUCTION=false\n",
      "ERROR\t2019-09-09 14:48:25 -0400\tmaster-replica-0\t4\t   KMP_DEVICE_THREAD_LIMIT=2147483647\n",
      "ERROR\t2019-09-09 14:48:25 -0400\tmaster-replica-0\t4\t   KMP_DISP_HAND_THREAD=false\n",
      "ERROR\t2019-09-09 14:48:25 -0400\tmaster-replica-0\t4\t   KMP_DISP_NUM_BUFFERS=7\n",
      "ERROR\t2019-09-09 14:48:25 -0400\tmaster-replica-0\t4\t   KMP_DUPLICATE_LIB_OK=false\n",
      "ERROR\t2019-09-09 14:48:25 -0400\tmaster-replica-0\t4\t   KMP_FORCE_REDUCTION: value is not defined\n",
      "ERROR\t2019-09-09 14:48:25 -0400\tmaster-replica-0\t4\t   KMP_FOREIGN_THREADS_THREADPRIVATE=true\n",
      "ERROR\t2019-09-09 14:48:25 -0400\tmaster-replica-0\t4\t   KMP_FORKJOIN_BARRIER='2,2'\n",
      "ERROR\t2019-09-09 14:48:25 -0400\tmaster-replica-0\t4\t   KMP_FORKJOIN_BARRIER_PATTERN='hyper,hyper'\n",
      "ERROR\t2019-09-09 14:48:25 -0400\tmaster-replica-0\t4\t   KMP_FORKJOIN_FRAMES=true\n",
      "ERROR\t2019-09-09 14:48:25 -0400\tmaster-replica-0\t4\t   KMP_FORKJOIN_FRAMES_MODE=3\n",
      "ERROR\t2019-09-09 14:48:25 -0400\tmaster-replica-0\t4\t   KMP_GTID_MODE=3\n",
      "ERROR\t2019-09-09 14:48:25 -0400\tmaster-replica-0\t4\t   KMP_HANDLE_SIGNALS=false\n",
      "ERROR\t2019-09-09 14:48:25 -0400\tmaster-replica-0\t4\t   KMP_HOT_TEAMS_MAX_LEVEL=1\n",
      "ERROR\t2019-09-09 14:48:25 -0400\tmaster-replica-0\t4\t   KMP_HOT_TEAMS_MODE=0\n",
      "ERROR\t2019-09-09 14:48:25 -0400\tmaster-replica-0\t4\t   KMP_INIT_AT_FORK=true\n",
      "ERROR\t2019-09-09 14:48:25 -0400\tmaster-replica-0\t4\t   KMP_INIT_WAIT=2048\n",
      "ERROR\t2019-09-09 14:48:25 -0400\tmaster-replica-0\t4\t   KMP_ITT_PREPARE_DELAY=0\n",
      "ERROR\t2019-09-09 14:48:25 -0400\tmaster-replica-0\t4\t   KMP_LIBRARY=throughput\n",
      "ERROR\t2019-09-09 14:48:25 -0400\tmaster-replica-0\t4\t   KMP_LOCK_KIND=queuing\n",
      "ERROR\t2019-09-09 14:48:25 -0400\tmaster-replica-0\t4\t   KMP_MALLOC_POOL_INCR=1M\n",
      "ERROR\t2019-09-09 14:48:25 -0400\tmaster-replica-0\t4\t   KMP_NEXT_WAIT=1024\n",
      "ERROR\t2019-09-09 14:48:25 -0400\tmaster-replica-0\t4\t   KMP_NUM_LOCKS_IN_BLOCK=1\n",
      "ERROR\t2019-09-09 14:48:25 -0400\tmaster-replica-0\t4\t   KMP_PLAIN_BARRIER='2,2'\n",
      "ERROR\t2019-09-09 14:48:25 -0400\tmaster-replica-0\t4\t   KMP_PLAIN_BARRIER_PATTERN='hyper,hyper'\n",
      "ERROR\t2019-09-09 14:48:25 -0400\tmaster-replica-0\t4\t   KMP_REDUCTION_BARRIER='1,1'\n",
      "ERROR\t2019-09-09 14:48:25 -0400\tmaster-replica-0\t4\t   KMP_REDUCTION_BARRIER_PATTERN='hyper,hyper'\n",
      "ERROR\t2019-09-09 14:48:25 -0400\tmaster-replica-0\t4\t   KMP_SCHEDULE='static,balanced;guided,iterative'\n",
      "ERROR\t2019-09-09 14:48:25 -0400\tmaster-replica-0\t4\t   KMP_SETTINGS=true\n",
      "ERROR\t2019-09-09 14:48:25 -0400\tmaster-replica-0\t4\t   KMP_SPIN_BACKOFF_PARAMS='4096,100'\n",
      "ERROR\t2019-09-09 14:48:25 -0400\tmaster-replica-0\t4\t   KMP_STACKOFFSET=64\n",
      "ERROR\t2019-09-09 14:48:25 -0400\tmaster-replica-0\t4\t   KMP_STACKPAD=0\n",
      "ERROR\t2019-09-09 14:48:25 -0400\tmaster-replica-0\t4\t   KMP_STACKSIZE=4M\n",
      "ERROR\t2019-09-09 14:48:25 -0400\tmaster-replica-0\t4\t   KMP_STORAGE_MAP=false\n",
      "ERROR\t2019-09-09 14:48:25 -0400\tmaster-replica-0\t4\t   KMP_TASKING=2\n",
      "ERROR\t2019-09-09 14:48:25 -0400\tmaster-replica-0\t4\t   KMP_TASKLOOP_MIN_TASKS=0\n",
      "ERROR\t2019-09-09 14:48:25 -0400\tmaster-replica-0\t4\t   KMP_TASK_STEALING_CONSTRAINT=1\n",
      "ERROR\t2019-09-09 14:48:25 -0400\tmaster-replica-0\t4\t   KMP_TEAMS_THREAD_LIMIT=4\n",
      "ERROR\t2019-09-09 14:48:25 -0400\tmaster-replica-0\t4\t   KMP_TOPOLOGY_METHOD=all\n",
      "ERROR\t2019-09-09 14:48:25 -0400\tmaster-replica-0\t4\t   KMP_USER_LEVEL_MWAIT=false\n",
      "ERROR\t2019-09-09 14:48:25 -0400\tmaster-replica-0\t4\t   KMP_VERSION=false\n",
      "ERROR\t2019-09-09 14:48:25 -0400\tmaster-replica-0\t4\t   KMP_WARNINGS=true\n",
      "ERROR\t2019-09-09 14:48:25 -0400\tmaster-replica-0\t4\t   OMP_AFFINITY_FORMAT='OMP: pid %P tid %T thread %n bound to OS proc set {%a}'\n",
      "ERROR\t2019-09-09 14:48:25 -0400\tmaster-replica-0\t4\t   OMP_ALLOCATOR=omp_default_mem_alloc\n",
      "ERROR\t2019-09-09 14:48:25 -0400\tmaster-replica-0\t4\t   OMP_CANCELLATION=false\n",
      "ERROR\t2019-09-09 14:48:25 -0400\tmaster-replica-0\t4\t   OMP_DEFAULT_DEVICE=0\n",
      "ERROR\t2019-09-09 14:48:25 -0400\tmaster-replica-0\t4\t   OMP_DISPLAY_AFFINITY=false\n",
      "ERROR\t2019-09-09 14:48:25 -0400\tmaster-replica-0\t4\t   OMP_DISPLAY_ENV=false\n",
      "ERROR\t2019-09-09 14:48:25 -0400\tmaster-replica-0\t4\t   OMP_DYNAMIC=false\n",
      "ERROR\t2019-09-09 14:48:25 -0400\tmaster-replica-0\t4\t   OMP_MAX_ACTIVE_LEVELS=2147483647\n",
      "ERROR\t2019-09-09 14:48:25 -0400\tmaster-replica-0\t4\t   OMP_MAX_TASK_PRIORITY=0\n",
      "ERROR\t2019-09-09 14:48:25 -0400\tmaster-replica-0\t4\t   OMP_NESTED=false\n",
      "ERROR\t2019-09-09 14:48:25 -0400\tmaster-replica-0\t4\t   OMP_NUM_THREADS='4'\n",
      "ERROR\t2019-09-09 14:48:25 -0400\tmaster-replica-0\t4\t   OMP_PLACES: value is not defined\n",
      "ERROR\t2019-09-09 14:48:25 -0400\tmaster-replica-0\t4\t   OMP_PROC_BIND='intel'\n",
      "ERROR\t2019-09-09 14:48:25 -0400\tmaster-replica-0\t4\t   OMP_SCHEDULE='static'\n",
      "ERROR\t2019-09-09 14:48:25 -0400\tmaster-replica-0\t4\t   OMP_STACKSIZE=4M\n",
      "ERROR\t2019-09-09 14:48:25 -0400\tmaster-replica-0\t4\t   OMP_TARGET_OFFLOAD=DEFAULT\n",
      "ERROR\t2019-09-09 14:48:25 -0400\tmaster-replica-0\t4\t   OMP_THREAD_LIMIT=2147483647\n",
      "ERROR\t2019-09-09 14:48:25 -0400\tmaster-replica-0\t4\t   OMP_TOOL=enabled\n",
      "ERROR\t2019-09-09 14:48:25 -0400\tmaster-replica-0\t4\t   OMP_TOOL_LIBRARIES: value is not defined\n",
      "ERROR\t2019-09-09 14:48:25 -0400\tmaster-replica-0\t4\t   OMP_WAIT_POLICY=PASSIVE\n",
      "ERROR\t2019-09-09 14:48:25 -0400\tmaster-replica-0\t4\t   KMP_AFFINITY='verbose,warnings,respect,granularity=fine,compact,1,0'\n",
      "INFO\t2019-09-09 14:48:25 -0400\tmaster-replica-0\t4\tCPU Frequency: 2300000000 Hz\n",
      "INFO\t2019-09-09 14:48:25 -0400\tmaster-replica-0\t4\tXLA service 0x3f646d0 executing computations on platform Host. Devices:\n",
      "INFO\t2019-09-09 14:48:25 -0400\tmaster-replica-0\t4\t  StreamExecutor device (0): <undefined>, <undefined>\n",
      "ERROR\t2019-09-09 14:48:25 -0400\tmaster-replica-0\t4\tOMP: Info #212: KMP_AFFINITY: decoding x2APIC ids.\n",
      "ERROR\t2019-09-09 14:48:25 -0400\tmaster-replica-0\t4\tOMP: Info #210: KMP_AFFINITY: Affinity capable, using global cpuid leaf 11 info\n",
      "ERROR\t2019-09-09 14:48:25 -0400\tmaster-replica-0\t4\tOMP: Info #154: KMP_AFFINITY: Initial OS proc set respected: 0-3\n",
      "ERROR\t2019-09-09 14:48:25 -0400\tmaster-replica-0\t4\tOMP: Info #156: KMP_AFFINITY: 4 available OS procs\n",
      "ERROR\t2019-09-09 14:48:25 -0400\tmaster-replica-0\t4\tOMP: Info #157: KMP_AFFINITY: Uniform topology\n",
      "ERROR\t2019-09-09 14:48:25 -0400\tmaster-replica-0\t4\tOMP: Info #179: KMP_AFFINITY: 1 packages x 2 cores/pkg x 2 threads/core (2 total cores)\n",
      "ERROR\t2019-09-09 14:48:25 -0400\tmaster-replica-0\t4\tOMP: Info #214: KMP_AFFINITY: OS proc to physical thread map:\n",
      "ERROR\t2019-09-09 14:48:25 -0400\tmaster-replica-0\t4\tOMP: Info #171: KMP_AFFINITY: OS proc 0 maps to package 0 core 0 thread 0 \n",
      "ERROR\t2019-09-09 14:48:25 -0400\tmaster-replica-0\t4\tOMP: Info #171: KMP_AFFINITY: OS proc 2 maps to package 0 core 0 thread 1 \n",
      "ERROR\t2019-09-09 14:48:25 -0400\tmaster-replica-0\t4\tOMP: Info #171: KMP_AFFINITY: OS proc 1 maps to package 0 core 1 thread 0 \n",
      "ERROR\t2019-09-09 14:48:25 -0400\tmaster-replica-0\t4\tOMP: Info #171: KMP_AFFINITY: OS proc 3 maps to package 0 core 1 thread 1 \n",
      "ERROR\t2019-09-09 14:48:25 -0400\tmaster-replica-0\t4\tOMP: Info #250: KMP_AFFINITY: pid 396 tid 396 thread 0 bound to OS proc set 0\n",
      "INFO\t2019-09-09 14:48:25 -0400\tmaster-replica-0\t4\tCreating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n",
      "ERROR\t2019-09-09 14:48:25 -0400\tmaster-replica-0\t4\tOMP: Info #250: KMP_AFFINITY: pid 396 tid 420 thread 1 bound to OS proc set 1\n",
      "ERROR\t2019-09-09 14:48:25 -0400\tmaster-replica-0\t4\tOMP: Info #250: KMP_AFFINITY: pid 396 tid 419 thread 2 bound to OS proc set 2\n",
      "WARNING\t2019-09-09 14:48:26 -0400\tmaster-replica-0\t4\tFrom /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "WARNING\t2019-09-09 14:48:26 -0400\tmaster-replica-0\t4\tInstructions for updating:\n",
      "WARNING\t2019-09-09 14:48:26 -0400\tmaster-replica-0\t4\tUse tf.cast instead.\n",
      "INFO\t2019-09-09 14:48:26 -0400\tmaster-replica-0\t3\t210/212 [============================>.] - ETA: 0s - loss: 3.8838 - acc: 0.759\n",
      "INFO\t2019-09-09 14:48:26 -0400\tmaster-replica-0\t3\t212/212 [==============================] - 3s 13ms/step - loss: 3.8849 - acc: 0.7590 - val_loss: 3.8072 - val_acc: 0.7638\n",
      "INFO\t2019-09-09 14:48:26 -0400\tmaster-replica-0\t3\tEpoch 00010: LearningRateScheduler reducing learning rate to 0.09882755724746081.\n",
      "INFO\t2019-09-09 14:48:26 -0400\tmaster-replica-0\t3\tEpoch 10/20\n",
      "INFO\t2019-09-09 14:48:26 -0400\tmaster-replica-0\t3\t  1/212 [..............................] - ETA: 1s - loss: 4.4246 - acc: 0.725\n",
      "INFO\t2019-09-09 14:48:26 -0400\tmaster-replica-0\t3\t  9/212 [>.............................] - ETA: 1s - loss: 3.6052 - acc: 0.776\n",
      "INFO\t2019-09-09 14:48:26 -0400\tmaster-replica-0\t3\t 14/212 [>.............................] - ETA: 1s - loss: 3.7022 - acc: 0.770\n",
      "INFO\t2019-09-09 14:48:26 -0400\tmaster-replica-0\t3\t 22/212 [==>...........................] - ETA: 1s - loss: 3.7542 - acc: 0.767\n",
      "INFO\t2019-09-09 14:48:26 -0400\tmaster-replica-0\t3\t 30/212 [===>..........................] - ETA: 1s - loss: 3.8241 - acc: 0.762\n",
      "INFO\t2019-09-09 14:48:26 -0400\tmaster-replica-0\t3\t 38/212 [====>.........................] - ETA: 1s - loss: 3.8479 - acc: 0.761\n",
      "INFO\t2019-09-09 14:48:26 -0400\tmaster-replica-0\t3\t 44/212 [=====>........................] - ETA: 1s - loss: 3.8619 - acc: 0.760\n",
      "INFO\t2019-09-09 14:48:26 -0400\tmaster-replica-0\t3\t 52/212 [======>.......................] - ETA: 1s - loss: 3.8512 - acc: 0.761\n",
      "INFO\t2019-09-09 14:48:26 -0400\tmaster-replica-0\t3\t 58/212 [=======>......................] - ETA: 1s - loss: 3.8670 - acc: 0.760\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO\t2019-09-09 14:48:26 -0400\tmaster-replica-0\t3\t 63/212 [=======>......................] - ETA: 1s - loss: 3.8895 - acc: 0.758\n",
      "INFO\t2019-09-09 14:48:26 -0400\tmaster-replica-0\t3\t 70/212 [========>.....................] - ETA: 1s - loss: 3.8692 - acc: 0.759\n",
      "INFO\t2019-09-09 14:48:27 -0400\tmaster-replica-0\t3\t 78/212 [==========>...................] - ETA: 1s - loss: 3.8830 - acc: 0.759\n",
      "INFO\t2019-09-09 14:48:27 -0400\tmaster-replica-0\t3\t 83/212 [==========>...................] - ETA: 1s - loss: 3.8775 - acc: 0.759\n",
      "INFO\t2019-09-09 14:48:27 -0400\tmaster-replica-0\t3\t 91/212 [===========>..................] - ETA: 0s - loss: 3.8851 - acc: 0.759\n",
      "INFO\t2019-09-09 14:48:27 -0400\tmaster-replica-0\t3\t 99/212 [=============>................] - ETA: 0s - loss: 3.8776 - acc: 0.759\n",
      "INFO\t2019-09-09 14:48:27 -0400\tmaster-replica-0\t3\t104/212 [=============>................] - ETA: 0s - loss: 3.8837 - acc: 0.759\n",
      "INFO\t2019-09-09 14:48:27 -0400\tmaster-replica-0\t3\t112/212 [==============>...............] - ETA: 0s - loss: 3.8809 - acc: 0.759\n",
      "INFO\t2019-09-09 14:48:27 -0400\tmaster-replica-0\t3\t118/212 [===============>..............] - ETA: 0s - loss: 3.8880 - acc: 0.758\n",
      "INFO\t2019-09-09 14:48:27 -0400\tmaster-replica-0\t3\t124/212 [================>.............] - ETA: 0s - loss: 3.8834 - acc: 0.759\n",
      "INFO\t2019-09-09 14:48:27 -0400\tmaster-replica-0\t3\t130/212 [=================>............] - ETA: 0s - loss: 3.8970 - acc: 0.758\n",
      "INFO\t2019-09-09 14:48:27 -0400\tmaster-replica-0\t3\t139/212 [==================>...........] - ETA: 0s - loss: 3.9016 - acc: 0.757\n",
      "INFO\t2019-09-09 14:48:27 -0400\tmaster-replica-0\t3\t145/212 [===================>..........] - ETA: 0s - loss: 3.9015 - acc: 0.757\n",
      "INFO\t2019-09-09 14:48:27 -0400\tmaster-replica-0\t3\t154/212 [====================>.........] - ETA: 0s - loss: 3.8992 - acc: 0.758\n",
      "INFO\t2019-09-09 14:48:27 -0400\tmaster-replica-0\t3\t161/212 [=====================>........] - ETA: 0s - loss: 3.8933 - acc: 0.758\n",
      "INFO\t2019-09-09 14:48:27 -0400\tmaster-replica-0\t3\t169/212 [======================>.......] - ETA: 0s - loss: 3.8791 - acc: 0.759\n",
      "INFO\t2019-09-09 14:48:27 -0400\tmaster-replica-0\t3\t176/212 [=======================>......] - ETA: 0s - loss: 3.8931 - acc: 0.758\n",
      "INFO\t2019-09-09 14:48:27 -0400\tmaster-replica-0\t3\t186/212 [=========================>....] - ETA: 0s - loss: 3.8944 - acc: 0.758\n",
      "INFO\t2019-09-09 14:48:27 -0400\tmaster-replica-0\t3\t193/212 [==========================>...] - ETA: 0s - loss: 3.8787 - acc: 0.759\n",
      "INFO\t2019-09-09 14:48:27 -0400\tmaster-replica-0\t3\t198/212 [===========================>..] - ETA: 0s - loss: 3.8813 - acc: 0.759\n",
      "INFO\t2019-09-09 14:48:29 -0400\tmaster-replica-0\t3\t206/212 [============================>.] - ETA: 0s - loss: 3.8748 - acc: 0.759\n",
      "INFO\t2019-09-09 14:48:29 -0400\tmaster-replica-0\t3\t212/212 [==============================] - 3s 13ms/step - loss: 3.8804 - acc: 0.7592 - val_loss: 3.8072 - val_acc: 0.7638\n",
      "INFO\t2019-09-09 14:48:29 -0400\tmaster-replica-0\t3\tEpoch 00011: LearningRateScheduler reducing learning rate to 0.09881779162246082.\n",
      "INFO\t2019-09-09 14:48:29 -0400\tmaster-replica-0\t3\tEpoch 11/20\n",
      "INFO\t2019-09-09 14:48:29 -0400\tmaster-replica-0\t3\t  1/212 [..............................] - ETA: 2s - loss: 3.8978 - acc: 0.758\n",
      "INFO\t2019-09-09 14:48:29 -0400\tmaster-replica-0\t3\t  6/212 [..............................] - ETA: 2s - loss: 3.7749 - acc: 0.765\n",
      "INFO\t2019-09-09 14:48:29 -0400\tmaster-replica-0\t3\t 15/212 [=>............................] - ETA: 1s - loss: 3.6450 - acc: 0.773\n",
      "INFO\t2019-09-09 14:48:29 -0400\tmaster-replica-0\t3\t 20/212 [=>............................] - ETA: 1s - loss: 3.6397 - acc: 0.774\n",
      "INFO\t2019-09-09 14:48:29 -0400\tmaster-replica-0\t3\t 27/212 [==>...........................] - ETA: 1s - loss: 3.6793 - acc: 0.771\n",
      "INFO\t2019-09-09 14:48:29 -0400\tmaster-replica-0\t3\t 35/212 [===>..........................] - ETA: 1s - loss: 3.7022 - acc: 0.770\n",
      "INFO\t2019-09-09 14:48:29 -0400\tmaster-replica-0\t3\t 42/212 [====>.........................] - ETA: 1s - loss: 3.6846 - acc: 0.771\n",
      "INFO\t2019-09-09 14:48:29 -0400\tmaster-replica-0\t3\t 51/212 [======>.......................] - ETA: 1s - loss: 3.7285 - acc: 0.768\n",
      "INFO\t2019-09-09 14:48:29 -0400\tmaster-replica-0\t3\t 58/212 [=======>......................] - ETA: 1s - loss: 3.7652 - acc: 0.766\n",
      "INFO\t2019-09-09 14:48:29 -0400\tmaster-replica-0\t3\t 66/212 [========>.....................] - ETA: 1s - loss: 3.8132 - acc: 0.763\n",
      "INFO\t2019-09-09 14:48:29 -0400\tmaster-replica-0\t3\t 73/212 [=========>....................] - ETA: 1s - loss: 3.8459 - acc: 0.761\n",
      "INFO\t2019-09-09 14:48:29 -0400\tmaster-replica-0\t3\t 82/212 [==========>...................] - ETA: 0s - loss: 3.8683 - acc: 0.760\n",
      "INFO\t2019-09-09 14:48:29 -0400\tmaster-replica-0\t3\t 90/212 [===========>..................] - ETA: 0s - loss: 3.8978 - acc: 0.758\n",
      "INFO\t2019-09-09 14:48:29 -0400\tmaster-replica-0\t3\t100/212 [=============>................] - ETA: 0s - loss: 3.9021 - acc: 0.757\n",
      "INFO\t2019-09-09 14:48:29 -0400\tmaster-replica-0\t3\t106/212 [==============>...............] - ETA: 0s - loss: 3.9058 - acc: 0.757\n",
      "INFO\t2019-09-09 14:48:30 -0400\tmaster-replica-0\t3\t113/212 [==============>...............] - ETA: 0s - loss: 3.9006 - acc: 0.758\n",
      "INFO\t2019-09-09 14:48:30 -0400\tmaster-replica-0\t3\t120/212 [===============>..............] - ETA: 0s - loss: 3.8917 - acc: 0.758\n",
      "INFO\t2019-09-09 14:48:30 -0400\tmaster-replica-0\t3\t129/212 [=================>............] - ETA: 0s - loss: 3.9003 - acc: 0.758\n",
      "INFO\t2019-09-09 14:48:30 -0400\tmaster-replica-0\t3\t138/212 [==================>...........] - ETA: 0s - loss: 3.9009 - acc: 0.758\n",
      "INFO\t2019-09-09 14:48:30 -0400\tmaster-replica-0\t3\t146/212 [===================>..........] - ETA: 0s - loss: 3.9014 - acc: 0.757\n",
      "INFO\t2019-09-09 14:48:30 -0400\tmaster-replica-0\t3\t154/212 [====================>.........] - ETA: 0s - loss: 3.8978 - acc: 0.758\n",
      "INFO\t2019-09-09 14:48:30 -0400\tmaster-replica-0\t3\t159/212 [=====================>........] - ETA: 0s - loss: 3.8965 - acc: 0.758\n",
      "INFO\t2019-09-09 14:48:30 -0400\tmaster-replica-0\t3\t167/212 [======================>.......] - ETA: 0s - loss: 3.9067 - acc: 0.757\n",
      "INFO\t2019-09-09 14:48:30 -0400\tmaster-replica-0\t3\t174/212 [=======================>......] - ETA: 0s - loss: 3.9033 - acc: 0.757\n",
      "INFO\t2019-09-09 14:48:30 -0400\tmaster-replica-0\t3\t180/212 [========================>.....] - ETA: 0s - loss: 3.9054 - acc: 0.757\n",
      "INFO\t2019-09-09 14:48:30 -0400\tmaster-replica-0\t3\t187/212 [=========================>....] - ETA: 0s - loss: 3.9142 - acc: 0.757\n",
      "INFO\t2019-09-09 14:48:30 -0400\tmaster-replica-0\t3\t196/212 [==========================>...] - ETA: 0s - loss: 3.8957 - acc: 0.758\n",
      "INFO\t2019-09-09 14:48:31 -0400\tmaster-replica-0\t3\t202/212 [===========================>..] - ETA: 0s - loss: 3.8921 - acc: 0.758\n",
      "INFO\t2019-09-09 14:48:31 -0400\tmaster-replica-0\t3\t212/212 [==============================] - 3s 13ms/step - loss: 3.8775 - acc: 0.7594 - val_loss: 3.8072 - val_acc: 0.7638\n",
      "INFO\t2019-09-09 14:48:31 -0400\tmaster-replica-0\t3\tEpoch 00012: LearningRateScheduler reducing learning rate to 0.09881290880996081.\n",
      "INFO\t2019-09-09 14:48:31 -0400\tmaster-replica-0\t3\tEpoch 12/20\n",
      "INFO\t2019-09-09 14:48:31 -0400\tmaster-replica-0\t3\t  1/212 [..............................] - ETA: 8s - loss: 4.2139 - acc: 0.738\n",
      "INFO\t2019-09-09 14:48:31 -0400\tmaster-replica-0\t3\t  7/212 [..............................] - ETA: 2s - loss: 3.7172 - acc: 0.769\n",
      "INFO\t2019-09-09 14:48:32 -0400\tmaster-replica-0\t3\t 14/212 [>.............................] - ETA: 2s - loss: 3.9204 - acc: 0.756\n",
      "INFO\t2019-09-09 14:48:32 -0400\tmaster-replica-0\t3\t 22/212 [==>...........................] - ETA: 1s - loss: 4.0080 - acc: 0.751\n",
      "ERROR\t2019-09-09 14:48:32 -0400\tmaster-replica-0\t4\tOMP: Info #250: KMP_AFFINITY: pid 396 tid 483 thread 3 bound to OS proc set 3\n",
      "ERROR\t2019-09-09 14:48:32 -0400\tmaster-replica-0\t4\tOMP: Info #250: KMP_AFFINITY: pid 396 tid 484 thread 4 bound to OS proc set 0\n",
      "ERROR\t2019-09-09 14:48:32 -0400\tmaster-replica-0\t4\tOMP: Info #250: KMP_AFFINITY: pid 396 tid 485 thread 5 bound to OS proc set 1\n",
      "ERROR\t2019-09-09 14:48:32 -0400\tmaster-replica-0\t4\tOMP: Info #250: KMP_AFFINITY: pid 396 tid 486 thread 6 bound to OS proc set 2\n",
      "ERROR\t2019-09-09 14:48:32 -0400\tmaster-replica-0\t4\tOMP: Info #250: KMP_AFFINITY: pid 396 tid 487 thread 7 bound to OS proc set 3\n",
      "ERROR\t2019-09-09 14:48:32 -0400\tmaster-replica-0\t4\tOMP: Info #250: KMP_AFFINITY: pid 396 tid 488 thread 8 bound to OS proc set 0\n",
      "INFO\t2019-09-09 14:48:32 -0400\tmaster-replica-0\t4\tEpoch 00001: LearningRateScheduler reducing learning rate to 0.04666403148705935.\n",
      "INFO\t2019-09-09 14:48:32 -0400\tmaster-replica-0\t4\tEpoch 1/20\n",
      "INFO\t2019-09-09 14:48:32 -0400\tmaster-replica-0\t3\t 32/212 [===>..........................] - ETA: 1s - loss: 3.8978 - acc: 0.758\n",
      "INFO\t2019-09-09 14:48:32 -0400\tmaster-replica-0\t4\t  1/446 [..............................] - ETA: 6:25 - loss: 0.6549 - acc: 0.698\n",
      "INFO\t2019-09-09 14:48:32 -0400\tmaster-replica-0\t3\t 42/212 [====>.........................] - ETA: 1s - loss: 3.8527 - acc: 0.761\n",
      "INFO\t2019-09-09 14:48:32 -0400\tmaster-replica-0\t4\t 16/446 [>.............................] - ETA: 24s - loss: 3.7117 - acc: 0.753\n",
      "INFO\t2019-09-09 14:48:32 -0400\tmaster-replica-0\t3\t 48/212 [=====>........................] - ETA: 1s - loss: 3.8474 - acc: 0.761\n",
      "INFO\t2019-09-09 14:48:32 -0400\tmaster-replica-0\t4\t 30/446 [=>............................] - ETA: 13s - loss: 3.7606 - acc: 0.75\n",
      "INFO\t2019-09-09 14:48:32 -0400\tmaster-replica-0\t3\t 57/212 [=======>......................] - ETA: 1s - loss: 3.8794 - acc: 0.759\n",
      "INFO\t2019-09-09 14:48:32 -0400\tmaster-replica-0\t4\t 46/446 [==>...........................] - ETA: 8s - loss: 3.7390 - acc: 0.7624\n",
      "INFO\t2019-09-09 14:48:32 -0400\tmaster-replica-0\t3\t 64/212 [========>.....................] - ETA: 1s - loss: 3.8336 - acc: 0.762\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO\t2019-09-09 14:48:32 -0400\tmaster-replica-0\t4\t 60/446 [===>..........................] - ETA: 6s - loss: 3.7644 - acc: 0.762\n",
      "INFO\t2019-09-09 14:48:32 -0400\tmaster-replica-0\t3\t 74/212 [=========>....................] - ETA: 0s - loss: 3.8352 - acc: 0.762\n",
      "INFO\t2019-09-09 14:48:32 -0400\tmaster-replica-0\t4\t 76/446 [====>.........................] - ETA: 5s - loss: 3.7651 - acc: 0.763\n",
      "INFO\t2019-09-09 14:48:32 -0400\tmaster-replica-0\t3\t 79/212 [==========>...................] - ETA: 0s - loss: 3.8458 - acc: 0.761\n",
      "INFO\t2019-09-09 14:48:32 -0400\tmaster-replica-0\t4\t 89/446 [====>.........................] - ETA: 4s - loss: 3.8502 - acc: 0.758\n",
      "INFO\t2019-09-09 14:48:32 -0400\tmaster-replica-0\t3\t 88/212 [===========>..................] - ETA: 0s - loss: 3.8476 - acc: 0.761\n",
      "INFO\t2019-09-09 14:48:32 -0400\tmaster-replica-0\t4\t104/446 [=====>........................] - ETA: 4s - loss: 3.8851 - acc: 0.756\n",
      "INFO\t2019-09-09 14:48:32 -0400\tmaster-replica-0\t3\t 98/212 [============>.................] - ETA: 0s - loss: 3.8602 - acc: 0.760\n",
      "INFO\t2019-09-09 14:48:32 -0400\tmaster-replica-0\t4\t118/446 [======>.......................] - ETA: 3s - loss: 3.8844 - acc: 0.756\n",
      "INFO\t2019-09-09 14:48:32 -0400\tmaster-replica-0\t3\t104/212 [=============>................] - ETA: 0s - loss: 3.8512 - acc: 0.761\n",
      "INFO\t2019-09-09 14:48:32 -0400\tmaster-replica-0\t4\t135/446 [========>.....................] - ETA: 3s - loss: 3.8909 - acc: 0.756\n",
      "INFO\t2019-09-09 14:48:32 -0400\tmaster-replica-0\t3\t114/212 [===============>..............] - ETA: 0s - loss: 3.8572 - acc: 0.760\n",
      "INFO\t2019-09-09 14:48:32 -0400\tmaster-replica-0\t4\t149/446 [=========>....................] - ETA: 2s - loss: 3.9002 - acc: 0.756\n",
      "INFO\t2019-09-09 14:48:32 -0400\tmaster-replica-0\t3\t123/212 [================>.............] - ETA: 0s - loss: 3.8550 - acc: 0.760\n",
      "INFO\t2019-09-09 14:48:32 -0400\tmaster-replica-0\t4\t165/446 [==========>...................] - ETA: 2s - loss: 3.8967 - acc: 0.756\n",
      "INFO\t2019-09-09 14:48:32 -0400\tmaster-replica-0\t4\t178/446 [==========>...................] - ETA: 2s - loss: 3.9172 - acc: 0.755\n",
      "INFO\t2019-09-09 14:48:32 -0400\tmaster-replica-0\t3\t132/212 [=================>............] - ETA: 0s - loss: 3.8563 - acc: 0.760\n",
      "INFO\t2019-09-09 14:48:32 -0400\tmaster-replica-0\t4\t193/446 [===========>..................] - ETA: 2s - loss: 3.8713 - acc: 0.758\n",
      "INFO\t2019-09-09 14:48:32 -0400\tmaster-replica-0\t3\t140/212 [==================>...........] - ETA: 0s - loss: 3.8602 - acc: 0.760\n",
      "INFO\t2019-09-09 14:48:32 -0400\tmaster-replica-0\t4\t206/446 [============>.................] - ETA: 1s - loss: 3.8607 - acc: 0.759\n",
      "INFO\t2019-09-09 14:48:32 -0400\tmaster-replica-0\t3\t150/212 [====================>.........] - ETA: 0s - loss: 3.8669 - acc: 0.760\n",
      "INFO\t2019-09-09 14:48:32 -0400\tmaster-replica-0\t4\t223/446 [==============>...............] - ETA: 1s - loss: 3.8386 - acc: 0.760\n",
      "INFO\t2019-09-09 14:48:32 -0400\tmaster-replica-0\t3\t156/212 [=====================>........] - ETA: 0s - loss: 3.8627 - acc: 0.760\n",
      "INFO\t2019-09-09 14:48:33 -0400\tmaster-replica-0\t4\t237/446 [==============>...............] - ETA: 1s - loss: 3.8308 - acc: 0.761\n",
      "INFO\t2019-09-09 14:48:33 -0400\tmaster-replica-0\t3\t166/212 [======================>.......] - ETA: 0s - loss: 3.8712 - acc: 0.759\n",
      "INFO\t2019-09-09 14:48:33 -0400\tmaster-replica-0\t4\t253/446 [================>.............] - ETA: 1s - loss: 3.8530 - acc: 0.759\n",
      "INFO\t2019-09-09 14:48:33 -0400\tmaster-replica-0\t3\t174/212 [=======================>......] - ETA: 0s - loss: 3.8851 - acc: 0.759\n",
      "INFO\t2019-09-09 14:48:33 -0400\tmaster-replica-0\t4\t266/446 [================>.............] - ETA: 1s - loss: 3.8473 - acc: 0.760\n",
      "INFO\t2019-09-09 14:48:33 -0400\tmaster-replica-0\t3\t183/212 [========================>.....] - ETA: 0s - loss: 3.8765 - acc: 0.759\n",
      "INFO\t2019-09-09 14:48:33 -0400\tmaster-replica-0\t4\t283/446 [==================>...........] - ETA: 1s - loss: 3.8573 - acc: 0.759\n",
      "INFO\t2019-09-09 14:48:33 -0400\tmaster-replica-0\t3\t192/212 [==========================>...] - ETA: 0s - loss: 3.8699 - acc: 0.759\n",
      "INFO\t2019-09-09 14:48:33 -0400\tmaster-replica-0\t4\t295/446 [==================>...........] - ETA: 0s - loss: 3.8583 - acc: 0.759\n",
      "INFO\t2019-09-09 14:48:33 -0400\tmaster-replica-0\t3\t202/212 [===========================>..] - ETA: 0s - loss: 3.8676 - acc: 0.760\n",
      "INFO\t2019-09-09 14:48:33 -0400\tmaster-replica-0\t4\t312/446 [===================>..........] - ETA: 0s - loss: 3.8604 - acc: 0.759\n",
      "INFO\t2019-09-09 14:48:33 -0400\tmaster-replica-0\t4\t325/446 [====================>.........] - ETA: 0s - loss: 3.8629 - acc: 0.759\n",
      "INFO\t2019-09-09 14:48:33 -0400\tmaster-replica-0\t4\t342/446 [======================>.......] - ETA: 0s - loss: 3.8691 - acc: 0.759\n",
      "INFO\t2019-09-09 14:48:33 -0400\tmaster-replica-0\t4\t359/446 [=======================>......] - ETA: 0s - loss: 3.8790 - acc: 0.758\n",
      "INFO\t2019-09-09 14:48:33 -0400\tmaster-replica-0\t4\t372/446 [========================>.....] - ETA: 0s - loss: 3.8787 - acc: 0.758\n",
      "INFO\t2019-09-09 14:48:33 -0400\tmaster-replica-0\t4\t388/446 [=========================>....] - ETA: 0s - loss: 3.8776 - acc: 0.758\n",
      "INFO\t2019-09-09 14:48:33 -0400\tmaster-replica-0\t4\t402/446 [==========================>...] - ETA: 0s - loss: 3.8870 - acc: 0.758\n",
      "INFO\t2019-09-09 14:48:33 -0400\tmaster-replica-0\t4\t418/446 [===========================>..] - ETA: 0s - loss: 3.8850 - acc: 0.758\n",
      "WARNING\t2019-09-09 14:48:34 -0400\tmaster-replica-0\t4\tfile_cache is unavailable when using oauth2client >= 4.0.0 or google-auth\n",
      "INFO\t2019-09-09 14:48:34 -0400\tmaster-replica-0\t4\tAttempting refresh to obtain initial access_token\n",
      "INFO\t2019-09-09 14:48:34 -0400\tmaster-replica-0\t3\t211/212 [============================>.] - ETA: 0s - loss: 3.8564 - acc: 0.760\n",
      "INFO\t2019-09-09 14:48:34 -0400\tmaster-replica-0\t3\t212/212 [==============================] - 3s 14ms/step - loss: 3.8546 - acc: 0.7609 - val_loss: 3.8072 - val_acc: 0.7638\n",
      "INFO\t2019-09-09 14:48:34 -0400\tmaster-replica-0\t3\tEpoch 00013: LearningRateScheduler reducing learning rate to 0.09881046740371081.\n",
      "INFO\t2019-09-09 14:48:34 -0400\tmaster-replica-0\t3\tEpoch 13/20\n",
      "INFO\t2019-09-09 14:48:34 -0400\tmaster-replica-0\t3\t  1/212 [..............................] - ETA: 1s - loss: 4.7406 - acc: 0.705\n",
      "INFO\t2019-09-09 14:48:34 -0400\tmaster-replica-0\t3\t 10/212 [>.............................] - ETA: 1s - loss: 4.3403 - acc: 0.730\n",
      "INFO\t2019-09-09 14:48:34 -0400\tmaster-replica-0\t3\t 21/212 [=>............................] - ETA: 1s - loss: 4.1587 - acc: 0.742\n",
      "INFO\t2019-09-09 14:48:35 -0400\tmaster-replica-0\t3\t 30/212 [===>..........................] - ETA: 1s - loss: 3.9997 - acc: 0.751\n",
      "INFO\t2019-09-09 14:48:35 -0400\tmaster-replica-0\t3\t 41/212 [====>.........................] - ETA: 0s - loss: 3.8927 - acc: 0.758\n",
      "INFO\t2019-09-09 14:48:35 -0400\tmaster-replica-0\t3\t 50/212 [======>.......................] - ETA: 0s - loss: 3.8852 - acc: 0.759\n",
      "INFO\t2019-09-09 14:48:35 -0400\tmaster-replica-0\t3\t 61/212 [=======>......................] - ETA: 0s - loss: 3.9117 - acc: 0.757\n",
      "INFO\t2019-09-09 14:48:35 -0400\tmaster-replica-0\t3\t 71/212 [=========>....................] - ETA: 0s - loss: 3.9156 - acc: 0.757\n",
      "INFO\t2019-09-09 14:48:35 -0400\tmaster-replica-0\t3\t 83/212 [==========>...................] - ETA: 0s - loss: 3.8560 - acc: 0.760\n",
      "INFO\t2019-09-09 14:48:35 -0400\tmaster-replica-0\t3\t 92/212 [============>.................] - ETA: 0s - loss: 3.8623 - acc: 0.760\n",
      "INFO\t2019-09-09 14:48:35 -0400\tmaster-replica-0\t3\t102/212 [=============>................] - ETA: 0s - loss: 3.8452 - acc: 0.761\n",
      "INFO\t2019-09-09 14:48:35 -0400\tmaster-replica-0\t3\t111/212 [==============>...............] - ETA: 0s - loss: 3.8732 - acc: 0.759\n",
      "INFO\t2019-09-09 14:48:35 -0400\tmaster-replica-0\t3\t122/212 [================>.............] - ETA: 0s - loss: 3.8685 - acc: 0.760\n",
      "INFO\t2019-09-09 14:48:35 -0400\tmaster-replica-0\t3\t132/212 [=================>............] - ETA: 0s - loss: 3.8891 - acc: 0.758\n",
      "INFO\t2019-09-09 14:48:35 -0400\tmaster-replica-0\t3\t143/212 [===================>..........] - ETA: 0s - loss: 3.8875 - acc: 0.758\n",
      "INFO\t2019-09-09 14:48:35 -0400\tmaster-replica-0\t3\t154/212 [====================>.........] - ETA: 0s - loss: 3.8985 - acc: 0.758\n",
      "INFO\t2019-09-09 14:48:35 -0400\tmaster-replica-0\t3\t163/212 [======================>.......] - ETA: 0s - loss: 3.9037 - acc: 0.757\n",
      "INFO\t2019-09-09 14:48:35 -0400\tmaster-replica-0\t4\t432/446 [============================>.] - ETA: 0s - loss: 3.8808 - acc: 0.758\n",
      "INFO\t2019-09-09 14:48:35 -0400\tmaster-replica-0\t4\t446/446 [==============================] - 4s 10ms/step - loss: 3.8718 - acc: 0.7592 - val_loss: 3.8072 - val_acc: 0.7638\n",
      "INFO\t2019-09-09 14:48:35 -0400\tmaster-replica-0\t4\tEpoch 00002: LearningRateScheduler reducing learning rate to 0.04166403148705935.\n",
      "INFO\t2019-09-09 14:48:35 -0400\tmaster-replica-0\t4\tEpoch 2/20\n",
      "INFO\t2019-09-09 14:48:35 -0400\tmaster-replica-0\t3\t174/212 [=======================>......] - ETA: 0s - loss: 3.8966 - acc: 0.758\n",
      "INFO\t2019-09-09 14:48:35 -0400\tmaster-replica-0\t4\t  1/446 [..............................] - ETA: 1s - loss: 3.5327 - acc: 0.780\n",
      "INFO\t2019-09-09 14:48:35 -0400\tmaster-replica-0\t3\t183/212 [========================>.....] - ETA: 0s - loss: 3.9007 - acc: 0.758\n",
      "INFO\t2019-09-09 14:48:35 -0400\tmaster-replica-0\t4\t 18/446 [>.............................] - ETA: 1s - loss: 3.8149 - acc: 0.763\n",
      "INFO\t2019-09-09 14:48:35 -0400\tmaster-replica-0\t3\t194/212 [==========================>...] - ETA: 0s - loss: 3.9087 - acc: 0.757\n",
      "INFO\t2019-09-09 14:48:35 -0400\tmaster-replica-0\t4\t 23/446 [>.............................] - ETA: 2s - loss: 3.7247 - acc: 0.768\n",
      "INFO\t2019-09-09 14:48:35 -0400\tmaster-replica-0\t4\t 37/446 [=>............................] - ETA: 1s - loss: 3.6760 - acc: 0.771\n",
      "INFO\t2019-09-09 14:48:36 -0400\tmaster-replica-0\t4\t 48/446 [==>...........................] - ETA: 1s - loss: 3.6983 - acc: 0.770\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO\t2019-09-09 14:48:36 -0400\tmaster-replica-0\t4\t 55/446 [==>...........................] - ETA: 1s - loss: 3.7616 - acc: 0.766\n",
      "INFO\t2019-09-09 14:48:36 -0400\tmaster-replica-0\t4\t 67/446 [===>..........................] - ETA: 1s - loss: 3.8260 - acc: 0.762\n",
      "INFO\t2019-09-09 14:48:36 -0400\tmaster-replica-0\t4\t 76/446 [====>.........................] - ETA: 1s - loss: 3.8523 - acc: 0.761\n",
      "INFO\t2019-09-09 14:48:36 -0400\tmaster-replica-0\t4\t 88/446 [====>.........................] - ETA: 1s - loss: 3.8664 - acc: 0.760\n",
      "INFO\t2019-09-09 14:48:36 -0400\tmaster-replica-0\t4\t 94/446 [=====>........................] - ETA: 1s - loss: 3.8804 - acc: 0.759\n",
      "INFO\t2019-09-09 14:48:36 -0400\tmaster-replica-0\t4\t109/446 [======>.......................] - ETA: 1s - loss: 3.9237 - acc: 0.756\n",
      "INFO\t2019-09-09 14:48:36 -0400\tmaster-replica-0\t4\t116/446 [======>.......................] - ETA: 1s - loss: 3.9039 - acc: 0.757\n",
      "INFO\t2019-09-09 14:48:36 -0400\tmaster-replica-0\t4\t125/446 [=======>......................] - ETA: 1s - loss: 3.9284 - acc: 0.756\n",
      "INFO\t2019-09-09 14:48:36 -0400\tmaster-replica-0\t4\t136/446 [========>.....................] - ETA: 1s - loss: 3.9305 - acc: 0.756\n",
      "INFO\t2019-09-09 14:48:36 -0400\tmaster-replica-0\t4\t146/446 [========>.....................] - ETA: 1s - loss: 3.9169 - acc: 0.757\n",
      "INFO\t2019-09-09 14:48:36 -0400\tmaster-replica-0\t4\t152/446 [=========>....................] - ETA: 1s - loss: 3.9104 - acc: 0.757\n",
      "INFO\t2019-09-09 14:48:36 -0400\tmaster-replica-0\t4\t163/446 [=========>....................] - ETA: 1s - loss: 3.9323 - acc: 0.756\n",
      "INFO\t2019-09-09 14:48:36 -0400\tmaster-replica-0\t4\t173/446 [==========>...................] - ETA: 1s - loss: 3.9411 - acc: 0.755\n",
      "INFO\t2019-09-09 14:48:36 -0400\tmaster-replica-0\t4\t188/446 [===========>..................] - ETA: 1s - loss: 3.9273 - acc: 0.756\n",
      "INFO\t2019-09-09 14:48:36 -0400\tmaster-replica-0\t4\t201/446 [============>.................] - ETA: 1s - loss: 3.8996 - acc: 0.758\n",
      "INFO\t2019-09-09 14:48:36 -0400\tmaster-replica-0\t4\t216/446 [=============>................] - ETA: 1s - loss: 3.9130 - acc: 0.757\n",
      "INFO\t2019-09-09 14:48:36 -0400\tmaster-replica-0\t4\t221/446 [=============>................] - ETA: 1s - loss: 3.9204 - acc: 0.756\n",
      "INFO\t2019-09-09 14:48:36 -0400\tmaster-replica-0\t4\t229/446 [==============>...............] - ETA: 1s - loss: 3.9039 - acc: 0.757\n",
      "INFO\t2019-09-09 14:48:37 -0400\tmaster-replica-0\t4\t242/446 [===============>..............] - ETA: 1s - loss: 3.8831 - acc: 0.759\n",
      "INFO\t2019-09-09 14:48:37 -0400\tmaster-replica-0\t4\t252/446 [===============>..............] - ETA: 0s - loss: 3.8972 - acc: 0.758\n",
      "INFO\t2019-09-09 14:48:37 -0400\tmaster-replica-0\t3\t203/212 [===========================>..] - ETA: 0s - loss: 3.9108 - acc: 0.757\n",
      "INFO\t2019-09-09 14:48:37 -0400\tmaster-replica-0\t3\t212/212 [==============================] - 2s 11ms/step - loss: 3.9048 - acc: 0.7577 - val_loss: 3.8072 - val_acc: 0.7638\n",
      "INFO\t2019-09-09 14:48:37 -0400\tmaster-replica-0\t4\t264/446 [================>.............] - ETA: 0s - loss: 3.8965 - acc: 0.758\n",
      "INFO\t2019-09-09 14:48:37 -0400\tmaster-replica-0\t3\tEpoch 00014: LearningRateScheduler reducing learning rate to 0.09880924670058581.\n",
      "INFO\t2019-09-09 14:48:37 -0400\tmaster-replica-0\t3\tEpoch 14/20\n",
      "INFO\t2019-09-09 14:48:37 -0400\tmaster-replica-0\t4\t274/446 [=================>............] - ETA: 0s - loss: 3.8849 - acc: 0.759\n",
      "INFO\t2019-09-09 14:48:37 -0400\tmaster-replica-0\t3\t  1/212 [..............................] - ETA: 13s - loss: 3.7925 - acc: 0.76\n",
      "INFO\t2019-09-09 14:48:37 -0400\tmaster-replica-0\t4\t284/446 [==================>...........] - ETA: 0s - loss: 3.8748 - acc: 0.759\n",
      "INFO\t2019-09-09 14:48:37 -0400\tmaster-replica-0\t3\t 12/212 [>.............................] - ETA: 1s - loss: 3.8101 - acc: 0.7636\n",
      "INFO\t2019-09-09 14:48:37 -0400\tmaster-replica-0\t4\t290/446 [==================>...........] - ETA: 0s - loss: 3.8738 - acc: 0.759\n",
      "INFO\t2019-09-09 14:48:37 -0400\tmaster-replica-0\t3\t 21/212 [=>............................] - ETA: 1s - loss: 3.8928 - acc: 0.758\n",
      "INFO\t2019-09-09 14:48:37 -0400\tmaster-replica-0\t4\t303/446 [===================>..........] - ETA: 0s - loss: 3.8701 - acc: 0.759\n",
      "INFO\t2019-09-09 14:48:37 -0400\tmaster-replica-0\t3\t 32/212 [===>..........................] - ETA: 1s - loss: 3.9308 - acc: 0.756\n",
      "INFO\t2019-09-09 14:48:37 -0400\tmaster-replica-0\t4\t310/446 [===================>..........] - ETA: 0s - loss: 3.8668 - acc: 0.760\n",
      "INFO\t2019-09-09 14:48:37 -0400\tmaster-replica-0\t3\t 40/212 [====>.........................] - ETA: 1s - loss: 3.9795 - acc: 0.753\n",
      "INFO\t2019-09-09 14:48:37 -0400\tmaster-replica-0\t4\t321/446 [====================>.........] - ETA: 0s - loss: 3.8815 - acc: 0.759\n",
      "INFO\t2019-09-09 14:48:37 -0400\tmaster-replica-0\t3\t 51/212 [======>.......................] - ETA: 1s - loss: 3.9867 - acc: 0.752\n",
      "INFO\t2019-09-09 14:48:37 -0400\tmaster-replica-0\t4\t331/446 [=====================>........] - ETA: 0s - loss: 3.8883 - acc: 0.758\n",
      "INFO\t2019-09-09 14:48:37 -0400\tmaster-replica-0\t3\t 60/212 [=======>......................] - ETA: 0s - loss: 3.9681 - acc: 0.753\n",
      "INFO\t2019-09-09 14:48:37 -0400\tmaster-replica-0\t4\t343/446 [======================>.......] - ETA: 0s - loss: 3.9009 - acc: 0.758\n",
      "INFO\t2019-09-09 14:48:37 -0400\tmaster-replica-0\t3\t 72/212 [=========>....................] - ETA: 0s - loss: 3.9125 - acc: 0.757\n",
      "INFO\t2019-09-09 14:48:37 -0400\tmaster-replica-0\t4\t355/446 [======================>.......] - ETA: 0s - loss: 3.9084 - acc: 0.757\n",
      "INFO\t2019-09-09 14:48:37 -0400\tmaster-replica-0\t3\t 82/212 [==========>...................] - ETA: 0s - loss: 3.9248 - acc: 0.756\n",
      "INFO\t2019-09-09 14:48:37 -0400\tmaster-replica-0\t4\t367/446 [=======================>......] - ETA: 0s - loss: 3.9093 - acc: 0.757\n",
      "INFO\t2019-09-09 14:48:37 -0400\tmaster-replica-0\t3\t 94/212 [============>.................] - ETA: 0s - loss: 3.9483 - acc: 0.755\n",
      "INFO\t2019-09-09 14:48:37 -0400\tmaster-replica-0\t4\t379/446 [========================>.....] - ETA: 0s - loss: 3.9050 - acc: 0.757\n",
      "INFO\t2019-09-09 14:48:37 -0400\tmaster-replica-0\t3\t103/212 [=============>................] - ETA: 0s - loss: 3.9152 - acc: 0.757\n",
      "INFO\t2019-09-09 14:48:37 -0400\tmaster-replica-0\t4\t393/446 [=========================>....] - ETA: 0s - loss: 3.9063 - acc: 0.757\n",
      "INFO\t2019-09-09 14:48:37 -0400\tmaster-replica-0\t3\t114/212 [===============>..............] - ETA: 0s - loss: 3.9302 - acc: 0.756\n",
      "INFO\t2019-09-09 14:48:37 -0400\tmaster-replica-0\t4\t406/446 [==========================>...] - ETA: 0s - loss: 3.9085 - acc: 0.757\n",
      "INFO\t2019-09-09 14:48:37 -0400\tmaster-replica-0\t3\t123/212 [================>.............] - ETA: 0s - loss: 3.9090 - acc: 0.757\n",
      "INFO\t2019-09-09 14:48:37 -0400\tmaster-replica-0\t4\t420/446 [===========================>..] - ETA: 0s - loss: 3.8939 - acc: 0.758\n",
      "INFO\t2019-09-09 14:48:37 -0400\tmaster-replica-0\t3\t135/212 [==================>...........] - ETA: 0s - loss: 3.9017 - acc: 0.757\n",
      "INFO\t2019-09-09 14:48:37 -0400\tmaster-replica-0\t4\t432/446 [============================>.] - ETA: 0s - loss: 3.8920 - acc: 0.758\n",
      "INFO\t2019-09-09 14:48:37 -0400\tmaster-replica-0\t3\t145/212 [===================>..........] - ETA: 0s - loss: 3.8957 - acc: 0.758\n",
      "INFO\t2019-09-09 14:48:38 -0400\tmaster-replica-0\t3\t156/212 [=====================>........] - ETA: 0s - loss: 3.8729 - acc: 0.759\n",
      "INFO\t2019-09-09 14:48:38 -0400\tmaster-replica-0\t3\t166/212 [======================>.......] - ETA: 0s - loss: 3.8712 - acc: 0.759\n",
      "INFO\t2019-09-09 14:48:38 -0400\tmaster-replica-0\t3\t175/212 [=======================>......] - ETA: 0s - loss: 3.8822 - acc: 0.759\n",
      "INFO\t2019-09-09 14:48:38 -0400\tmaster-replica-0\t3\t187/212 [=========================>....] - ETA: 0s - loss: 3.8838 - acc: 0.759\n",
      "INFO\t2019-09-09 14:48:38 -0400\tmaster-replica-0\t3\t196/212 [==========================>...] - ETA: 0s - loss: 3.8844 - acc: 0.759\n",
      "INFO\t2019-09-09 14:48:39 -0400\tmaster-replica-0\t4\t440/446 [============================>.] - ETA: 0s - loss: 3.8920 - acc: 0.758\n",
      "INFO\t2019-09-09 14:48:39 -0400\tmaster-replica-0\t4\t446/446 [==============================] - 3s 8ms/step - loss: 3.8813 - acc: 0.7592 - val_loss: 3.8072 - val_acc: 0.7638\n",
      "INFO\t2019-09-09 14:48:39 -0400\tmaster-replica-0\t4\tEpoch 00003: LearningRateScheduler reducing learning rate to 0.03916403148705935.\n",
      "INFO\t2019-09-09 14:48:39 -0400\tmaster-replica-0\t4\tEpoch 3/20\n",
      "INFO\t2019-09-09 14:48:39 -0400\tmaster-replica-0\t4\t  1/446 [..............................] - ETA: 37s - loss: 5.0783 - acc: 0.68\n",
      "INFO\t2019-09-09 14:48:39 -0400\tmaster-replica-0\t4\t 17/446 [>.............................] - ETA: 3s - loss: 4.0652 - acc: 0.7478\n",
      "INFO\t2019-09-09 14:48:39 -0400\tmaster-replica-0\t4\t 27/446 [>.............................] - ETA: 2s - loss: 4.0888 - acc: 0.746\n",
      "INFO\t2019-09-09 14:48:39 -0400\tmaster-replica-0\t3\t207/212 [============================>.] - ETA: 0s - loss: 3.8928 - acc: 0.758\n",
      "INFO\t2019-09-09 14:48:39 -0400\tmaster-replica-0\t3\t212/212 [==============================] - 2s 11ms/step - loss: 3.8884 - acc: 0.7588 - val_loss: 3.8072 - val_acc: 0.7638\n",
      "INFO\t2019-09-09 14:48:39 -0400\tmaster-replica-0\t3\tEpoch 00015: LearningRateScheduler reducing learning rate to 0.09880863634902332.\n",
      "INFO\t2019-09-09 14:48:39 -0400\tmaster-replica-0\t3\tEpoch 15/20\n",
      "INFO\t2019-09-09 14:48:39 -0400\tmaster-replica-0\t4\t 37/446 [=>............................] - ETA: 2s - loss: 4.0221 - acc: 0.750\n",
      "INFO\t2019-09-09 14:48:39 -0400\tmaster-replica-0\t3\t  1/212 [..............................] - ETA: 1s - loss: 3.8978 - acc: 0.758\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO\t2019-09-09 14:48:39 -0400\tmaster-replica-0\t4\t 48/446 [==>...........................] - ETA: 2s - loss: 3.9835 - acc: 0.752\n",
      "INFO\t2019-09-09 14:48:39 -0400\tmaster-replica-0\t3\t 13/212 [>.............................] - ETA: 0s - loss: 3.7439 - acc: 0.767\n",
      "INFO\t2019-09-09 14:48:39 -0400\tmaster-replica-0\t4\t 61/446 [===>..........................] - ETA: 2s - loss: 3.9454 - acc: 0.755\n",
      "INFO\t2019-09-09 14:48:39 -0400\tmaster-replica-0\t3\t 23/212 [==>...........................] - ETA: 0s - loss: 3.6963 - acc: 0.770\n",
      "INFO\t2019-09-09 14:48:39 -0400\tmaster-replica-0\t4\t 70/446 [===>..........................] - ETA: 2s - loss: 4.0090 - acc: 0.751\n",
      "INFO\t2019-09-09 14:48:39 -0400\tmaster-replica-0\t3\t 35/212 [===>..........................] - ETA: 0s - loss: 3.7774 - acc: 0.765\n",
      "INFO\t2019-09-09 14:48:39 -0400\tmaster-replica-0\t4\t 80/446 [====>.........................] - ETA: 2s - loss: 3.9578 - acc: 0.754\n",
      "INFO\t2019-09-09 14:48:39 -0400\tmaster-replica-0\t3\t 46/212 [=====>........................] - ETA: 0s - loss: 3.7673 - acc: 0.766\n",
      "INFO\t2019-09-09 14:48:39 -0400\tmaster-replica-0\t4\t 92/446 [=====>........................] - ETA: 1s - loss: 3.9239 - acc: 0.756\n",
      "INFO\t2019-09-09 14:48:39 -0400\tmaster-replica-0\t3\t 55/212 [======>.......................] - ETA: 0s - loss: 3.8270 - acc: 0.762\n",
      "INFO\t2019-09-09 14:48:39 -0400\tmaster-replica-0\t4\t105/446 [======>.......................] - ETA: 1s - loss: 3.8944 - acc: 0.758\n",
      "INFO\t2019-09-09 14:48:39 -0400\tmaster-replica-0\t3\t 66/212 [========>.....................] - ETA: 0s - loss: 3.8340 - acc: 0.762\n",
      "INFO\t2019-09-09 14:48:39 -0400\tmaster-replica-0\t4\t118/446 [======>.......................] - ETA: 1s - loss: 3.9257 - acc: 0.756\n",
      "INFO\t2019-09-09 14:48:39 -0400\tmaster-replica-0\t3\t 75/212 [=========>....................] - ETA: 0s - loss: 3.8417 - acc: 0.761\n",
      "INFO\t2019-09-09 14:48:39 -0400\tmaster-replica-0\t4\t132/446 [=======>......................] - ETA: 1s - loss: 3.9258 - acc: 0.756\n",
      "INFO\t2019-09-09 14:48:39 -0400\tmaster-replica-0\t3\t 86/212 [===========>..................] - ETA: 0s - loss: 3.8991 - acc: 0.758\n",
      "INFO\t2019-09-09 14:48:39 -0400\tmaster-replica-0\t4\t144/446 [========>.....................] - ETA: 1s - loss: 3.9268 - acc: 0.756\n",
      "INFO\t2019-09-09 14:48:39 -0400\tmaster-replica-0\t3\t 95/212 [============>.................] - ETA: 0s - loss: 3.9067 - acc: 0.757\n",
      "INFO\t2019-09-09 14:48:39 -0400\tmaster-replica-0\t4\t157/446 [=========>....................] - ETA: 1s - loss: 3.9335 - acc: 0.756\n",
      "INFO\t2019-09-09 14:48:39 -0400\tmaster-replica-0\t3\t104/212 [=============>................] - ETA: 0s - loss: 3.8989 - acc: 0.758\n",
      "INFO\t2019-09-09 14:48:40 -0400\tmaster-replica-0\t4\t168/446 [==========>...................] - ETA: 1s - loss: 3.9165 - acc: 0.757\n",
      "INFO\t2019-09-09 14:48:40 -0400\tmaster-replica-0\t3\t113/212 [==============>...............] - ETA: 0s - loss: 3.8839 - acc: 0.759\n",
      "INFO\t2019-09-09 14:48:40 -0400\tmaster-replica-0\t4\t180/446 [===========>..................] - ETA: 1s - loss: 3.9142 - acc: 0.757\n",
      "INFO\t2019-09-09 14:48:40 -0400\tmaster-replica-0\t3\t124/212 [================>.............] - ETA: 0s - loss: 3.8961 - acc: 0.758\n",
      "INFO\t2019-09-09 14:48:40 -0400\tmaster-replica-0\t4\t193/446 [===========>..................] - ETA: 1s - loss: 3.9023 - acc: 0.757\n",
      "INFO\t2019-09-09 14:48:40 -0400\tmaster-replica-0\t3\t133/212 [=================>............] - ETA: 0s - loss: 3.8947 - acc: 0.758\n",
      "INFO\t2019-09-09 14:48:40 -0400\tmaster-replica-0\t4\t205/446 [============>.................] - ETA: 1s - loss: 3.9032 - acc: 0.757\n",
      "INFO\t2019-09-09 14:48:40 -0400\tmaster-replica-0\t3\t143/212 [===================>..........] - ETA: 0s - loss: 3.9089 - acc: 0.757\n",
      "INFO\t2019-09-09 14:48:40 -0400\tmaster-replica-0\t4\t216/446 [=============>................] - ETA: 1s - loss: 3.8813 - acc: 0.759\n",
      "INFO\t2019-09-09 14:48:40 -0400\tmaster-replica-0\t3\t152/212 [====================>.........] - ETA: 0s - loss: 3.8992 - acc: 0.758\n",
      "INFO\t2019-09-09 14:48:40 -0400\tmaster-replica-0\t4\t231/446 [==============>...............] - ETA: 1s - loss: 3.8959 - acc: 0.758\n",
      "INFO\t2019-09-09 14:48:40 -0400\tmaster-replica-0\t3\t163/212 [======================>.......] - ETA: 0s - loss: 3.8959 - acc: 0.758\n",
      "INFO\t2019-09-09 14:48:40 -0400\tmaster-replica-0\t4\t242/446 [===============>..............] - ETA: 0s - loss: 3.8949 - acc: 0.758\n",
      "INFO\t2019-09-09 14:48:40 -0400\tmaster-replica-0\t3\t173/212 [=======================>......] - ETA: 0s - loss: 3.8887 - acc: 0.758\n",
      "INFO\t2019-09-09 14:48:40 -0400\tmaster-replica-0\t4\t252/446 [===============>..............] - ETA: 0s - loss: 3.8850 - acc: 0.759\n",
      "INFO\t2019-09-09 14:48:40 -0400\tmaster-replica-0\t3\t184/212 [=========================>....] - ETA: 0s - loss: 3.8955 - acc: 0.758\n",
      "INFO\t2019-09-09 14:48:40 -0400\tmaster-replica-0\t4\t264/446 [================>.............] - ETA: 0s - loss: 3.8740 - acc: 0.759\n",
      "INFO\t2019-09-09 14:48:40 -0400\tmaster-replica-0\t3\t194/212 [==========================>...] - ETA: 0s - loss: 3.8783 - acc: 0.759\n",
      "INFO\t2019-09-09 14:48:40 -0400\tmaster-replica-0\t4\t277/446 [=================>............] - ETA: 0s - loss: 3.8731 - acc: 0.759\n",
      "INFO\t2019-09-09 14:48:40 -0400\tmaster-replica-0\t4\t288/446 [==================>...........] - ETA: 0s - loss: 3.8716 - acc: 0.759\n",
      "INFO\t2019-09-09 14:48:40 -0400\tmaster-replica-0\t4\t297/446 [==================>...........] - ETA: 0s - loss: 3.8732 - acc: 0.759\n",
      "INFO\t2019-09-09 14:48:40 -0400\tmaster-replica-0\t4\t308/446 [===================>..........] - ETA: 0s - loss: 3.8783 - acc: 0.759\n",
      "INFO\t2019-09-09 14:48:40 -0400\tmaster-replica-0\t4\t319/446 [====================>.........] - ETA: 0s - loss: 3.8760 - acc: 0.759\n",
      "INFO\t2019-09-09 14:48:40 -0400\tmaster-replica-0\t4\t330/446 [=====================>........] - ETA: 0s - loss: 3.8740 - acc: 0.759\n",
      "INFO\t2019-09-09 14:48:40 -0400\tmaster-replica-0\t4\t344/446 [======================>.......] - ETA: 0s - loss: 3.8671 - acc: 0.760\n",
      "INFO\t2019-09-09 14:48:40 -0400\tmaster-replica-0\t4\t359/446 [=======================>......] - ETA: 0s - loss: 3.8685 - acc: 0.760\n",
      "INFO\t2019-09-09 14:48:40 -0400\tmaster-replica-0\t4\t372/446 [========================>.....] - ETA: 0s - loss: 3.8639 - acc: 0.760\n",
      "INFO\t2019-09-09 14:48:40 -0400\tmaster-replica-0\t4\t380/446 [========================>.....] - ETA: 0s - loss: 3.8674 - acc: 0.760\n",
      "INFO\t2019-09-09 14:48:41 -0400\tmaster-replica-0\t4\t389/446 [=========================>....] - ETA: 0s - loss: 3.8653 - acc: 0.760\n",
      "INFO\t2019-09-09 14:48:41 -0400\tmaster-replica-0\t4\t399/446 [=========================>....] - ETA: 0s - loss: 3.8614 - acc: 0.760\n",
      "INFO\t2019-09-09 14:48:41 -0400\tmaster-replica-0\t4\t415/446 [==========================>...] - ETA: 0s - loss: 3.8594 - acc: 0.760\n",
      "INFO\t2019-09-09 14:48:41 -0400\tmaster-replica-0\t4\t423/446 [===========================>..] - ETA: 0s - loss: 3.8663 - acc: 0.760\n",
      "INFO\t2019-09-09 14:48:41 -0400\tmaster-replica-0\t4\t437/446 [============================>.] - ETA: 0s - loss: 3.8723 - acc: 0.759\n",
      "INFO\t2019-09-09 14:48:41 -0400\tmaster-replica-0\t3\t204/212 [===========================>..] - ETA: 0s - loss: 3.8798 - acc: 0.759\n",
      "INFO\t2019-09-09 14:48:41 -0400\tmaster-replica-0\t3\t212/212 [==============================] - 2s 10ms/step - loss: 3.8725 - acc: 0.7597 - val_loss: 3.8072 - val_acc: 0.7638\n",
      "INFO\t2019-09-09 14:48:41 -0400\tmaster-replica-0\t3\tEpoch 00016: LearningRateScheduler reducing learning rate to 0.09880833117324207.\n",
      "INFO\t2019-09-09 14:48:41 -0400\tmaster-replica-0\t3\tEpoch 16/20\n",
      "INFO\t2019-09-09 14:48:41 -0400\tmaster-replica-0\t3\t  1/212 [..............................] - ETA: 20s - loss: 4.0032 - acc: 0.75\n",
      "INFO\t2019-09-09 14:48:41 -0400\tmaster-replica-0\t3\t 12/212 [>.............................] - ETA: 2s - loss: 3.8803 - acc: 0.7593\n",
      "INFO\t2019-09-09 14:48:41 -0400\tmaster-replica-0\t3\t 21/212 [=>............................] - ETA: 1s - loss: 3.9129 - acc: 0.757\n",
      "INFO\t2019-09-09 14:48:41 -0400\tmaster-replica-0\t3\t 32/212 [===>..........................] - ETA: 1s - loss: 3.9110 - acc: 0.757\n",
      "INFO\t2019-09-09 14:48:41 -0400\tmaster-replica-0\t3\t 40/212 [====>.........................] - ETA: 1s - loss: 3.8504 - acc: 0.761\n",
      "INFO\t2019-09-09 14:48:41 -0400\tmaster-replica-0\t3\t 51/212 [======>.......................] - ETA: 1s - loss: 3.9226 - acc: 0.756\n",
      "INFO\t2019-09-09 14:48:42 -0400\tmaster-replica-0\t3\t 61/212 [=======>......................] - ETA: 1s - loss: 3.8823 - acc: 0.759\n",
      "INFO\t2019-09-09 14:48:42 -0400\tmaster-replica-0\t3\t 72/212 [=========>....................] - ETA: 0s - loss: 3.8730 - acc: 0.759\n",
      "INFO\t2019-09-09 14:48:42 -0400\tmaster-replica-0\t3\t 81/212 [==========>...................] - ETA: 0s - loss: 3.8861 - acc: 0.758\n",
      "INFO\t2019-09-09 14:48:42 -0400\tmaster-replica-0\t3\t 92/212 [============>.................] - ETA: 0s - loss: 3.8784 - acc: 0.759\n",
      "INFO\t2019-09-09 14:48:42 -0400\tmaster-replica-0\t3\t102/212 [=============>................] - ETA: 0s - loss: 3.8700 - acc: 0.759\n",
      "INFO\t2019-09-09 14:48:42 -0400\tmaster-replica-0\t3\t112/212 [==============>...............] - ETA: 0s - loss: 3.8790 - acc: 0.759\n",
      "INFO\t2019-09-09 14:48:42 -0400\tmaster-replica-0\t3\t121/212 [================>.............] - ETA: 0s - loss: 3.8970 - acc: 0.758\n",
      "INFO\t2019-09-09 14:48:42 -0400\tmaster-replica-0\t3\t132/212 [=================>............] - ETA: 0s - loss: 3.9082 - acc: 0.757\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO\t2019-09-09 14:48:42 -0400\tmaster-replica-0\t4\t445/446 [============================>.] - ETA: 0s - loss: 3.8810 - acc: 0.759\n",
      "INFO\t2019-09-09 14:48:42 -0400\tmaster-replica-0\t4\t446/446 [==============================] - 3s 7ms/step - loss: 3.8822 - acc: 0.7591 - val_loss: 3.8072 - val_acc: 0.7638\n",
      "INFO\t2019-09-09 14:48:42 -0400\tmaster-replica-0\t4\tEpoch 00004: LearningRateScheduler reducing learning rate to 0.03791403148705935.\n",
      "INFO\t2019-09-09 14:48:42 -0400\tmaster-replica-0\t4\tEpoch 4/20\n",
      "INFO\t2019-09-09 14:48:42 -0400\tmaster-replica-0\t3\t141/212 [==================>...........] - ETA: 0s - loss: 3.8851 - acc: 0.759\n",
      "INFO\t2019-09-09 14:48:42 -0400\tmaster-replica-0\t4\t  1/446 [..............................] - ETA: 7s - loss: 3.3119 - acc: 0.794\n",
      "INFO\t2019-09-09 14:48:42 -0400\tmaster-replica-0\t3\t152/212 [====================>.........] - ETA: 0s - loss: 3.8840 - acc: 0.759\n",
      "INFO\t2019-09-09 14:48:42 -0400\tmaster-replica-0\t4\t 14/446 [..............................] - ETA: 2s - loss: 3.7062 - acc: 0.770\n",
      "INFO\t2019-09-09 14:48:42 -0400\tmaster-replica-0\t3\t161/212 [=====================>........] - ETA: 0s - loss: 3.8802 - acc: 0.759\n",
      "INFO\t2019-09-09 14:48:42 -0400\tmaster-replica-0\t4\t 24/446 [>.............................] - ETA: 2s - loss: 3.7259 - acc: 0.768\n",
      "INFO\t2019-09-09 14:48:42 -0400\tmaster-replica-0\t3\t172/212 [=======================>......] - ETA: 0s - loss: 3.8764 - acc: 0.759\n",
      "INFO\t2019-09-09 14:48:42 -0400\tmaster-replica-0\t4\t 36/446 [=>............................] - ETA: 1s - loss: 3.7903 - acc: 0.764\n",
      "INFO\t2019-09-09 14:48:42 -0400\tmaster-replica-0\t3\t182/212 [========================>.....] - ETA: 0s - loss: 3.8834 - acc: 0.759\n",
      "INFO\t2019-09-09 14:48:42 -0400\tmaster-replica-0\t4\t 47/446 [==>...........................] - ETA: 1s - loss: 3.9133 - acc: 0.757\n",
      "INFO\t2019-09-09 14:48:42 -0400\tmaster-replica-0\t3\t192/212 [==========================>...] - ETA: 0s - loss: 3.8907 - acc: 0.758\n",
      "INFO\t2019-09-09 14:48:42 -0400\tmaster-replica-0\t4\t 62/446 [===>..........................] - ETA: 1s - loss: 3.9672 - acc: 0.753\n",
      "INFO\t2019-09-09 14:48:42 -0400\tmaster-replica-0\t4\t 74/446 [===>..........................] - ETA: 1s - loss: 3.9415 - acc: 0.755\n",
      "INFO\t2019-09-09 14:48:42 -0400\tmaster-replica-0\t4\t 90/446 [=====>........................] - ETA: 1s - loss: 3.9302 - acc: 0.756\n",
      "INFO\t2019-09-09 14:48:42 -0400\tmaster-replica-0\t4\t105/446 [======>.......................] - ETA: 1s - loss: 3.9133 - acc: 0.757\n",
      "INFO\t2019-09-09 14:48:42 -0400\tmaster-replica-0\t4\t121/446 [=======>......................] - ETA: 1s - loss: 3.9159 - acc: 0.757\n",
      "INFO\t2019-09-09 14:48:42 -0400\tmaster-replica-0\t4\t128/446 [=======>......................] - ETA: 1s - loss: 3.9157 - acc: 0.757\n",
      "INFO\t2019-09-09 14:48:43 -0400\tmaster-replica-0\t4\t144/446 [========>.....................] - ETA: 1s - loss: 3.9222 - acc: 0.756\n",
      "INFO\t2019-09-09 14:48:43 -0400\tmaster-replica-0\t4\t155/446 [=========>....................] - ETA: 1s - loss: 3.9031 - acc: 0.757\n",
      "INFO\t2019-09-09 14:48:43 -0400\tmaster-replica-0\t4\t169/446 [==========>...................] - ETA: 1s - loss: 3.9390 - acc: 0.755\n",
      "INFO\t2019-09-09 14:48:43 -0400\tmaster-replica-0\t4\t184/446 [===========>..................] - ETA: 1s - loss: 3.9407 - acc: 0.755\n",
      "INFO\t2019-09-09 14:48:43 -0400\tmaster-replica-0\t4\t199/446 [============>.................] - ETA: 0s - loss: 3.9632 - acc: 0.754\n",
      "INFO\t2019-09-09 14:48:43 -0400\tmaster-replica-0\t4\t213/446 [=============>................] - ETA: 0s - loss: 3.9484 - acc: 0.755\n",
      "INFO\t2019-09-09 14:48:43 -0400\tmaster-replica-0\t4\t224/446 [==============>...............] - ETA: 0s - loss: 3.9526 - acc: 0.754\n",
      "INFO\t2019-09-09 14:48:43 -0400\tmaster-replica-0\t4\t239/446 [===============>..............] - ETA: 0s - loss: 3.9281 - acc: 0.756\n",
      "INFO\t2019-09-09 14:48:43 -0400\tmaster-replica-0\t4\t252/446 [===============>..............] - ETA: 0s - loss: 3.9069 - acc: 0.757\n",
      "INFO\t2019-09-09 14:48:43 -0400\tmaster-replica-0\t4\t263/446 [================>.............] - ETA: 0s - loss: 3.9046 - acc: 0.757\n",
      "INFO\t2019-09-09 14:48:43 -0400\tmaster-replica-0\t4\t278/446 [=================>............] - ETA: 0s - loss: 3.9100 - acc: 0.757\n",
      "INFO\t2019-09-09 14:48:43 -0400\tmaster-replica-0\t4\t293/446 [==================>...........] - ETA: 0s - loss: 3.9253 - acc: 0.756\n",
      "INFO\t2019-09-09 14:48:43 -0400\tmaster-replica-0\t4\t304/446 [===================>..........] - ETA: 0s - loss: 3.9235 - acc: 0.756\n",
      "INFO\t2019-09-09 14:48:43 -0400\tmaster-replica-0\t4\t315/446 [====================>.........] - ETA: 0s - loss: 3.9077 - acc: 0.757\n",
      "INFO\t2019-09-09 14:48:43 -0400\tmaster-replica-0\t4\t327/446 [====================>.........] - ETA: 0s - loss: 3.9055 - acc: 0.757\n",
      "INFO\t2019-09-09 14:48:43 -0400\tmaster-replica-0\t3\t202/212 [===========================>..] - ETA: 0s - loss: 3.8895 - acc: 0.758\n",
      "INFO\t2019-09-09 14:48:43 -0400\tmaster-replica-0\t3\t212/212 [==============================] - 2s 11ms/step - loss: 3.8889 - acc: 0.7587 - val_loss: 3.8072 - val_acc: 0.7638\n",
      "INFO\t2019-09-09 14:48:43 -0400\tmaster-replica-0\t3\tEpoch 00017: LearningRateScheduler reducing learning rate to 0.09880817858535144.\n",
      "INFO\t2019-09-09 14:48:43 -0400\tmaster-replica-0\t3\tEpoch 17/20\n",
      "INFO\t2019-09-09 14:48:43 -0400\tmaster-replica-0\t4\t338/446 [=====================>........] - ETA: 0s - loss: 3.9064 - acc: 0.757\n",
      "INFO\t2019-09-09 14:48:43 -0400\tmaster-replica-0\t3\t  1/212 [..............................] - ETA: 1s - loss: 4.0032 - acc: 0.751\n",
      "INFO\t2019-09-09 14:48:43 -0400\tmaster-replica-0\t4\t350/446 [======================>.......] - ETA: 0s - loss: 3.8898 - acc: 0.758\n",
      "INFO\t2019-09-09 14:48:43 -0400\tmaster-replica-0\t3\t 10/212 [>.............................] - ETA: 1s - loss: 3.6239 - acc: 0.775\n",
      "INFO\t2019-09-09 14:48:43 -0400\tmaster-replica-0\t4\t364/446 [=======================>......] - ETA: 0s - loss: 3.8918 - acc: 0.758\n",
      "INFO\t2019-09-09 14:48:43 -0400\tmaster-replica-0\t3\t 17/212 [=>............................] - ETA: 1s - loss: 3.8483 - acc: 0.761\n",
      "INFO\t2019-09-09 14:48:43 -0400\tmaster-replica-0\t4\t377/446 [========================>.....] - ETA: 0s - loss: 3.8964 - acc: 0.758\n",
      "INFO\t2019-09-09 14:48:44 -0400\tmaster-replica-0\t3\t 25/212 [==>...........................] - ETA: 1s - loss: 3.9695 - acc: 0.753\n",
      "INFO\t2019-09-09 14:48:44 -0400\tmaster-replica-0\t4\t385/446 [========================>.....] - ETA: 0s - loss: 3.8929 - acc: 0.758\n",
      "INFO\t2019-09-09 14:48:44 -0400\tmaster-replica-0\t3\t 35/212 [===>..........................] - ETA: 1s - loss: 3.9039 - acc: 0.757\n",
      "INFO\t2019-09-09 14:48:44 -0400\tmaster-replica-0\t4\t398/446 [=========================>....] - ETA: 0s - loss: 3.8750 - acc: 0.759\n",
      "INFO\t2019-09-09 14:48:44 -0400\tmaster-replica-0\t3\t 44/212 [=====>........................] - ETA: 1s - loss: 3.8308 - acc: 0.762\n",
      "INFO\t2019-09-09 14:48:44 -0400\tmaster-replica-0\t4\t411/446 [==========================>...] - ETA: 0s - loss: 3.8760 - acc: 0.759\n",
      "INFO\t2019-09-09 14:48:44 -0400\tmaster-replica-0\t3\t 55/212 [======>.......................] - ETA: 0s - loss: 3.8500 - acc: 0.761\n",
      "INFO\t2019-09-09 14:48:44 -0400\tmaster-replica-0\t4\t423/446 [===========================>..] - ETA: 0s - loss: 3.8788 - acc: 0.759\n",
      "INFO\t2019-09-09 14:48:44 -0400\tmaster-replica-0\t3\t 64/212 [========>.....................] - ETA: 0s - loss: 3.8748 - acc: 0.759\n",
      "INFO\t2019-09-09 14:48:44 -0400\tmaster-replica-0\t3\t 74/212 [=========>....................] - ETA: 0s - loss: 3.8580 - acc: 0.760\n",
      "INFO\t2019-09-09 14:48:44 -0400\tmaster-replica-0\t3\t 82/212 [==========>...................] - ETA: 0s - loss: 3.8876 - acc: 0.758\n",
      "INFO\t2019-09-09 14:48:44 -0400\tmaster-replica-0\t3\t 92/212 [============>.................] - ETA: 0s - loss: 3.9059 - acc: 0.757\n",
      "INFO\t2019-09-09 14:48:44 -0400\tmaster-replica-0\t3\t100/212 [=============>................] - ETA: 0s - loss: 3.8894 - acc: 0.758\n",
      "INFO\t2019-09-09 14:48:44 -0400\tmaster-replica-0\t3\t110/212 [==============>...............] - ETA: 0s - loss: 3.8777 - acc: 0.759\n",
      "INFO\t2019-09-09 14:48:44 -0400\tmaster-replica-0\t3\t120/212 [===============>..............] - ETA: 0s - loss: 3.8776 - acc: 0.759\n",
      "INFO\t2019-09-09 14:48:44 -0400\tmaster-replica-0\t3\t128/212 [=================>............] - ETA: 0s - loss: 3.8756 - acc: 0.759\n",
      "INFO\t2019-09-09 14:48:44 -0400\tmaster-replica-0\t3\t136/212 [==================>...........] - ETA: 0s - loss: 3.8792 - acc: 0.759\n",
      "INFO\t2019-09-09 14:48:44 -0400\tmaster-replica-0\t3\t145/212 [===================>..........] - ETA: 0s - loss: 3.8622 - acc: 0.760\n",
      "INFO\t2019-09-09 14:48:44 -0400\tmaster-replica-0\t3\t155/212 [====================>.........] - ETA: 0s - loss: 3.8673 - acc: 0.760\n",
      "INFO\t2019-09-09 14:48:44 -0400\tmaster-replica-0\t3\t163/212 [======================>.......] - ETA: 0s - loss: 3.8642 - acc: 0.760\n",
      "INFO\t2019-09-09 14:48:44 -0400\tmaster-replica-0\t3\t173/212 [=======================>......] - ETA: 0s - loss: 3.8503 - acc: 0.761\n",
      "INFO\t2019-09-09 14:48:44 -0400\tmaster-replica-0\t3\t182/212 [========================>.....] - ETA: 0s - loss: 3.8492 - acc: 0.761\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO\t2019-09-09 14:48:45 -0400\tmaster-replica-0\t3\t190/212 [=========================>....] - ETA: 0s - loss: 3.8563 - acc: 0.760\n",
      "INFO\t2019-09-09 14:48:45 -0400\tmaster-replica-0\t3\t196/212 [==========================>...] - ETA: 0s - loss: 3.8661 - acc: 0.760\n",
      "INFO\t2019-09-09 14:48:45 -0400\tmaster-replica-0\t3\t204/212 [===========================>..] - ETA: 0s - loss: 3.8741 - acc: 0.759\n",
      "INFO\t2019-09-09 14:48:45 -0400\tmaster-replica-0\t4\t435/446 [============================>.] - ETA: 0s - loss: 3.8789 - acc: 0.759\n",
      "INFO\t2019-09-09 14:48:45 -0400\tmaster-replica-0\t4\t446/446 [==============================] - 3s 6ms/step - loss: 3.8813 - acc: 0.7592 - val_loss: 3.8072 - val_acc: 0.7638\n",
      "INFO\t2019-09-09 14:48:45 -0400\tmaster-replica-0\t4\tEpoch 00005: LearningRateScheduler reducing learning rate to 0.03728903148705935.\n",
      "INFO\t2019-09-09 14:48:45 -0400\tmaster-replica-0\t4\tEpoch 5/20\n",
      "INFO\t2019-09-09 14:48:45 -0400\tmaster-replica-0\t4\t  1/446 [..............................] - ETA: 28s - loss: 3.5327 - acc: 0.78\n",
      "INFO\t2019-09-09 14:48:45 -0400\tmaster-replica-0\t4\t 14/446 [..............................] - ETA: 3s - loss: 3.5643 - acc: 0.7789\n",
      "INFO\t2019-09-09 14:48:45 -0400\tmaster-replica-0\t4\t 27/446 [>.............................] - ETA: 2s - loss: 3.6309 - acc: 0.774\n",
      "INFO\t2019-09-09 14:48:45 -0400\tmaster-replica-0\t4\t 39/446 [=>............................] - ETA: 2s - loss: 3.6743 - acc: 0.772\n",
      "INFO\t2019-09-09 14:48:45 -0400\tmaster-replica-0\t4\t 50/446 [==>...........................] - ETA: 2s - loss: 3.6961 - acc: 0.770\n",
      "INFO\t2019-09-09 14:48:45 -0400\tmaster-replica-0\t4\t 60/446 [===>..........................] - ETA: 2s - loss: 3.6983 - acc: 0.770\n",
      "INFO\t2019-09-09 14:48:45 -0400\tmaster-replica-0\t4\t 71/446 [===>..........................] - ETA: 2s - loss: 3.6727 - acc: 0.772\n",
      "INFO\t2019-09-09 14:48:45 -0400\tmaster-replica-0\t4\t 80/446 [====>.........................] - ETA: 1s - loss: 3.6404 - acc: 0.774\n",
      "INFO\t2019-09-09 14:48:45 -0400\tmaster-replica-0\t4\t 92/446 [=====>........................] - ETA: 1s - loss: 3.6887 - acc: 0.771\n",
      "INFO\t2019-09-09 14:48:45 -0400\tmaster-replica-0\t4\t103/446 [=====>........................] - ETA: 1s - loss: 3.7149 - acc: 0.769\n",
      "INFO\t2019-09-09 14:48:45 -0400\tmaster-replica-0\t4\t116/446 [======>.......................] - ETA: 1s - loss: 3.7478 - acc: 0.767\n",
      "INFO\t2019-09-09 14:48:45 -0400\tmaster-replica-0\t4\t130/446 [=======>......................] - ETA: 1s - loss: 3.7620 - acc: 0.766\n",
      "INFO\t2019-09-09 14:48:46 -0400\tmaster-replica-0\t4\t140/446 [========>.....................] - ETA: 1s - loss: 3.7788 - acc: 0.765\n",
      "INFO\t2019-09-09 14:48:46 -0400\tmaster-replica-0\t4\t153/446 [=========>....................] - ETA: 1s - loss: 3.7954 - acc: 0.764\n",
      "INFO\t2019-09-09 14:48:46 -0400\tmaster-replica-0\t4\t164/446 [==========>...................] - ETA: 1s - loss: 3.7953 - acc: 0.764\n",
      "INFO\t2019-09-09 14:48:46 -0400\tmaster-replica-0\t3\t210/212 [============================>.] - ETA: 0s - loss: 3.8718 - acc: 0.759\n",
      "INFO\t2019-09-09 14:48:46 -0400\tmaster-replica-0\t3\t212/212 [==============================] - 2s 11ms/step - loss: 3.8814 - acc: 0.7592 - val_loss: 3.8072 - val_acc: 0.7638\n",
      "INFO\t2019-09-09 14:48:46 -0400\tmaster-replica-0\t4\t179/446 [===========>..................] - ETA: 1s - loss: 3.8066 - acc: 0.763\n",
      "INFO\t2019-09-09 14:48:46 -0400\tmaster-replica-0\t3\tEpoch 00018: LearningRateScheduler reducing learning rate to 0.09880810229140613.\n",
      "INFO\t2019-09-09 14:48:46 -0400\tmaster-replica-0\t3\tEpoch 18/20\n",
      "INFO\t2019-09-09 14:48:46 -0400\tmaster-replica-0\t3\t  1/212 [..............................] - ETA: 1s - loss: 3.2658 - acc: 0.797\n",
      "INFO\t2019-09-09 14:48:46 -0400\tmaster-replica-0\t4\t193/446 [===========>..................] - ETA: 1s - loss: 3.8107 - acc: 0.763\n",
      "INFO\t2019-09-09 14:48:46 -0400\tmaster-replica-0\t3\t 12/212 [>.............................] - ETA: 0s - loss: 3.7398 - acc: 0.768\n",
      "INFO\t2019-09-09 14:48:46 -0400\tmaster-replica-0\t4\t210/446 [=============>................] - ETA: 1s - loss: 3.8198 - acc: 0.763\n",
      "INFO\t2019-09-09 14:48:46 -0400\tmaster-replica-0\t3\t 21/212 [=>............................] - ETA: 0s - loss: 3.7825 - acc: 0.765\n",
      "INFO\t2019-09-09 14:48:46 -0400\tmaster-replica-0\t4\t221/446 [=============>................] - ETA: 1s - loss: 3.8105 - acc: 0.763\n",
      "INFO\t2019-09-09 14:48:46 -0400\tmaster-replica-0\t3\t 30/212 [===>..........................] - ETA: 0s - loss: 3.8311 - acc: 0.762\n",
      "INFO\t2019-09-09 14:48:46 -0400\tmaster-replica-0\t4\t233/446 [==============>...............] - ETA: 0s - loss: 3.8303 - acc: 0.762\n",
      "INFO\t2019-09-09 14:48:46 -0400\tmaster-replica-0\t3\t 39/212 [====>.........................] - ETA: 0s - loss: 3.7763 - acc: 0.765\n",
      "INFO\t2019-09-09 14:48:46 -0400\tmaster-replica-0\t4\t248/446 [===============>..............] - ETA: 0s - loss: 3.8408 - acc: 0.761\n",
      "INFO\t2019-09-09 14:48:46 -0400\tmaster-replica-0\t3\t 50/212 [======>.......................] - ETA: 0s - loss: 3.7946 - acc: 0.764\n",
      "INFO\t2019-09-09 14:48:46 -0400\tmaster-replica-0\t4\t257/446 [================>.............] - ETA: 0s - loss: 3.8291 - acc: 0.762\n",
      "INFO\t2019-09-09 14:48:46 -0400\tmaster-replica-0\t4\t271/446 [=================>............] - ETA: 0s - loss: 3.8374 - acc: 0.761\n",
      "INFO\t2019-09-09 14:48:46 -0400\tmaster-replica-0\t3\t 59/212 [=======>......................] - ETA: 0s - loss: 3.8353 - acc: 0.762\n",
      "INFO\t2019-09-09 14:48:46 -0400\tmaster-replica-0\t3\t 71/212 [=========>....................] - ETA: 0s - loss: 3.8014 - acc: 0.764\n",
      "INFO\t2019-09-09 14:48:46 -0400\tmaster-replica-0\t4\t280/446 [=================>............] - ETA: 0s - loss: 3.8466 - acc: 0.761\n",
      "INFO\t2019-09-09 14:48:46 -0400\tmaster-replica-0\t3\t 80/212 [==========>...................] - ETA: 0s - loss: 3.8359 - acc: 0.762\n",
      "INFO\t2019-09-09 14:48:46 -0400\tmaster-replica-0\t4\t294/446 [==================>...........] - ETA: 0s - loss: 3.8707 - acc: 0.759\n",
      "INFO\t2019-09-09 14:48:46 -0400\tmaster-replica-0\t4\t305/446 [===================>..........] - ETA: 0s - loss: 3.8607 - acc: 0.760\n",
      "INFO\t2019-09-09 14:48:46 -0400\tmaster-replica-0\t3\t 91/212 [===========>..................] - ETA: 0s - loss: 3.8388 - acc: 0.761\n",
      "INFO\t2019-09-09 14:48:46 -0400\tmaster-replica-0\t4\t320/446 [====================>.........] - ETA: 0s - loss: 3.8619 - acc: 0.760\n",
      "INFO\t2019-09-09 14:48:46 -0400\tmaster-replica-0\t3\t 98/212 [============>.................] - ETA: 0s - loss: 3.8183 - acc: 0.763\n",
      "INFO\t2019-09-09 14:48:46 -0400\tmaster-replica-0\t3\t109/212 [==============>...............] - ETA: 0s - loss: 3.8147 - acc: 0.763\n",
      "INFO\t2019-09-09 14:48:46 -0400\tmaster-replica-0\t4\t328/446 [=====================>........] - ETA: 0s - loss: 3.8747 - acc: 0.759\n",
      "INFO\t2019-09-09 14:48:46 -0400\tmaster-replica-0\t4\t341/446 [=====================>........] - ETA: 0s - loss: 3.8733 - acc: 0.759\n",
      "INFO\t2019-09-09 14:48:46 -0400\tmaster-replica-0\t3\t118/212 [===============>..............] - ETA: 0s - loss: 3.8175 - acc: 0.763\n",
      "INFO\t2019-09-09 14:48:46 -0400\tmaster-replica-0\t4\t352/446 [======================>.......] - ETA: 0s - loss: 3.8664 - acc: 0.760\n",
      "INFO\t2019-09-09 14:48:46 -0400\tmaster-replica-0\t3\t129/212 [=================>............] - ETA: 0s - loss: 3.8154 - acc: 0.763\n",
      "INFO\t2019-09-09 14:48:46 -0400\tmaster-replica-0\t4\t368/446 [=======================>......] - ETA: 0s - loss: 3.8597 - acc: 0.760\n",
      "INFO\t2019-09-09 14:48:46 -0400\tmaster-replica-0\t3\t138/212 [==================>...........] - ETA: 0s - loss: 3.8184 - acc: 0.763\n",
      "INFO\t2019-09-09 14:48:46 -0400\tmaster-replica-0\t4\t379/446 [========================>.....] - ETA: 0s - loss: 3.8590 - acc: 0.760\n",
      "INFO\t2019-09-09 14:48:47 -0400\tmaster-replica-0\t3\t150/212 [====================>.........] - ETA: 0s - loss: 3.8522 - acc: 0.761\n",
      "INFO\t2019-09-09 14:48:47 -0400\tmaster-replica-0\t4\t395/446 [=========================>....] - ETA: 0s - loss: 3.8704 - acc: 0.759\n",
      "INFO\t2019-09-09 14:48:47 -0400\tmaster-replica-0\t3\t158/212 [=====================>........] - ETA: 0s - loss: 3.8292 - acc: 0.762\n",
      "INFO\t2019-09-09 14:48:47 -0400\tmaster-replica-0\t4\t404/446 [==========================>...] - ETA: 0s - loss: 3.8732 - acc: 0.759\n",
      "INFO\t2019-09-09 14:48:47 -0400\tmaster-replica-0\t3\t168/212 [======================>.......] - ETA: 0s - loss: 3.8427 - acc: 0.761\n",
      "INFO\t2019-09-09 14:48:47 -0400\tmaster-replica-0\t4\t420/446 [===========================>..] - ETA: 0s - loss: 3.8760 - acc: 0.759\n",
      "INFO\t2019-09-09 14:48:47 -0400\tmaster-replica-0\t3\t177/212 [========================>.....] - ETA: 0s - loss: 3.8336 - acc: 0.762\n",
      "INFO\t2019-09-09 14:48:47 -0400\tmaster-replica-0\t4\t427/446 [===========================>..] - ETA: 0s - loss: 3.8781 - acc: 0.759\n",
      "INFO\t2019-09-09 14:48:47 -0400\tmaster-replica-0\t3\t188/212 [=========================>....] - ETA: 0s - loss: 3.8435 - acc: 0.761\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO\t2019-09-09 14:48:47 -0400\tmaster-replica-0\t3\t198/212 [===========================>..] - ETA: 0s - loss: 3.8505 - acc: 0.761\n",
      "INFO\t2019-09-09 14:48:48 -0400\tmaster-replica-0\t4\t441/446 [============================>.] - ETA: 0s - loss: 3.8857 - acc: 0.758\n",
      "INFO\t2019-09-09 14:48:48 -0400\tmaster-replica-0\t4\t446/446 [==============================] - 3s 7ms/step - loss: 3.8813 - acc: 0.7592 - val_loss: 3.8072 - val_acc: 0.7638\n",
      "INFO\t2019-09-09 14:48:48 -0400\tmaster-replica-0\t4\tEpoch 00006: LearningRateScheduler reducing learning rate to 0.03697653148705935.\n",
      "INFO\t2019-09-09 14:48:48 -0400\tmaster-replica-0\t4\tEpoch 6/20\n",
      "INFO\t2019-09-09 14:48:48 -0400\tmaster-replica-0\t3\t207/212 [============================>.] - ETA: 0s - loss: 3.8587 - acc: 0.760\n",
      "INFO\t2019-09-09 14:48:48 -0400\tmaster-replica-0\t3\t212/212 [==============================] - 2s 11ms/step - loss: 3.8636 - acc: 0.7603 - val_loss: 3.8072 - val_acc: 0.7638\n",
      "INFO\t2019-09-09 14:48:48 -0400\tmaster-replica-0\t3\tEpoch 00019: LearningRateScheduler reducing learning rate to 0.09880806414443347.\n",
      "INFO\t2019-09-09 14:48:48 -0400\tmaster-replica-0\t3\tEpoch 19/20\n",
      "INFO\t2019-09-09 14:48:48 -0400\tmaster-replica-0\t4\t  1/446 [..............................] - ETA: 35s - loss: 3.7535 - acc: 0.76\n",
      "INFO\t2019-09-09 14:48:48 -0400\tmaster-replica-0\t3\t  1/212 [..............................] - ETA: 1s - loss: 3.6871 - acc: 0.771\n",
      "INFO\t2019-09-09 14:48:48 -0400\tmaster-replica-0\t4\t 15/446 [>.............................] - ETA: 3s - loss: 3.5916 - acc: 0.7772\n",
      "INFO\t2019-09-09 14:48:48 -0400\tmaster-replica-0\t3\t 12/212 [>.............................] - ETA: 0s - loss: 3.9417 - acc: 0.755\n",
      "INFO\t2019-09-09 14:48:48 -0400\tmaster-replica-0\t4\t 22/446 [>.............................] - ETA: 3s - loss: 3.7535 - acc: 0.767\n",
      "INFO\t2019-09-09 14:48:48 -0400\tmaster-replica-0\t3\t 23/212 [==>...........................] - ETA: 0s - loss: 4.0490 - acc: 0.748\n",
      "INFO\t2019-09-09 14:48:48 -0400\tmaster-replica-0\t4\t 34/446 [=>............................] - ETA: 2s - loss: 3.8834 - acc: 0.759\n",
      "INFO\t2019-09-09 14:48:48 -0400\tmaster-replica-0\t3\t 32/212 [===>..........................] - ETA: 0s - loss: 3.9538 - acc: 0.754\n",
      "INFO\t2019-09-09 14:48:48 -0400\tmaster-replica-0\t4\t 47/446 [==>...........................] - ETA: 2s - loss: 3.9086 - acc: 0.757\n",
      "INFO\t2019-09-09 14:48:48 -0400\tmaster-replica-0\t3\t 43/212 [=====>........................] - ETA: 0s - loss: 4.0032 - acc: 0.751\n",
      "INFO\t2019-09-09 14:48:48 -0400\tmaster-replica-0\t4\t 59/446 [==>...........................] - ETA: 2s - loss: 3.9406 - acc: 0.755\n",
      "INFO\t2019-09-09 14:48:48 -0400\tmaster-replica-0\t3\t 51/212 [======>.......................] - ETA: 0s - loss: 3.9701 - acc: 0.753\n",
      "INFO\t2019-09-09 14:48:48 -0400\tmaster-replica-0\t4\t 67/446 [===>..........................] - ETA: 2s - loss: 3.9513 - acc: 0.754\n",
      "INFO\t2019-09-09 14:48:48 -0400\tmaster-replica-0\t3\t 62/212 [=======>......................] - ETA: 0s - loss: 3.9301 - acc: 0.756\n",
      "INFO\t2019-09-09 14:48:48 -0400\tmaster-replica-0\t4\t 82/446 [====>.........................] - ETA: 2s - loss: 3.8855 - acc: 0.758\n",
      "INFO\t2019-09-09 14:48:48 -0400\tmaster-replica-0\t3\t 71/212 [=========>....................] - ETA: 0s - loss: 3.9394 - acc: 0.755\n",
      "INFO\t2019-09-09 14:48:48 -0400\tmaster-replica-0\t4\t 93/446 [=====>........................] - ETA: 1s - loss: 3.9506 - acc: 0.754\n",
      "INFO\t2019-09-09 14:48:48 -0400\tmaster-replica-0\t3\t 81/212 [==========>...................] - ETA: 0s - loss: 3.9343 - acc: 0.755\n",
      "INFO\t2019-09-09 14:48:48 -0400\tmaster-replica-0\t4\t109/446 [======>.......................] - ETA: 1s - loss: 3.9885 - acc: 0.752\n",
      "INFO\t2019-09-09 14:48:48 -0400\tmaster-replica-0\t3\t 90/212 [===========>..................] - ETA: 0s - loss: 3.9201 - acc: 0.756\n",
      "INFO\t2019-09-09 14:48:48 -0400\tmaster-replica-0\t4\t120/446 [=======>......................] - ETA: 1s - loss: 3.9762 - acc: 0.753\n",
      "INFO\t2019-09-09 14:48:49 -0400\tmaster-replica-0\t3\t 99/212 [=============>................] - ETA: 0s - loss: 3.9064 - acc: 0.757\n",
      "INFO\t2019-09-09 14:48:49 -0400\tmaster-replica-0\t4\t129/446 [=======>......................] - ETA: 1s - loss: 4.0103 - acc: 0.751\n",
      "INFO\t2019-09-09 14:48:49 -0400\tmaster-replica-0\t3\t109/212 [==============>...............] - ETA: 0s - loss: 3.8920 - acc: 0.758\n",
      "INFO\t2019-09-09 14:48:49 -0400\tmaster-replica-0\t4\t140/446 [========>.....................] - ETA: 1s - loss: 4.0216 - acc: 0.750\n",
      "INFO\t2019-09-09 14:48:49 -0400\tmaster-replica-0\t3\t118/212 [===============>..............] - ETA: 0s - loss: 3.8836 - acc: 0.759\n",
      "INFO\t2019-09-09 14:48:49 -0400\tmaster-replica-0\t4\t153/446 [=========>....................] - ETA: 1s - loss: 3.9743 - acc: 0.753\n",
      "INFO\t2019-09-09 14:48:49 -0400\tmaster-replica-0\t3\t128/212 [=================>............] - ETA: 0s - loss: 3.8855 - acc: 0.758\n",
      "INFO\t2019-09-09 14:48:49 -0400\tmaster-replica-0\t4\t166/446 [==========>...................] - ETA: 1s - loss: 3.9517 - acc: 0.754\n",
      "INFO\t2019-09-09 14:48:49 -0400\tmaster-replica-0\t3\t136/212 [==================>...........] - ETA: 0s - loss: 3.8916 - acc: 0.758\n",
      "INFO\t2019-09-09 14:48:49 -0400\tmaster-replica-0\t4\t181/446 [===========>..................] - ETA: 1s - loss: 3.9511 - acc: 0.754\n",
      "INFO\t2019-09-09 14:48:49 -0400\tmaster-replica-0\t3\t146/212 [===================>..........] - ETA: 0s - loss: 3.9022 - acc: 0.757\n",
      "INFO\t2019-09-09 14:48:49 -0400\tmaster-replica-0\t4\t194/446 [============>.................] - ETA: 1s - loss: 3.9538 - acc: 0.754\n",
      "INFO\t2019-09-09 14:48:49 -0400\tmaster-replica-0\t3\t155/212 [====================>.........] - ETA: 0s - loss: 3.9080 - acc: 0.757\n",
      "INFO\t2019-09-09 14:48:49 -0400\tmaster-replica-0\t4\t211/446 [=============>................] - ETA: 1s - loss: 3.9513 - acc: 0.754\n",
      "INFO\t2019-09-09 14:48:49 -0400\tmaster-replica-0\t3\t165/212 [======================>.......] - ETA: 0s - loss: 3.9029 - acc: 0.757\n",
      "INFO\t2019-09-09 14:48:49 -0400\tmaster-replica-0\t4\t220/446 [=============>................] - ETA: 1s - loss: 3.9402 - acc: 0.755\n",
      "INFO\t2019-09-09 14:48:49 -0400\tmaster-replica-0\t3\t174/212 [=======================>......] - ETA: 0s - loss: 3.9003 - acc: 0.758\n",
      "INFO\t2019-09-09 14:48:49 -0400\tmaster-replica-0\t4\t232/446 [==============>...............] - ETA: 1s - loss: 3.9239 - acc: 0.756\n",
      "INFO\t2019-09-09 14:48:49 -0400\tmaster-replica-0\t3\t184/212 [=========================>....] - ETA: 0s - loss: 3.8904 - acc: 0.758\n",
      "INFO\t2019-09-09 14:48:49 -0400\tmaster-replica-0\t4\t247/446 [===============>..............] - ETA: 0s - loss: 3.9448 - acc: 0.755\n",
      "INFO\t2019-09-09 14:48:49 -0400\tmaster-replica-0\t3\t192/212 [==========================>...] - ETA: 0s - loss: 3.8836 - acc: 0.759\n",
      "INFO\t2019-09-09 14:48:49 -0400\tmaster-replica-0\t4\t260/446 [================>.............] - ETA: 0s - loss: 3.9353 - acc: 0.755\n",
      "INFO\t2019-09-09 14:48:49 -0400\tmaster-replica-0\t3\t202/212 [===========================>..] - ETA: 0s - loss: 3.8775 - acc: 0.759\n",
      "INFO\t2019-09-09 14:48:49 -0400\tmaster-replica-0\t4\t269/446 [=================>............] - ETA: 0s - loss: 3.9374 - acc: 0.755\n",
      "INFO\t2019-09-09 14:48:49 -0400\tmaster-replica-0\t4\t281/446 [=================>............] - ETA: 0s - loss: 3.9233 - acc: 0.756\n",
      "INFO\t2019-09-09 14:48:49 -0400\tmaster-replica-0\t4\t292/446 [==================>...........] - ETA: 0s - loss: 3.9229 - acc: 0.756\n",
      "INFO\t2019-09-09 14:48:49 -0400\tmaster-replica-0\t4\t302/446 [===================>..........] - ETA: 0s - loss: 3.9334 - acc: 0.756\n",
      "INFO\t2019-09-09 14:48:49 -0400\tmaster-replica-0\t4\t315/446 [====================>.........] - ETA: 0s - loss: 3.9400 - acc: 0.755\n",
      "INFO\t2019-09-09 14:48:49 -0400\tmaster-replica-0\t4\t326/446 [====================>.........] - ETA: 0s - loss: 3.9276 - acc: 0.756\n",
      "INFO\t2019-09-09 14:48:49 -0400\tmaster-replica-0\t4\t338/446 [=====================>........] - ETA: 0s - loss: 3.9188 - acc: 0.756\n",
      "INFO\t2019-09-09 14:48:49 -0400\tmaster-replica-0\t4\t349/446 [======================>.......] - ETA: 0s - loss: 3.9123 - acc: 0.757\n",
      "INFO\t2019-09-09 14:48:50 -0400\tmaster-replica-0\t4\t364/446 [=======================>......] - ETA: 0s - loss: 3.9209 - acc: 0.756\n",
      "INFO\t2019-09-09 14:48:50 -0400\tmaster-replica-0\t4\t374/446 [========================>.....] - ETA: 0s - loss: 3.9153 - acc: 0.757\n",
      "INFO\t2019-09-09 14:48:50 -0400\tmaster-replica-0\t4\t386/446 [========================>.....] - ETA: 0s - loss: 3.9108 - acc: 0.757\n",
      "INFO\t2019-09-09 14:48:50 -0400\tmaster-replica-0\t4\t395/446 [=========================>....] - ETA: 0s - loss: 3.9022 - acc: 0.757\n",
      "INFO\t2019-09-09 14:48:50 -0400\tmaster-replica-0\t4\t410/446 [==========================>...] - ETA: 0s - loss: 3.9038 - acc: 0.757\n",
      "INFO\t2019-09-09 14:48:50 -0400\tmaster-replica-0\t4\t419/446 [===========================>..] - ETA: 0s - loss: 3.8858 - acc: 0.758\n",
      "INFO\t2019-09-09 14:48:50 -0400\tmaster-replica-0\t4\t432/446 [============================>.] - ETA: 0s - loss: 3.8869 - acc: 0.758\n",
      "INFO\t2019-09-09 14:48:50 -0400\tmaster-replica-0\t3\t211/212 [============================>.] - ETA: 0s - loss: 3.8889 - acc: 0.758\n",
      "INFO\t2019-09-09 14:48:50 -0400\tmaster-replica-0\t3\t212/212 [==============================] - 2s 11ms/step - loss: 3.8914 - acc: 0.7586 - val_loss: 3.8072 - val_acc: 0.7638\n",
      "INFO\t2019-09-09 14:48:50 -0400\tmaster-replica-0\t3\tEpoch 00020: LearningRateScheduler reducing learning rate to 0.09880804507094715.\n",
      "INFO\t2019-09-09 14:48:50 -0400\tmaster-replica-0\t3\tEpoch 20/20\n",
      "INFO\t2019-09-09 14:48:50 -0400\tmaster-replica-0\t3\t  1/212 [..............................] - ETA: 5s - loss: 2.9497 - acc: 0.817\n",
      "INFO\t2019-09-09 14:48:50 -0400\tmaster-replica-0\t3\t 11/212 [>.............................] - ETA: 1s - loss: 3.8978 - acc: 0.758\n",
      "INFO\t2019-09-09 14:48:50 -0400\tmaster-replica-0\t3\t 20/212 [=>............................] - ETA: 1s - loss: 3.9031 - acc: 0.757\n",
      "INFO\t2019-09-09 14:48:50 -0400\tmaster-replica-0\t3\t 28/212 [==>...........................] - ETA: 1s - loss: 3.8903 - acc: 0.758\n",
      "INFO\t2019-09-09 14:48:51 -0400\tmaster-replica-0\t3\t 37/212 [====>.........................] - ETA: 1s - loss: 3.9519 - acc: 0.754\n",
      "INFO\t2019-09-09 14:48:51 -0400\tmaster-replica-0\t3\t 47/212 [=====>........................] - ETA: 1s - loss: 3.9270 - acc: 0.756\n",
      "INFO\t2019-09-09 14:48:51 -0400\tmaster-replica-0\t3\t 55/212 [======>.......................] - ETA: 0s - loss: 3.9476 - acc: 0.755\n",
      "INFO\t2019-09-09 14:48:51 -0400\tmaster-replica-0\t3\t 65/212 [========>.....................] - ETA: 0s - loss: 3.9465 - acc: 0.755\n",
      "INFO\t2019-09-09 14:48:51 -0400\tmaster-replica-0\t3\t 73/212 [=========>....................] - ETA: 0s - loss: 3.9339 - acc: 0.755\n",
      "INFO\t2019-09-09 14:48:51 -0400\tmaster-replica-0\t3\t 82/212 [==========>...................] - ETA: 0s - loss: 3.9145 - acc: 0.757\n",
      "INFO\t2019-09-09 14:48:51 -0400\tmaster-replica-0\t3\t 90/212 [===========>..................] - ETA: 0s - loss: 3.9095 - acc: 0.757\n",
      "INFO\t2019-09-09 14:48:51 -0400\tmaster-replica-0\t3\t100/212 [=============>................] - ETA: 0s - loss: 3.9063 - acc: 0.757\n",
      "INFO\t2019-09-09 14:48:51 -0400\tmaster-replica-0\t3\t108/212 [==============>...............] - ETA: 0s - loss: 3.8793 - acc: 0.759\n",
      "INFO\t2019-09-09 14:48:51 -0400\tmaster-replica-0\t3\t118/212 [===============>..............] - ETA: 0s - loss: 3.8782 - acc: 0.759\n",
      "INFO\t2019-09-09 14:48:51 -0400\tmaster-replica-0\t3\t126/212 [================>.............] - ETA: 0s - loss: 3.8761 - acc: 0.759\n",
      "INFO\t2019-09-09 14:48:51 -0400\tmaster-replica-0\t3\t136/212 [==================>...........] - ETA: 0s - loss: 3.8529 - acc: 0.761\n",
      "INFO\t2019-09-09 14:48:51 -0400\tmaster-replica-0\t3\t146/212 [===================>..........] - ETA: 0s - loss: 3.8733 - acc: 0.759\n",
      "INFO\t2019-09-09 14:48:51 -0400\tmaster-replica-0\t3\t154/212 [====================>.........] - ETA: 0s - loss: 3.8657 - acc: 0.760\n",
      "INFO\t2019-09-09 14:48:51 -0400\tmaster-replica-0\t3\t164/212 [======================>.......] - ETA: 0s - loss: 3.8760 - acc: 0.759\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO\t2019-09-09 14:48:51 -0400\tmaster-replica-0\t3\t173/212 [=======================>......] - ETA: 0s - loss: 3.8771 - acc: 0.759\n",
      "INFO\t2019-09-09 14:48:51 -0400\tmaster-replica-0\t3\t183/212 [========================>.....] - ETA: 0s - loss: 3.8806 - acc: 0.759\n",
      "INFO\t2019-09-09 14:48:51 -0400\tmaster-replica-0\t3\t191/212 [==========================>...] - ETA: 0s - loss: 3.8703 - acc: 0.759\n",
      "INFO\t2019-09-09 14:48:51 -0400\tmaster-replica-0\t3\t199/212 [===========================>..] - ETA: 0s - loss: 3.8576 - acc: 0.760\n",
      "INFO\t2019-09-09 14:48:52 -0400\tmaster-replica-0\t4\t436/446 [============================>.] - ETA: 0s - loss: 3.8842 - acc: 0.759\n",
      "INFO\t2019-09-09 14:48:52 -0400\tmaster-replica-0\t4\t446/446 [==============================] - 4s 9ms/step - loss: 3.8822 - acc: 0.7591 - val_loss: 3.8072 - val_acc: 0.7638\n",
      "INFO\t2019-09-09 14:48:52 -0400\tmaster-replica-0\t4\tEpoch 00007: LearningRateScheduler reducing learning rate to 0.03682028148705935.\n",
      "INFO\t2019-09-09 14:48:52 -0400\tmaster-replica-0\t4\tEpoch 7/20\n",
      "INFO\t2019-09-09 14:48:52 -0400\tmaster-replica-0\t4\t  1/446 [..............................] - ETA: 8s - loss: 4.4159 - acc: 0.726\n",
      "INFO\t2019-09-09 14:48:52 -0400\tmaster-replica-0\t4\t 13/446 [..............................] - ETA: 2s - loss: 3.8554 - acc: 0.760\n",
      "INFO\t2019-09-09 14:48:52 -0400\tmaster-replica-0\t4\t 28/446 [>.............................] - ETA: 2s - loss: 3.9743 - acc: 0.753\n",
      "INFO\t2019-09-09 14:48:52 -0400\tmaster-replica-0\t4\t 41/446 [=>............................] - ETA: 1s - loss: 3.9097 - acc: 0.757\n",
      "INFO\t2019-09-09 14:48:52 -0400\tmaster-replica-0\t4\t 54/446 [==>...........................] - ETA: 1s - loss: 3.9375 - acc: 0.755\n",
      "INFO\t2019-09-09 14:48:52 -0400\tmaster-replica-0\t4\t 67/446 [===>..........................] - ETA: 1s - loss: 3.9348 - acc: 0.755\n",
      "INFO\t2019-09-09 14:48:52 -0400\tmaster-replica-0\t4\t 78/446 [====>.........................] - ETA: 1s - loss: 3.9545 - acc: 0.754\n",
      "INFO\t2019-09-09 14:48:52 -0400\tmaster-replica-0\t4\t 94/446 [=====>........................] - ETA: 1s - loss: 3.9297 - acc: 0.756\n",
      "INFO\t2019-09-09 14:48:52 -0400\tmaster-replica-0\t4\t103/446 [=====>........................] - ETA: 1s - loss: 3.9465 - acc: 0.755\n",
      "INFO\t2019-09-09 14:48:52 -0400\tmaster-replica-0\t4\t120/446 [=======>......................] - ETA: 1s - loss: 3.9173 - acc: 0.757\n",
      "INFO\t2019-09-09 14:48:52 -0400\tmaster-replica-0\t4\t129/446 [=======>......................] - ETA: 1s - loss: 3.9144 - acc: 0.757\n",
      "INFO\t2019-09-09 14:48:52 -0400\tmaster-replica-0\t4\t143/446 [========>.....................] - ETA: 1s - loss: 3.9048 - acc: 0.757\n",
      "INFO\t2019-09-09 14:48:53 -0400\tmaster-replica-0\t4\t151/446 [=========>....................] - ETA: 1s - loss: 3.8778 - acc: 0.759\n",
      "INFO\t2019-09-09 14:48:53 -0400\tmaster-replica-0\t3\t207/212 [============================>.] - ETA: 0s - loss: 3.8622 - acc: 0.760\n",
      "INFO\t2019-09-09 14:48:53 -0400\tmaster-replica-0\t3\t212/212 [==============================] - 2s 11ms/step - loss: 3.8531 - acc: 0.7609 - val_loss: 3.8072 - val_acc: 0.7638\n",
      "INFO\t2019-09-09 14:48:53 -0400\tmaster-replica-0\t4\t167/446 [==========>...................] - ETA: 1s - loss: 3.8738 - acc: 0.759\n",
      "INFO\t2019-09-09 14:48:53 -0400\tmaster-replica-0\t4\t180/446 [===========>..................] - ETA: 1s - loss: 3.8823 - acc: 0.759\n",
      "INFO\t2019-09-09 14:48:53 -0400\tmaster-replica-0\t4\t193/446 [===========>..................] - ETA: 1s - loss: 3.8851 - acc: 0.759\n",
      "INFO\t2019-09-09 14:48:53 -0400\tmaster-replica-0\t4\t204/446 [============>.................] - ETA: 1s - loss: 3.8531 - acc: 0.760\n",
      "INFO\t2019-09-09 14:48:53 -0400\tmaster-replica-0\t4\t216/446 [=============>................] - ETA: 1s - loss: 3.8752 - acc: 0.759\n",
      "INFO\t2019-09-09 14:48:53 -0400\tmaster-replica-0\t4\t228/446 [==============>...............] - ETA: 0s - loss: 3.8494 - acc: 0.761\n",
      "INFO\t2019-09-09 14:48:53 -0400\tmaster-replica-0\t4\t241/446 [===============>..............] - ETA: 0s - loss: 3.8662 - acc: 0.760\n",
      "INFO\t2019-09-09 14:48:53 -0400\tmaster-replica-0\t4\t252/446 [===============>..............] - ETA: 0s - loss: 3.8403 - acc: 0.761\n",
      "INFO\t2019-09-09 14:48:53 -0400\tmaster-replica-0\t4\t266/446 [================>.............] - ETA: 0s - loss: 3.8399 - acc: 0.761\n",
      "INFO\t2019-09-09 14:48:53 -0400\tmaster-replica-0\t4\t280/446 [=================>............] - ETA: 0s - loss: 3.8458 - acc: 0.761\n",
      "INFO\t2019-09-09 14:48:53 -0400\tmaster-replica-0\t4\t294/446 [==================>...........] - ETA: 0s - loss: 3.8519 - acc: 0.761\n",
      "INFO\t2019-09-09 14:48:53 -0400\tmaster-replica-0\t4\t311/446 [===================>..........] - ETA: 0s - loss: 3.8614 - acc: 0.760\n",
      "INFO\t2019-09-09 14:48:53 -0400\tmaster-replica-0\t4\t323/446 [====================>.........] - ETA: 0s - loss: 3.8650 - acc: 0.760\n",
      "INFO\t2019-09-09 14:48:53 -0400\tmaster-replica-0\t4\t331/446 [=====================>........] - ETA: 0s - loss: 3.8709 - acc: 0.759\n",
      "INFO\t2019-09-09 14:48:53 -0400\tmaster-replica-0\t4\t342/446 [======================>.......] - ETA: 0s - loss: 3.8762 - acc: 0.759\n",
      "INFO\t2019-09-09 14:48:53 -0400\tmaster-replica-0\t4\t352/446 [======================>.......] - ETA: 0s - loss: 3.8752 - acc: 0.759\n",
      "INFO\t2019-09-09 14:48:53 -0400\tmaster-replica-0\t4\t359/446 [=======================>......] - ETA: 0s - loss: 3.8815 - acc: 0.759\n",
      "INFO\t2019-09-09 14:48:53 -0400\tmaster-replica-0\t4\t368/446 [=======================>......] - ETA: 0s - loss: 3.8753 - acc: 0.759\n",
      "INFO\t2019-09-09 14:48:54 -0400\tmaster-replica-0\t4\t382/446 [========================>.....] - ETA: 0s - loss: 3.8697 - acc: 0.759\n",
      "INFO\t2019-09-09 14:48:54 -0400\tmaster-replica-0\t4\t394/446 [=========================>....] - ETA: 0s - loss: 3.8740 - acc: 0.759\n",
      "INFO\t2019-09-09 14:48:54 -0400\tmaster-replica-0\t4\t407/446 [==========================>...] - ETA: 0s - loss: 3.8745 - acc: 0.759\n",
      "INFO\t2019-09-09 14:48:54 -0400\tmaster-replica-0\t4\t415/446 [==========================>...] - ETA: 0s - loss: 3.8775 - acc: 0.759\n",
      "INFO\t2019-09-09 14:48:54 -0400\tmaster-replica-0\t4\t428/446 [===========================>..] - ETA: 0s - loss: 3.8861 - acc: 0.758\n",
      "INFO\t2019-09-09 14:48:55 -0400\tmaster-replica-0\t4\t442/446 [============================>.] - ETA: 0s - loss: 3.8759 - acc: 0.759\n",
      "INFO\t2019-09-09 14:48:55 -0400\tmaster-replica-0\t4\t446/446 [==============================] - 3s 7ms/step - loss: 3.8798 - acc: 0.7593 - val_loss: 3.8072 - val_acc: 0.7638\n",
      "INFO\t2019-09-09 14:48:55 -0400\tmaster-replica-0\t4\tEpoch 00008: LearningRateScheduler reducing learning rate to 0.03674215648705935.\n",
      "INFO\t2019-09-09 14:48:55 -0400\tmaster-replica-0\t4\tEpoch 8/20\n",
      "INFO\t2019-09-09 14:48:55 -0400\tmaster-replica-0\t4\t  1/446 [..............................] - ETA: 42s - loss: 3.3119 - acc: 0.79\n",
      "INFO\t2019-09-09 14:48:55 -0400\tmaster-replica-0\t4\t 12/446 [..............................] - ETA: 5s - loss: 3.9559 - acc: 0.7546\n",
      "INFO\t2019-09-09 14:48:55 -0400\tmaster-replica-0\t4\t 26/446 [>.............................] - ETA: 3s - loss: 3.7960 - acc: 0.764\n",
      "INFO\t2019-09-09 14:48:55 -0400\tmaster-replica-0\t4\t 34/446 [=>............................] - ETA: 3s - loss: 3.8055 - acc: 0.763\n",
      "INFO\t2019-09-09 14:48:55 -0400\tmaster-replica-0\t4\t 44/446 [=>............................] - ETA: 2s - loss: 3.8740 - acc: 0.759\n",
      "INFO\t2019-09-09 14:48:55 -0400\tmaster-replica-0\t4\t 58/446 [==>...........................] - ETA: 2s - loss: 3.8525 - acc: 0.761\n",
      "INFO\t2019-09-09 14:48:55 -0400\tmaster-replica-0\t4\t 71/446 [===>..........................] - ETA: 2s - loss: 3.8997 - acc: 0.758\n",
      "INFO\t2019-09-09 14:48:55 -0400\tmaster-replica-0\t4\t 79/446 [====>.........................] - ETA: 2s - loss: 3.9268 - acc: 0.756\n",
      "INFO\t2019-09-09 14:48:55 -0400\tmaster-replica-0\t4\t 92/446 [=====>........................] - ETA: 1s - loss: 3.9167 - acc: 0.757\n",
      "INFO\t2019-09-09 14:48:55 -0400\tmaster-replica-0\t4\t103/446 [=====>........................] - ETA: 1s - loss: 3.8736 - acc: 0.759\n",
      "INFO\t2019-09-09 14:48:55 -0400\tmaster-replica-0\t4\t110/446 [======>.......................] - ETA: 1s - loss: 3.8880 - acc: 0.758\n",
      "INFO\t2019-09-09 14:48:56 -0400\tmaster-replica-0\t4\t122/446 [=======>......................] - ETA: 1s - loss: 3.8983 - acc: 0.758\n",
      "INFO\t2019-09-09 14:48:56 -0400\tmaster-replica-0\t4\t136/446 [========>.....................] - ETA: 1s - loss: 3.9354 - acc: 0.755\n",
      "INFO\t2019-09-09 14:48:56 -0400\tmaster-replica-0\t4\t153/446 [=========>....................] - ETA: 1s - loss: 3.9455 - acc: 0.755\n",
      "INFO\t2019-09-09 14:48:56 -0400\tmaster-replica-0\t4\t160/446 [=========>....................] - ETA: 1s - loss: 3.9329 - acc: 0.756\n",
      "INFO\t2019-09-09 14:48:56 -0400\tmaster-replica-0\t4\t171/446 [==========>...................] - ETA: 1s - loss: 3.9072 - acc: 0.757\n",
      "INFO\t2019-09-09 14:48:56 -0400\tmaster-replica-0\t4\t184/446 [===========>..................] - ETA: 1s - loss: 3.8891 - acc: 0.758\n",
      "INFO\t2019-09-09 14:48:56 -0400\tmaster-replica-0\t4\t194/446 [============>.................] - ETA: 1s - loss: 3.8753 - acc: 0.759\n",
      "INFO\t2019-09-09 14:48:56 -0400\tmaster-replica-0\t4\t208/446 [============>.................] - ETA: 1s - loss: 3.8703 - acc: 0.759\n",
      "INFO\t2019-09-09 14:48:56 -0400\tmaster-replica-0\t4\t221/446 [=============>................] - ETA: 1s - loss: 3.8674 - acc: 0.760\n",
      "INFO\t2019-09-09 14:48:56 -0400\tmaster-replica-0\t4\t234/446 [==============>...............] - ETA: 1s - loss: 3.8573 - acc: 0.760\n",
      "INFO\t2019-09-09 14:48:56 -0400\tmaster-replica-0\t4\t247/446 [===============>..............] - ETA: 0s - loss: 3.8536 - acc: 0.760\n",
      "INFO\t2019-09-09 14:48:56 -0400\tmaster-replica-0\t4\t263/446 [================>.............] - ETA: 0s - loss: 3.8828 - acc: 0.759\n",
      "INFO\t2019-09-09 14:48:56 -0400\tmaster-replica-0\t4\t274/446 [=================>............] - ETA: 0s - loss: 3.8849 - acc: 0.759\n",
      "INFO\t2019-09-09 14:48:56 -0400\tmaster-replica-0\t4\t284/446 [==================>...........] - ETA: 0s - loss: 3.8639 - acc: 0.760\n",
      "INFO\t2019-09-09 14:48:56 -0400\tmaster-replica-0\t4\t290/446 [==================>...........] - ETA: 0s - loss: 3.8533 - acc: 0.760\n",
      "INFO\t2019-09-09 14:48:56 -0400\tmaster-replica-0\t4\t301/446 [===================>..........] - ETA: 0s - loss: 3.8504 - acc: 0.761\n",
      "INFO\t2019-09-09 14:48:56 -0400\tmaster-replica-0\t4\t313/446 [====================>.........] - ETA: 0s - loss: 3.8473 - acc: 0.761\n",
      "INFO\t2019-09-09 14:48:56 -0400\tmaster-replica-0\t4\t325/446 [====================>.........] - ETA: 0s - loss: 3.8486 - acc: 0.761\n",
      "INFO\t2019-09-09 14:48:57 -0400\tmaster-replica-0\t4\t335/446 [=====================>........] - ETA: 0s - loss: 3.8590 - acc: 0.760\n",
      "INFO\t2019-09-09 14:48:57 -0400\tmaster-replica-0\t4\t351/446 [======================>.......] - ETA: 0s - loss: 3.8611 - acc: 0.760\n",
      "INFO\t2019-09-09 14:48:57 -0400\tmaster-replica-0\t4\t364/446 [=======================>......] - ETA: 0s - loss: 3.8676 - acc: 0.760\n",
      "INFO\t2019-09-09 14:48:57 -0400\tmaster-replica-0\t4\t378/446 [========================>.....] - ETA: 0s - loss: 3.8680 - acc: 0.760\n",
      "INFO\t2019-09-09 14:48:57 -0400\tmaster-replica-0\t4\t386/446 [========================>.....] - ETA: 0s - loss: 3.8674 - acc: 0.760\n",
      "INFO\t2019-09-09 14:48:57 -0400\tmaster-replica-0\t4\t400/446 [=========================>....] - ETA: 0s - loss: 3.8694 - acc: 0.759\n",
      "INFO\t2019-09-09 14:48:57 -0400\tmaster-replica-0\t4\t406/446 [==========================>...] - ETA: 0s - loss: 3.8743 - acc: 0.759\n",
      "INFO\t2019-09-09 14:48:57 -0400\tmaster-replica-0\t4\t418/446 [===========================>..] - ETA: 0s - loss: 3.8882 - acc: 0.758\n",
      "INFO\t2019-09-09 14:48:57 -0400\tmaster-replica-0\t4\t433/446 [============================>.] - ETA: 0s - loss: 3.8876 - acc: 0.758\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO\t2019-09-09 14:48:58 -0400\tmaster-replica-0\t4\t442/446 [============================>.] - ETA: 0s - loss: 3.8854 - acc: 0.758\n",
      "INFO\t2019-09-09 14:48:58 -0400\tmaster-replica-0\t4\t446/446 [==============================] - 3s 7ms/step - loss: 3.8817 - acc: 0.7592 - val_loss: 3.8072 - val_acc: 0.7638\n",
      "INFO\t2019-09-09 14:48:58 -0400\tmaster-replica-0\t4\tEpoch 00009: LearningRateScheduler reducing learning rate to 0.03670309398705935.\n",
      "INFO\t2019-09-09 14:48:58 -0400\tmaster-replica-0\t4\tEpoch 9/20\n",
      "INFO\t2019-09-09 14:48:58 -0400\tmaster-replica-0\t4\t  1/446 [..............................] - ETA: 1s - loss: 3.0911 - acc: 0.808\n",
      "INFO\t2019-09-09 14:48:58 -0400\tmaster-replica-0\t4\t  9/446 [..............................] - ETA: 2s - loss: 3.8026 - acc: 0.764\n",
      "INFO\t2019-09-09 14:48:58 -0400\tmaster-replica-0\t4\t 22/446 [>.............................] - ETA: 2s - loss: 3.6431 - acc: 0.774\n",
      "INFO\t2019-09-09 14:48:58 -0400\tmaster-replica-0\t4\t 33/446 [=>............................] - ETA: 1s - loss: 3.5796 - acc: 0.777\n",
      "INFO\t2019-09-09 14:48:58 -0400\tmaster-replica-0\t4\t 45/446 [==>...........................] - ETA: 1s - loss: 3.6554 - acc: 0.773\n",
      "INFO\t2019-09-09 14:48:58 -0400\tmaster-replica-0\t4\t 55/446 [==>...........................] - ETA: 1s - loss: 3.6853 - acc: 0.771\n",
      "INFO\t2019-09-09 14:48:58 -0400\tmaster-replica-0\t4\t 69/446 [===>..........................] - ETA: 1s - loss: 3.8175 - acc: 0.763\n",
      "INFO\t2019-09-09 14:48:58 -0400\tmaster-replica-0\t4\t 82/446 [====>.........................] - ETA: 1s - loss: 3.8558 - acc: 0.760\n",
      "INFO\t2019-09-09 14:48:59 -0400\tmaster-replica-0\t4\t 95/446 [=====>........................] - ETA: 1s - loss: 3.9069 - acc: 0.757\n",
      "INFO\t2019-09-09 14:48:59 -0400\tmaster-replica-0\t4\t107/446 [======>.......................] - ETA: 1s - loss: 3.8567 - acc: 0.760\n",
      "INFO\t2019-09-09 14:48:59 -0400\tmaster-replica-0\t4\t121/446 [=======>......................] - ETA: 1s - loss: 3.8867 - acc: 0.758\n",
      "INFO\t2019-09-09 14:48:59 -0400\tmaster-replica-0\t4\t133/446 [=======>......................] - ETA: 1s - loss: 3.8614 - acc: 0.760\n",
      "INFO\t2019-09-09 14:48:59 -0400\tmaster-replica-0\t4\t147/446 [========>.....................] - ETA: 1s - loss: 3.8226 - acc: 0.762\n",
      "INFO\t2019-09-09 14:48:59 -0400\tmaster-replica-0\t4\t160/446 [=========>....................] - ETA: 1s - loss: 3.8101 - acc: 0.763\n",
      "INFO\t2019-09-09 14:48:59 -0400\tmaster-replica-0\t4\t174/446 [==========>...................] - ETA: 1s - loss: 3.8246 - acc: 0.762\n",
      "INFO\t2019-09-09 14:48:59 -0400\tmaster-replica-0\t4\t187/446 [===========>..................] - ETA: 1s - loss: 3.8232 - acc: 0.762\n",
      "INFO\t2019-09-09 14:48:59 -0400\tmaster-replica-0\t4\t197/446 [============>.................] - ETA: 1s - loss: 3.8152 - acc: 0.763\n",
      "INFO\t2019-09-09 14:48:59 -0400\tmaster-replica-0\t4\t211/446 [=============>................] - ETA: 1s - loss: 3.8310 - acc: 0.762\n",
      "INFO\t2019-09-09 14:48:59 -0400\tmaster-replica-0\t4\t222/446 [=============>................] - ETA: 0s - loss: 3.8510 - acc: 0.761\n",
      "INFO\t2019-09-09 14:48:59 -0400\tmaster-replica-0\t4\t235/446 [==============>...............] - ETA: 0s - loss: 3.8606 - acc: 0.760\n",
      "INFO\t2019-09-09 14:48:59 -0400\tmaster-replica-0\t4\t246/446 [===============>..............] - ETA: 0s - loss: 3.8666 - acc: 0.760\n",
      "INFO\t2019-09-09 14:48:59 -0400\tmaster-replica-0\t4\t258/446 [================>.............] - ETA: 0s - loss: 3.8605 - acc: 0.760\n",
      "INFO\t2019-09-09 14:48:59 -0400\tmaster-replica-0\t4\t270/446 [=================>............] - ETA: 0s - loss: 3.8557 - acc: 0.760\n",
      "INFO\t2019-09-09 14:48:59 -0400\tmaster-replica-0\t4\t287/446 [==================>...........] - ETA: 0s - loss: 3.8666 - acc: 0.760\n",
      "INFO\t2019-09-09 14:48:59 -0400\tmaster-replica-0\t4\t296/446 [==================>...........] - ETA: 0s - loss: 3.8624 - acc: 0.760\n",
      "INFO\t2019-09-09 14:48:59 -0400\tmaster-replica-0\t4\t306/446 [===================>..........] - ETA: 0s - loss: 3.8596 - acc: 0.760\n",
      "INFO\t2019-09-09 14:49:00 -0400\tmaster-replica-0\t4\t319/446 [====================>.........] - ETA: 0s - loss: 3.8504 - acc: 0.761\n",
      "INFO\t2019-09-09 14:49:00 -0400\tmaster-replica-0\t4\t335/446 [=====================>........] - ETA: 0s - loss: 3.8708 - acc: 0.759\n",
      "INFO\t2019-09-09 14:49:00 -0400\tmaster-replica-0\t4\t346/446 [======================>.......] - ETA: 0s - loss: 3.8633 - acc: 0.760\n",
      "INFO\t2019-09-09 14:49:00 -0400\tmaster-replica-0\t4\t358/446 [=======================>......] - ETA: 0s - loss: 3.8781 - acc: 0.759\n",
      "INFO\t2019-09-09 14:49:00 -0400\tmaster-replica-0\t4\t366/446 [=======================>......] - ETA: 0s - loss: 3.8784 - acc: 0.759\n",
      "INFO\t2019-09-09 14:49:00 -0400\tmaster-replica-0\t4\t378/446 [========================>.....] - ETA: 0s - loss: 3.8797 - acc: 0.759\n",
      "INFO\t2019-09-09 14:49:00 -0400\tmaster-replica-0\t4\t392/446 [=========================>....] - ETA: 0s - loss: 3.8741 - acc: 0.759\n",
      "INFO\t2019-09-09 14:49:00 -0400\tmaster-replica-0\t4\t403/446 [==========================>...] - ETA: 0s - loss: 3.8861 - acc: 0.758\n",
      "INFO\t2019-09-09 14:49:00 -0400\tmaster-replica-0\t4\t414/446 [==========================>...] - ETA: 0s - loss: 3.8847 - acc: 0.759\n",
      "INFO\t2019-09-09 14:49:00 -0400\tmaster-replica-0\t4\t428/446 [===========================>..] - ETA: 0s - loss: 3.8866 - acc: 0.758\n",
      "WARNING\t2019-09-09 14:49:00 -0400\tmaster-replica-0\t3\tThis model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.RMSprop object at 0x7f08a5dcfbe0>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "WARNING\t2019-09-09 14:49:00 -0400\tmaster-replica-0\t3\t\n",
      "WARNING\t2019-09-09 14:49:00 -0400\tmaster-replica-0\t3\tConsider using a TensorFlow optimizer from `tf.train`.\n",
      "INFO\t2019-09-09 14:49:01 -0400\tmaster-replica-0\t4\t443/446 [============================>.] - ETA: 0s - loss: 3.8876 - acc: 0.758\n",
      "INFO\t2019-09-09 14:49:01 -0400\tmaster-replica-0\t4\t446/446 [==============================] - 3s 7ms/step - loss: 3.8817 - acc: 0.7592 - val_loss: 3.8072 - val_acc: 0.7638\n",
      "INFO\t2019-09-09 14:49:01 -0400\tmaster-replica-0\t4\tEpoch 00010: LearningRateScheduler reducing learning rate to 0.036683562737059354.\n",
      "INFO\t2019-09-09 14:49:01 -0400\tmaster-replica-0\t4\tEpoch 10/20\n",
      "INFO\t2019-09-09 14:49:01 -0400\tmaster-replica-0\t4\t  1/446 [..............................] - ETA: 17s - loss: 3.7535 - acc: 0.76\n",
      "INFO\t2019-09-09 14:49:01 -0400\tmaster-replica-0\t4\t 11/446 [..............................] - ETA: 3s - loss: 4.0747 - acc: 0.7472\n",
      "INFO\t2019-09-09 14:49:01 -0400\tmaster-replica-0\t4\t 23/446 [>.............................] - ETA: 2s - loss: 3.7247 - acc: 0.768\n",
      "INFO\t2019-09-09 14:49:01 -0400\tmaster-replica-0\t4\t 34/446 [=>............................] - ETA: 2s - loss: 3.7405 - acc: 0.767\n",
      "INFO\t2019-09-09 14:49:01 -0400\tmaster-replica-0\t4\t 45/446 [==>...........................] - ETA: 2s - loss: 3.7143 - acc: 0.769\n",
      "INFO\t2019-09-09 14:49:02 -0400\tmaster-replica-0\t4\t 61/446 [===>..........................] - ETA: 1s - loss: 3.7752 - acc: 0.765\n",
      "INFO\t2019-09-09 14:49:02 -0400\tmaster-replica-0\t4\t 72/446 [===>..........................] - ETA: 1s - loss: 3.7781 - acc: 0.765\n",
      "INFO\t2019-09-09 14:49:02 -0400\tmaster-replica-0\t4\t 84/446 [====>.........................] - ETA: 1s - loss: 3.8534 - acc: 0.760\n",
      "INFO\t2019-09-09 14:49:02 -0400\tmaster-replica-0\t4\t 96/446 [=====>........................] - ETA: 1s - loss: 3.8961 - acc: 0.758\n",
      "INFO\t2019-09-09 14:49:02 -0400\tmaster-replica-0\t4\t108/446 [======>.......................] - ETA: 1s - loss: 3.9028 - acc: 0.757\n",
      "INFO\t2019-09-09 14:49:02 -0400\tmaster-replica-0\t4\t114/446 [======>.......................] - ETA: 1s - loss: 3.9317 - acc: 0.756\n",
      "INFO\t2019-09-09 14:49:02 -0400\tmaster-replica-0\t4\t128/446 [=======>......................] - ETA: 1s - loss: 3.9467 - acc: 0.755\n",
      "INFO\t2019-09-09 14:49:02 -0400\tmaster-replica-0\t4\t142/446 [========>.....................] - ETA: 1s - loss: 3.9090 - acc: 0.757\n",
      "INFO\t2019-09-09 14:49:02 -0400\tmaster-replica-0\t4\t155/446 [=========>....................] - ETA: 1s - loss: 3.8874 - acc: 0.758\n",
      "INFO\t2019-09-09 14:49:02 -0400\tmaster-replica-0\t4\t168/446 [==========>...................] - ETA: 1s - loss: 3.9047 - acc: 0.757\n",
      "INFO\t2019-09-09 14:49:02 -0400\tmaster-replica-0\t4\t183/446 [===========>..................] - ETA: 1s - loss: 3.9043 - acc: 0.757\n",
      "INFO\t2019-09-09 14:49:02 -0400\tmaster-replica-0\t4\t194/446 [============>.................] - ETA: 1s - loss: 3.8981 - acc: 0.758\n",
      "INFO\t2019-09-09 14:49:02 -0400\tmaster-replica-0\t4\t210/446 [=============>................] - ETA: 1s - loss: 3.8829 - acc: 0.759\n",
      "INFO\t2019-09-09 14:49:02 -0400\tmaster-replica-0\t4\t219/446 [=============>................] - ETA: 1s - loss: 3.8715 - acc: 0.759\n",
      "INFO\t2019-09-09 14:49:02 -0400\tmaster-replica-0\t4\t234/446 [==============>...............] - ETA: 0s - loss: 3.8875 - acc: 0.758\n",
      "INFO\t2019-09-09 14:49:02 -0400\tmaster-replica-0\t4\t247/446 [===============>..............] - ETA: 0s - loss: 3.8858 - acc: 0.758\n",
      "INFO\t2019-09-09 14:49:02 -0400\tmaster-replica-0\t4\t256/446 [================>.............] - ETA: 0s - loss: 3.8872 - acc: 0.758\n",
      "INFO\t2019-09-09 14:49:02 -0400\tmaster-replica-0\t4\t268/446 [=================>............] - ETA: 0s - loss: 3.8919 - acc: 0.758\n",
      "INFO\t2019-09-09 14:49:02 -0400\tmaster-replica-0\t4\t280/446 [=================>............] - ETA: 0s - loss: 3.9002 - acc: 0.758\n",
      "INFO\t2019-09-09 14:49:03 -0400\tmaster-replica-0\t4\t295/446 [==================>...........] - ETA: 0s - loss: 3.8695 - acc: 0.759\n",
      "INFO\t2019-09-09 14:49:03 -0400\tmaster-replica-0\t4\t306/446 [===================>..........] - ETA: 0s - loss: 3.8654 - acc: 0.760\n",
      "INFO\t2019-09-09 14:49:03 -0400\tmaster-replica-0\t4\t322/446 [====================>.........] - ETA: 0s - loss: 3.8776 - acc: 0.759\n",
      "INFO\t2019-09-09 14:49:03 -0400\tmaster-replica-0\t4\t333/446 [=====================>........] - ETA: 0s - loss: 3.8643 - acc: 0.760\n",
      "INFO\t2019-09-09 14:49:03 -0400\tmaster-replica-0\t4\t346/446 [======================>.......] - ETA: 0s - loss: 3.8537 - acc: 0.760\n",
      "INFO\t2019-09-09 14:49:03 -0400\tmaster-replica-0\t4\t356/446 [======================>.......] - ETA: 0s - loss: 3.8497 - acc: 0.761\n",
      "INFO\t2019-09-09 14:49:03 -0400\tmaster-replica-0\t4\t369/446 [=======================>......] - ETA: 0s - loss: 3.8600 - acc: 0.760\n",
      "INFO\t2019-09-09 14:49:03 -0400\tmaster-replica-0\t4\t379/446 [========================>.....] - ETA: 0s - loss: 3.8718 - acc: 0.759\n",
      "INFO\t2019-09-09 14:49:03 -0400\tmaster-replica-0\t4\t390/446 [=========================>....] - ETA: 0s - loss: 3.8719 - acc: 0.759\n",
      "INFO\t2019-09-09 14:49:03 -0400\tmaster-replica-0\t4\t403/446 [==========================>...] - ETA: 0s - loss: 3.8658 - acc: 0.760\n",
      "INFO\t2019-09-09 14:49:03 -0400\tmaster-replica-0\t4\t416/446 [==========================>...] - ETA: 0s - loss: 3.8671 - acc: 0.760\n",
      "INFO\t2019-09-09 14:49:03 -0400\tmaster-replica-0\t4\t426/446 [===========================>..] - ETA: 0s - loss: 3.8769 - acc: 0.759\n",
      "INFO\t2019-09-09 14:49:04 -0400\tmaster-replica-0\t4\t440/446 [============================>.] - ETA: 0s - loss: 3.8795 - acc: 0.759\n",
      "INFO\t2019-09-09 14:49:04 -0400\tmaster-replica-0\t4\t446/446 [==============================] - 3s 7ms/step - loss: 3.8813 - acc: 0.7592 - val_loss: 3.8072 - val_acc: 0.7638\n",
      "INFO\t2019-09-09 14:49:04 -0400\tmaster-replica-0\t4\tEpoch 00011: LearningRateScheduler reducing learning rate to 0.03667379711205935.\n",
      "INFO\t2019-09-09 14:49:04 -0400\tmaster-replica-0\t4\tEpoch 11/20\n",
      "INFO\t2019-09-09 14:49:04 -0400\tmaster-replica-0\t4\t  1/446 [..............................] - ETA: 36s - loss: 3.7535 - acc: 0.76\n",
      "INFO\t2019-09-09 14:49:04 -0400\tmaster-replica-0\t4\t 15/446 [>.............................] - ETA: 3s - loss: 4.1510 - acc: 0.7425\n",
      "INFO\t2019-09-09 14:49:04 -0400\tmaster-replica-0\t4\t 26/446 [>.............................] - ETA: 3s - loss: 3.8554 - acc: 0.760\n",
      "INFO\t2019-09-09 14:49:05 -0400\tmaster-replica-0\t4\t 39/446 [=>............................] - ETA: 2s - loss: 3.7818 - acc: 0.765\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO\t2019-09-09 14:49:05 -0400\tmaster-replica-0\t4\t 51/446 [==>...........................] - ETA: 2s - loss: 3.7925 - acc: 0.764\n",
      "INFO\t2019-09-09 14:49:05 -0400\tmaster-replica-0\t4\t 65/446 [===>..........................] - ETA: 2s - loss: 3.8588 - acc: 0.760\n",
      "INFO\t2019-09-09 14:49:05 -0400\tmaster-replica-0\t4\t 73/446 [===>..........................] - ETA: 2s - loss: 3.8412 - acc: 0.761\n",
      "INFO\t2019-09-09 14:49:05 -0400\tmaster-replica-0\t4\t 87/446 [====>.........................] - ETA: 1s - loss: 3.8094 - acc: 0.763\n",
      "INFO\t2019-09-09 14:49:05 -0400\tmaster-replica-0\t4\t 98/446 [=====>........................] - ETA: 1s - loss: 3.8279 - acc: 0.762\n",
      "INFO\t2019-09-09 14:49:05 -0400\tmaster-replica-0\t4\t113/446 [======>.......................] - ETA: 1s - loss: 3.8356 - acc: 0.762\n",
      "INFO\t2019-09-09 14:49:05 -0400\tmaster-replica-0\t4\t124/446 [=======>......................] - ETA: 1s - loss: 3.8960 - acc: 0.758\n",
      "INFO\t2019-09-09 14:49:05 -0400\tmaster-replica-0\t4\t138/446 [========>.....................] - ETA: 1s - loss: 3.8847 - acc: 0.759\n",
      "INFO\t2019-09-09 14:49:05 -0400\tmaster-replica-0\t4\t151/446 [=========>....................] - ETA: 1s - loss: 3.8881 - acc: 0.758\n",
      "WARNING\t2019-09-09 14:49:05 -0400\tmaster-replica-0\t3\tFrom /usr/local/lib/python3.5/dist-packages/tensorflow/python/keras/engine/network.py:1436: update_checkpoint_state (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "WARNING\t2019-09-09 14:49:05 -0400\tmaster-replica-0\t3\tInstructions for updating:\n",
      "WARNING\t2019-09-09 14:49:05 -0400\tmaster-replica-0\t3\tUse tf.train.CheckpointManager to manage checkpoints rather than manually editing the Checkpoint proto.\n",
      "INFO\t2019-09-09 14:49:05 -0400\tmaster-replica-0\t4\t165/446 [==========>...................] - ETA: 1s - loss: 3.8633 - acc: 0.760\n",
      "INFO\t2019-09-09 14:49:05 -0400\tmaster-replica-0\t4\t176/446 [==========>...................] - ETA: 1s - loss: 3.8627 - acc: 0.760\n",
      "INFO\t2019-09-09 14:49:05 -0400\tmaster-replica-0\t4\t188/446 [===========>..................] - ETA: 1s - loss: 3.8651 - acc: 0.760\n",
      "INFO\t2019-09-09 14:49:05 -0400\tmaster-replica-0\t4\t199/446 [============>.................] - ETA: 1s - loss: 3.8767 - acc: 0.759\n",
      "INFO\t2019-09-09 14:49:05 -0400\tmaster-replica-0\t4\t213/446 [=============>................] - ETA: 1s - loss: 3.8862 - acc: 0.758\n",
      "INFO\t2019-09-09 14:49:05 -0400\tmaster-replica-0\t4\t224/446 [==============>...............] - ETA: 1s - loss: 3.8777 - acc: 0.759\n",
      "INFO\t2019-09-09 14:49:05 -0400\tmaster-replica-0\t4\t238/446 [===============>..............] - ETA: 0s - loss: 3.8741 - acc: 0.759\n",
      "INFO\t2019-09-09 14:49:05 -0400\tmaster-replica-0\t4\t250/446 [===============>..............] - ETA: 0s - loss: 3.8878 - acc: 0.758\n",
      "INFO\t2019-09-09 14:49:05 -0400\tmaster-replica-0\t4\t260/446 [================>.............] - ETA: 0s - loss: 3.9038 - acc: 0.757\n",
      "INFO\t2019-09-09 14:49:06 -0400\tmaster-replica-0\t4\t270/446 [=================>............] - ETA: 0s - loss: 3.9073 - acc: 0.757\n",
      "INFO\t2019-09-09 14:49:06 -0400\tmaster-replica-0\t4\t281/446 [=================>............] - ETA: 0s - loss: 3.9123 - acc: 0.757\n",
      "INFO\t2019-09-09 14:49:06 -0400\tmaster-replica-0\t4\t294/446 [==================>...........] - ETA: 0s - loss: 3.9203 - acc: 0.756\n",
      "INFO\t2019-09-09 14:49:06 -0400\tmaster-replica-0\t4\t303/446 [===================>..........] - ETA: 0s - loss: 3.9117 - acc: 0.757\n",
      "INFO\t2019-09-09 14:49:06 -0400\tmaster-replica-0\t4\t316/446 [====================>.........] - ETA: 0s - loss: 3.8877 - acc: 0.758\n",
      "INFO\t2019-09-09 14:49:06 -0400\tmaster-replica-0\t4\t327/446 [====================>.........] - ETA: 0s - loss: 3.8764 - acc: 0.759\n",
      "INFO\t2019-09-09 14:49:06 -0400\tmaster-replica-0\t4\t340/446 [=====================>........] - ETA: 0s - loss: 3.8873 - acc: 0.758\n",
      "INFO\t2019-09-09 14:49:06 -0400\tmaster-replica-0\t4\t350/446 [======================>.......] - ETA: 0s - loss: 3.8892 - acc: 0.758\n",
      "INFO\t2019-09-09 14:49:06 -0400\tmaster-replica-0\t4\t365/446 [=======================>......] - ETA: 0s - loss: 3.8733 - acc: 0.759\n",
      "INFO\t2019-09-09 14:49:06 -0400\tmaster-replica-0\t4\t378/446 [========================>.....] - ETA: 0s - loss: 3.8628 - acc: 0.760\n",
      "INFO\t2019-09-09 14:49:06 -0400\tmaster-replica-0\t4\t391/446 [=========================>....] - ETA: 0s - loss: 3.8721 - acc: 0.759\n",
      "INFO\t2019-09-09 14:49:06 -0400\tmaster-replica-0\t4\t398/446 [=========================>....] - ETA: 0s - loss: 3.8645 - acc: 0.760\n",
      "INFO\t2019-09-09 14:49:06 -0400\tmaster-replica-0\t4\t410/446 [==========================>...] - ETA: 0s - loss: 3.8704 - acc: 0.759\n",
      "INFO\t2019-09-09 14:49:06 -0400\tmaster-replica-0\t4\t423/446 [===========================>..] - ETA: 0s - loss: 3.8819 - acc: 0.759\n",
      "WARNING\t2019-09-09 14:49:07 -0400\tmaster-replica-0\t3\tModel was compiled with an optimizer, but the optimizer is not from `tf.train` (e.g. `tf.train.AdagradOptimizer`). Only the serving graph was exported. The train and evaluate graphs were not added to the SavedModel.\n",
      "INFO\t2019-09-09 14:49:07 -0400\tmaster-replica-0\t4\t435/446 [============================>.] - ETA: 0s - loss: 3.8906 - acc: 0.758\n",
      "INFO\t2019-09-09 14:49:07 -0400\tmaster-replica-0\t4\t446/446 [==============================] - 3s 7ms/step - loss: 3.8822 - acc: 0.7591 - val_loss: 3.8072 - val_acc: 0.7638\n",
      "INFO\t2019-09-09 14:49:07 -0400\tmaster-replica-0\t4\tEpoch 00012: LearningRateScheduler reducing learning rate to 0.03666891429955935.\n",
      "INFO\t2019-09-09 14:49:07 -0400\tmaster-replica-0\t4\tEpoch 12/20\n",
      "INFO\t2019-09-09 14:49:07 -0400\tmaster-replica-0\t4\t  1/446 [..............................] - ETA: 2s - loss: 3.7535 - acc: 0.767\n",
      "INFO\t2019-09-09 14:49:07 -0400\tmaster-replica-0\t4\t 16/446 [>.............................] - ETA: 1s - loss: 4.0295 - acc: 0.750\n",
      "INFO\t2019-09-09 14:49:07 -0400\tmaster-replica-0\t4\t 30/446 [=>............................] - ETA: 1s - loss: 3.9522 - acc: 0.754\n",
      "INFO\t2019-09-09 14:49:07 -0400\tmaster-replica-0\t4\t 47/446 [==>...........................] - ETA: 1s - loss: 3.9367 - acc: 0.755\n",
      "INFO\t2019-09-09 14:49:08 -0400\tmaster-replica-0\t4\t 59/446 [==>...........................] - ETA: 1s - loss: 3.9107 - acc: 0.757\n",
      "INFO\t2019-09-09 14:49:08 -0400\tmaster-replica-0\t4\t 75/446 [====>.........................] - ETA: 1s - loss: 3.9302 - acc: 0.756\n",
      "INFO\t2019-09-09 14:49:08 -0400\tmaster-replica-0\t4\t 92/446 [=====>........................] - ETA: 1s - loss: 3.9479 - acc: 0.755\n",
      "INFO\t2019-09-09 14:49:08 -0400\tmaster-replica-0\t4\t106/446 [======>.......................] - ETA: 1s - loss: 3.9160 - acc: 0.757\n",
      "INFO\t2019-09-09 14:49:08 -0400\tmaster-replica-0\t4\t123/446 [=======>......................] - ETA: 1s - loss: 3.9438 - acc: 0.755\n",
      "INFO\t2019-09-09 14:49:08 -0400\tmaster-replica-0\t4\t138/446 [========>.....................] - ETA: 1s - loss: 3.9039 - acc: 0.757\n",
      "INFO\t2019-09-09 14:49:08 -0400\tmaster-replica-0\t4\t154/446 [=========>....................] - ETA: 1s - loss: 3.8897 - acc: 0.758\n",
      "INFO\t2019-09-09 14:49:08 -0400\tmaster-replica-0\t4\t169/446 [==========>...................] - ETA: 0s - loss: 3.8711 - acc: 0.759\n",
      "INFO\t2019-09-09 14:49:08 -0400\tmaster-replica-0\t4\t187/446 [===========>..................] - ETA: 0s - loss: 3.8763 - acc: 0.759\n",
      "INFO\t2019-09-09 14:49:08 -0400\tmaster-replica-0\t4\t201/446 [============>.................] - ETA: 0s - loss: 3.8524 - acc: 0.761\n",
      "INFO\t2019-09-09 14:49:08 -0400\tmaster-replica-0\t4\t218/446 [=============>................] - ETA: 0s - loss: 3.8366 - acc: 0.762\n",
      "INFO\t2019-09-09 14:49:08 -0400\tmaster-replica-0\t4\t231/446 [==============>...............] - ETA: 0s - loss: 3.8329 - acc: 0.762\n",
      "INFO\t2019-09-09 14:49:08 -0400\tmaster-replica-0\t4\t248/446 [===============>..............] - ETA: 0s - loss: 3.8524 - acc: 0.761\n",
      "INFO\t2019-09-09 14:49:08 -0400\tmaster-replica-0\t4\t262/446 [================>.............] - ETA: 0s - loss: 3.8530 - acc: 0.761\n",
      "INFO\t2019-09-09 14:49:08 -0400\tmaster-replica-0\t4\t279/446 [=================>............] - ETA: 0s - loss: 3.8651 - acc: 0.760\n",
      "INFO\t2019-09-09 14:49:08 -0400\tmaster-replica-0\t4\t293/446 [==================>...........] - ETA: 0s - loss: 3.8688 - acc: 0.760\n",
      "INFO\t2019-09-09 14:49:08 -0400\tmaster-replica-0\t4\t310/446 [===================>..........] - ETA: 0s - loss: 3.8718 - acc: 0.759\n",
      "INFO\t2019-09-09 14:49:08 -0400\tmaster-replica-0\t4\t325/446 [====================>.........] - ETA: 0s - loss: 3.8697 - acc: 0.759\n",
      "INFO\t2019-09-09 14:49:08 -0400\tmaster-replica-0\t4\t342/446 [======================>.......] - ETA: 0s - loss: 3.8613 - acc: 0.760\n",
      "INFO\t2019-09-09 14:49:08 -0400\tmaster-replica-0\t4\t355/446 [======================>.......] - ETA: 0s - loss: 3.8736 - acc: 0.759\n",
      "INFO\t2019-09-09 14:49:09 -0400\tmaster-replica-0\t4\t372/446 [========================>.....] - ETA: 0s - loss: 3.8894 - acc: 0.758\n",
      "INFO\t2019-09-09 14:49:09 -0400\tmaster-replica-0\t4\t389/446 [=========================>....] - ETA: 0s - loss: 3.8846 - acc: 0.759\n",
      "INFO\t2019-09-09 14:49:09 -0400\tmaster-replica-0\t4\t406/446 [==========================>...] - ETA: 0s - loss: 3.8770 - acc: 0.759\n",
      "INFO\t2019-09-09 14:49:09 -0400\tmaster-replica-0\t4\t422/446 [===========================>..] - ETA: 0s - loss: 3.8817 - acc: 0.759\n",
      "INFO\t2019-09-09 14:49:10 -0400\tmaster-replica-0\t4\t439/446 [============================>.] - ETA: 0s - loss: 3.8803 - acc: 0.759\n",
      "INFO\t2019-09-09 14:49:10 -0400\tmaster-replica-0\t4\t446/446 [==============================] - 3s 6ms/step - loss: 3.8808 - acc: 0.7592 - val_loss: 3.8072 - val_acc: 0.7638\n",
      "INFO\t2019-09-09 14:49:10 -0400\tmaster-replica-0\t4\tEpoch 00013: LearningRateScheduler reducing learning rate to 0.03666647289330935.\n",
      "INFO\t2019-09-09 14:49:10 -0400\tmaster-replica-0\t4\tEpoch 13/20\n",
      "INFO\t2019-09-09 14:49:10 -0400\tmaster-replica-0\t4\t  1/446 [..............................] - ETA: 22s - loss: 3.9743 - acc: 0.75\n",
      "INFO\t2019-09-09 14:49:10 -0400\tmaster-replica-0\t4\t 18/446 [>.............................] - ETA: 2s - loss: 3.8517 - acc: 0.7610\n",
      "INFO\t2019-09-09 14:49:10 -0400\tmaster-replica-0\t4\t 32/446 [=>............................] - ETA: 1s - loss: 3.7949 - acc: 0.764\n",
      "INFO\t2019-09-09 14:49:10 -0400\tmaster-replica-0\t4\t 49/446 [==>...........................] - ETA: 1s - loss: 3.8662 - acc: 0.760\n",
      "INFO\t2019-09-09 14:49:10 -0400\tmaster-replica-0\t4\t 63/446 [===>..........................] - ETA: 1s - loss: 3.9393 - acc: 0.755\n",
      "INFO\t2019-09-09 14:49:10 -0400\tmaster-replica-0\t4\t 80/446 [====>.........................] - ETA: 1s - loss: 3.8391 - acc: 0.761\n",
      "INFO\t2019-09-09 14:49:10 -0400\tmaster-replica-0\t4\t 94/446 [=====>........................] - ETA: 1s - loss: 3.8733 - acc: 0.759\n",
      "INFO\t2019-09-09 14:49:10 -0400\tmaster-replica-0\t4\t110/446 [======>.......................] - ETA: 1s - loss: 3.8900 - acc: 0.758\n",
      "INFO\t2019-09-09 14:49:10 -0400\tmaster-replica-0\t4\t124/446 [=======>......................] - ETA: 1s - loss: 3.8693 - acc: 0.759\n",
      "INFO\t2019-09-09 14:49:10 -0400\tmaster-replica-0\t4\t142/446 [========>.....................] - ETA: 1s - loss: 3.8764 - acc: 0.759\n",
      "INFO\t2019-09-09 14:49:10 -0400\tmaster-replica-0\t4\t156/446 [=========>....................] - ETA: 1s - loss: 3.8696 - acc: 0.759\n",
      "INFO\t2019-09-09 14:49:10 -0400\tmaster-replica-0\t4\t173/446 [==========>...................] - ETA: 0s - loss: 3.8850 - acc: 0.759\n",
      "INFO\t2019-09-09 14:49:10 -0400\tmaster-replica-0\t4\t187/446 [===========>..................] - ETA: 0s - loss: 3.8940 - acc: 0.758\n",
      "INFO\t2019-09-09 14:49:11 -0400\tmaster-replica-0\t4\t203/446 [============>.................] - ETA: 0s - loss: 3.8786 - acc: 0.759\n",
      "INFO\t2019-09-09 14:49:11 -0400\tmaster-replica-0\t4\t218/446 [=============>................] - ETA: 0s - loss: 3.8842 - acc: 0.759\n",
      "INFO\t2019-09-09 14:49:11 -0400\tmaster-replica-0\t4\t235/446 [==============>...............] - ETA: 0s - loss: 3.8625 - acc: 0.760\n",
      "INFO\t2019-09-09 14:49:11 -0400\tmaster-replica-0\t4\t250/446 [===============>..............] - ETA: 0s - loss: 3.8551 - acc: 0.760\n",
      "INFO\t2019-09-09 14:49:11 -0400\tmaster-replica-0\t4\t267/446 [================>.............] - ETA: 0s - loss: 3.8536 - acc: 0.760\n",
      "INFO\t2019-09-09 14:49:11 -0400\tmaster-replica-0\t4\t280/446 [=================>............] - ETA: 0s - loss: 3.8710 - acc: 0.759\n",
      "INFO\t2019-09-09 14:49:11 -0400\tmaster-replica-0\t4\t296/446 [==================>...........] - ETA: 0s - loss: 3.8639 - acc: 0.760\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO\t2019-09-09 14:49:11 -0400\tmaster-replica-0\t4\t309/446 [===================>..........] - ETA: 0s - loss: 3.8800 - acc: 0.759\n",
      "INFO\t2019-09-09 14:49:11 -0400\tmaster-replica-0\t4\t326/446 [====================>.........] - ETA: 0s - loss: 3.8890 - acc: 0.758\n",
      "INFO\t2019-09-09 14:49:11 -0400\tmaster-replica-0\t4\t341/446 [=====================>........] - ETA: 0s - loss: 3.8882 - acc: 0.758\n",
      "INFO\t2019-09-09 14:49:11 -0400\tmaster-replica-0\t4\t358/446 [=======================>......] - ETA: 0s - loss: 3.8726 - acc: 0.759\n",
      "INFO\t2019-09-09 14:49:11 -0400\tmaster-replica-0\t4\t372/446 [========================>.....] - ETA: 0s - loss: 3.8699 - acc: 0.759\n",
      "INFO\t2019-09-09 14:49:11 -0400\tmaster-replica-0\t4\t389/446 [=========================>....] - ETA: 0s - loss: 3.8631 - acc: 0.760\n",
      "INFO\t2019-09-09 14:49:11 -0400\tmaster-replica-0\t4\t404/446 [==========================>...] - ETA: 0s - loss: 3.8694 - acc: 0.759\n",
      "INFO\t2019-09-09 14:49:11 -0400\tmaster-replica-0\t4\t422/446 [===========================>..] - ETA: 0s - loss: 3.8754 - acc: 0.759\n",
      "INFO\t2019-09-09 14:49:12 -0400\tmaster-replica-0\t4\t440/446 [============================>.] - ETA: 0s - loss: 3.8785 - acc: 0.759\n",
      "INFO\t2019-09-09 14:49:12 -0400\tmaster-replica-0\t4\t446/446 [==============================] - 3s 6ms/step - loss: 3.8817 - acc: 0.7592 - val_loss: 3.8072 - val_acc: 0.7638\n",
      "INFO\t2019-09-09 14:49:12 -0400\tmaster-replica-0\t4\tEpoch 00014: LearningRateScheduler reducing learning rate to 0.03666525219018435.\n",
      "INFO\t2019-09-09 14:49:12 -0400\tmaster-replica-0\t4\tEpoch 14/20\n",
      "INFO\t2019-09-09 14:49:12 -0400\tmaster-replica-0\t4\t  1/446 [..............................] - ETA: 4s - loss: 4.1951 - acc: 0.739\n",
      "INFO\t2019-09-09 14:49:12 -0400\tmaster-replica-0\t4\t 17/446 [>.............................] - ETA: 1s - loss: 3.9483 - acc: 0.755\n",
      "INFO\t2019-09-09 14:49:13 -0400\tmaster-replica-0\t4\t 33/446 [=>............................] - ETA: 1s - loss: 3.9275 - acc: 0.756\n",
      "INFO\t2019-09-09 14:49:13 -0400\tmaster-replica-0\t4\t 45/446 [==>...........................] - ETA: 1s - loss: 3.8762 - acc: 0.759\n",
      "INFO\t2019-09-09 14:49:13 -0400\tmaster-replica-0\t4\t 62/446 [===>..........................] - ETA: 1s - loss: 3.8390 - acc: 0.761\n",
      "INFO\t2019-09-09 14:49:13 -0400\tmaster-replica-0\t4\t 75/446 [====>.........................] - ETA: 1s - loss: 3.9037 - acc: 0.757\n",
      "INFO\t2019-09-09 14:49:13 -0400\tmaster-replica-0\t4\t 92/446 [=====>........................] - ETA: 1s - loss: 3.8471 - acc: 0.761\n",
      "INFO\t2019-09-09 14:49:13 -0400\tmaster-replica-0\t4\t108/446 [======>.......................] - ETA: 1s - loss: 3.8557 - acc: 0.760\n",
      "INFO\t2019-09-09 14:49:13 -0400\tmaster-replica-0\t4\t126/446 [=======>......................] - ETA: 1s - loss: 3.8306 - acc: 0.762\n",
      "INFO\t2019-09-09 14:49:13 -0400\tmaster-replica-0\t4\t139/446 [========>.....................] - ETA: 1s - loss: 3.8218 - acc: 0.762\n",
      "INFO\t2019-09-09 14:49:13 -0400\tmaster-replica-0\t4\t155/446 [=========>....................] - ETA: 1s - loss: 3.8219 - acc: 0.762\n",
      "INFO\t2019-09-09 14:49:13 -0400\tmaster-replica-0\t4\t169/446 [==========>...................] - ETA: 0s - loss: 3.8280 - acc: 0.762\n",
      "INFO\t2019-09-09 14:49:13 -0400\tmaster-replica-0\t4\t185/446 [===========>..................] - ETA: 0s - loss: 3.8192 - acc: 0.763\n",
      "INFO\t2019-09-09 14:49:13 -0400\tmaster-replica-0\t4\t198/446 [============>.................] - ETA: 0s - loss: 3.8071 - acc: 0.763\n",
      "INFO\t2019-09-09 14:49:13 -0400\tmaster-replica-0\t4\t214/446 [=============>................] - ETA: 0s - loss: 3.8268 - acc: 0.762\n",
      "INFO\t2019-09-09 14:49:13 -0400\tmaster-replica-0\t4\t227/446 [==============>...............] - ETA: 0s - loss: 3.8245 - acc: 0.762\n",
      "INFO\t2019-09-09 14:49:13 -0400\tmaster-replica-0\t4\t243/446 [===============>..............] - ETA: 0s - loss: 3.8326 - acc: 0.762\n",
      "INFO\t2019-09-09 14:49:13 -0400\tmaster-replica-0\t4\t257/446 [================>.............] - ETA: 0s - loss: 3.8429 - acc: 0.761\n",
      "INFO\t2019-09-09 14:49:13 -0400\tmaster-replica-0\t4\t274/446 [=================>............] - ETA: 0s - loss: 3.8518 - acc: 0.761\n",
      "INFO\t2019-09-09 14:49:13 -0400\tmaster-replica-0\t4\t288/446 [==================>...........] - ETA: 0s - loss: 3.8586 - acc: 0.760\n",
      "INFO\t2019-09-09 14:49:13 -0400\tmaster-replica-0\t4\t304/446 [===================>..........] - ETA: 0s - loss: 3.8741 - acc: 0.759\n",
      "INFO\t2019-09-09 14:49:14 -0400\tmaster-replica-0\t4\t317/446 [====================>.........] - ETA: 0s - loss: 3.8705 - acc: 0.759\n",
      "INFO\t2019-09-09 14:49:14 -0400\tmaster-replica-0\t4\t333/446 [=====================>........] - ETA: 0s - loss: 3.8722 - acc: 0.759\n",
      "INFO\t2019-09-09 14:49:14 -0400\tmaster-replica-0\t4\t345/446 [======================>.......] - ETA: 0s - loss: 3.8790 - acc: 0.759\n",
      "INFO\t2019-09-09 14:49:14 -0400\tmaster-replica-0\t4\t362/446 [=======================>......] - ETA: 0s - loss: 3.8737 - acc: 0.759\n",
      "INFO\t2019-09-09 14:49:14 -0400\tmaster-replica-0\t4\t376/446 [========================>.....] - ETA: 0s - loss: 3.8545 - acc: 0.760\n",
      "INFO\t2019-09-09 14:49:14 -0400\tmaster-replica-0\t4\t393/446 [=========================>....] - ETA: 0s - loss: 3.8636 - acc: 0.760\n",
      "INFO\t2019-09-09 14:49:14 -0400\tmaster-replica-0\t4\t406/446 [==========================>...] - ETA: 0s - loss: 3.8688 - acc: 0.760\n",
      "INFO\t2019-09-09 14:49:14 -0400\tmaster-replica-0\t4\t422/446 [===========================>..] - ETA: 0s - loss: 3.8786 - acc: 0.759\n",
      "INFO\t2019-09-09 14:49:15 -0400\tmaster-replica-0\t4\t435/446 [============================>.] - ETA: 0s - loss: 3.8830 - acc: 0.759\n",
      "INFO\t2019-09-09 14:49:15 -0400\tmaster-replica-0\t4\t446/446 [==============================] - 3s 6ms/step - loss: 3.8813 - acc: 0.7592 - val_loss: 3.8072 - val_acc: 0.7638\n",
      "INFO\t2019-09-09 14:49:15 -0400\tmaster-replica-0\t4\tEpoch 00015: LearningRateScheduler reducing learning rate to 0.03666464183862185.\n",
      "INFO\t2019-09-09 14:49:15 -0400\tmaster-replica-0\t4\tEpoch 15/20\n",
      "INFO\t2019-09-09 14:49:15 -0400\tmaster-replica-0\t4\t  1/446 [..............................] - ETA: 1s - loss: 3.5327 - acc: 0.780\n",
      "INFO\t2019-09-09 14:49:15 -0400\tmaster-replica-0\t4\t 18/446 [>.............................] - ETA: 1s - loss: 3.8885 - acc: 0.758\n",
      "INFO\t2019-09-09 14:49:15 -0400\tmaster-replica-0\t4\t 35/446 [=>............................] - ETA: 1s - loss: 3.7977 - acc: 0.764\n",
      "INFO\t2019-09-09 14:49:15 -0400\tmaster-replica-0\t4\t 51/446 [==>...........................] - ETA: 1s - loss: 3.7838 - acc: 0.765\n",
      "INFO\t2019-09-09 14:49:15 -0400\tmaster-replica-0\t4\t 68/446 [===>..........................] - ETA: 1s - loss: 3.8217 - acc: 0.762\n",
      "INFO\t2019-09-09 14:49:15 -0400\tmaster-replica-0\t4\t 85/446 [====>.........................] - ETA: 1s - loss: 3.8003 - acc: 0.764\n",
      "INFO\t2019-09-09 14:49:15 -0400\tmaster-replica-0\t4\t 97/446 [=====>........................] - ETA: 1s - loss: 3.8264 - acc: 0.762\n",
      "INFO\t2019-09-09 14:49:15 -0400\tmaster-replica-0\t4\t114/446 [======>.......................] - ETA: 1s - loss: 3.8252 - acc: 0.762\n",
      "INFO\t2019-09-09 14:49:15 -0400\tmaster-replica-0\t4\t128/446 [=======>......................] - ETA: 1s - loss: 3.8450 - acc: 0.761\n",
      "INFO\t2019-09-09 14:49:15 -0400\tmaster-replica-0\t4\t145/446 [========>.....................] - ETA: 0s - loss: 3.8160 - acc: 0.763\n",
      "INFO\t2019-09-09 14:49:15 -0400\tmaster-replica-0\t4\t159/446 [=========>....................] - ETA: 0s - loss: 3.8216 - acc: 0.762\n",
      "INFO\t2019-09-09 14:49:16 -0400\tmaster-replica-0\t4\t176/446 [==========>...................] - ETA: 0s - loss: 3.8451 - acc: 0.761\n",
      "INFO\t2019-09-09 14:49:16 -0400\tmaster-replica-0\t4\t190/446 [===========>..................] - ETA: 0s - loss: 3.8697 - acc: 0.759\n",
      "INFO\t2019-09-09 14:49:16 -0400\tmaster-replica-0\t4\t207/446 [============>.................] - ETA: 0s - loss: 3.8933 - acc: 0.758\n",
      "INFO\t2019-09-09 14:49:16 -0400\tmaster-replica-0\t4\t221/446 [=============>................] - ETA: 0s - loss: 3.8744 - acc: 0.759\n",
      "INFO\t2019-09-09 14:49:16 -0400\tmaster-replica-0\t4\t237/446 [==============>...............] - ETA: 0s - loss: 3.8644 - acc: 0.760\n",
      "INFO\t2019-09-09 14:49:16 -0400\tmaster-replica-0\t4\t252/446 [===============>..............] - ETA: 0s - loss: 3.8552 - acc: 0.760\n",
      "INFO\t2019-09-09 14:49:16 -0400\tmaster-replica-0\t4\t269/446 [=================>............] - ETA: 0s - loss: 3.8537 - acc: 0.760\n",
      "INFO\t2019-09-09 14:49:16 -0400\tmaster-replica-0\t4\t283/446 [==================>...........] - ETA: 0s - loss: 3.8534 - acc: 0.760\n",
      "INFO\t2019-09-09 14:49:16 -0400\tmaster-replica-0\t4\t298/446 [===================>..........] - ETA: 0s - loss: 3.8513 - acc: 0.761\n",
      "INFO\t2019-09-09 14:49:16 -0400\tmaster-replica-0\t4\t312/446 [===================>..........] - ETA: 0s - loss: 3.8731 - acc: 0.759\n",
      "INFO\t2019-09-09 14:49:16 -0400\tmaster-replica-0\t4\t330/446 [=====================>........] - ETA: 0s - loss: 3.8679 - acc: 0.760\n",
      "INFO\t2019-09-09 14:49:16 -0400\tmaster-replica-0\t4\t344/446 [======================>.......] - ETA: 0s - loss: 3.8748 - acc: 0.759\n",
      "INFO\t2019-09-09 14:49:16 -0400\tmaster-replica-0\t4\t361/446 [=======================>......] - ETA: 0s - loss: 3.8795 - acc: 0.759\n",
      "INFO\t2019-09-09 14:49:16 -0400\tmaster-replica-0\t4\t376/446 [========================>.....] - ETA: 0s - loss: 3.8786 - acc: 0.759\n",
      "INFO\t2019-09-09 14:49:16 -0400\tmaster-replica-0\t4\t393/446 [=========================>....] - ETA: 0s - loss: 3.8732 - acc: 0.759\n",
      "INFO\t2019-09-09 14:49:16 -0400\tmaster-replica-0\t4\t407/446 [==========================>...] - ETA: 0s - loss: 3.8734 - acc: 0.759\n",
      "INFO\t2019-09-09 14:49:16 -0400\tmaster-replica-0\t4\t425/446 [===========================>..] - ETA: 0s - loss: 3.8657 - acc: 0.760\n",
      "INFO\t2019-09-09 14:49:17 -0400\tmaster-replica-0\t4\t438/446 [============================>.] - ETA: 0s - loss: 3.8715 - acc: 0.759\n",
      "INFO\t2019-09-09 14:49:17 -0400\tmaster-replica-0\t4\t446/446 [==============================] - 2s 5ms/step - loss: 3.8813 - acc: 0.7592 - val_loss: 3.8072 - val_acc: 0.7638\n",
      "INFO\t2019-09-09 14:49:17 -0400\tmaster-replica-0\t4\tEpoch 00016: LearningRateScheduler reducing learning rate to 0.0366643366628406.\n",
      "INFO\t2019-09-09 14:49:17 -0400\tmaster-replica-0\t4\tEpoch 16/20\n",
      "INFO\t2019-09-09 14:49:17 -0400\tmaster-replica-0\t4\t  1/446 [..............................] - ETA: 41s - loss: 4.1951 - acc: 0.73\n",
      "INFO\t2019-09-09 14:49:18 -0400\tmaster-replica-0\t4\t 16/446 [>.............................] - ETA: 3s - loss: 3.9743 - acc: 0.7534\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO\t2019-09-09 14:49:18 -0400\tmaster-replica-0\t4\t 29/446 [>.............................] - ETA: 2s - loss: 3.7155 - acc: 0.769\n",
      "INFO\t2019-09-09 14:49:18 -0400\tmaster-replica-0\t4\t 44/446 [=>............................] - ETA: 2s - loss: 3.8539 - acc: 0.760\n",
      "INFO\t2019-09-09 14:49:18 -0400\tmaster-replica-0\t4\t 55/446 [==>...........................] - ETA: 2s - loss: 3.8579 - acc: 0.760\n",
      "INFO\t2019-09-09 14:49:18 -0400\tmaster-replica-0\t4\t 69/446 [===>..........................] - ETA: 1s - loss: 3.7663 - acc: 0.766\n",
      "INFO\t2019-09-09 14:49:18 -0400\tmaster-replica-0\t4\t 85/446 [====>.........................] - ETA: 1s - loss: 3.7769 - acc: 0.765\n",
      "INFO\t2019-09-09 14:49:18 -0400\tmaster-replica-0\t4\t 99/446 [=====>........................] - ETA: 1s - loss: 3.7781 - acc: 0.765\n",
      "INFO\t2019-09-09 14:49:18 -0400\tmaster-replica-0\t4\t112/446 [======>.......................] - ETA: 1s - loss: 3.8265 - acc: 0.762\n",
      "INFO\t2019-09-09 14:49:18 -0400\tmaster-replica-0\t4\t127/446 [=======>......................] - ETA: 1s - loss: 3.8561 - acc: 0.760\n",
      "INFO\t2019-09-09 14:49:18 -0400\tmaster-replica-0\t4\t138/446 [========>.....................] - ETA: 1s - loss: 3.8495 - acc: 0.761\n",
      "INFO\t2019-09-09 14:49:18 -0400\tmaster-replica-0\t4\t152/446 [=========>....................] - ETA: 1s - loss: 3.8363 - acc: 0.762\n",
      "INFO\t2019-09-09 14:49:18 -0400\tmaster-replica-0\t4\t163/446 [=========>....................] - ETA: 1s - loss: 3.8389 - acc: 0.761\n",
      "INFO\t2019-09-09 14:49:18 -0400\tmaster-replica-0\t4\t179/446 [===========>..................] - ETA: 1s - loss: 3.8399 - acc: 0.761\n",
      "INFO\t2019-09-09 14:49:18 -0400\tmaster-replica-0\t4\t192/446 [===========>..................] - ETA: 1s - loss: 3.8225 - acc: 0.762\n",
      "INFO\t2019-09-09 14:49:18 -0400\tmaster-replica-0\t4\t209/446 [=============>................] - ETA: 0s - loss: 3.8169 - acc: 0.763\n",
      "INFO\t2019-09-09 14:49:18 -0400\tmaster-replica-0\t4\t221/446 [=============>................] - ETA: 0s - loss: 3.8185 - acc: 0.763\n",
      "INFO\t2019-09-09 14:49:18 -0400\tmaster-replica-0\t4\t238/446 [===============>..............] - ETA: 0s - loss: 3.8398 - acc: 0.761\n",
      "INFO\t2019-09-09 14:49:18 -0400\tmaster-replica-0\t4\t251/446 [===============>..............] - ETA: 0s - loss: 3.8424 - acc: 0.761\n",
      "INFO\t2019-09-09 14:49:18 -0400\tmaster-replica-0\t4\t267/446 [================>.............] - ETA: 0s - loss: 3.8627 - acc: 0.760\n",
      "INFO\t2019-09-09 14:49:19 -0400\tmaster-replica-0\t4\t283/446 [==================>...........] - ETA: 0s - loss: 3.8729 - acc: 0.759\n",
      "INFO\t2019-09-09 14:49:19 -0400\tmaster-replica-0\t4\t298/446 [===================>..........] - ETA: 0s - loss: 3.8825 - acc: 0.759\n",
      "INFO\t2019-09-09 14:49:19 -0400\tmaster-replica-0\t4\t314/446 [====================>.........] - ETA: 0s - loss: 3.8738 - acc: 0.759\n",
      "INFO\t2019-09-09 14:49:19 -0400\tmaster-replica-0\t4\t328/446 [=====================>........] - ETA: 0s - loss: 3.8747 - acc: 0.759\n",
      "INFO\t2019-09-09 14:49:19 -0400\tmaster-replica-0\t4\t344/446 [======================>.......] - ETA: 0s - loss: 3.8787 - acc: 0.759\n",
      "INFO\t2019-09-09 14:49:19 -0400\tmaster-replica-0\t4\t357/446 [=======================>......] - ETA: 0s - loss: 3.8840 - acc: 0.759\n",
      "INFO\t2019-09-09 14:49:19 -0400\tmaster-replica-0\t4\t364/446 [=======================>......] - ETA: 0s - loss: 3.8839 - acc: 0.759\n",
      "WARNING\t2019-09-09 14:49:19 -0400\tmaster-replica-0\t3\tFrom /usr/local/lib/python3.5/dist-packages/tensorflow/python/saved_model/signature_def_utils_impl.py:205: build_tensor_info (from tensorflow.python.saved_model.utils_impl) is deprecated and will be removed in a future version.\n",
      "WARNING\t2019-09-09 14:49:19 -0400\tmaster-replica-0\t3\tInstructions for updating:\n",
      "WARNING\t2019-09-09 14:49:19 -0400\tmaster-replica-0\t3\tThis function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.utils.build_tensor_info or tf.compat.v1.saved_model.build_tensor_info.\n",
      "INFO\t2019-09-09 14:49:19 -0400\tmaster-replica-0\t3\tSignatures INCLUDED in export for Eval: None\n",
      "INFO\t2019-09-09 14:49:19 -0400\tmaster-replica-0\t3\tSignatures INCLUDED in export for Train: None\n",
      "INFO\t2019-09-09 14:49:19 -0400\tmaster-replica-0\t3\tSignatures INCLUDED in export for Classify: None\n",
      "INFO\t2019-09-09 14:49:19 -0400\tmaster-replica-0\t3\tSignatures INCLUDED in export for Regress: None\n",
      "INFO\t2019-09-09 14:49:19 -0400\tmaster-replica-0\t3\tSignatures INCLUDED in export for Predict: ['serving_default']\n",
      "INFO\t2019-09-09 14:49:19 -0400\tmaster-replica-0\t4\t370/446 [=======================>......] - ETA: 0s - loss: 3.8878 - acc: 0.758\n",
      "INFO\t2019-09-09 14:49:19 -0400\tmaster-replica-0\t3\tNo assets to save.\n",
      "INFO\t2019-09-09 14:49:19 -0400\tmaster-replica-0\t3\tNo assets to write.\n",
      "INFO\t2019-09-09 14:49:19 -0400\tmaster-replica-0\t4\t384/446 [========================>.....] - ETA: 0s - loss: 3.8812 - acc: 0.759\n",
      "INFO\t2019-09-09 14:49:19 -0400\tmaster-replica-0\t4\t391/446 [=========================>....] - ETA: 0s - loss: 3.8755 - acc: 0.759\n",
      "INFO\t2019-09-09 14:49:19 -0400\tmaster-replica-0\t4\t399/446 [=========================>....] - ETA: 0s - loss: 3.8786 - acc: 0.759\n",
      "INFO\t2019-09-09 14:49:19 -0400\tmaster-replica-0\t4\t405/446 [==========================>...] - ETA: 0s - loss: 3.8784 - acc: 0.759\n",
      "INFO\t2019-09-09 14:49:19 -0400\tmaster-replica-0\t4\t422/446 [===========================>..] - ETA: 0s - loss: 3.8786 - acc: 0.759\n",
      "INFO\t2019-09-09 14:49:20 -0400\tmaster-replica-0\t3\tSavedModel written to: gs://mo_ml/lingh/3/keras_export/1568054936/saved_model.pb\n",
      "INFO\t2019-09-09 14:49:20 -0400\tmaster-replica-0\t4\t429/446 [===========================>..] - ETA: 0s - loss: 3.8745 - acc: 0.759\n",
      "INFO\t2019-09-09 14:49:20 -0400\tmaster-replica-0\t4\t446/446 [==============================] - 3s 7ms/step - loss: 3.8798 - acc: 0.7593 - val_loss: 3.8072 - val_acc: 0.7638\n",
      "INFO\t2019-09-09 14:49:20 -0400\tmaster-replica-0\t4\tEpoch 00017: LearningRateScheduler reducing learning rate to 0.03666418407494998.\n",
      "INFO\t2019-09-09 14:49:20 -0400\tmaster-replica-0\t4\tEpoch 17/20\n",
      "INFO\t2019-09-09 14:49:20 -0400\tmaster-replica-0\t4\t  1/446 [..............................] - ETA: 28s - loss: 3.5327 - acc: 0.78\n",
      "INFO\t2019-09-09 14:49:21 -0400\tmaster-replica-0\t4\t 16/446 [>.............................] - ETA: 3s - loss: 3.9467 - acc: 0.7551\n",
      "INFO\t2019-09-09 14:49:21 -0400\tmaster-replica-0\t4\t 32/446 [=>............................] - ETA: 2s - loss: 3.9053 - acc: 0.757\n",
      "INFO\t2019-09-09 14:49:21 -0400\tmaster-replica-0\t4\t 48/446 [==>...........................] - ETA: 1s - loss: 3.8363 - acc: 0.762\n",
      "INFO\t2019-09-09 14:49:21 -0400\tmaster-replica-0\t4\t 61/446 [===>..........................] - ETA: 1s - loss: 3.7318 - acc: 0.768\n",
      "INFO\t2019-09-09 14:49:21 -0400\tmaster-replica-0\t4\t 77/446 [====>.........................] - ETA: 1s - loss: 3.7879 - acc: 0.765\n",
      "INFO\t2019-09-09 14:49:21 -0400\tmaster-replica-0\t4\t 91/446 [=====>........................] - ETA: 1s - loss: 3.8676 - acc: 0.760\n",
      "INFO\t2019-09-09 14:49:21 -0400\tmaster-replica-0\t4\t108/446 [======>.......................] - ETA: 1s - loss: 3.9150 - acc: 0.757\n",
      "INFO\t2019-09-09 14:49:21 -0400\tmaster-replica-0\t4\t122/446 [=======>......................] - ETA: 1s - loss: 3.8838 - acc: 0.759\n",
      "INFO\t2019-09-09 14:49:21 -0400\tmaster-replica-0\t4\t139/446 [========>.....................] - ETA: 1s - loss: 3.8695 - acc: 0.759\n",
      "INFO\t2019-09-09 14:49:21 -0400\tmaster-replica-0\t4\t153/446 [=========>....................] - ETA: 1s - loss: 3.8704 - acc: 0.759\n",
      "INFO\t2019-09-09 14:49:21 -0400\tmaster-replica-0\t4\t169/446 [==========>...................] - ETA: 1s - loss: 3.8763 - acc: 0.759\n",
      "INFO\t2019-09-09 14:49:21 -0400\tmaster-replica-0\t4\t183/446 [===========>..................] - ETA: 0s - loss: 3.8766 - acc: 0.759\n",
      "INFO\t2019-09-09 14:49:21 -0400\tmaster-replica-0\t4\t200/446 [============>.................] - ETA: 0s - loss: 3.8838 - acc: 0.759\n",
      "INFO\t2019-09-09 14:49:21 -0400\tmaster-replica-0\t4\t214/446 [=============>................] - ETA: 0s - loss: 3.9052 - acc: 0.757\n",
      "INFO\t2019-09-09 14:49:21 -0400\tmaster-replica-0\t4\t231/446 [==============>...............] - ETA: 0s - loss: 3.8940 - acc: 0.758\n",
      "INFO\t2019-09-09 14:49:21 -0400\tmaster-replica-0\t4\t245/446 [===============>..............] - ETA: 0s - loss: 3.9085 - acc: 0.757\n",
      "INFO\t2019-09-09 14:49:21 -0400\tmaster-replica-0\t4\t262/446 [================>.............] - ETA: 0s - loss: 3.9094 - acc: 0.757\n",
      "INFO\t2019-09-09 14:49:21 -0400\tmaster-replica-0\t4\t275/446 [=================>............] - ETA: 0s - loss: 3.9237 - acc: 0.756\n",
      "INFO\t2019-09-09 14:49:21 -0400\tmaster-replica-0\t4\t292/446 [==================>...........] - ETA: 0s - loss: 3.9093 - acc: 0.757\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO\t2019-09-09 14:49:21 -0400\tmaster-replica-0\t4\t307/446 [===================>..........] - ETA: 0s - loss: 3.9046 - acc: 0.757\n",
      "INFO\t2019-09-09 14:49:22 -0400\tmaster-replica-0\t4\t324/446 [====================>.........] - ETA: 0s - loss: 3.8837 - acc: 0.759\n",
      "INFO\t2019-09-09 14:49:22 -0400\tmaster-replica-0\t4\t338/446 [=====================>........] - ETA: 0s - loss: 3.8868 - acc: 0.758\n",
      "INFO\t2019-09-09 14:49:22 -0400\tmaster-replica-0\t4\t355/446 [======================>.......] - ETA: 0s - loss: 3.8804 - acc: 0.759\n",
      "INFO\t2019-09-09 14:49:22 -0400\tmaster-replica-0\t4\t367/446 [=======================>......] - ETA: 0s - loss: 3.8690 - acc: 0.760\n",
      "INFO\t2019-09-09 14:49:22 -0400\tmaster-replica-0\t3\tWARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "INFO\t2019-09-09 14:49:22 -0400\tmaster-replica-0\t3\tFor more information, please see:\n",
      "INFO\t2019-09-09 14:49:22 -0400\tmaster-replica-0\t3\t  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "INFO\t2019-09-09 14:49:22 -0400\tmaster-replica-0\t3\t  * https://github.com/tensorflow/addons\n",
      "INFO\t2019-09-09 14:49:22 -0400\tmaster-replica-0\t3\tIf you depend on functionality not listed there, please file an issue.\n",
      "INFO\t2019-09-09 14:49:22 -0400\tmaster-replica-0\t3\tModel exported to: gs://mo_ml/lingh/3/keras_export\n",
      "INFO\t2019-09-09 14:49:22 -0400\tmaster-replica-0\t4\t383/446 [========================>.....] - ETA: 0s - loss: 3.8671 - acc: 0.760\n",
      "INFO\t2019-09-09 14:49:22 -0400\tmaster-replica-0\t4\t397/446 [=========================>....] - ETA: 0s - loss: 3.8731 - acc: 0.759\n",
      "INFO\t2019-09-09 14:49:22 -0400\tmaster-replica-0\t4\t414/446 [==========================>...] - ETA: 0s - loss: 3.8714 - acc: 0.759\n",
      "INFO\t2019-09-09 14:49:22 -0400\tmaster-replica-0\t4\t427/446 [===========================>..] - ETA: 0s - loss: 3.8797 - acc: 0.759\n",
      "INFO\t2019-09-09 14:49:22 -0400\tmaster-replica-0\t3\tModule completed; cleaning up.\n",
      "INFO\t2019-09-09 14:49:22 -0400\tmaster-replica-0\t3\tClean up finished.\n",
      "INFO\t2019-09-09 14:49:22 -0400\tmaster-replica-0\t3\tTask completed successfully.\n",
      "INFO\t2019-09-09 14:49:23 -0400\tmaster-replica-0\t4\t444/446 [============================>.] - ETA: 0s - loss: 3.8878 - acc: 0.758\n",
      "INFO\t2019-09-09 14:49:23 -0400\tmaster-replica-0\t4\t446/446 [==============================] - 3s 6ms/step - loss: 3.8842 - acc: 0.7590 - val_loss: 3.8072 - val_acc: 0.7638\n",
      "INFO\t2019-09-09 14:49:23 -0400\tmaster-replica-0\t4\tEpoch 00018: LearningRateScheduler reducing learning rate to 0.036664107781004665.\n",
      "INFO\t2019-09-09 14:49:23 -0400\tmaster-replica-0\t4\tEpoch 18/20\n",
      "INFO\t2019-09-09 14:49:23 -0400\tmaster-replica-0\t4\t  1/446 [..............................] - ETA: 39s - loss: 2.6495 - acc: 0.83\n",
      "INFO\t2019-09-09 14:49:23 -0400\tmaster-replica-0\t4\t 17/446 [>.............................] - ETA: 3s - loss: 3.7665 - acc: 0.7663\n",
      "INFO\t2019-09-09 14:49:23 -0400\tmaster-replica-0\t4\t 31/446 [=>............................] - ETA: 2s - loss: 3.7393 - acc: 0.768\n",
      "INFO\t2019-09-09 14:49:23 -0400\tmaster-replica-0\t4\t 48/446 [==>...........................] - ETA: 2s - loss: 3.8731 - acc: 0.759\n",
      "INFO\t2019-09-09 14:49:23 -0400\tmaster-replica-0\t4\t 62/446 [===>..........................] - ETA: 1s - loss: 3.9067 - acc: 0.757\n",
      "INFO\t2019-09-09 14:49:23 -0400\tmaster-replica-0\t4\t 77/446 [====>.........................] - ETA: 1s - loss: 3.8195 - acc: 0.763\n",
      "INFO\t2019-09-09 14:49:23 -0400\tmaster-replica-0\t4\t 90/446 [=====>........................] - ETA: 1s - loss: 3.8026 - acc: 0.764\n",
      "INFO\t2019-09-09 14:49:24 -0400\tmaster-replica-0\t4\t107/446 [======>.......................] - ETA: 1s - loss: 3.8134 - acc: 0.763\n",
      "INFO\t2019-09-09 14:49:24 -0400\tmaster-replica-0\t4\t122/446 [=======>......................] - ETA: 1s - loss: 3.7952 - acc: 0.764\n",
      "INFO\t2019-09-09 14:49:24 -0400\tmaster-replica-0\t4\t139/446 [========>.....................] - ETA: 1s - loss: 3.8044 - acc: 0.764\n",
      "INFO\t2019-09-09 14:49:24 -0400\tmaster-replica-0\t4\t156/446 [=========>....................] - ETA: 1s - loss: 3.8186 - acc: 0.763\n",
      "INFO\t2019-09-09 14:49:24 -0400\tmaster-replica-0\t4\t172/446 [==========>...................] - ETA: 1s - loss: 3.8139 - acc: 0.763\n",
      "INFO\t2019-09-09 14:49:24 -0400\tmaster-replica-0\t4\t188/446 [===========>..................] - ETA: 0s - loss: 3.8064 - acc: 0.763\n",
      "INFO\t2019-09-09 14:49:24 -0400\tmaster-replica-0\t4\t205/446 [============>.................] - ETA: 0s - loss: 3.8246 - acc: 0.762\n",
      "INFO\t2019-09-09 14:49:24 -0400\tmaster-replica-0\t4\t218/446 [=============>................] - ETA: 0s - loss: 3.8386 - acc: 0.761\n",
      "INFO\t2019-09-09 14:49:24 -0400\tmaster-replica-0\t4\t234/446 [==============>...............] - ETA: 0s - loss: 3.8394 - acc: 0.761\n",
      "INFO\t2019-09-09 14:49:24 -0400\tmaster-replica-0\t4\t248/446 [===============>..............] - ETA: 0s - loss: 3.8470 - acc: 0.761\n",
      "INFO\t2019-09-09 14:49:24 -0400\tmaster-replica-0\t4\t264/446 [================>.............] - ETA: 0s - loss: 3.8656 - acc: 0.760\n",
      "INFO\t2019-09-09 14:49:24 -0400\tmaster-replica-0\t4\t276/446 [=================>............] - ETA: 0s - loss: 3.8535 - acc: 0.760\n",
      "INFO\t2019-09-09 14:49:24 -0400\tmaster-replica-0\t4\t293/446 [==================>...........] - ETA: 0s - loss: 3.8590 - acc: 0.760\n",
      "INFO\t2019-09-09 14:49:24 -0400\tmaster-replica-0\t4\t309/446 [===================>..........] - ETA: 0s - loss: 3.8593 - acc: 0.760\n",
      "INFO\t2019-09-09 14:49:24 -0400\tmaster-replica-0\t4\t325/446 [====================>.........] - ETA: 0s - loss: 3.8500 - acc: 0.761\n",
      "INFO\t2019-09-09 14:49:24 -0400\tmaster-replica-0\t4\t339/446 [=====================>........] - ETA: 0s - loss: 3.8473 - acc: 0.761\n",
      "INFO\t2019-09-09 14:49:24 -0400\tmaster-replica-0\t4\t356/446 [======================>.......] - ETA: 0s - loss: 3.8484 - acc: 0.761\n",
      "INFO\t2019-09-09 14:49:24 -0400\tmaster-replica-0\t4\t368/446 [=======================>......] - ETA: 0s - loss: 3.8561 - acc: 0.760\n",
      "INFO\t2019-09-09 14:49:24 -0400\tmaster-replica-0\t4\t385/446 [========================>.....] - ETA: 0s - loss: 3.8499 - acc: 0.761\n",
      "INFO\t2019-09-09 14:49:25 -0400\tmaster-replica-0\t4\t399/446 [=========================>....] - ETA: 0s - loss: 3.8432 - acc: 0.761\n",
      "INFO\t2019-09-09 14:49:25 -0400\tmaster-replica-0\t4\t416/446 [==========================>...] - ETA: 0s - loss: 3.8634 - acc: 0.760\n",
      "INFO\t2019-09-09 14:49:26 -0400\tmaster-replica-0\t4\t431/446 [===========================>..] - ETA: 0s - loss: 3.8744 - acc: 0.759\n",
      "INFO\t2019-09-09 14:49:26 -0400\tmaster-replica-0\t4\t446/446 [==============================] - 3s 6ms/step - loss: 3.8813 - acc: 0.7592 - val_loss: 3.8072 - val_acc: 0.7638\n",
      "INFO\t2019-09-09 14:49:26 -0400\tmaster-replica-0\t4\tEpoch 00019: LearningRateScheduler reducing learning rate to 0.03666406963403201.\n",
      "INFO\t2019-09-09 14:49:26 -0400\tmaster-replica-0\t4\tEpoch 19/20\n",
      "INFO\t2019-09-09 14:49:26 -0400\tmaster-replica-0\t4\t  1/446 [..............................] - ETA: 20s - loss: 2.8703 - acc: 0.82\n",
      "INFO\t2019-09-09 14:49:26 -0400\tmaster-replica-0\t4\t 18/446 [>.............................] - ETA: 2s - loss: 3.6922 - acc: 0.7709\n",
      "INFO\t2019-09-09 14:49:26 -0400\tmaster-replica-0\t4\t 32/446 [=>............................] - ETA: 1s - loss: 3.8777 - acc: 0.759\n",
      "INFO\t2019-09-09 14:49:26 -0400\tmaster-replica-0\t4\t 49/446 [==>...........................] - ETA: 1s - loss: 3.8707 - acc: 0.759\n",
      "INFO\t2019-09-09 14:49:26 -0400\tmaster-replica-0\t4\t 63/446 [===>..........................] - ETA: 1s - loss: 3.9042 - acc: 0.757\n",
      "INFO\t2019-09-09 14:49:26 -0400\tmaster-replica-0\t4\t 80/446 [====>.........................] - ETA: 1s - loss: 3.8970 - acc: 0.758\n",
      "INFO\t2019-09-09 14:49:26 -0400\tmaster-replica-0\t4\t 94/446 [=====>........................] - ETA: 1s - loss: 3.9086 - acc: 0.757\n",
      "INFO\t2019-09-09 14:49:26 -0400\tmaster-replica-0\t4\t109/446 [======>.......................] - ETA: 1s - loss: 3.9358 - acc: 0.755\n",
      "INFO\t2019-09-09 14:49:26 -0400\tmaster-replica-0\t4\t124/446 [=======>......................] - ETA: 1s - loss: 3.9084 - acc: 0.757\n",
      "INFO\t2019-09-09 14:49:26 -0400\tmaster-replica-0\t4\t141/446 [========>.....................] - ETA: 1s - loss: 3.9101 - acc: 0.757\n",
      "INFO\t2019-09-09 14:49:26 -0400\tmaster-replica-0\t4\t156/446 [=========>....................] - ETA: 1s - loss: 3.9021 - acc: 0.757\n",
      "INFO\t2019-09-09 14:49:26 -0400\tmaster-replica-0\t4\t173/446 [==========>...................] - ETA: 0s - loss: 3.9067 - acc: 0.757\n",
      "INFO\t2019-09-09 14:49:26 -0400\tmaster-replica-0\t4\t187/446 [===========>..................] - ETA: 0s - loss: 3.8681 - acc: 0.760\n",
      "INFO\t2019-09-09 14:49:26 -0400\tmaster-replica-0\t4\t203/446 [============>.................] - ETA: 0s - loss: 3.8884 - acc: 0.758\n",
      "INFO\t2019-09-09 14:49:26 -0400\tmaster-replica-0\t4\t216/446 [=============>................] - ETA: 0s - loss: 3.9028 - acc: 0.757\n",
      "INFO\t2019-09-09 14:49:27 -0400\tmaster-replica-0\t4\t233/446 [==============>...............] - ETA: 0s - loss: 3.9033 - acc: 0.757\n",
      "INFO\t2019-09-09 14:49:27 -0400\tmaster-replica-0\t4\t249/446 [===============>..............] - ETA: 0s - loss: 3.8963 - acc: 0.758\n",
      "INFO\t2019-09-09 14:49:27 -0400\tmaster-replica-0\t4\t266/446 [================>.............] - ETA: 0s - loss: 3.8872 - acc: 0.758\n",
      "INFO\t2019-09-09 14:49:27 -0400\tmaster-replica-0\t4\t281/446 [=================>............] - ETA: 0s - loss: 3.8887 - acc: 0.758\n",
      "INFO\t2019-09-09 14:49:27 -0400\tmaster-replica-0\t4\t298/446 [===================>..........] - ETA: 0s - loss: 3.8950 - acc: 0.758\n",
      "INFO\t2019-09-09 14:49:27 -0400\tmaster-replica-0\t4\t312/446 [===================>..........] - ETA: 0s - loss: 3.8915 - acc: 0.758\n",
      "INFO\t2019-09-09 14:49:27 -0400\tmaster-replica-0\t4\t329/446 [=====================>........] - ETA: 0s - loss: 3.8951 - acc: 0.758\n",
      "INFO\t2019-09-09 14:49:27 -0400\tmaster-replica-0\t4\t343/446 [======================>.......] - ETA: 0s - loss: 3.8971 - acc: 0.758\n",
      "INFO\t2019-09-09 14:49:27 -0400\tmaster-replica-0\t4\t360/446 [=======================>......] - ETA: 0s - loss: 3.8940 - acc: 0.758\n",
      "INFO\t2019-09-09 14:49:27 -0400\tmaster-replica-0\t4\t376/446 [========================>.....] - ETA: 0s - loss: 3.8786 - acc: 0.759\n",
      "INFO\t2019-09-09 14:49:27 -0400\tmaster-replica-0\t4\t390/446 [=========================>....] - ETA: 0s - loss: 3.8832 - acc: 0.759\n",
      "INFO\t2019-09-09 14:49:27 -0400\tmaster-replica-0\t4\t405/446 [==========================>...] - ETA: 0s - loss: 3.8827 - acc: 0.759\n",
      "INFO\t2019-09-09 14:49:27 -0400\tmaster-replica-0\t4\t418/446 [===========================>..] - ETA: 0s - loss: 3.8845 - acc: 0.759\n",
      "INFO\t2019-09-09 14:49:28 -0400\tmaster-replica-0\t4\t435/446 [============================>.] - ETA: 0s - loss: 3.8875 - acc: 0.758\n",
      "INFO\t2019-09-09 14:49:28 -0400\tmaster-replica-0\t4\t446/446 [==============================] - 3s 6ms/step - loss: 3.8803 - acc: 0.7593 - val_loss: 3.8072 - val_acc: 0.7638\n",
      "INFO\t2019-09-09 14:49:28 -0400\tmaster-replica-0\t4\tEpoch 00020: LearningRateScheduler reducing learning rate to 0.036664050560545676.\n",
      "INFO\t2019-09-09 14:49:28 -0400\tmaster-replica-0\t4\tEpoch 20/20\n",
      "INFO\t2019-09-09 14:49:28 -0400\tmaster-replica-0\t4\t  1/446 [..............................] - ETA: 12s - loss: 3.5327 - acc: 0.78\n",
      "INFO\t2019-09-09 14:49:29 -0400\tmaster-replica-0\t4\t 19/446 [>.............................] - ETA: 1s - loss: 3.5560 - acc: 0.7794\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO\t2019-09-09 14:49:29 -0400\tmaster-replica-0\t4\t 33/446 [=>............................] - ETA: 1s - loss: 3.6866 - acc: 0.771\n",
      "INFO\t2019-09-09 14:49:29 -0400\tmaster-replica-0\t4\t 51/446 [==>...........................] - ETA: 1s - loss: 3.7319 - acc: 0.768\n",
      "INFO\t2019-09-09 14:49:29 -0400\tmaster-replica-0\t4\t 66/446 [===>..........................] - ETA: 1s - loss: 3.7167 - acc: 0.769\n",
      "INFO\t2019-09-09 14:49:29 -0400\tmaster-replica-0\t4\t 84/446 [====>.........................] - ETA: 1s - loss: 3.8061 - acc: 0.763\n",
      "INFO\t2019-09-09 14:49:29 -0400\tmaster-replica-0\t4\t 99/446 [=====>........................] - ETA: 1s - loss: 3.7669 - acc: 0.766\n",
      "INFO\t2019-09-09 14:49:29 -0400\tmaster-replica-0\t4\t116/446 [======>.......................] - ETA: 1s - loss: 3.7897 - acc: 0.764\n",
      "INFO\t2019-09-09 14:49:29 -0400\tmaster-replica-0\t4\t131/446 [=======>......................] - ETA: 1s - loss: 3.8277 - acc: 0.762\n",
      "INFO\t2019-09-09 14:49:29 -0400\tmaster-replica-0\t4\t149/446 [=========>....................] - ETA: 0s - loss: 3.7846 - acc: 0.765\n",
      "INFO\t2019-09-09 14:49:29 -0400\tmaster-replica-0\t4\t163/446 [=========>....................] - ETA: 0s - loss: 3.7887 - acc: 0.764\n",
      "INFO\t2019-09-09 14:49:29 -0400\tmaster-replica-0\t4\t181/446 [===========>..................] - ETA: 0s - loss: 3.7926 - acc: 0.764\n",
      "INFO\t2019-09-09 14:49:29 -0400\tmaster-replica-0\t4\t195/446 [============>.................] - ETA: 0s - loss: 3.8124 - acc: 0.763\n",
      "INFO\t2019-09-09 14:49:29 -0400\tmaster-replica-0\t4\t212/446 [=============>................] - ETA: 0s - loss: 3.8119 - acc: 0.763\n",
      "INFO\t2019-09-09 14:49:29 -0400\tmaster-replica-0\t4\t227/446 [==============>...............] - ETA: 0s - loss: 3.8275 - acc: 0.762\n",
      "INFO\t2019-09-09 14:49:29 -0400\tmaster-replica-0\t4\t245/446 [===============>..............] - ETA: 0s - loss: 3.8328 - acc: 0.762\n",
      "INFO\t2019-09-09 14:49:29 -0400\tmaster-replica-0\t4\t261/446 [================>.............] - ETA: 0s - loss: 3.8440 - acc: 0.761\n",
      "INFO\t2019-09-09 14:49:29 -0400\tmaster-replica-0\t4\t279/446 [=================>............] - ETA: 0s - loss: 3.8525 - acc: 0.761\n",
      "INFO\t2019-09-09 14:49:29 -0400\tmaster-replica-0\t4\t293/446 [==================>...........] - ETA: 0s - loss: 3.8560 - acc: 0.760\n",
      "INFO\t2019-09-09 14:49:29 -0400\tmaster-replica-0\t4\t310/446 [===================>..........] - ETA: 0s - loss: 3.8426 - acc: 0.761\n",
      "INFO\t2019-09-09 14:49:30 -0400\tmaster-replica-0\t4\t324/446 [====================>.........] - ETA: 0s - loss: 3.8408 - acc: 0.761\n",
      "INFO\t2019-09-09 14:49:30 -0400\tmaster-replica-0\t4\t341/446 [=====================>........] - ETA: 0s - loss: 3.8461 - acc: 0.761\n",
      "INFO\t2019-09-09 14:49:30 -0400\tmaster-replica-0\t4\t356/446 [======================>.......] - ETA: 0s - loss: 3.8472 - acc: 0.761\n",
      "INFO\t2019-09-09 14:49:30 -0400\tmaster-replica-0\t4\t373/446 [========================>.....] - ETA: 0s - loss: 3.8648 - acc: 0.760\n",
      "INFO\t2019-09-09 14:49:30 -0400\tmaster-replica-0\t4\t388/446 [=========================>....] - ETA: 0s - loss: 3.8571 - acc: 0.760\n",
      "INFO\t2019-09-09 14:49:30 -0400\tmaster-replica-0\t4\t406/446 [==========================>...] - ETA: 0s - loss: 3.8677 - acc: 0.760\n",
      "INFO\t2019-09-09 14:49:30 -0400\tmaster-replica-0\t4\t419/446 [===========================>..] - ETA: 0s - loss: 3.8789 - acc: 0.759\n",
      "INFO\t2019-09-09 14:49:31 -0400\tmaster-replica-0\t4\t437/446 [============================>.] - ETA: 0s - loss: 3.8814 - acc: 0.759\n",
      "INFO\t2019-09-09 14:49:31 -0400\tmaster-replica-0\t4\t446/446 [==============================] - 3s 6ms/step - loss: 3.8808 - acc: 0.7592 - val_loss: 3.8072 - val_acc: 0.7638\n",
      "WARNING\t2019-09-09 14:49:38 -0400\tmaster-replica-0\t4\tThis model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.RMSprop object at 0x7ff50e5dc4a8>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "WARNING\t2019-09-09 14:49:38 -0400\tmaster-replica-0\t4\t\n",
      "WARNING\t2019-09-09 14:49:38 -0400\tmaster-replica-0\t4\tConsider using a TensorFlow optimizer from `tf.train`.\n",
      "WARNING\t2019-09-09 14:49:42 -0400\tmaster-replica-0\t4\tFrom /usr/local/lib/python3.5/dist-packages/tensorflow/python/keras/engine/network.py:1436: update_checkpoint_state (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "WARNING\t2019-09-09 14:49:42 -0400\tmaster-replica-0\t4\tInstructions for updating:\n",
      "WARNING\t2019-09-09 14:49:42 -0400\tmaster-replica-0\t4\tUse tf.train.CheckpointManager to manage checkpoints rather than manually editing the Checkpoint proto.\n",
      "WARNING\t2019-09-09 14:49:44 -0400\tmaster-replica-0\t4\tModel was compiled with an optimizer, but the optimizer is not from `tf.train` (e.g. `tf.train.AdagradOptimizer`). Only the serving graph was exported. The train and evaluate graphs were not added to the SavedModel.\n",
      "WARNING\t2019-09-09 14:49:56 -0400\tmaster-replica-0\t4\tFrom /usr/local/lib/python3.5/dist-packages/tensorflow/python/saved_model/signature_def_utils_impl.py:205: build_tensor_info (from tensorflow.python.saved_model.utils_impl) is deprecated and will be removed in a future version.\n",
      "WARNING\t2019-09-09 14:49:56 -0400\tmaster-replica-0\t4\tInstructions for updating:\n",
      "WARNING\t2019-09-09 14:49:56 -0400\tmaster-replica-0\t4\tThis function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.utils.build_tensor_info or tf.compat.v1.saved_model.build_tensor_info.\n",
      "INFO\t2019-09-09 14:49:56 -0400\tmaster-replica-0\t4\tSignatures INCLUDED in export for Classify: None\n",
      "INFO\t2019-09-09 14:49:56 -0400\tmaster-replica-0\t4\tSignatures INCLUDED in export for Regress: None\n",
      "INFO\t2019-09-09 14:49:56 -0400\tmaster-replica-0\t4\tSignatures INCLUDED in export for Train: None\n",
      "INFO\t2019-09-09 14:49:56 -0400\tmaster-replica-0\t4\tSignatures INCLUDED in export for Predict: ['serving_default']\n",
      "INFO\t2019-09-09 14:49:56 -0400\tmaster-replica-0\t4\tSignatures INCLUDED in export for Eval: None\n",
      "INFO\t2019-09-09 14:49:56 -0400\tmaster-replica-0\t4\tNo assets to save.\n",
      "INFO\t2019-09-09 14:49:56 -0400\tmaster-replica-0\t4\tNo assets to write.\n",
      "INFO\t2019-09-09 14:49:57 -0400\tmaster-replica-0\t4\tSavedModel written to: gs://mo_ml/lingh/4/keras_export/1568054974/saved_model.pb\n",
      "INFO\t2019-09-09 14:49:59 -0400\tmaster-replica-0\t4\tWARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "INFO\t2019-09-09 14:49:59 -0400\tmaster-replica-0\t4\tFor more information, please see:\n",
      "INFO\t2019-09-09 14:49:59 -0400\tmaster-replica-0\t4\t  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "INFO\t2019-09-09 14:49:59 -0400\tmaster-replica-0\t4\t  * https://github.com/tensorflow/addons\n",
      "INFO\t2019-09-09 14:49:59 -0400\tmaster-replica-0\t4\tIf you depend on functionality not listed there, please file an issue.\n",
      "INFO\t2019-09-09 14:49:59 -0400\tmaster-replica-0\t4\tModel exported to: gs://mo_ml/lingh/4/keras_export\n",
      "INFO\t2019-09-09 14:49:59 -0400\tmaster-replica-0\t4\tModule completed; cleaning up.\n",
      "INFO\t2019-09-09 14:49:59 -0400\tmaster-replica-0\t4\tClean up finished.\n",
      "INFO\t2019-09-09 14:49:59 -0400\tmaster-replica-0\t4\tTask completed successfully.\n",
      "INFO\t2019-09-09 14:53:44 -0400\tservice\t3\tJob completed successfully.\n",
      "INFO\t2019-09-09 14:54:17 -0400\tservice\t4\tJob completed successfully.\n",
      "endTime: '2019-09-09T14:54:32'\n",
      "jobId: my_first_keras_job\n",
      "startTime: '2019-09-09T14:37:57'\n",
      "state: SUCCEEDED\n"
     ]
    }
   ],
   "source": [
    "! gcloud ai-platform jobs submit training $JOB_NAME \\\n",
    "  --config hptuning_config.yaml \\\n",
    "  --package-path trainer/ \\\n",
    "  --module-name trainer.task \\\n",
    "  --region $REGION \\\n",
    "  --python-version 3.5 \\\n",
    "  --runtime-version 1.13 \\\n",
    "  --job-dir $JOB_DIR \\\n",
    "  --stream-logs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gAO6-zv6osJ8"
   },
   "source": [
    "## Part 2. Quickstart for online predictions in AI Platform\n",
    "\n",
    "This section shows how to use AI Platform and your trained model from Part 1\n",
    "to predict a person's income bracket from other Census information about them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Oi1xMGzLsjf_"
   },
   "source": [
    "### Create model and version resources in AI Platform\n",
    "\n",
    "To serve online predictions using the model you trained and exported in Part 1,\n",
    "create a *model* resource in AI Platform and a *version* resource\n",
    "within it. The version resource is what actually uses your trained model to\n",
    "serve predictions. This structure lets you adjust and retrain your model many times and\n",
    "organize all the versions together in AI Platform. Learn more about [models\n",
    "and\n",
    "versions](https://cloud.google.com/ml-engine/docs/tensorflow/projects-models-versions-jobs).\n",
    "\n",
    "First, name and create the model resource:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "SurMKEbBtc2W",
    "outputId": "28321881-0678-4805-a05c-290b8cfcad4e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31mERROR:\u001b[0m (gcloud.ai-platform.models.create) Resource in project [paradox-mo] is the subject of a conflict: Field: model.name Error: A model with the same name already exists.\r\n",
      "- '@type': type.googleapis.com/google.rpc.BadRequest\r\n",
      "  fieldViolations:\r\n",
      "  - description: A model with the same name already exists.\r\n",
      "    field: model.name\r\n"
     ]
    }
   ],
   "source": [
    "MODEL_NAME = \"my_first_keras_model\"\n",
    "\n",
    "! gcloud ai-platform models create $MODEL_NAME \\\n",
    "  --regions $REGION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "c5YLJugmt-Wm"
   },
   "source": [
    "Next, create the model version. The training job from Part 1 exported a timestamped\n",
    "[TensorFlow SavedModel\n",
    "directory](https://www.tensorflow.org/guide/saved_model#structure_of_a_savedmodel_directory)\n",
    "to your Cloud Storage bucket. AI Platform uses this directory to create a\n",
    "model version. Learn more about [SavedModel and\n",
    "AI Platform](https://cloud.google.com/ml-engine/docs/tensorflow/deploying-models).\n",
    "\n",
    "You may be able to find the path to this directory in your training job's logs.\n",
    "Look for a line like:\n",
    "\n",
    "```\n",
    "Model exported to:  gs://<your-bucket-name>/keras-job-dir/keras_export/1545439782\n",
    "```\n",
    "\n",
    "Execute the following command to identify your SavedModel directory and use it to create a model version resource:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://mo_ml/lingh/1/keras_export/1568054530/\r\n",
      "gs://mo_ml/lingh/1/keras_export/1568054530/saved_model.pb\r\n",
      "gs://mo_ml/lingh/1/keras_export/1568054530/assets/\r\n",
      "gs://mo_ml/lingh/1/keras_export/1568054530/variables/\r\n"
     ]
    }
   ],
   "source": [
    "! gsutil ls gs://mo_ml/lingh/1/keras_export/1568054530"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "cellView": "both",
    "colab": {},
    "colab_type": "code",
    "id": "NYfK78654CVm"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating version (this might take a few minutes)......done.                    \n"
     ]
    }
   ],
   "source": [
    "MODEL_VERSION = \"v2\"\n",
    "\n",
    "# Get a list of directories in the `keras_export` parent directory\n",
    "# KERAS_EXPORT_DIRS = ! gsutil ls gs://mo_ml/lingh/1/keras_export/1568054530\n",
    "\n",
    "# Pick the directory with the latest timestamp, in case you've trained\n",
    "# multiple times\n",
    "# KERAS_EXPORT_DIRS = ! gsutil ls gs://mo_ml/lingh/1/keras_export/1568054530\n",
    "SAVED_MODEL_PATH = 'gs://mo_ml/lingh/1/keras_export/1568054530/'\n",
    "\n",
    "# Create model version based on that SavedModel directory\n",
    "! gcloud ai-platform versions create $MODEL_VERSION \\\n",
    "  --model $MODEL_NAME \\\n",
    "  --runtime-version 1.13 \\\n",
    "  --python-version 3.5 \\\n",
    "  --framework tensorflow \\\n",
    "  --origin $SAVED_MODEL_PATH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JzevJps9IOcU"
   },
   "source": [
    "### Prepare input for prediction\n",
    "\n",
    "To receive valid and useful predictions, you must preprocess input for prediction in the same way that training data was preprocessed. In a production\n",
    "system, you may want to create a preprocessing pipeline that can be used identically at training time and prediction time.\n",
    "\n",
    "For this exercise, use the training package's data-loading code to select a random sample from the evaluation data. This data is in the form that was used to evaluate accuracy after each epoch of training, so it can be used to send test predictions without further preprocessing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 669
    },
    "colab_type": "code",
    "id": "zuh7LWeWv_GT",
    "outputId": "c0e90fbe-ba9a-4095-943f-b8d17b4cf13f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0909 17:00:39.021347 4559709632 deprecation_wrapper.py:119] From trainer/util.py:128: The name tf.gfile.MakeDirs is deprecated. Please use tf.io.gfile.makedirs instead.\n",
      "\n",
      "W0909 17:00:39.023051 4559709632 deprecation_wrapper.py:119] From trainer/util.py:131: The name tf.gfile.Exists is deprecated. Please use tf.io.gfile.exists instead.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>education_num</th>\n",
       "      <th>marital_status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>capital_gain</th>\n",
       "      <th>capital_loss</th>\n",
       "      <th>hours_per_week</th>\n",
       "      <th>native_country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13880</th>\n",
       "      <td>1.120017</td>\n",
       "      <td>3</td>\n",
       "      <td>1.136580</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.144792</td>\n",
       "      <td>-0.217132</td>\n",
       "      <td>-0.034039</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15111</th>\n",
       "      <td>0.171866</td>\n",
       "      <td>3</td>\n",
       "      <td>-0.419265</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>-0.144792</td>\n",
       "      <td>-0.217132</td>\n",
       "      <td>-0.034039</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5168</th>\n",
       "      <td>-0.557481</td>\n",
       "      <td>3</td>\n",
       "      <td>-0.030304</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>-0.144792</td>\n",
       "      <td>-0.217132</td>\n",
       "      <td>-1.648058</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2286</th>\n",
       "      <td>0.609474</td>\n",
       "      <td>3</td>\n",
       "      <td>-0.419265</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>-0.144792</td>\n",
       "      <td>-0.217132</td>\n",
       "      <td>-0.034039</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11605</th>\n",
       "      <td>-0.776285</td>\n",
       "      <td>3</td>\n",
       "      <td>-0.419265</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.144792</td>\n",
       "      <td>-0.217132</td>\n",
       "      <td>-0.034039</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13563</th>\n",
       "      <td>-0.703350</td>\n",
       "      <td>3</td>\n",
       "      <td>0.358658</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>-0.144792</td>\n",
       "      <td>-0.217132</td>\n",
       "      <td>-0.034039</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15323</th>\n",
       "      <td>-1.140958</td>\n",
       "      <td>3</td>\n",
       "      <td>1.136580</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>-0.144792</td>\n",
       "      <td>-0.217132</td>\n",
       "      <td>-0.034039</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5847</th>\n",
       "      <td>-0.046938</td>\n",
       "      <td>3</td>\n",
       "      <td>-0.419265</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>-0.144792</td>\n",
       "      <td>-0.217132</td>\n",
       "      <td>2.386988</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16053</th>\n",
       "      <td>-0.776285</td>\n",
       "      <td>3</td>\n",
       "      <td>-1.975110</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>-0.144792</td>\n",
       "      <td>-0.217132</td>\n",
       "      <td>-0.437544</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1909</th>\n",
       "      <td>2.651645</td>\n",
       "      <td>3</td>\n",
       "      <td>-1.586149</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>-0.144792</td>\n",
       "      <td>-0.217132</td>\n",
       "      <td>-0.034039</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2861</th>\n",
       "      <td>-0.995089</td>\n",
       "      <td>3</td>\n",
       "      <td>-0.419265</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>-0.144792</td>\n",
       "      <td>-0.217132</td>\n",
       "      <td>-0.841048</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3847</th>\n",
       "      <td>-0.557481</td>\n",
       "      <td>3</td>\n",
       "      <td>-0.419265</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>-0.144792</td>\n",
       "      <td>-0.217132</td>\n",
       "      <td>-0.034039</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15775</th>\n",
       "      <td>-0.192807</td>\n",
       "      <td>4</td>\n",
       "      <td>-0.419265</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>-0.144792</td>\n",
       "      <td>-0.217132</td>\n",
       "      <td>0.450166</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3721</th>\n",
       "      <td>1.703494</td>\n",
       "      <td>3</td>\n",
       "      <td>-0.808226</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>-0.144792</td>\n",
       "      <td>-0.217132</td>\n",
       "      <td>-0.276142</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15409</th>\n",
       "      <td>-0.484546</td>\n",
       "      <td>3</td>\n",
       "      <td>0.747619</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>-0.144792</td>\n",
       "      <td>-0.217132</td>\n",
       "      <td>-0.034039</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11074</th>\n",
       "      <td>-0.630415</td>\n",
       "      <td>3</td>\n",
       "      <td>-0.419265</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.144792</td>\n",
       "      <td>-0.217132</td>\n",
       "      <td>0.934372</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13047</th>\n",
       "      <td>-0.192807</td>\n",
       "      <td>3</td>\n",
       "      <td>0.747619</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.301384</td>\n",
       "      <td>-0.217132</td>\n",
       "      <td>-0.034039</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6466</th>\n",
       "      <td>0.901213</td>\n",
       "      <td>7</td>\n",
       "      <td>0.747619</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>-0.144792</td>\n",
       "      <td>-0.217132</td>\n",
       "      <td>0.369465</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8182</th>\n",
       "      <td>0.098931</td>\n",
       "      <td>3</td>\n",
       "      <td>1.136580</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>-0.144792</td>\n",
       "      <td>-0.217132</td>\n",
       "      <td>2.548390</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12813</th>\n",
       "      <td>-0.922154</td>\n",
       "      <td>3</td>\n",
       "      <td>1.136580</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>-0.144792</td>\n",
       "      <td>-0.217132</td>\n",
       "      <td>-2.051562</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            age  workclass  education_num  marital_status  occupation  \\\n",
       "13880  1.120017          3       1.136580               2           2   \n",
       "15111  0.171866          3      -0.419265               4           7   \n",
       "5168  -0.557481          3      -0.030304               0           0   \n",
       "2286   0.609474          3      -0.419265               2           6   \n",
       "11605 -0.776285          3      -0.419265               4           0   \n",
       "13563 -0.703350          3       0.358658               4           2   \n",
       "15323 -1.140958          3       1.136580               4           0   \n",
       "5847  -0.046938          3      -0.419265               2          11   \n",
       "16053 -0.776285          3      -1.975110               2           7   \n",
       "1909   2.651645          3      -1.586149               2          13   \n",
       "2861  -0.995089          3      -0.419265               2          11   \n",
       "3847  -0.557481          3      -0.419265               0           0   \n",
       "15775 -0.192807          4      -0.419265               2           2   \n",
       "3721   1.703494          3      -0.808226               6           0   \n",
       "15409 -0.484546          3       0.747619               2           3   \n",
       "11074 -0.630415          3      -0.419265               2           7   \n",
       "13047 -0.192807          3       0.747619               4           3   \n",
       "6466   0.901213          7       0.747619               2          11   \n",
       "8182   0.098931          3       1.136580               2          11   \n",
       "12813 -0.922154          3       1.136580               4           7   \n",
       "\n",
       "       relationship  race  capital_gain  capital_loss  hours_per_week  \\\n",
       "13880             0     2     -0.144792     -0.217132       -0.034039   \n",
       "15111             3     4     -0.144792     -0.217132       -0.034039   \n",
       "5168              4     4     -0.144792     -0.217132       -1.648058   \n",
       "2286              0     4     -0.144792     -0.217132       -0.034039   \n",
       "11605             1     2     -0.144792     -0.217132       -0.034039   \n",
       "13563             3     4     -0.144792     -0.217132       -0.034039   \n",
       "15323             3     4     -0.144792     -0.217132       -0.034039   \n",
       "5847              0     4     -0.144792     -0.217132        2.386988   \n",
       "16053             2     4     -0.144792     -0.217132       -0.437544   \n",
       "1909              0     4     -0.144792     -0.217132       -0.034039   \n",
       "2861              0     4     -0.144792     -0.217132       -0.841048   \n",
       "3847              4     4     -0.144792     -0.217132       -0.034039   \n",
       "15775             0     4     -0.144792     -0.217132        0.450166   \n",
       "3721              4     4     -0.144792     -0.217132       -0.276142   \n",
       "15409             5     4     -0.144792     -0.217132       -0.034039   \n",
       "11074             0     1     -0.144792     -0.217132        0.934372   \n",
       "13047             1     4      0.301384     -0.217132       -0.034039   \n",
       "6466              0     4     -0.144792     -0.217132        0.369465   \n",
       "8182              5     4     -0.144792     -0.217132        2.548390   \n",
       "12813             3     4     -0.144792     -0.217132       -2.051562   \n",
       "\n",
       "       native_country  \n",
       "13880              38  \n",
       "15111              38  \n",
       "5168               38  \n",
       "2286               38  \n",
       "11605              38  \n",
       "13563              38  \n",
       "15323              38  \n",
       "5847               38  \n",
       "16053              38  \n",
       "1909               38  \n",
       "2861               38  \n",
       "3847               38  \n",
       "15775              38  \n",
       "3721               25  \n",
       "15409              38  \n",
       "11074               2  \n",
       "13047              38  \n",
       "6466               38  \n",
       "8182               -1  \n",
       "12813              38  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from trainer import util\n",
    "\n",
    "_, _, eval_x, eval_y = util.load_data()\n",
    "\n",
    "prediction_input = eval_x.sample(20)\n",
    "prediction_targets = eval_y[prediction_input.index]\n",
    "\n",
    "prediction_input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HV1JhIWkn1t5"
   },
   "source": [
    "Notice that categorical fields, like `occupation`,  have already been converted to integers (with the same mapping that was used for training). Numerical fields, like `age`, have been scaled to a\n",
    "[z-score](https://developers.google.com/machine-learning/crash-course/representation/cleaning-data). Some fields have been dropped from the original\n",
    "data. Compare the prediction input with the raw data for the same examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 669
    },
    "colab_type": "code",
    "id": "fvRzpDgugqQr",
    "outputId": "4158ec9d-88d6-429e-f8cc-8582415b3b8d"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education_num</th>\n",
       "      <th>marital_status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>gender</th>\n",
       "      <th>capital_gain</th>\n",
       "      <th>capital_loss</th>\n",
       "      <th>hours_per_week</th>\n",
       "      <th>native_country</th>\n",
       "      <th>income_bracket</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13880</th>\n",
       "      <td>54</td>\n",
       "      <td>Private</td>\n",
       "      <td>249352</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Craft-repair</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15111</th>\n",
       "      <td>41</td>\n",
       "      <td>Private</td>\n",
       "      <td>227065</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Other-service</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5168</th>\n",
       "      <td>31</td>\n",
       "      <td>Private</td>\n",
       "      <td>106637</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>10</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Unmarried</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2286</th>\n",
       "      <td>47</td>\n",
       "      <td>Private</td>\n",
       "      <td>145636</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Machine-op-inspct</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11605</th>\n",
       "      <td>28</td>\n",
       "      <td>Private</td>\n",
       "      <td>271012</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13563</th>\n",
       "      <td>29</td>\n",
       "      <td>Private</td>\n",
       "      <td>130856</td>\n",
       "      <td>Assoc-voc</td>\n",
       "      <td>11</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Craft-repair</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15323</th>\n",
       "      <td>23</td>\n",
       "      <td>Private</td>\n",
       "      <td>107882</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5847</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>178322</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Sales</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>70</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16053</th>\n",
       "      <td>28</td>\n",
       "      <td>Private</td>\n",
       "      <td>425127</td>\n",
       "      <td>9th</td>\n",
       "      <td>5</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Other-service</td>\n",
       "      <td>Other-relative</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1909</th>\n",
       "      <td>75</td>\n",
       "      <td>Private</td>\n",
       "      <td>233362</td>\n",
       "      <td>10th</td>\n",
       "      <td>6</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Transport-moving</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2861</th>\n",
       "      <td>25</td>\n",
       "      <td>Private</td>\n",
       "      <td>54298</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Sales</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3847</th>\n",
       "      <td>31</td>\n",
       "      <td>Private</td>\n",
       "      <td>263110</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Unmarried</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15775</th>\n",
       "      <td>36</td>\n",
       "      <td>Self-emp-inc</td>\n",
       "      <td>196554</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Craft-repair</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>46</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3721</th>\n",
       "      <td>62</td>\n",
       "      <td>Private</td>\n",
       "      <td>235997</td>\n",
       "      <td>12th</td>\n",
       "      <td>8</td>\n",
       "      <td>Widowed</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Unmarried</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>37</td>\n",
       "      <td>Mexico</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15409</th>\n",
       "      <td>32</td>\n",
       "      <td>Private</td>\n",
       "      <td>101103</td>\n",
       "      <td>Assoc-acdm</td>\n",
       "      <td>12</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Wife</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11074</th>\n",
       "      <td>30</td>\n",
       "      <td>Private</td>\n",
       "      <td>194971</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Other-service</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Asian-Pac-Islander</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>52</td>\n",
       "      <td>China</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13047</th>\n",
       "      <td>36</td>\n",
       "      <td>Private</td>\n",
       "      <td>131766</td>\n",
       "      <td>Assoc-acdm</td>\n",
       "      <td>12</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>3325</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6466</th>\n",
       "      <td>51</td>\n",
       "      <td>Without-pay</td>\n",
       "      <td>124963</td>\n",
       "      <td>Assoc-acdm</td>\n",
       "      <td>12</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Sales</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8182</th>\n",
       "      <td>40</td>\n",
       "      <td>Private</td>\n",
       "      <td>153799</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Sales</td>\n",
       "      <td>Wife</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>72</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12813</th>\n",
       "      <td>26</td>\n",
       "      <td>Private</td>\n",
       "      <td>174592</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Other-service</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       age     workclass  fnlwgt     education  education_num  \\\n",
       "13880   54       Private  249352     Bachelors             13   \n",
       "15111   41       Private  227065       HS-grad              9   \n",
       "5168    31       Private  106637  Some-college             10   \n",
       "2286    47       Private  145636       HS-grad              9   \n",
       "11605   28       Private  271012       HS-grad              9   \n",
       "13563   29       Private  130856     Assoc-voc             11   \n",
       "15323   23       Private  107882     Bachelors             13   \n",
       "5847    38       Private  178322       HS-grad              9   \n",
       "16053   28       Private  425127           9th              5   \n",
       "1909    75       Private  233362          10th              6   \n",
       "2861    25       Private   54298       HS-grad              9   \n",
       "3847    31       Private  263110       HS-grad              9   \n",
       "15775   36  Self-emp-inc  196554       HS-grad              9   \n",
       "3721    62       Private  235997          12th              8   \n",
       "15409   32       Private  101103    Assoc-acdm             12   \n",
       "11074   30       Private  194971       HS-grad              9   \n",
       "13047   36       Private  131766    Assoc-acdm             12   \n",
       "6466    51   Without-pay  124963    Assoc-acdm             12   \n",
       "8182    40       Private  153799     Bachelors             13   \n",
       "12813   26       Private  174592     Bachelors             13   \n",
       "\n",
       "           marital_status         occupation    relationship  \\\n",
       "13880  Married-civ-spouse       Craft-repair         Husband   \n",
       "15111       Never-married      Other-service       Own-child   \n",
       "5168             Divorced       Adm-clerical       Unmarried   \n",
       "2286   Married-civ-spouse  Machine-op-inspct         Husband   \n",
       "11605       Never-married       Adm-clerical   Not-in-family   \n",
       "13563       Never-married       Craft-repair       Own-child   \n",
       "15323       Never-married       Adm-clerical       Own-child   \n",
       "5847   Married-civ-spouse              Sales         Husband   \n",
       "16053  Married-civ-spouse      Other-service  Other-relative   \n",
       "1909   Married-civ-spouse   Transport-moving         Husband   \n",
       "2861   Married-civ-spouse              Sales         Husband   \n",
       "3847             Divorced       Adm-clerical       Unmarried   \n",
       "15775  Married-civ-spouse       Craft-repair         Husband   \n",
       "3721              Widowed       Adm-clerical       Unmarried   \n",
       "15409  Married-civ-spouse    Exec-managerial            Wife   \n",
       "11074  Married-civ-spouse      Other-service         Husband   \n",
       "13047       Never-married    Exec-managerial   Not-in-family   \n",
       "6466   Married-civ-spouse              Sales         Husband   \n",
       "8182   Married-civ-spouse              Sales            Wife   \n",
       "12813       Never-married      Other-service       Own-child   \n",
       "\n",
       "                     race  gender  capital_gain  capital_loss  hours_per_week  \\\n",
       "13880               Black    Male             0             0              40   \n",
       "15111               White    Male             0             0              40   \n",
       "5168                White  Female             0             0              20   \n",
       "2286                White    Male             0             0              40   \n",
       "11605               Black  Female             0             0              40   \n",
       "13563               White    Male             0             0              40   \n",
       "15323               White  Female             0             0              40   \n",
       "5847                White    Male             0             0              70   \n",
       "16053               White  Female             0             0              35   \n",
       "1909                White    Male             0             0              40   \n",
       "2861                White    Male             0             0              30   \n",
       "3847                White  Female             0             0              40   \n",
       "15775               White    Male             0             0              46   \n",
       "3721                White  Female             0             0              37   \n",
       "15409               White  Female             0             0              40   \n",
       "11074  Asian-Pac-Islander    Male             0             0              52   \n",
       "13047               White  Female          3325             0              40   \n",
       "6466                White    Male             0             0              45   \n",
       "8182                White  Female             0             0              72   \n",
       "12813               White  Female             0             0              15   \n",
       "\n",
       "      native_country income_bracket  \n",
       "13880  United-States          <=50K  \n",
       "15111  United-States          <=50K  \n",
       "5168   United-States          <=50K  \n",
       "2286   United-States           >50K  \n",
       "11605  United-States          <=50K  \n",
       "13563  United-States          <=50K  \n",
       "15323  United-States          <=50K  \n",
       "5847   United-States           >50K  \n",
       "16053  United-States          <=50K  \n",
       "1909   United-States          <=50K  \n",
       "2861   United-States          <=50K  \n",
       "3847   United-States          <=50K  \n",
       "15775  United-States           >50K  \n",
       "3721          Mexico          <=50K  \n",
       "15409  United-States          <=50K  \n",
       "11074          China          <=50K  \n",
       "13047  United-States          <=50K  \n",
       "6466   United-States          <=50K  \n",
       "8182             NaN           >50K  \n",
       "12813  United-States          <=50K  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "_, eval_file_path = util.download(util.DATA_DIR)\n",
    "raw_eval_data = pd.read_csv(eval_file_path,\n",
    "                            names=util._CSV_COLUMNS,\n",
    "                            na_values='?')\n",
    "\n",
    "raw_eval_data.iloc[prediction_input.index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HFAbbH6ksG6s"
   },
   "source": [
    "Export the prediction input to a newline-delimited JSON file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 357
    },
    "colab_type": "code",
    "id": "Yl3JALtnsGj-",
    "outputId": "f6d961a8-1ce8-4084-abb3-317b8d4336db"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.1200168132781982, 3.0, 1.1365801095962524, 2.0, 2.0, 0.0, 2.0, -0.1447920799255371, -0.2171318680047989, -0.03403923660516739, 38.0]\r\n",
      "[0.1718660145998001, 3.0, -0.41926509141921997, 4.0, 7.0, 3.0, 4.0, -0.1447920799255371, -0.2171318680047989, -0.03403923660516739, 38.0]\r\n",
      "[-0.5574807524681091, 3.0, -0.030303768813610077, 0.0, 0.0, 4.0, 4.0, -0.1447920799255371, -0.2171318680047989, -1.6480576992034912, 38.0]\r\n",
      "[0.6094740629196167, 3.0, -0.41926509141921997, 2.0, 6.0, 0.0, 4.0, -0.1447920799255371, -0.2171318680047989, -0.03403923660516739, 38.0]\r\n",
      "[-0.7762847542762756, 3.0, -0.41926509141921997, 4.0, 0.0, 1.0, 2.0, -0.1447920799255371, -0.2171318680047989, -0.03403923660516739, 38.0]\r\n",
      "[-0.7033500671386719, 3.0, 0.3586575388908386, 4.0, 2.0, 3.0, 4.0, -0.1447920799255371, -0.2171318680047989, -0.03403923660516739, 38.0]\r\n",
      "[-1.1409581899642944, 3.0, 1.1365801095962524, 4.0, 0.0, 3.0, 4.0, -0.1447920799255371, -0.2171318680047989, -0.03403923660516739, 38.0]\r\n",
      "[-0.046938009560108185, 3.0, -0.41926509141921997, 2.0, 11.0, 0.0, 4.0, -0.1447920799255371, -0.2171318680047989, 2.386988401412964, 38.0]\r\n",
      "[-0.7762847542762756, 3.0, -1.9751102924346924, 2.0, 7.0, 2.0, 4.0, -0.1447920799255371, -0.2171318680047989, -0.4375438690185547, 38.0]\r\n",
      "[2.6516449451446533, 3.0, -1.586148977279663, 2.0, 13.0, 0.0, 4.0, -0.1447920799255371, -0.2171318680047989, -0.03403923660516739, 38.0]\r\n",
      "[-0.9950888156890869, 3.0, -0.41926509141921997, 2.0, 11.0, 0.0, 4.0, -0.1447920799255371, -0.2171318680047989, -0.8410484790802002, 38.0]\r\n",
      "[-0.5574807524681091, 3.0, -0.41926509141921997, 0.0, 0.0, 4.0, 4.0, -0.1447920799255371, -0.2171318680047989, -0.03403923660516739, 38.0]\r\n",
      "[-0.1928073614835739, 4.0, -0.41926509141921997, 2.0, 2.0, 0.0, 4.0, -0.1447920799255371, -0.2171318680047989, 0.4501663148403168, 38.0]\r\n",
      "[1.7034941911697388, 3.0, -0.8082264065742493, 6.0, 0.0, 4.0, 4.0, -0.1447920799255371, -0.2171318680047989, -0.2761420011520386, 25.0]\r\n",
      "[-0.48454606533050537, 3.0, 0.7476188540458679, 2.0, 3.0, 5.0, 4.0, -0.1447920799255371, -0.2171318680047989, -0.03403923660516739, 38.0]\r\n",
      "[-0.6304154396057129, 3.0, -0.41926509141921997, 2.0, 7.0, 0.0, 1.0, -0.1447920799255371, -0.2171318680047989, 0.934371829032898, 2.0]\r\n",
      "[-0.1928073614835739, 3.0, 0.7476188540458679, 4.0, 3.0, 1.0, 4.0, 0.3013837933540344, -0.2171318680047989, -0.03403923660516739, 38.0]\r\n",
      "[0.901212751865387, 7.0, 0.7476188540458679, 2.0, 11.0, 0.0, 4.0, -0.1447920799255371, -0.2171318680047989, 0.3694653809070587, 38.0]\r\n",
      "[0.09893134236335754, 3.0, 1.1365801095962524, 2.0, 11.0, 5.0, 4.0, -0.1447920799255371, -0.2171318680047989, 2.5483903884887695, -1.0]\r\n",
      "[-0.9221541285514832, 3.0, 1.1365801095962524, 4.0, 7.0, 3.0, 4.0, -0.1447920799255371, -0.2171318680047989, -2.0515623092651367, 38.0]\r\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "with open('prediction_input.json', 'w') as json_file:\n",
    "  for row in prediction_input.values.tolist():\n",
    "    json.dump(row, json_file)\n",
    "    json_file.write('\\n')\n",
    "\n",
    "! cat prediction_input.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kVvEmazFKUCp"
   },
   "source": [
    "The `gcloud` command-line tool accepts newline-delimited JSON for online\n",
    "prediction, and this particular Keras model expects a flat list of\n",
    "numbers for each input example.\n",
    "\n",
    "AI Platform requires a different format when you make online prediction requests to the REST API without using the `gcloud` tool. The way you structure\n",
    "your model may also change how you must format data for prediction. Learn more\n",
    "about [formatting data for online\n",
    "prediction](https://cloud.google.com/ml-engine/docs/tensorflow/prediction-overview#prediction_input_data)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "91xQnLqRN8A8"
   },
   "source": [
    "### Submit the online prediction request"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KrDIoVLaG7zZ"
   },
   "source": [
    "Use `gcloud` to submit your online prediction request."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 374
    },
    "colab_type": "code",
    "id": "5gIcXDFwOERG",
    "outputId": "104e950d-5377-4ee1-f812-789ab4c09b90"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DENSE_4\r\n",
      "[0.0]\r\n",
      "[0.0]\r\n",
      "[0.0]\r\n",
      "[0.0]\r\n",
      "[0.0]\r\n",
      "[0.0]\r\n",
      "[0.0]\r\n",
      "[0.0]\r\n",
      "[0.0]\r\n",
      "[0.0]\r\n",
      "[0.0]\r\n",
      "[0.0]\r\n",
      "[0.0]\r\n",
      "[0.0]\r\n",
      "[0.0]\r\n",
      "[0.0]\r\n",
      "[0.0]\r\n",
      "[0.0]\r\n",
      "[0.0]\r\n",
      "[0.0]\r\n"
     ]
    }
   ],
   "source": [
    "! gcloud ai-platform predict \\\n",
    "  --model $MODEL_NAME \\\n",
    "  --version $MODEL_VERSION \\\n",
    "  --json-instances prediction_input.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "n6U2DYKJGwdf"
   },
   "source": [
    "Since the model's last layer uses a [sigmoid function](https://developers.google.com/machine-learning/glossary/#sigmoid_function) for its activation, outputs between 0 and 0.5 represent negative predictions (\"<=50K\") and outputs between 0.5 and 1 represent positive ones (\">50K\").\n",
    "\n",
    "Do the predicted income brackets match the actual ones? Run the following cell\n",
    "to see the true labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 357
    },
    "colab_type": "code",
    "id": "w2Piq3PcGhaX",
    "outputId": "8fcc69d4-485b-4733-e594-0a92afa2c323"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.]], dtype=float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_targets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GKP7F6-EDb5_"
   },
   "source": [
    "## Part 3. Developing the Keras model from scratch\n",
    "\n",
    "At this point, you have trained a machine learning model on AI Platform, deployed the trained model as a version resource on AI Platform, and received online predictions from the deployment. The next section walks through recreating the Keras code used to train your model. It covers the following parts of developing a machine learning model for use with AI Platform:\n",
    "\n",
    "* Downloading and preprocessing data\n",
    "* Designing and training the model\n",
    "* Visualizing training and exporting the trained model\n",
    "\n",
    "While this section provides more detailed insight to the tasks completed in previous parts, to learn more about using `tf.keras`, read [TensorFlow's guide to Keras](https://www.tensorflow.org/tutorials/keras). To learn more about structuring code as a training packge for AI Platform, read [Packaging a training application](https://cloud.google.com/ml-engine/docs/tensorflow/packaging-trainer) and reference the [complete training code](https://github.com/GoogleCloudPlatform/cloudml-samples/tree/master/census/tf-keras), which is structured as a Python package."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-VtUN0L5x4ql"
   },
   "source": [
    "### Import libraries and define constants\n",
    "\n",
    "First, import Python libraries required for training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "RcxfR3GfscsA",
    "outputId": "11ea7f86-9030-4120-872b-0e232ec1c0b5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.7.16 (default, Apr 12 2019, 15:32:40) \n",
      "[GCC 4.2.1 Compatible Apple LLVM 10.0.1 (clang-1001.0.46.3)]\n",
      "1.14.0\n",
      "2.2.4-tf\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from six.moves import urllib\n",
    "import tempfile\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "# Examine software versions\n",
    "print(__import__('sys').version)\n",
    "print(tf.__version__)\n",
    "print(tf.keras.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xWZQbZQmx26U"
   },
   "source": [
    "Then, define some useful constants:\n",
    "\n",
    "* Information for downloading training and evaluation data\n",
    "* Information required for Pandas to interpret the data and convert categorical fields into numeric features\n",
    "* Hyperparameters for training, such as learning rate and batch size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.7.16 (default, Apr 12 2019, 15:32:40) \n",
      "[GCC 4.2.1 Compatible Apple LLVM 10.0.1 (clang-1001.0.46.3)]\n",
      "1.14.0\n",
      "2.2.4-tf\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from six.moves import urllib\n",
    "import tempfile\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "# Examine software versions\n",
    "print(__import__('sys').version)\n",
    "print(tf.__version__)\n",
    "print(tf.keras.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Cx4OXeXEsh_v"
   },
   "outputs": [],
   "source": [
    "### For downloading data ###\n",
    "\n",
    "# Storage directory\n",
    "DATA_DIR = os.path.join(tempfile.gettempdir(), 'census_data')\n",
    "\n",
    "# Download options.\n",
    "DATA_URL = 'https://storage.googleapis.com/cloud-samples-data/ml-engine' \\\n",
    "           '/census/data'\n",
    "TRAINING_FILE = 'adult.data.csv'\n",
    "EVAL_FILE = 'adult.test.csv'\n",
    "TRAINING_URL = '%s/%s' % (DATA_URL, TRAINING_FILE)\n",
    "EVAL_URL = '%s/%s' % (DATA_URL, EVAL_FILE)\n",
    "\n",
    "### For interpreting data ###\n",
    "\n",
    "# These are the features in the dataset.\n",
    "# Dataset information: https://archive.ics.uci.edu/ml/datasets/census+income\n",
    "_CSV_COLUMNS = [\n",
    "    'age', 'workclass', 'fnlwgt', 'education', 'education_num',\n",
    "    'marital_status', 'occupation', 'relationship', 'race', 'gender',\n",
    "    'capital_gain', 'capital_loss', 'hours_per_week', 'native_country',\n",
    "    'income_bracket'\n",
    "]\n",
    "\n",
    "_CATEGORICAL_TYPES = {\n",
    "    'workclass': pd.api.types.CategoricalDtype(categories=[\n",
    "        'Federal-gov', 'Local-gov', 'Never-worked', 'Private', 'Self-emp-inc',\n",
    "        'Self-emp-not-inc', 'State-gov', 'Without-pay'\n",
    "    ]),\n",
    "    'marital_status': pd.api.types.CategoricalDtype(categories=[\n",
    "        'Divorced', 'Married-AF-spouse', 'Married-civ-spouse',\n",
    "        'Married-spouse-absent', 'Never-married', 'Separated', 'Widowed'\n",
    "    ]),\n",
    "    'occupation': pd.api.types.CategoricalDtype([\n",
    "        'Adm-clerical', 'Armed-Forces', 'Craft-repair', 'Exec-managerial',\n",
    "        'Farming-fishing', 'Handlers-cleaners', 'Machine-op-inspct',\n",
    "        'Other-service', 'Priv-house-serv', 'Prof-specialty', 'Protective-serv',\n",
    "        'Sales', 'Tech-support', 'Transport-moving'\n",
    "    ]),\n",
    "    'relationship': pd.api.types.CategoricalDtype(categories=[\n",
    "        'Husband', 'Not-in-family', 'Other-relative', 'Own-child', 'Unmarried',\n",
    "        'Wife'\n",
    "    ]),\n",
    "    'race': pd.api.types.CategoricalDtype(categories=[\n",
    "        'Amer-Indian-Eskimo', 'Asian-Pac-Islander', 'Black', 'Other', 'White'\n",
    "    ]),\n",
    "    'native_country': pd.api.types.CategoricalDtype(categories=[\n",
    "        'Cambodia', 'Canada', 'China', 'Columbia', 'Cuba', 'Dominican-Republic',\n",
    "        'Ecuador', 'El-Salvador', 'England', 'France', 'Germany', 'Greece',\n",
    "        'Guatemala', 'Haiti', 'Holand-Netherlands', 'Honduras', 'Hong', 'Hungary',\n",
    "        'India', 'Iran', 'Ireland', 'Italy', 'Jamaica', 'Japan', 'Laos', 'Mexico',\n",
    "        'Nicaragua', 'Outlying-US(Guam-USVI-etc)', 'Peru', 'Philippines', 'Poland',\n",
    "        'Portugal', 'Puerto-Rico', 'Scotland', 'South', 'Taiwan', 'Thailand',\n",
    "        'Trinadad&Tobago', 'United-States', 'Vietnam', 'Yugoslavia'\n",
    "    ]),\n",
    "    'income_bracket': pd.api.types.CategoricalDtype(categories=[\n",
    "        '<=50K', '>50K'\n",
    "    ])\n",
    "}\n",
    "\n",
    "# This is the label (target) we want to predict.\n",
    "_LABEL_COLUMN = 'income_bracket'\n",
    "\n",
    "### Hyperparameters for training ###\n",
    "\n",
    "# This the training batch size\n",
    "BATCH_SIZE = 128\n",
    "\n",
    "# This is the number of epochs (passes over the full training data)\n",
    "NUM_EPOCHS = 20\n",
    "\n",
    "# Define learning rate.\n",
    "LEARNING_RATE = .01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bSJjhQ8ZyDae"
   },
   "source": [
    "### Download and preprocess data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uafupKCgxazq"
   },
   "source": [
    "#### Download the data\n",
    "\n",
    "Next, define functions to download training and evaluation data. These functions also fix minor irregularities in the data's formatting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "cellView": "both",
    "colab": {},
    "colab_type": "code",
    "id": "iGorBTXWUZPy"
   },
   "outputs": [],
   "source": [
    "def _download_and_clean_file(filename, url):\n",
    "    \"\"\"Downloads data from url, and makes changes to match the CSV format.\n",
    "  \n",
    "    The CSVs may use spaces after the comma delimters (non-standard) or include\n",
    "    rows which do not represent well-formed examples. This function strips out\n",
    "    some of these problems.\n",
    "  \n",
    "    Args:\n",
    "      filename: filename to save url to\n",
    "      url: URL of resource to download\n",
    "    \"\"\"\n",
    "    temp_file, _ = urllib.request.urlretrieve(url)\n",
    "    with tf.gfile.Open(temp_file, 'r') as temp_file_object:\n",
    "        with tf.gfile.Open(filename, 'w') as file_object:\n",
    "            for line in temp_file_object:\n",
    "                line = line.strip()\n",
    "                line = line.replace(', ', ',')\n",
    "                if not line or ',' not in line:\n",
    "                    continue\n",
    "                if line[-1] == '.':\n",
    "                    line = line[:-1]\n",
    "                line += '\\n'\n",
    "                file_object.write(line)\n",
    "    tf.gfile.Remove(temp_file)\n",
    "\n",
    "\n",
    "def download(data_dir):\n",
    "    \"\"\"Downloads census data if it is not already present.\n",
    "  \n",
    "    Args:\n",
    "      data_dir: directory where we will access/save the census data\n",
    "    \"\"\"\n",
    "    tf.gfile.MakeDirs(data_dir)\n",
    "\n",
    "    training_file_path = os.path.join(data_dir, TRAINING_FILE)\n",
    "    if not tf.gfile.Exists(training_file_path):\n",
    "        _download_and_clean_file(training_file_path, TRAINING_URL)\n",
    "\n",
    "    eval_file_path = os.path.join(data_dir, EVAL_FILE)\n",
    "    if not tf.gfile.Exists(eval_file_path):\n",
    "        _download_and_clean_file(eval_file_path, EVAL_URL)\n",
    "\n",
    "    return training_file_path, eval_file_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fuX5SyAOgYsG"
   },
   "source": [
    "Use those functions to download the data for training and verify that you have CSV files for training and evaluation: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "9Wii7NAss92J",
    "outputId": "dab93c34-27af-4dcb-91cc-e3ba9a8e9bd0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 10312\r\n",
      "-rw-r--r--  1 lingh  staff  3518450 Sep  9 14:33 adult.data.csv\r\n",
      "-rw-r--r--  1 lingh  staff  1758573 Sep  9 14:33 adult.test.csv\r\n"
     ]
    }
   ],
   "source": [
    "training_file_path, eval_file_path = download(DATA_DIR)\n",
    "\n",
    "# You should see 2 files: adult.data.csv and adult.test.csv\n",
    "!ls -l $DATA_DIR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tHSJTrDygqpS"
   },
   "source": [
    "Next, load these files using Pandas and examine the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "KHWiAYCew28Q",
    "outputId": "36eb1311-815e-4800-9c6b-fc5ea88c39af"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education_num</th>\n",
       "      <th>marital_status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>gender</th>\n",
       "      <th>capital_gain</th>\n",
       "      <th>capital_loss</th>\n",
       "      <th>hours_per_week</th>\n",
       "      <th>native_country</th>\n",
       "      <th>income_bracket</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>77516</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>2174</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>83311</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>215646</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53</td>\n",
       "      <td>Private</td>\n",
       "      <td>234721</td>\n",
       "      <td>11th</td>\n",
       "      <td>7</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>Private</td>\n",
       "      <td>338409</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Wife</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>Cuba</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age         workclass  fnlwgt  education  education_num  \\\n",
       "0   39         State-gov   77516  Bachelors             13   \n",
       "1   50  Self-emp-not-inc   83311  Bachelors             13   \n",
       "2   38           Private  215646    HS-grad              9   \n",
       "3   53           Private  234721       11th              7   \n",
       "4   28           Private  338409  Bachelors             13   \n",
       "\n",
       "       marital_status         occupation   relationship   race  gender  \\\n",
       "0       Never-married       Adm-clerical  Not-in-family  White    Male   \n",
       "1  Married-civ-spouse    Exec-managerial        Husband  White    Male   \n",
       "2            Divorced  Handlers-cleaners  Not-in-family  White    Male   \n",
       "3  Married-civ-spouse  Handlers-cleaners        Husband  Black    Male   \n",
       "4  Married-civ-spouse     Prof-specialty           Wife  Black  Female   \n",
       "\n",
       "   capital_gain  capital_loss  hours_per_week native_country income_bracket  \n",
       "0          2174             0              40  United-States          <=50K  \n",
       "1             0             0              13  United-States          <=50K  \n",
       "2             0             0              40  United-States          <=50K  \n",
       "3             0             0              40  United-States          <=50K  \n",
       "4             0             0              40           Cuba          <=50K  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This census data uses the value '?' for fields (column) that are missing data. \n",
    "# We use na_values to find ? and set it to NaN values.\n",
    "# https://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_csv.html\n",
    "\n",
    "train_df = pd.read_csv(training_file_path, names=_CSV_COLUMNS, na_values='?')\n",
    "eval_df = pd.read_csv(eval_file_path, names=_CSV_COLUMNS, na_values='?')\n",
    "\n",
    "# Here's what the data looks like before we preprocess the data.\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Hhsa1-6qVD0n"
   },
   "source": [
    "#### Preprocess the data\n",
    "\n",
    "The first preprocessing step removes certain features from the data and\n",
    "converts categorical features to numerical values for use with Keras.\n",
    "\n",
    "Learn more about [feature engineering](https://developers.google.com/machine-learning/crash-course/representation/feature-engineering) and [bias in data](https://developers.google.com/machine-learning/crash-course/fairness/types-of-bias)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WHbJecf1Bb2r"
   },
   "outputs": [],
   "source": [
    "UNUSED_COLUMNS = ['fnlwgt', 'education', 'gender']\n",
    "\n",
    "\n",
    "def preprocess(dataframe):\n",
    "    \"\"\"Converts categorical features to numeric. Removes unused columns.\n",
    "  \n",
    "    Args:\n",
    "      dataframe: Pandas dataframe with raw data\n",
    "  \n",
    "    Returns:\n",
    "      Dataframe with preprocessed data\n",
    "    \"\"\"\n",
    "    dataframe = dataframe.drop(columns=UNUSED_COLUMNS)\n",
    "\n",
    "    # Convert integer valued (numeric) columns to floating point\n",
    "    numeric_columns = dataframe.select_dtypes(['int64']).columns\n",
    "    dataframe[numeric_columns] = dataframe[numeric_columns].astype('float32')\n",
    "\n",
    "    # Convert categorical columns to numeric\n",
    "    cat_columns = dataframe.select_dtypes(['object']).columns\n",
    "    dataframe[cat_columns] = dataframe[cat_columns].apply(lambda x: x.astype(\n",
    "        _CATEGORICAL_TYPES[x.name]))\n",
    "    dataframe[cat_columns] = dataframe[cat_columns].apply(lambda x: x.cat.codes)\n",
    "    return dataframe\n",
    "\n",
    "\n",
    "prepped_train_df = preprocess(train_df)\n",
    "prepped_eval_df = preprocess(eval_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ce0Ln1P-mpwx"
   },
   "source": [
    "Run the following cell to see how preprocessing changed the data. Notice in particular that `income_bracket`, the label that you're training the model to predict, has changed from `<=50K` and `>50K` to `0` and `1`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "YbMskdWmTCED",
    "outputId": "add41517-a4b6-41e2-9168-15d0f587c971"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>education_num</th>\n",
       "      <th>marital_status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>capital_gain</th>\n",
       "      <th>capital_loss</th>\n",
       "      <th>hours_per_week</th>\n",
       "      <th>native_country</th>\n",
       "      <th>income_bracket</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39.0</td>\n",
       "      <td>6</td>\n",
       "      <td>13.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2174.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50.0</td>\n",
       "      <td>5</td>\n",
       "      <td>13.0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38.0</td>\n",
       "      <td>3</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53.0</td>\n",
       "      <td>3</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28.0</td>\n",
       "      <td>3</td>\n",
       "      <td>13.0</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    age  workclass  education_num  marital_status  occupation  relationship  \\\n",
       "0  39.0          6           13.0               4           0             1   \n",
       "1  50.0          5           13.0               2           3             0   \n",
       "2  38.0          3            9.0               0           5             1   \n",
       "3  53.0          3            7.0               2           5             0   \n",
       "4  28.0          3           13.0               2           9             5   \n",
       "\n",
       "   race  capital_gain  capital_loss  hours_per_week  native_country  \\\n",
       "0     4        2174.0           0.0            40.0              38   \n",
       "1     4           0.0           0.0            13.0              38   \n",
       "2     4           0.0           0.0            40.0              38   \n",
       "3     2           0.0           0.0            40.0              38   \n",
       "4     2           0.0           0.0            40.0               4   \n",
       "\n",
       "   income_bracket  \n",
       "0               0  \n",
       "1               0  \n",
       "2               0  \n",
       "3               0  \n",
       "4               0  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prepped_train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OCzBX6LuCmTT"
   },
   "source": [
    "Next, separate the data into features (\"x\") and labels (\"y\"), and reshape the label arrays into a format for use with `tf.data.Dataset` later:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gPq7WY51GW6M"
   },
   "outputs": [],
   "source": [
    "# Split train and test data with labels.\n",
    "# The pop() method will extract (copy) and remove the label column from the dataframe\n",
    "train_x, train_y = prepped_train_df, prepped_train_df.pop(_LABEL_COLUMN)\n",
    "eval_x, eval_y = prepped_eval_df, prepped_eval_df.pop(_LABEL_COLUMN)\n",
    "\n",
    "# Reshape label columns for use with tf.data.Dataset\n",
    "train_y = np.asarray(train_y).astype('float32').reshape((-1, 1))\n",
    "eval_y = np.asarray(eval_y).astype('float32').reshape((-1, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "A1tDH7_RDAIK"
   },
   "source": [
    "Scaling training data so each numerical feature column has a mean of 0 and a standard deviation of 1 [can improve your model](https://developers.google.com/machine-learning/crash-course/representation/cleaning-data).\n",
    "\n",
    "In a production system, you may want to save the means and standard deviations from your training set and use them to perform an identical transformation on test data at prediction time. For convenience in this exercise, temporarily combine the training and evaluation data to scale all of them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OXAMwr3dCsqd"
   },
   "outputs": [],
   "source": [
    "def standardize(dataframe):\n",
    "    \"\"\"Scales numerical columns using their means and standard deviation to get\n",
    "    z-scores: the mean of each numerical column becomes 0, and the standard\n",
    "    deviation becomes 1. This can help the model converge during training.\n",
    "  \n",
    "    Args:\n",
    "      dataframe: Pandas dataframe\n",
    "  \n",
    "    Returns:\n",
    "      Input dataframe with the numerical columns scaled to z-scores\n",
    "    \"\"\"\n",
    "    dtypes = list(zip(dataframe.dtypes.index, map(str, dataframe.dtypes)))\n",
    "    # Normalize numeric columns.\n",
    "    for column, dtype in dtypes:\n",
    "        if dtype == 'float32':\n",
    "            dataframe[column] -= dataframe[column].mean()\n",
    "            dataframe[column] /= dataframe[column].std()\n",
    "    return dataframe\n",
    "\n",
    "\n",
    "# Join train_x and eval_x to normalize on overall means and standard\n",
    "# deviations. Then separate them again.\n",
    "all_x = pd.concat([train_x, eval_x], keys=['train', 'eval'])\n",
    "all_x = standardize(all_x)\n",
    "train_x, eval_x = all_x.xs('train'), all_x.xs('eval')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aqKZk6NawDe-"
   },
   "source": [
    "Finally, examine some of your fully preprocessed training data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "6NZqE3Wlg1yg",
    "outputId": "6f782613-c20c-47e1-cbce-ac73ccdc1236"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>education_num</th>\n",
       "      <th>marital_status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>capital_gain</th>\n",
       "      <th>capital_loss</th>\n",
       "      <th>hours_per_week</th>\n",
       "      <th>native_country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.025997</td>\n",
       "      <td>6</td>\n",
       "      <td>1.136580</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.146933</td>\n",
       "      <td>-0.217132</td>\n",
       "      <td>-0.034039</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.828278</td>\n",
       "      <td>5</td>\n",
       "      <td>1.136580</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>-0.144792</td>\n",
       "      <td>-0.217132</td>\n",
       "      <td>-2.212964</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.046938</td>\n",
       "      <td>3</td>\n",
       "      <td>-0.419265</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>-0.144792</td>\n",
       "      <td>-0.217132</td>\n",
       "      <td>-0.034039</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.047082</td>\n",
       "      <td>3</td>\n",
       "      <td>-1.197188</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.144792</td>\n",
       "      <td>-0.217132</td>\n",
       "      <td>-0.034039</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.776285</td>\n",
       "      <td>3</td>\n",
       "      <td>1.136580</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.144792</td>\n",
       "      <td>-0.217132</td>\n",
       "      <td>-0.034039</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        age  workclass  education_num  marital_status  occupation  \\\n",
       "0  0.025997          6       1.136580               4           0   \n",
       "1  0.828278          5       1.136580               2           3   \n",
       "2 -0.046938          3      -0.419265               0           5   \n",
       "3  1.047082          3      -1.197188               2           5   \n",
       "4 -0.776285          3       1.136580               2           9   \n",
       "\n",
       "   relationship  race  capital_gain  capital_loss  hours_per_week  \\\n",
       "0             1     4      0.146933     -0.217132       -0.034039   \n",
       "1             0     4     -0.144792     -0.217132       -2.212964   \n",
       "2             1     4     -0.144792     -0.217132       -0.034039   \n",
       "3             0     2     -0.144792     -0.217132       -0.034039   \n",
       "4             5     2     -0.144792     -0.217132       -0.034039   \n",
       "\n",
       "   native_country  \n",
       "0              38  \n",
       "1              38  \n",
       "2              38  \n",
       "3              38  \n",
       "4               4  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verify dataset features\n",
    "# Note how only the numeric fields (not categorical) have been standardized\n",
    "train_x.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "V1bLJFrNxHXV"
   },
   "source": [
    "### Design and train the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iWkmN8ZmwSXU"
   },
   "source": [
    "#### Create training and validation datasets\n",
    "\n",
    "Create an input function to convert features and labels into a\n",
    "[`tf.data.Dataset`](https://www.tensorflow.org/guide/datasets) for training or evaluation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PIfE-YaXwRaU"
   },
   "outputs": [],
   "source": [
    "def input_fn(features, labels, shuffle, num_epochs, batch_size):\n",
    "    \"\"\"Generates an input function to be used for model training.\n",
    "  \n",
    "    Args:\n",
    "      features: numpy array of features used for training or inference\n",
    "      labels: numpy array of labels for each example\n",
    "      shuffle: boolean for whether to shuffle the data or not (set True for\n",
    "        training, False for evaluation)\n",
    "      num_epochs: number of epochs to provide the data for\n",
    "      batch_size: batch size for training\n",
    "  \n",
    "    Returns:\n",
    "      A tf.data.Dataset that can provide data to the Keras model for training or\n",
    "        evaluation\n",
    "    \"\"\"\n",
    "    if labels is None:\n",
    "        inputs = features\n",
    "    else:\n",
    "        inputs = (features, labels)\n",
    "    dataset = tf.data.Dataset.from_tensor_slices(inputs)\n",
    "\n",
    "    if shuffle:\n",
    "        dataset = dataset.shuffle(buffer_size=len(features))\n",
    "\n",
    "    # We call repeat after shuffling, rather than before, to prevent separate\n",
    "    # epochs from blending together.\n",
    "    dataset = dataset.repeat(num_epochs)\n",
    "    dataset = dataset.batch(batch_size)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "f8paLJ_rF84R"
   },
   "source": [
    "Next, create these training and evaluation datasets.Use the `NUM_EPOCHS`\n",
    "and `BATCH_SIZE` hyperparameters defined previously to define how the training\n",
    "dataset provides examples to the model during training. Set up the validation\n",
    "dataset to provide all its examples in one batch, for a single validation step\n",
    "at the end of each training epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_xdC2P5EF7rH"
   },
   "outputs": [],
   "source": [
    "# Pass a numpy array by using DataFrame.values\n",
    "training_dataset = input_fn(features=train_x.values, \n",
    "                    labels=train_y, \n",
    "                    shuffle=True, \n",
    "                    num_epochs=NUM_EPOCHS, \n",
    "                    batch_size=BATCH_SIZE)\n",
    "\n",
    "num_eval_examples = eval_x.shape[0]\n",
    "\n",
    "# Pass a numpy array by using DataFrame.values\n",
    "validation_dataset = input_fn(features=eval_x.values, \n",
    "                    labels=eval_y, \n",
    "                    shuffle=False, \n",
    "                    num_epochs=NUM_EPOCHS, \n",
    "                    batch_size=num_eval_examples)                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vZrDBXnxggOH"
   },
   "source": [
    "#### Design a Keras Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JY_A0yPyqU08"
   },
   "source": [
    "Design your neural network using the [Keras Sequential API](https://www.tensorflow.org/guide/keras#sequential_model).\n",
    "\n",
    "This deep neural network (DNN) has several hidden layers, and the last layer uses a sigmoid activation function to output a value between 0 and 1:\n",
    "\n",
    "* The input layer has 100 units using the ReLU activation function.\n",
    "* The hidden layer has 75 units using the ReLU activation function.\n",
    "* The hidden layer has 50 units using the ReLU activation function.\n",
    "* The hidden layer has 25 units using the ReLU activation function.\n",
    "* The output layer has 1 units using a sigmoid activation function.\n",
    "* The optimizer uses the binary cross-entropy loss function, which is appropriate for a binary classification problem like this one.\n",
    "\n",
    "Feel free to change these layers to try to improve the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "j_lsOhQAvzS-"
   },
   "outputs": [],
   "source": [
    "def create_keras_model(input_dim, learning_rate):\n",
    "    \"\"\"Creates Keras Model for Binary Classification.\n",
    "  \n",
    "    Args:\n",
    "      input_dim: How many features the input has\n",
    "      learning_rate: Learning rate for training\n",
    "  \n",
    "    Returns:\n",
    "      The compiled Keras model (still needs to be trained)\n",
    "    \"\"\"\n",
    "    Dense = tf.keras.layers.Dense\n",
    "    model = tf.keras.Sequential(\n",
    "      [\n",
    "          Dense(100, activation=tf.nn.relu, kernel_initializer='uniform',\n",
    "                  input_shape=(input_dim,)),\n",
    "          Dense(75, activation=tf.nn.relu),\n",
    "          Dense(50, activation=tf.nn.relu),\n",
    "          Dense(25, activation=tf.nn.relu),\n",
    "          Dense(1, activation=tf.nn.sigmoid)\n",
    "      ])\n",
    "    # Custom Optimizer:\n",
    "    # https://www.tensorflow.org/api_docs/python/tf/train/RMSPropOptimizer\n",
    "    optimizer = tf.keras.optimizers.RMSprop(\n",
    "        lr=learning_rate)\n",
    "\n",
    "    # Compile Keras model\n",
    "    model.compile(\n",
    "        loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mo5zTRNvBWv4"
   },
   "source": [
    "Next, create the Keras model object and examine its structure:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 391
    },
    "colab_type": "code",
    "id": "zdyOuwQcSjaY",
    "outputId": "4364f1a7-8c6a-492f-fc70-17e93a0a5a01"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0909 17:03:59.651063 4559709632 deprecation.py:506] From /Users/lingh/Git/ML/ml-paved-road/ml-paved-road-pipeline/venv/lib/python2.7/site-packages/tensorflow/python/keras/initializers.py:119: calling __init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "W0909 17:03:59.654956 4559709632 deprecation.py:506] From /Users/lingh/Git/ML/ml-paved-road/ml-paved-road-pipeline/venv/lib/python2.7/site-packages/tensorflow/python/ops/init_ops.py:1251: calling __init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "W0909 17:03:59.844829 4559709632 deprecation.py:323] From /Users/lingh/Git/ML/ml-paved-road/ml-paved-road-pipeline/venv/lib/python2.7/site-packages/tensorflow/python/ops/nn_impl.py:180: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features: 11\n",
      "Number of examples: 32561\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 100)               1200      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 75)                7575      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 50)                3800      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 25)                1275      \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 26        \n",
      "=================================================================\n",
      "Total params: 13,876\n",
      "Trainable params: 13,876\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "num_train_examples, input_dim = train_x.shape\n",
    "print('Number of features: {}'.format(input_dim))\n",
    "print('Number of examples: {}'.format(num_train_examples))\n",
    "\n",
    "keras_model = create_keras_model(\n",
    "    input_dim=input_dim,\n",
    "    learning_rate=LEARNING_RATE)\n",
    "\n",
    "# Take a detailed look inside the model\n",
    "keras_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4cqeQttaHbZt"
   },
   "source": [
    "#### Train and evaluate the model\n",
    "\n",
    "Define a learning rate decay to encourage model paramaters to make smaller\n",
    "changes as training goes on:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7eLa_Yoj2rhv"
   },
   "outputs": [],
   "source": [
    "# Setup Learning Rate decay.\n",
    "lr_decay_cb = tf.keras.callbacks.LearningRateScheduler(\n",
    "    lambda epoch: LEARNING_RATE + 0.02 * (0.5 ** (1 + epoch)),\n",
    "    verbose=True)\n",
    "\n",
    "# Setup TensorBoard callback.\n",
    "tensorboard_cb = tf.keras.callbacks.TensorBoard(\n",
    "      os.path.join(JOB_DIR, 'keras_tensorboard'),\n",
    "      histogram_freq=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1fExnH6bhOSC"
   },
   "source": [
    "Finally, train the model. Provide the appropriate `steps_per_epoch` for the\n",
    "model to train on the entire training dataset (with `BATCH_SIZE` examples per step) during each epoch. And instruct the model to calculate validation\n",
    "accuracy with one big validation batch at the end of each epoch.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1428
    },
    "colab_type": "code",
    "id": "MG4EvLiorMmZ",
    "outputId": "ca1a5e4a-026f-482b-9cf5-0a84819470c9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: LearningRateScheduler reducing learning rate to 0.02.\n",
      "Epoch 1/20\n",
      "\r",
      "  1/254 [..............................] - ETA: 45s - loss: 0.7574 - acc: 0.2812"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0909 17:05:38.269429 4559709632 callbacks.py:257] Method (on_train_batch_end) is slow compared to the batch update (4.172346). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "254/254 [==============================] - 11s 42ms/step - loss: 0.5236 - acc: 0.7892 - val_loss: 0.3548 - val_acc: 0.8350\n",
      "\n",
      "Epoch 00002: LearningRateScheduler reducing learning rate to 0.015.\n",
      "Epoch 2/20\n",
      "254/254 [==============================] - 2s 8ms/step - loss: 0.3569 - acc: 0.8341 - val_loss: 0.3450 - val_acc: 0.8350\n",
      "\n",
      "Epoch 00003: LearningRateScheduler reducing learning rate to 0.0125.\n",
      "Epoch 3/20\n",
      "254/254 [==============================] - 2s 8ms/step - loss: 0.3406 - acc: 0.8439 - val_loss: 0.3308 - val_acc: 0.8483\n",
      "\n",
      "Epoch 00004: LearningRateScheduler reducing learning rate to 0.01125.\n",
      "Epoch 4/20\n",
      "254/254 [==============================] - 2s 8ms/step - loss: 0.3322 - acc: 0.8441 - val_loss: 0.3244 - val_acc: 0.8476\n",
      "\n",
      "Epoch 00005: LearningRateScheduler reducing learning rate to 0.010625.\n",
      "Epoch 5/20\n",
      "254/254 [==============================] - 3s 10ms/step - loss: 0.3306 - acc: 0.8479 - val_loss: 0.3279 - val_acc: 0.8502\n",
      "\n",
      "Epoch 00006: LearningRateScheduler reducing learning rate to 0.0103125.\n",
      "Epoch 6/20\n",
      "254/254 [==============================] - 2s 8ms/step - loss: 0.3277 - acc: 0.8484 - val_loss: 0.3272 - val_acc: 0.8494\n",
      "\n",
      "Epoch 00007: LearningRateScheduler reducing learning rate to 0.01015625.\n",
      "Epoch 7/20\n",
      "254/254 [==============================] - 2s 8ms/step - loss: 0.3269 - acc: 0.8484 - val_loss: 0.3330 - val_acc: 0.8513\n",
      "\n",
      "Epoch 00008: LearningRateScheduler reducing learning rate to 0.010078125.\n",
      "Epoch 8/20\n",
      "254/254 [==============================] - 2s 8ms/step - loss: 0.3242 - acc: 0.8503 - val_loss: 0.3246 - val_acc: 0.8497\n",
      "\n",
      "Epoch 00009: LearningRateScheduler reducing learning rate to 0.0100390625.\n",
      "Epoch 9/20\n",
      "254/254 [==============================] - 2s 8ms/step - loss: 0.3235 - acc: 0.8494 - val_loss: 0.3220 - val_acc: 0.8507\n",
      "\n",
      "Epoch 00010: LearningRateScheduler reducing learning rate to 0.01001953125.\n",
      "Epoch 10/20\n",
      "254/254 [==============================] - 2s 8ms/step - loss: 0.3224 - acc: 0.8504 - val_loss: 0.3239 - val_acc: 0.8489\n",
      "\n",
      "Epoch 00011: LearningRateScheduler reducing learning rate to 0.010009765625.\n",
      "Epoch 11/20\n",
      "254/254 [==============================] - 2s 9ms/step - loss: 0.3227 - acc: 0.8507 - val_loss: 0.3295 - val_acc: 0.8511\n",
      "\n",
      "Epoch 00012: LearningRateScheduler reducing learning rate to 0.0100048828125.\n",
      "Epoch 12/20\n",
      "254/254 [==============================] - 2s 8ms/step - loss: 0.3218 - acc: 0.8502 - val_loss: 0.3215 - val_acc: 0.8502\n",
      "\n",
      "Epoch 00013: LearningRateScheduler reducing learning rate to 0.0100024414062.\n",
      "Epoch 13/20\n",
      "254/254 [==============================] - 2s 8ms/step - loss: 0.3216 - acc: 0.8514 - val_loss: 0.3346 - val_acc: 0.8519\n",
      "\n",
      "Epoch 00014: LearningRateScheduler reducing learning rate to 0.0100012207031.\n",
      "Epoch 14/20\n",
      "254/254 [==============================] - 2s 9ms/step - loss: 0.3225 - acc: 0.8509 - val_loss: 0.3322 - val_acc: 0.8527\n",
      "\n",
      "Epoch 00015: LearningRateScheduler reducing learning rate to 0.0100006103516.\n",
      "Epoch 15/20\n",
      "254/254 [==============================] - 2s 8ms/step - loss: 0.3224 - acc: 0.8517 - val_loss: 0.3306 - val_acc: 0.8507\n",
      "\n",
      "Epoch 00016: LearningRateScheduler reducing learning rate to 0.0100003051758.\n",
      "Epoch 16/20\n",
      "254/254 [==============================] - 2s 8ms/step - loss: 0.3212 - acc: 0.8521 - val_loss: 0.3183 - val_acc: 0.8525\n",
      "\n",
      "Epoch 00017: LearningRateScheduler reducing learning rate to 0.0100001525879.\n",
      "Epoch 17/20\n",
      "254/254 [==============================] - 2s 8ms/step - loss: 0.3194 - acc: 0.8529 - val_loss: 0.3198 - val_acc: 0.8488\n",
      "\n",
      "Epoch 00018: LearningRateScheduler reducing learning rate to 0.0100000762939.\n",
      "Epoch 18/20\n",
      "254/254 [==============================] - 2s 8ms/step - loss: 0.3197 - acc: 0.8505 - val_loss: 0.3376 - val_acc: 0.8494\n",
      "\n",
      "Epoch 00019: LearningRateScheduler reducing learning rate to 0.010000038147.\n",
      "Epoch 19/20\n",
      "254/254 [==============================] - 2s 8ms/step - loss: 0.3195 - acc: 0.8525 - val_loss: 0.3398 - val_acc: 0.8496\n",
      "\n",
      "Epoch 00020: LearningRateScheduler reducing learning rate to 0.0100000190735.\n",
      "Epoch 20/20\n",
      "254/254 [==============================] - 2s 9ms/step - loss: 0.3219 - acc: 0.8510 - val_loss: 0.3284 - val_acc: 0.8504\n"
     ]
    }
   ],
   "source": [
    "history = keras_model.fit(training_dataset, \n",
    "                          epochs=NUM_EPOCHS, \n",
    "                          steps_per_epoch=int(num_train_examples/BATCH_SIZE), \n",
    "                          validation_data=validation_dataset, \n",
    "                          validation_steps=1, \n",
    "                          callbacks=[lr_decay_cb, tensorboard_cb],\n",
    "                          verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fW7vTPm2pd2l"
   },
   "source": [
    "### Visualize training and export the trained model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "S9ZQcgetLHz9"
   },
   "source": [
    "#### Visualize training\n",
    "\n",
    "Import `matplotlib` to visualize how the model learned over the training period."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 153
    },
    "colab_type": "code",
    "id": "ISzcM0lxMOPX",
    "outputId": "6a3b5418-2c20-4a29-b3eb-1d0b52cf22c3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://artifactory.spotify.net/artifactory/api/pypi/pypi/simple/\r\n",
      "Requirement already satisfied: matplotlib in /Users/lingh/Git/ML/cloudml-samples/env/lib/python3.7/site-packages (3.1.1)\r\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/lingh/Git/ML/cloudml-samples/env/lib/python3.7/site-packages (from matplotlib) (0.10.0)\r\n",
      "Requirement already satisfied: numpy>=1.11 in /Users/lingh/Git/ML/cloudml-samples/env/lib/python3.7/site-packages (from matplotlib) (1.17.2)\r\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /Users/lingh/Git/ML/cloudml-samples/env/lib/python3.7/site-packages (from matplotlib) (2.4.2)\r\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /Users/lingh/Git/ML/cloudml-samples/env/lib/python3.7/site-packages (from matplotlib) (2.8.0)\r\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /Users/lingh/Git/ML/cloudml-samples/env/lib/python3.7/site-packages (from matplotlib) (1.1.0)\r\n",
      "Requirement already satisfied: six in /Users/lingh/Git/ML/cloudml-samples/env/lib/python3.7/site-packages (from cycler>=0.10->matplotlib) (1.12.0)\r\n",
      "Requirement already satisfied: setuptools in /Users/lingh/Git/ML/cloudml-samples/env/lib/python3.7/site-packages (from kiwisolver>=1.0.1->matplotlib) (41.2.0)\r\n"
     ]
    }
   ],
   "source": [
    "! pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'acc': [0.7891855,\n",
       "  0.8341228,\n",
       "  0.84393454,\n",
       "  0.8440883,\n",
       "  0.84793305,\n",
       "  0.8483637,\n",
       "  0.8483637,\n",
       "  0.8503322,\n",
       "  0.8494402,\n",
       "  0.85042447,\n",
       "  0.850732,\n",
       "  0.8501784,\n",
       "  0.8514087,\n",
       "  0.8508858,\n",
       "  0.85174704,\n",
       "  0.85205466,\n",
       "  0.8528543,\n",
       "  0.85051674,\n",
       "  0.852516,\n",
       "  0.8509781],\n",
       " 'loss': [0.5236134129011725,\n",
       "  0.35693925132197657,\n",
       "  0.34058777002368384,\n",
       "  0.33221788053202816,\n",
       "  0.3305738250336309,\n",
       "  0.32765423471298744,\n",
       "  0.3268505919167376,\n",
       "  0.32420060126565575,\n",
       "  0.32348356061563716,\n",
       "  0.32241853033229123,\n",
       "  0.32274373873012274,\n",
       "  0.32180390131520475,\n",
       "  0.3216130336321245,\n",
       "  0.3225158886529329,\n",
       "  0.3224135387952872,\n",
       "  0.3212459571952895,\n",
       "  0.31941202306371974,\n",
       "  0.31970904785113075,\n",
       "  0.31947893584807086,\n",
       "  0.32186690160608666],\n",
       " 'lr': [0.02,\n",
       "  0.015,\n",
       "  0.0125,\n",
       "  0.01125,\n",
       "  0.010625,\n",
       "  0.0103125,\n",
       "  0.01015625,\n",
       "  0.010078125,\n",
       "  0.010039062,\n",
       "  0.0100195315,\n",
       "  0.010009766,\n",
       "  0.010004883,\n",
       "  0.010002442,\n",
       "  0.010001221,\n",
       "  0.010000611,\n",
       "  0.010000305,\n",
       "  0.0100001525,\n",
       "  0.010000076,\n",
       "  0.010000038,\n",
       "  0.010000019],\n",
       " 'val_acc': [0.834992,\n",
       "  0.834992,\n",
       "  0.84832287,\n",
       "  0.8475857,\n",
       "  0.8502273,\n",
       "  0.84936726,\n",
       "  0.8513331,\n",
       "  0.84973586,\n",
       "  0.85065734,\n",
       "  0.8489372,\n",
       "  0.8511488,\n",
       "  0.8502273,\n",
       "  0.8519474,\n",
       "  0.852746,\n",
       "  0.85065734,\n",
       "  0.8525003,\n",
       "  0.84881437,\n",
       "  0.84942865,\n",
       "  0.84961295,\n",
       "  0.8504116],\n",
       " 'val_loss': [0.354765921831131,\n",
       "  0.34500235319137573,\n",
       "  0.3307952880859375,\n",
       "  0.32435721158981323,\n",
       "  0.32792744040489197,\n",
       "  0.3272358775138855,\n",
       "  0.3330192565917969,\n",
       "  0.3246324062347412,\n",
       "  0.3219662606716156,\n",
       "  0.32392263412475586,\n",
       "  0.32950571179389954,\n",
       "  0.32146120071411133,\n",
       "  0.33457401394844055,\n",
       "  0.33217406272888184,\n",
       "  0.3306160867214203,\n",
       "  0.3183327913284302,\n",
       "  0.31983715295791626,\n",
       "  0.3375718891620636,\n",
       "  0.3397940695285797,\n",
       "  0.32835426926612854]}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "e6tLXXT0SR-q"
   },
   "source": [
    "Plot the model's loss (binary cross-entropy) and accuracy, as measured at the\n",
    "end of each training epoch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 573
    },
    "colab_type": "code",
    "id": "yU1TzdlY0i-Y",
    "outputId": "f895d4cc-58bf-4ef2-d7d5-85586b0fcdb1"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'history' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-39-1830ad911983>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Visualize History for Loss.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Keras model loss'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'history' is not defined"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize History for Loss.\n",
    "plt.title('Keras model loss')\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['training', 'validation'], loc='upper right')\n",
    "plt.show()\n",
    "\n",
    "# Visualize History for Accuracy.\n",
    "plt.title('Keras model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.legend(['training', 'validation'], loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "D2L4TkncQb0F"
   },
   "source": [
    "Over time, loss decreases and accuracy increases. But do they converge to a\n",
    "stable level? Are there big differences between the training and validation\n",
    "metrics (a sign of overfitting)?\n",
    "\n",
    "Learn about [how to improve your machine learning\n",
    "model](https://developers.google.com/machine-learning/crash-course/). Then, feel\n",
    "free to adjust hyperparameters or the model architecture and train again."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gmTiOQObmTqd"
   },
   "source": [
    "#### Export the model for serving\n",
    "\n",
    "Use\n",
    "[tf.contrib.saved_model.save_keras_model](https://www.tensorflow.org/api_docs/python/tf/contrib/saved_model/save_keras_model) to export a TensorFlow SavedModel directory. This is the format that Cloud\n",
    "AI Platform requires when you [create a model version\n",
    "resource](https://cloud.google.com/ml-engine/docs/tensorflow/deploying-models#create_a_model_version).\n",
    "\n",
    "Since not all optimizers can be exported to the SavedModel format, you may see\n",
    "warnings during the export process. As long you successfully export a serving\n",
    "graph, AI Platform can used the SavedModel to serve predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 479
    },
    "colab_type": "code",
    "id": "d4BaDUJzmTW_",
    "outputId": "7934b523-2892-4c0e-a3ab-b305ae247e4f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0905 18:25:13.332287 4469126592 lazy_loader.py:50] \n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "W0905 18:25:13.419960 4469126592 deprecation.py:506] From /Users/lingh/.pyenv/versions/3.7.0/envs/my-virtual-env-3.7.0/lib/python3.7/site-packages/tensorflow/python/ops/init_ops.py:97: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "W0905 18:25:13.421025 4469126592 deprecation.py:506] From /Users/lingh/.pyenv/versions/3.7.0/envs/my-virtual-env-3.7.0/lib/python3.7/site-packages/tensorflow/python/ops/init_ops.py:97: calling GlorotUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "W0905 18:25:13.978749 4469126592 deprecation.py:323] From /Users/lingh/.pyenv/versions/3.7.0/envs/my-virtual-env-3.7.0/lib/python3.7/site-packages/tensorflow/python/saved_model/signature_def_utils_impl.py:253: build_tensor_info (from tensorflow.python.saved_model.utils_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.utils.build_tensor_info or tf.compat.v1.saved_model.build_tensor_info.\n",
      "W0905 18:25:13.979928 4469126592 export_utils.py:182] Export includes no default signature!\n",
      "W0905 18:25:14.260349 4469126592 export_utils.py:182] Export includes no default signature!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model exported to:  None\n"
     ]
    }
   ],
   "source": [
    "# Export the model to a local SavedModel directory \n",
    "export_path = tf.contrib.saved_model.save_keras_model(keras_model, 'keras_export')\n",
    "print(\"Model exported to: \", export_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dzGLPJbikj1t"
   },
   "source": [
    "You may export a SavedModel directory to your local filesystem or to Cloud\n",
    "Storage, as long as you have the necessary permissions. In your current\n",
    "environment, you granted access to Cloud Storage by authenticating your GCP account and setting the `GOOGLE_APPLICATION_CREDENTIALS` environment variable.\n",
    "AI Platform training jobs can also export directly to Cloud Storage, because\n",
    "AI Platform service accounts [have access to Cloud Storage buckets in their own\n",
    "project](https://cloud.google.com/ml-engine/docs/tensorflow/working-with-cloud-storage).\n",
    "\n",
    "Try exporting directly to Cloud Storage:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 258
    },
    "colab_type": "code",
    "id": "_eIF2qfykiFJ",
    "outputId": "d7ad6247-bd8b-4c67-b76d-71f5c3e91a0e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0909 17:12:16.988176 4559709632 lazy_loader.py:50] \n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "W0909 17:12:39.178097 4559709632 deprecation.py:506] From /Users/lingh/Git/ML/ml-paved-road/ml-paved-road-pipeline/venv/lib/python2.7/site-packages/tensorflow/python/ops/init_ops.py:97: calling __init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "W0909 17:12:39.180713 4559709632 deprecation.py:506] From /Users/lingh/Git/ML/ml-paved-road/ml-paved-road-pipeline/venv/lib/python2.7/site-packages/tensorflow/python/ops/init_ops.py:97: calling __init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "W0909 17:12:59.770643 4559709632 deprecation.py:323] From /Users/lingh/Git/ML/ml-paved-road/ml-paved-road-pipeline/venv/lib/python2.7/site-packages/tensorflow/python/saved_model/signature_def_utils_impl.py:253: build_tensor_info (from tensorflow.python.saved_model.utils_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.utils.build_tensor_info or tf.compat.v1.saved_model.build_tensor_info.\n",
      "W0909 17:12:59.772460 4559709632 export_utils.py:182] Export includes no default signature!\n",
      "W0909 17:13:03.385768 4559709632 export_utils.py:182] Export includes no default signature!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Model exported to: ', None)\n"
     ]
    }
   ],
   "source": [
    "# Export the model to a SavedModel directory in Cloud Storage\n",
    "export_path = tf.contrib.saved_model.save_keras_model(keras_model, JOB_DIR + '/keras_export')\n",
    "print(\"Model exported to: \", export_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "i805caqculq4"
   },
   "source": [
    "You can now deploy this model to AI Platform and serve predictions by\n",
    "following the steps from Part 2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "x27DXeUGzb-M"
   },
   "source": [
    "## Cleaning up\n",
    "\n",
    "To clean up all GCP resources used in this project, you can [delete the GCP\n",
    "project](https://cloud.google.com/resource-manager/docs/creating-managing-projects#shutting_down_projects) you used for the tutorial.\n",
    "\n",
    "Alternatively, you can clean up individual resources by running the following\n",
    "commands:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 442
    },
    "colab_type": "code",
    "id": "no210oWF68Uk",
    "outputId": "b03da82b-41ac-4243-e2b9-b9b4be12b0e8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleting version [v2]......done.                                               \n",
      "\u001b[1;31mERROR:\u001b[0m (gcloud.ai-platform.models.delete) FAILED_PRECONDITION: Field: name Error: A model with versions cannot be deleted. Please delete the versions first.\n",
      "- '@type': type.googleapis.com/google.rpc.BadRequest\n",
      "  fieldViolations:\n",
      "  - description: A model with versions cannot be deleted. Please delete the versions\n",
      "      first.\n",
      "    field: name\n",
      "Removing gs://lingh/keras-job-dir/#1568063125655802...\n",
      "Removing gs://lingh/keras-job-dir/keras_export/#1568063539846745...\n",
      "Removing gs://lingh/keras-job-dir/keras_export/assets/#1568063588828087...\n",
      "Removing gs://lingh/keras-job-dir/keras_export/assets/saved_model.json#1568063589786540...\n",
      "Removing gs://lingh/keras-job-dir/keras_export/saved_model.pb#1568063586253047...\n",
      "Removing gs://lingh/keras-job-dir/keras_export/variables/#1568063542692814...\n",
      "Removing gs://lingh/keras-job-dir/keras_export/variables/checkpoint#1568063579417051...\n",
      "Removing gs://lingh/keras-job-dir/keras_export/variables/variables.data-00000-of-00002#1568063574701832...\n",
      "Removing gs://lingh/keras-job-dir/keras_export/variables/variables.data-00001-of-00002#1568063573523550...\n",
      "Removing gs://lingh/keras-job-dir/keras_tensorboard/#1568063126868185...\n",
      "Removing gs://lingh/keras-job-dir/keras_tensorboard/events.out.tfevents.1568063126.Lings-MacBook-Pro.local#1568063180291737...\n",
      "Removing gs://lingh/keras-job-dir/keras_export/variables/variables.index#1568063575957676...\n",
      "Removing gs://lingh/keras-job-dir/keras_tensorboard/events.out.tfevents.1568063136.Lings-MacBook-Pro.local.profile-empty#1568063136861437...\n",
      "Removing gs://lingh/keras-job-dir/keras_tensorboard/plugins/profile/2019-09-09_17-05-29/#1568063135689188...\n",
      "Removing gs://lingh/keras-job-dir/keras_tensorboard/plugins/profile/2019-09-09_17-05-29/local.trace#1568063138144840...\n",
      "Removing gs://lingh/keras-job-dir/keras_tensorboard/plugins/#1568063133143028...\n",
      "Removing gs://lingh/keras-job-dir/keras_tensorboard/plugins/profile/#1568063134454094...\n",
      "/ [17/17 objects] 100% Done                                                     \n",
      "Operation completed over 17 objects.                                             \n"
     ]
    }
   ],
   "source": [
    "# Delete model version resource\n",
    "! gcloud ai-platform versions delete $MODEL_VERSION --quiet --model $MODEL_NAME \n",
    "\n",
    "# Delete model resource\n",
    "! gcloud ai-platform models delete $MODEL_NAME --quiet\n",
    "\n",
    "# Delete Cloud Storage objects that were created\n",
    "! gsutil -m rm -r $JOB_DIR\n",
    "\n",
    "# If the training job is still running, cancel it\n",
    "! gcloud ai-platform jobs cancel $JOB_NAME --quiet --verbosity critical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3F2g4OjbJ3gZ"
   },
   "source": [
    "If your Cloud Storage bucket doesn't contain any other objects and you would like to delete it, run `gsutil rm -r gs://$BUCKET_NAME`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "K0UXLWaBJnrY"
   },
   "source": [
    "## What's next?\n",
    "\n",
    "* View the [complete training\n",
    "code](https://github.com/GoogleCloudPlatform/cloudml-samples/tree/master/census/tf-keras) used in this guide, which structures the code to accept custom\n",
    "hyperparameters as command-line flags.\n",
    "* Read about [packaging\n",
    "code](https://cloud.google.com/ml-engine/docs/tensorflow/packaging-trainer) for an AI Platform training job.\n",
    "* Read about [deploying a\n",
    "model](https://cloud.google.com/ml-engine/docs/tensorflow/deploying-models) to serve predictions."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Getting started: Training and prediction with Keras in AI Platform",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
