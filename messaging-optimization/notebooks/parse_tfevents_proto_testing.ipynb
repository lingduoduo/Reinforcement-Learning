{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/slayton/paradox/user-protection/up-ml-models/user-protection-pipeline/tf-supervised/src/main/python\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<module 'trainers.schemas.eval_out_pb2' from 'trainers/schemas/eval_out_pb2.pyc'>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorboard as tb\n",
    "from google.protobuf import json_format\n",
    "\n",
    "# Work in python dir to import protobuf generated python module for eval out\n",
    "\n",
    "%cd '/Users/slayton/paradox/user-protection/up-ml-models/user-protection-pipeline/tf-supervised/src/main/python'\n",
    "from trainers.schemas import eval_out_pb2\n",
    "reload(eval_out_pb2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "event = \"/Users/slayton/Downloads/email_tf_training_Email.unsubscribed.Train.DefaultFeatures.LinearModel_2019-04-28_20190621T180108.458687-1179a67ed6df_eval_LinearModelMetrics_events.out.tfevents.1561140225.cmle-training-master-eb7659c54d-0-w5l9n\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[json_format.MessageToDict(x).keys() for x in tf.train.summary_iterator(event)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for summary in tf.train.summary_iterator(event):\n",
    "    for v in summary.summary.value:\n",
    "        print(v.tag)\n",
    "                                         \n",
    "                                         \n",
    "                                         \n",
    "                                         \n",
    "                                         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorboard.plugins.pr_curve import pr_curves_plugin\n",
    "from tensorboard.util import tensor_util\n",
    "from tensorboard.plugins.pr_curve import metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[e for e in [x for x in tf.train.summary_iterator(event)]]\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_thresholds(num_thresholds):\n",
    "    \"\"\"Computes a list of specific thresholds from the number of thresholds.\n",
    "    Args:\n",
    "      num_thresholds: The number of thresholds.\n",
    "    Returns:\n",
    "      A list of specific thresholds (floats).\n",
    "    \"\"\"\n",
    "    return [float(v) / num_thresholds for v in range(1, num_thresholds + 1)]\n",
    "    \n",
    "\n",
    "def _process_tensor_event(v, thresholds, tag):\n",
    "    \"\"\"Converts a TensorEvent into a dict that encapsulates information on it.\n",
    "    Args:\n",
    "      event: The TensorEvent to convert.\n",
    "      thresholds: An array of floats that ranges from 0 to 1 (in that\n",
    "        direction and inclusive of 0 and 1).\n",
    "    Returns:\n",
    "      A JSON-able dictionary of PR curve data for 1 step.\n",
    "    \"\"\"\n",
    "    pr = None\n",
    "    for m in v.summary.value:\n",
    "        if m.tag == tag:\n",
    "            tnsr = m.tensor\n",
    "            pr = _make_pr_entry(\n",
    "                                tensor_util.make_ndarray(tnsr),\n",
    "                                compute_thresholds(thresholds))\n",
    "        else:\n",
    "            pr = pr\n",
    "    \n",
    "    return pr\n",
    "\n",
    "\n",
    "def _make_pr_entry(data_array, thresholds):\n",
    "    \"\"\"Creates an entry for PR curve data. Each entry corresponds to 1 step.\n",
    "    Args:\n",
    "      step: The step.\n",
    "      wall_time: The wall time.\n",
    "      data_array: A numpy array of PR curve data stored in the summary format.\n",
    "      thresholds: An array of floating point thresholds.\n",
    "    Returns:\n",
    "      A PR curve entry.\n",
    "    \"\"\"\n",
    "    # Trim entries for which TP + FP = 0 (precision is undefined) at the tail of\n",
    "    # the data.\n",
    "    true_positives = [int(v) for v in data_array[metadata.TRUE_POSITIVES_INDEX]]\n",
    "    false_positives = [\n",
    "        int(v) for v in data_array[metadata.FALSE_POSITIVES_INDEX]]\n",
    "    tp_index = metadata.TRUE_POSITIVES_INDEX\n",
    "    fp_index = metadata.FALSE_POSITIVES_INDEX\n",
    "    positives = data_array[[tp_index, fp_index], :].astype(int).sum(axis=0)\n",
    "    end_index_inclusive = len(positives) - 1\n",
    "    while end_index_inclusive > 0 and positives[end_index_inclusive] == 0:\n",
    "      end_index_inclusive -= 1\n",
    "    end_index = end_index_inclusive + 1\n",
    "\n",
    "    return {\n",
    "        'precision': data_array[metadata.PRECISION_INDEX, :end_index].tolist(),\n",
    "        'recall': data_array[metadata.RECALL_INDEX, :end_index].tolist(),\n",
    "        'true_positives': true_positives[:end_index],\n",
    "        'false_positives': false_positives[:end_index],\n",
    "        'true_negatives':\n",
    "            [int(v) for v in\n",
    "             data_array[metadata.TRUE_NEGATIVES_INDEX][:end_index]],\n",
    "        'false_negatives':\n",
    "            [int(v) for v in\n",
    "             data_array[metadata.FALSE_NEGATIVES_INDEX][:end_index]],\n",
    "        'thresholds': thresholds[:end_index],\n",
    "    }\n",
    "\n",
    "def loop_events(event_file, num_thresholds):\n",
    "    output = []\n",
    "    for e in [x for x in tf.train.summary_iterator(event)]:\n",
    "        for v in e.summary.value:\n",
    "            if v.tensor.dtype != 0:\n",
    "                if v.tensor.tensor_shape != 0:\n",
    "                    if len(v.tensor.tensor_shape.dim) > 1:\n",
    "                        if v.tensor.tensor_shape.dim[0] != v.tensor.tensor_shape.dim[1]:\n",
    "                        # Curve Data\n",
    "                            print(_process_tensor_event(e, num_thresholds, v.tag))\n",
    "                            output.append(_process_tensor_event(e, num_thresholds, v.tag))\n",
    "            else:\n",
    "                print(v)\n",
    "                output.append({'tag':v.tag, 'value': v.simple_value, 'step': e.step,'wall_time': e.wall_time})\n",
    "    return output\n",
    "                    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[x for x in tf.train.summary_iterator(event)]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pr_curves = loop_events(event, 21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.DataFrame(pr_curves)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from luigi.contrib.gcs import GCSClient\n",
    "from os.path import join as pjoin\n",
    "from os.path import basename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to convert from tfEvent to Eval Out Proto\n",
    "def event_to_eval_out(event_path, thresholds):\n",
    "    # Initialize Output List\n",
    "    eval_out = []\n",
    "    # Parse Event File\n",
    "    events = tf.train.summary_iterator(event_path)\n",
    "    for e in events:\n",
    "        #print(e.summary)\n",
    "        if len(e.summary.value)>0:\n",
    "            eval_message = eval_out_pb2.Eval()\n",
    "            eval_metrics = eval_message.eval_metrics.add()\n",
    "            eval_metrics.global_step = e.step\n",
    "            for v in e.summary.value:\n",
    "                set_proto_value(v, eval_metrics, thresholds)\n",
    "            eval_out.append(eval_message)\n",
    "    return eval_out\n",
    "\n",
    "def set_proto_value(v, message, thresholds):\n",
    "    try:\n",
    "        # - Assumes name in eval_out proto == name in Model.py eval_config_metrics dict\n",
    "        # Strip /0 appended by pr_curve and or_curve plugin code that we don't own\n",
    "        getattr(message, ''.join([i for i in v.tag if (i != \"0\") and (i != \"/\")]))\n",
    "        \n",
    "        if \"/0\" in v.tag:\n",
    "            # special handling for pr and or curves\n",
    "            process_curves(v, message, thresholds)\n",
    "        else:\n",
    "            setattr(message, v.tag, v.simple_value)\n",
    "    except AttributeError:\n",
    "        pass\n",
    "\n",
    "            \n",
    "def precision(true_pos, false_pos):\n",
    "    return float(true_pos / (false_pos + true_pos))\n",
    "\n",
    "def recall(true_pos, false_neg):\n",
    "    return float(true_pos / (true_pos + false_neg))\n",
    "    \n",
    "# Ugly function for PR Curve Plugin Data\n",
    "def process_curves(v, eval_metrics, thresholds):\n",
    "    tnsr = v.tensor\n",
    "    pr = _make_pr_entry(\n",
    "                tensor_util.make_ndarray(tnsr),\n",
    "                compute_thresholds(thresholds))\n",
    "    for i, thresh in enumerate(pr['thresholds']):\n",
    "        if v.tag == 'or_curve/0':\n",
    "            or_curve = eval_metrics.or_curve.add()\n",
    "            or_curve.open_rate = float(pr['precision'][i])\n",
    "            or_curve.reach_rate = float(pr['recall'][i])\n",
    "        if v.tag == 'pr_curve/0':\n",
    "            or_curve = eval_metrics.pr_curve.add()\n",
    "            or_curve.precision = float(pr['precision'][i])\n",
    "            or_curve.recall = float(pr['recall'][i])            \n",
    "        or_curve.threshold = float(pr['thresholds'][i])\n",
    "        or_curve.true_positive = float(pr['true_positives'][i])\n",
    "        or_curve.true_negative = float(pr['true_negatives'][i])\n",
    "        or_curve.false_positive = float(pr['false_positives'][i])\n",
    "        or_curve.false_negative = float(pr['false_negatives'][i])\n",
    "\n",
    "def get_eval_file(jobdir, estimator_type):\n",
    "    # jobdir is the path set as the training job dir in the training job\n",
    "    eval_path = pjoin(jobdir, \"eval_{estimator_type}Metrics\".format(estimator_type = estimator_type))\n",
    "    client = GCSClient()\n",
    "    eval_files = client.listdir(eval_path)\n",
    "    #print(eval_path)\n",
    "    out_times = []\n",
    "    for f in eval_files:\n",
    "        if f.strip(\"/\") != eval_path:\n",
    "            # Get Write Times\n",
    "            # Assumes filename form `\"events\".\"out\".\"tfevents\".{Timestamp}...`\n",
    "            # Which is set by tensorflow and could break on update\n",
    "            out_times.append((f, int(basename(f).split(\".\")[3])))\n",
    "    # Get max file path\n",
    "    print(max(out_times,key=lambda item:item[1])[0])\n",
    "    return max(out_times,key=lambda item:item[1])[0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jobdir = \"gs://up_ml/email/tf/training/Email.unsubscribed.Train.DefaultFeatures.LinearModel/2019-04-28/20190621T180108.458687-1179a67ed6df\"\n",
    "estimator_type = \"LinearModel\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = event_to_eval_out(get_eval_file(jobdir, estimator_type), 21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_format.MessageToDict(metrics[0],preserving_proto_field_name=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's Write to BQ\n",
    "import json\n",
    "import sys\n",
    "\n",
    "from google.cloud import bigquery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project = 'users-protection'\n",
    "dataset_id = \"slayton_test\"  # the ID of your dataset\n",
    "table_id = \"test_bq_write\"  # the ID of your table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read Schema function\n",
    "def get_tbl_schema():\n",
    "    with open('trainers/schemas/eval_out/eval_table.schema') as f:\n",
    "        d = json.load(f)\n",
    "        return d\n",
    "        \n",
    "schema = get_tbl_schema()\n",
    "\n",
    "\n",
    "def _get_field_schema(field):\n",
    "    name = field['name']\n",
    "    field_type = field.get('type', 'STRING')\n",
    "    mode = field.get('mode', 'NULLABLE')\n",
    "    fields = field.get('fields', [])\n",
    "\n",
    "    if fields:\n",
    "        subschema = []\n",
    "        for f in fields:\n",
    "            fields_res = _get_field_schema(f)\n",
    "            subschema.append(fields_res)\n",
    "    else:\n",
    "        subschema = []\n",
    "\n",
    "    field_schema = bigquery.SchemaField(name=name, \n",
    "        field_type=field_type,\n",
    "        mode=mode,\n",
    "        fields=subschema\n",
    "    )\n",
    "    return field_schema\n",
    "\n",
    "\n",
    "def parse_bq_json_schema(schema_filename):\n",
    "    schema = []\n",
    "    with open(schema_filename, 'r') as infile:\n",
    "        jsonschema = json.load(infile)\n",
    "\n",
    "    for field in jsonschema:\n",
    "        schema.append(_get_field_schema(field))\n",
    "\n",
    "    return schema\n",
    "\n",
    "parse_bq_json_schema('trainers/schemas/eval_out/eval_table.schema')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_to_bq(project, dataset, table):\n",
    "    client = bigquery.Client(project=project)\n",
    "    table_ref = client.dataset(dataset_id).table(table_id)\n",
    "    try:\n",
    "        # Check if table exists if does, yay\n",
    "        table = client.get_table(table_ref)\n",
    "    except:\n",
    "        # Create Table\n",
    "        table = bigquery.Table(table_ref, schema=parse_bq_json_schema('trainers/schemas/eval_out/eval_table.schema'))\n",
    "        table = client.create_table(table)  # API request\n",
    "        assert table.table_id == table_id\n",
    "\n",
    "    client.insert_rows_json(table, [json_format.MessageToDict(metrics[0], preserving_proto_field_name=True)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from trainers.schemas import eval_out_pb2\n",
    "from trainers.schemas import train_task_params_pb2\n",
    "\n",
    "\n",
    "\n",
    "eval_out_message = eval_out_pb2.EvalOut()\n",
    "eval_message = eval_out_pb2.Eval()\n",
    "train_param_message = train_task_params_pb2.TrainInstance()\n",
    "eval_out_message.model.train_instance.CopyFrom(train_param_message)\n",
    "eval_out_message.eval.CopyFrom(eval_message)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/slayton/virtual_envs/tensorflow_env/lib/python2.7/site-packages/google/auth/_default.py:66: UserWarning: Your application has authenticated using end user credentials from Google Cloud SDK. We recommend that most server applications use service accounts instead. If your application continues to use end user credentials from Cloud SDK, you might receive a \"quota exceeded\" or \"API not enabled\" error. For more information about service accounts, see https://cloud.google.com/docs/authentication/\n",
      "  warnings.warn(_CLOUD_SDK_CREDENTIALS_WARNING)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://up_ml/email/tf/training/Email.unsubscribed.Train.DefaultFeatures.LinearModel/2019-04-28/20190621T180108.458687-1179a67ed6df/eval_LinearModelMetrics/events.out.tfevents.1561140225.cmle-training-master-eb7659c54d-0-w5l9n\n",
      "WARNING:tensorflow:From /Users/slayton/virtual_envs/tensorflow_env/lib/python2.7/site-packages/tensorflow/python/summary/summary_iterator.py:68: tf_record_iterator (from tensorflow.python.lib.io.tf_record) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use eager execution and: \n",
      "`tf.data.TFRecordDataset(path)`\n",
      "Ignoring Eval Type: loss\n",
      "Ignoring Eval Type: confusion_matrix\n",
      "Ignoring Eval Type: checkpoint_path\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "eval_metrics {\n",
       "  global_step: 10004\n",
       "  accuracy: 0.898695528507\n",
       "  auc: 0.537977695465\n",
       "  precision: 0.00110558315646\n",
       "  recall: 0.124352328479\n",
       "  f1_score: 0.00219167885371\n",
       "  true_pos: 24.0\n",
       "  or_curve {\n",
       "    threshold: 0.047619048506\n",
       "    true_positive: 193.0\n",
       "    true_negative: 0.0\n",
       "    false_positive: 215523.0\n",
       "    false_negative: 0.0\n",
       "    open_rate: 0.000894694880117\n",
       "    reach_rate: 1.0\n",
       "  }\n",
       "  or_curve {\n",
       "    threshold: 0.095238097012\n",
       "    true_positive: 193.0\n",
       "    true_negative: 1079.0\n",
       "    false_positive: 214444.0\n",
       "    false_negative: 0.0\n",
       "    open_rate: 0.000899192586076\n",
       "    reach_rate: 0.994998037815\n",
       "  }\n",
       "  or_curve {\n",
       "    threshold: 0.142857149243\n",
       "    true_positive: 187.0\n",
       "    true_negative: 7507.0\n",
       "    false_positive: 208016.0\n",
       "    false_negative: 6.0\n",
       "    open_rate: 0.000898161903024\n",
       "    reach_rate: 0.965171813965\n",
       "  }\n",
       "  or_curve {\n",
       "    threshold: 0.190476194024\n",
       "    true_positive: 176.0\n",
       "    true_negative: 31668.0\n",
       "    false_positive: 183855.0\n",
       "    false_negative: 17.0\n",
       "    open_rate: 0.000956360599957\n",
       "    reach_rate: 0.85311704874\n",
       "  }\n",
       "  or_curve {\n",
       "    threshold: 0.238095238805\n",
       "    true_positive: 157.0\n",
       "    true_negative: 44639.0\n",
       "    false_positive: 170884.0\n",
       "    false_negative: 36.0\n",
       "    open_rate: 0.00091790856095\n",
       "    reach_rate: 0.792899012566\n",
       "  }\n",
       "  or_curve {\n",
       "    threshold: 0.285714298487\n",
       "    true_positive: 136.0\n",
       "    true_negative: 69553.0\n",
       "    false_positive: 145970.0\n",
       "    false_negative: 57.0\n",
       "    open_rate: 0.000930831069127\n",
       "    reach_rate: 0.677307188511\n",
       "  }\n",
       "  or_curve {\n",
       "    threshold: 0.333333343267\n",
       "    true_positive: 109.0\n",
       "    true_negative: 101380.0\n",
       "    false_positive: 114143.0\n",
       "    false_negative: 84.0\n",
       "    open_rate: 0.000954031420406\n",
       "    reach_rate: 0.529640853405\n",
       "  }\n",
       "  or_curve {\n",
       "    threshold: 0.380952388048\n",
       "    true_positive: 86.0\n",
       "    true_negative: 135781.0\n",
       "    false_positive: 79742.0\n",
       "    false_negative: 107.0\n",
       "    open_rate: 0.00107731623575\n",
       "    reach_rate: 0.370060622692\n",
       "  }\n",
       "  or_curve {\n",
       "    threshold: 0.428571432829\n",
       "    true_positive: 54.0\n",
       "    true_negative: 168415.0\n",
       "    false_positive: 47108.0\n",
       "    false_negative: 139.0\n",
       "    open_rate: 0.00114498962648\n",
       "    reach_rate: 0.218630045652\n",
       "  }\n",
       "  or_curve {\n",
       "    threshold: 0.47619047761\n",
       "    true_positive: 30.0\n",
       "    true_negative: 186618.0\n",
       "    false_positive: 28905.0\n",
       "    false_negative: 163.0\n",
       "    open_rate: 0.00103680661414\n",
       "    reach_rate: 0.134134694934\n",
       "  }\n",
       "  or_curve {\n",
       "    threshold: 0.523809552193\n",
       "    true_positive: 24.0\n",
       "    true_negative: 193839.0\n",
       "    false_positive: 21684.0\n",
       "    false_negative: 169.0\n",
       "    open_rate: 0.00110558315646\n",
       "    reach_rate: 0.100632309914\n",
       "  }\n",
       "  or_curve {\n",
       "    threshold: 0.571428596973\n",
       "    true_positive: 23.0\n",
       "    true_negative: 200088.0\n",
       "    false_positive: 15435.0\n",
       "    false_negative: 170.0\n",
       "    open_rate: 0.00148790271487\n",
       "    reach_rate: 0.0716590359807\n",
       "  }\n",
       "  or_curve {\n",
       "    threshold: 0.619047641754\n",
       "    true_positive: 14.0\n",
       "    true_negative: 206160.0\n",
       "    false_positive: 9363.0\n",
       "    false_negative: 179.0\n",
       "    open_rate: 0.0014930148609\n",
       "    reach_rate: 0.0434691905975\n",
       "  }\n",
       "  or_curve {\n",
       "    threshold: 0.666666686535\n",
       "    true_positive: 9.0\n",
       "    true_negative: 210702.0\n",
       "    false_positive: 4821.0\n",
       "    false_negative: 184.0\n",
       "    open_rate: 0.00186335400213\n",
       "    reach_rate: 0.0223905500025\n",
       "  }\n",
       "  or_curve {\n",
       "    threshold: 0.714285731316\n",
       "    true_positive: 4.0\n",
       "    true_negative: 213148.0\n",
       "    false_positive: 2375.0\n",
       "    false_negative: 189.0\n",
       "    open_rate: 0.00168137869332\n",
       "    reach_rate: 0.0110283894464\n",
       "  }\n",
       "  or_curve {\n",
       "    threshold: 0.761904776096\n",
       "    true_positive: 3.0\n",
       "    true_negative: 214484.0\n",
       "    false_positive: 1039.0\n",
       "    false_negative: 190.0\n",
       "    open_rate: 0.0028790787328\n",
       "    reach_rate: 0.00483042513952\n",
       "  }\n",
       "  or_curve {\n",
       "    threshold: 0.809523820877\n",
       "    true_positive: 1.0\n",
       "    true_negative: 215098.0\n",
       "    false_positive: 425.0\n",
       "    false_negative: 192.0\n",
       "    open_rate: 0.00234741787426\n",
       "    reach_rate: 0.00197481876239\n",
       "  }\n",
       "  or_curve {\n",
       "    threshold: 0.857142865658\n",
       "    true_positive: 0.0\n",
       "    true_negative: 215387.0\n",
       "    false_positive: 136.0\n",
       "    false_negative: 193.0\n",
       "    open_rate: 0.0\n",
       "    reach_rate: 0.000630458584055\n",
       "  }\n",
       "  or_curve {\n",
       "    threshold: 0.904761910439\n",
       "    true_positive: 0.0\n",
       "    true_negative: 215502.0\n",
       "    false_positive: 21.0\n",
       "    false_negative: 193.0\n",
       "    open_rate: 0.0\n",
       "    reach_rate: 9.7350217402e-05\n",
       "  }\n",
       "  or_curve {\n",
       "    threshold: 0.952380955219\n",
       "    true_positive: 0.0\n",
       "    true_negative: 215522.0\n",
       "    false_positive: 1.0\n",
       "    false_negative: 193.0\n",
       "    open_rate: 0.0\n",
       "    reach_rate: 4.63572496301e-06\n",
       "  }\n",
       "  pr_curve {\n",
       "    threshold: 0.047619048506\n",
       "    true_positive: 193.0\n",
       "    true_negative: 0.0\n",
       "    false_positive: 215523.0\n",
       "    false_negative: 0.0\n",
       "    precision: 0.000894694880117\n",
       "    recall: 1.0\n",
       "  }\n",
       "  pr_curve {\n",
       "    threshold: 0.095238097012\n",
       "    true_positive: 193.0\n",
       "    true_negative: 1079.0\n",
       "    false_positive: 214444.0\n",
       "    false_negative: 0.0\n",
       "    precision: 0.000899192586076\n",
       "    recall: 1.0\n",
       "  }\n",
       "  pr_curve {\n",
       "    threshold: 0.142857149243\n",
       "    true_positive: 187.0\n",
       "    true_negative: 7507.0\n",
       "    false_positive: 208016.0\n",
       "    false_negative: 6.0\n",
       "    precision: 0.000898161903024\n",
       "    recall: 0.96891194582\n",
       "  }\n",
       "  pr_curve {\n",
       "    threshold: 0.190476194024\n",
       "    true_positive: 176.0\n",
       "    true_negative: 31668.0\n",
       "    false_positive: 183855.0\n",
       "    false_negative: 17.0\n",
       "    precision: 0.000956360599957\n",
       "    recall: 0.911917090416\n",
       "  }\n",
       "  pr_curve {\n",
       "    threshold: 0.238095238805\n",
       "    true_positive: 157.0\n",
       "    true_negative: 44639.0\n",
       "    false_positive: 170884.0\n",
       "    false_negative: 36.0\n",
       "    precision: 0.00091790856095\n",
       "    recall: 0.813471496105\n",
       "  }\n",
       "  pr_curve {\n",
       "    threshold: 0.285714298487\n",
       "    true_positive: 136.0\n",
       "    true_negative: 69553.0\n",
       "    false_positive: 145970.0\n",
       "    false_negative: 57.0\n",
       "    precision: 0.000930831069127\n",
       "    recall: 0.704663217068\n",
       "  }\n",
       "  pr_curve {\n",
       "    threshold: 0.333333343267\n",
       "    true_positive: 109.0\n",
       "    true_negative: 101380.0\n",
       "    false_positive: 114143.0\n",
       "    false_negative: 84.0\n",
       "    precision: 0.000954031420406\n",
       "    recall: 0.564766824245\n",
       "  }\n",
       "  pr_curve {\n",
       "    threshold: 0.380952388048\n",
       "    true_positive: 86.0\n",
       "    true_negative: 135781.0\n",
       "    false_positive: 79742.0\n",
       "    false_negative: 107.0\n",
       "    precision: 0.00107731623575\n",
       "    recall: 0.445595860481\n",
       "  }\n",
       "  pr_curve {\n",
       "    threshold: 0.428571432829\n",
       "    true_positive: 54.0\n",
       "    true_negative: 168415.0\n",
       "    false_positive: 47108.0\n",
       "    false_negative: 139.0\n",
       "    precision: 0.00114498962648\n",
       "    recall: 0.279792755842\n",
       "  }\n",
       "  pr_curve {\n",
       "    threshold: 0.47619047761\n",
       "    true_positive: 30.0\n",
       "    true_negative: 186618.0\n",
       "    false_positive: 28905.0\n",
       "    false_negative: 163.0\n",
       "    precision: 0.00103680661414\n",
       "    recall: 0.155440419912\n",
       "  }\n",
       "  pr_curve {\n",
       "    threshold: 0.523809552193\n",
       "    true_positive: 24.0\n",
       "    true_negative: 193839.0\n",
       "    false_positive: 21684.0\n",
       "    false_negative: 169.0\n",
       "    precision: 0.00110558315646\n",
       "    recall: 0.124352328479\n",
       "  }\n",
       "  pr_curve {\n",
       "    threshold: 0.571428596973\n",
       "    true_positive: 23.0\n",
       "    true_negative: 200088.0\n",
       "    false_positive: 15435.0\n",
       "    false_negative: 170.0\n",
       "    precision: 0.00148790271487\n",
       "    recall: 0.119170986116\n",
       "  }\n",
       "  pr_curve {\n",
       "    threshold: 0.619047641754\n",
       "    true_positive: 14.0\n",
       "    true_negative: 206160.0\n",
       "    false_positive: 9363.0\n",
       "    false_negative: 179.0\n",
       "    precision: 0.0014930148609\n",
       "    recall: 0.0725388601422\n",
       "  }\n",
       "  pr_curve {\n",
       "    threshold: 0.666666686535\n",
       "    true_positive: 9.0\n",
       "    true_negative: 210702.0\n",
       "    false_positive: 4821.0\n",
       "    false_negative: 184.0\n",
       "    precision: 0.00186335400213\n",
       "    recall: 0.0466321259737\n",
       "  }\n",
       "  pr_curve {\n",
       "    threshold: 0.714285731316\n",
       "    true_positive: 4.0\n",
       "    true_negative: 213148.0\n",
       "    false_positive: 2375.0\n",
       "    false_negative: 189.0\n",
       "    precision: 0.00168137869332\n",
       "    recall: 0.0207253880799\n",
       "  }\n",
       "  pr_curve {\n",
       "    threshold: 0.761904776096\n",
       "    true_positive: 3.0\n",
       "    true_negative: 214484.0\n",
       "    false_positive: 1039.0\n",
       "    false_negative: 190.0\n",
       "    precision: 0.0028790787328\n",
       "    recall: 0.0155440410599\n",
       "  }\n",
       "  pr_curve {\n",
       "    threshold: 0.809523820877\n",
       "    true_positive: 1.0\n",
       "    true_negative: 215098.0\n",
       "    false_positive: 425.0\n",
       "    false_negative: 192.0\n",
       "    precision: 0.00234741787426\n",
       "    recall: 0.00518134701997\n",
       "  }\n",
       "  pr_curve {\n",
       "    threshold: 0.857142865658\n",
       "    true_positive: 0.0\n",
       "    true_negative: 215387.0\n",
       "    false_positive: 136.0\n",
       "    false_negative: 193.0\n",
       "    precision: 0.0\n",
       "    recall: 0.0\n",
       "  }\n",
       "  pr_curve {\n",
       "    threshold: 0.904761910439\n",
       "    true_positive: 0.0\n",
       "    true_negative: 215502.0\n",
       "    false_positive: 21.0\n",
       "    false_negative: 193.0\n",
       "    precision: 0.0\n",
       "    recall: 0.0\n",
       "  }\n",
       "  pr_curve {\n",
       "    threshold: 0.952380955219\n",
       "    true_positive: 0.0\n",
       "    true_negative: 215522.0\n",
       "    false_positive: 1.0\n",
       "    false_negative: 193.0\n",
       "    precision: 0.0\n",
       "    recall: 0.0\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jobdir = \"gs://up_ml/email/tf/training/Email.unsubscribed.Train.DefaultFeatures.LinearModel/2019-04-28/20190621T180108.458687-1179a67ed6df\"\n",
    "estimator_type = \"LinearModel\"\n",
    "\n",
    "from tasks.eval_out_write import BQEval, BQWriter\n",
    "eval_out = BQEval(jobdir, 21, estimator_type).run()[0]\n",
    "\n",
    "eval_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "writing rows\n"
     ]
    }
   ],
   "source": [
    "BQWriter(data=eval_out, project=\"users-protection\",dataset=\"slayton_test2\", table=\"eval_out_test\", table_schema=\"trainers/schemas/eval_out/eval_out_table.schema\").write_to_bq()\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
